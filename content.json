{"meta":{"title":"King哥","subtitle":"To know everything, no words don't talk, listening to people is enough to cause alarm（知无不言，言无不尽 言者无罪，闻者足戒）","description":"To know everything, no words don't talk, listening to people is enough to cause alarm（知无不言，言无不尽 言者无罪，闻者足戒）","author":"Jeremy Kinge","url":"http://kingge.top"},"pages":[{"title":"分类","date":"2017-08-14T08:51:40.000Z","updated":"2017-08-14T08:52:32.618Z","comments":true,"path":"categories/index.html","permalink":"http://kingge.top/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2014-12-22T04:39:04.000Z","updated":"2017-08-14T09:29:28.873Z","comments":true,"path":"tags/index.html","permalink":"http://kingge.top/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2017-08-14T09:28:56.000Z","updated":"2017-08-14T09:28:56.524Z","comments":true,"path":"about/index.html","permalink":"http://kingge.top/about/index.html","excerpt":"","text":""},{"title":"picture","date":"2017-08-14T09:29:06.000Z","updated":"2017-08-14T09:29:07.017Z","comments":true,"path":"picture/index.html","permalink":"http://kingge.top/picture/index.html","excerpt":"","text":""}],"posts":[{"title":"max-allowed-packet的问题","slug":"max-allowed-packet的问题","date":"2017-08-17T02:37:15.000Z","updated":"2017-08-17T09:44:39.015Z","comments":true,"path":"2017/08/17/max-allowed-packet的问题/","link":"","permalink":"http://kingge.top/2017/08/17/max-allowed-packet的问题/","excerpt":"","text":"前言 近期，因启动项目有个批量插入的sql结果太大，超过了mysql自带的缓存，报了这个错误 修改： 定位到mysql的安装目录下面，然后修改my.ini 的max_allowed_packet = 8M默认是1M","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://kingge.top/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://kingge.top/tags/Mysql/"},{"name":"异常","slug":"异常","permalink":"http://kingge.top/tags/异常/"},{"name":"sql异常","slug":"sql异常","permalink":"http://kingge.top/tags/sql异常/"}]},{"title":"博客迁移","slug":"博客迁移","date":"2017-08-14T02:26:07.157Z","updated":"2017-08-16T02:35:53.838Z","comments":true,"path":"2017/08/14/博客迁移/","link":"","permalink":"http://kingge.top/2017/08/14/博客迁移/","excerpt":"","text":"今天周一，天气炎热，调开空调。噼里啪啦的敲完今天的工作，因为今天本人决定再次迁移自己的PersonalBlog。个人一共换过很多个博客，前期使用过网易博客，后来访问量上不去(网易博客他并不是一个IT社区)，后来换到了博客园，感觉还行，但是好景不长，感觉本人有处女座的完美主义，很纠结，总感觉这个博客园UI设计不行。 最后又换到了CSDN，今天又临时决定迁移到了本人的服务器上面，自由管理。 我的性格知道的人应该知道，我是知无不言言无不尽，只要我会的有所感悟的都会分享出来。以后每天心情一更，工作方面一周一更。 最后：人生需要面对,搞笑我是认真的。","categories":[{"name":"心情","slug":"心情","permalink":"http://kingge.top/categories/心情/"}],"tags":[]},{"title":"Hessian 多系统访问","slug":"Hessian 多系统访问","date":"2017-08-14T01:31:13.972Z","updated":"2017-08-17T03:20:39.201Z","comments":true,"path":"2017/08/14/Hessian 多系统访问/","link":"","permalink":"http://kingge.top/2017/08/14/Hessian 多系统访问/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"实现多数据量的导入数据库","slug":"实现多数据量的导入数据库","date":"2017-08-01T06:37:15.000Z","updated":"2017-08-17T08:21:15.695Z","comments":true,"path":"2017/08/01/实现多数据量的导入数据库/","link":"","permalink":"http://kingge.top/2017/08/01/实现多数据量的导入数据库/","excerpt":"","text":"引言 在做一个项目的时候，涉及到需要从一个表格中获取百万条数据然后插入到数据库中，最后采用JDBC的executeBantch方法实现这个功能。 采取的策略 尽量关闭字段索引（因为再插入数据的时候还是需要维护索引的，在创建索引和维护索引 会耗费时间,随着数据量的增加而增加，可以在插入数据后再去为字段创建索引） 虽然索引可以提高查询速度但是，插入数据的时候会导致索性的更新。索性越多，插入会越慢。可以看文档描述:Although it can be tempting to create an indexes for every possible column used in a query, unnecessary indexes waste space and waste time for MySQL to determine which indexes to use. Indexes also add to the cost of inserts, updates, and deletes because each index must be updated. You must find the right balance to achieve fast queries using the optimal set of indexes. 分批次提交数据 在分布式条件下，还可以考虑在不同的数据库结点提交，有底层的消息系统完成数据扩展 过滤预处理数据 预处理数据的场景：为了避免插入的数据（假设ListA）跟数据库中某些数据重复，那么我们会把要插入的数据去数据库中查询是否已经存在，获得返回的已经存在数据（ListB）。然后在插入数据的时候判断当前数据是否在ListB中，那么当前数据不能够插入数据库。过滤出来，最后得到一个可以插入数据库的ListC 代码关键代码/*数据分析结束*/ /*往数据库写数据开始*/ Connection conn=null; PreparedStatement idsUserAdd=null; try &#123; Class.forName(\"com.mysql.jdbc.Driver\") ; conn = DriverManager.getConnection(ConfigTool.getProperty(\"jdbc.url\").toString() , ConfigTool.getProperty(\"jdbc.username\").toString() , ConfigTool.getProperty(\"jdbc.password\").toString()); conn.setAutoCommit(false); //构造预处理statement idsUserAdd = conn.prepareStatement(\"INSERT INTO dc_matedata (\"+ \" ID,`NAME`, DATATYPE,`CODE`,TYPE_ID,`LENGTH`, \"+ \" DATANAME, VALUEAREA,`RESTRICT`, REMARK,MD_DATE)\"+ \" values(?,?,?,?,?,?,?,?,?,?,now())\"); //最大列表的数目当做循环次数 int xhcs=addMetadataList.size();//addMetadataList需要插入的数据 for(int i=0;i&lt;xhcs;i++)&#123; idsUserAdd.setString(1,addMetadataList.get(i).get(\"id\").toString()); idsUserAdd.setString(2,addMetadataList.get(i).get(\"name\").toString()); idsUserAdd.setString(3,addMetadataList.get(i).get(\"dataType\").toString()); idsUserAdd.setString(4,addMetadataList.get(i).get(\"code\").toString()); idsUserAdd.setString(5,addMetadataList.get(i).get(\"typeId\").toString()); idsUserAdd.setString(6,addMetadataList.get(i).get(\"dataLength\").toString()); idsUserAdd.setString(7,addMetadataList.get(i).get(\"dataName\").toString()); idsUserAdd.setString(8,addMetadataList.get(i).get(\"valueArea\").toString()); idsUserAdd.setString(9,addMetadataList.get(i).get(\"dataRestrict\").toString()); idsUserAdd.setString(10,addMetadataList.get(i).get(\"dataRemark\").toString()); idsUserAdd.addBatch(); //每10000次提交一次 if(i%10000==0||i==xhcs-1)&#123;//可以设置不同的大小；如50，100，500，1000等等 i==xhcs-1（最后一次） idsUserAdd.executeBatch(); conn.commit(); idsUserAdd.clearBatch(); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); throw e; &#125;finally &#123; try &#123; if(idsUserAdd!=null) idsUserAdd.close(); if(conn!=null) conn.close(); &#125;catch(Exception e)&#123; e.printStackTrace(); throw e; &#125; &#125; /*往数据库写数据结束*/ 完整代码/** * 校验需要导入的元数据信息，封装错误信息并批量插入数据库 */ @Override public List&lt;Map&lt;String, Object&gt;&gt; saveDCMetadataBatch(List&lt;Map&lt;String, Object&gt;&gt; list, boolean valid, boolean addError) throws Exception&#123; List&lt;Map&lt;String,Object&gt;&gt; errorList=new ArrayList&lt;Map&lt;String,Object&gt;&gt;();//获得不能够添加成功的数据 Map&lt;String,Object&gt; map=new HashMap&lt;String,Object&gt;();//查询条件 Map&lt;String,String&gt; codeMap=new HashMap&lt;String,String&gt;();//每个分类对应的元数据的编号最大值 Map&lt;String,Object&gt; metaName=new HashMap&lt;String,Object&gt;();//查询数据库中是否存在相同的数据（这里校验的是：元数据的中文简称） Map&lt;String,Object&gt; metaDataName=new HashMap&lt;String,Object&gt;();//查询数据库中是否存在相同的数据（这里校验的是：元数据的数据项名称） map.put(\"metaName\",list);//需要查询的元数据中文名称 map.put(\"metaDataTypeId\",list);//导入的元数据的编号 List&lt;Map&lt;String, Object&gt;&gt; metaExistList = dCMatedataDao.getDCMetadata(map);//根据元数据名称查询当前分类下是否存在同样元数据 map.put(\"metaName\",null);//置空 map.put(\"metaDataName\",list); List&lt;Map&lt;String, Object&gt;&gt; metaExistListTwo = dCMatedataDao.getDCMetadata(map);//根据元数据数据项名称查询存在的元数据 //保存重复的信息 for(int i=0;i&lt;metaExistList.size();i++) metaName.put(metaExistList.get(i).get(\"name\").toString()+metaExistList.get(i).get(\"code\").toString() ,metaExistList.get(i).get(\"id\"));//添加父类的编号为后缀-唯一性保证 for(int i=0;i&lt;metaExistListTwo.size();i++) metaDataName.put(metaExistListTwo.get(i).get(\"dataname\").toString()+metaExistListTwo.get(i).get(\"code\").toString(), metaExistListTwo.get(i).get(\"id\")); /*整理出来的数据-开始*/ List&lt;Map&lt;String,Object&gt;&gt; addMetadataList=new ArrayList&lt;Map&lt;String,Object&gt;&gt;(); /*整理出来的数据-结束*/ for (int i = 0; i &lt; list.size(); i++) &#123; Map&lt;String, Object&gt; MetadataObj = list.get(i); try &#123; String metadatId = StringUtil.getUUID();//元数据id /*校验开始*/ if (valid)&#123; if(validUser(MetadataObj,\"name\",addError)!=null)&#123;//验证输入的数据是否符合格式和必填。 errorList.add(MetadataObj); continue; &#125; &#125; /*前端校验结束*/ /*校验是否存在同名的元数据*/ String dataCodeCheck = MetadataObj.get(\"dataCode\").toString().trim(); //元数据父分类编号 String name = MetadataObj.get(\"name\").toString().trim();//元数据中文简称 if (metaName.containsKey(name+dataCodeCheck)) &#123; if (addError) &#123; MetadataObj.put(\"errInfo\", \"中文简称已存在\"); &#125; errorList.add(MetadataObj); continue; &#125; /*校验是否存在相同数据项的元数据*/ String dataName = MetadataObj.get(\"dataName\").toString().trim();//数据项名 if (metaDataName.containsKey(dataName+dataCodeCheck)) &#123; if (addError) &#123; MetadataObj.put(\"errInfo\", \"数据项名已存在\"); &#125; errorList.add(MetadataObj); continue; &#125; String dataCode = MetadataObj.get(\"dataCode\").toString().trim(); //元数据父分类编号 List&lt;Map&lt;String, Object&gt;&gt; footCount = dCMatedataDao.getFootCount(dataCode); if( footCount.size() &gt; 0)&#123; if (addError) &#123; MetadataObj.put(\"errInfo\", \"分类编码不是最后一级分类\"); &#125; errorList.add(MetadataObj); continue; &#125; Map&lt;String, Object&gt; typeByCode = dCMatedataDao.getMetadataTypeByCode(dataCode); if( typeByCode == null || typeByCode.size() &lt; 1)&#123; if (addError) &#123; MetadataObj.put(\"errInfo\", \"分类编码不存在，请先添加分类\"); &#125; errorList.add(MetadataObj); continue; &#125; //校验是在添加的List中是否存在相同的数据项名或者中文简称 //校验导入文件中是否存在一样的中文简称或者数据项名 boolean nameExist = false; boolean dataNameExist = false; for (int j = 0; j &lt; addMetadataList.size(); j++)&#123; Map&lt;String, Object&gt; map2 = addMetadataList.get(j); String typeId = map2.get(\"typeId\").toString(); String nameE = map2.get(\"name\").toString(); String dataNameE = map2.get(\"dataName\").toString(); if( typeId.equals(typeByCode.get(\"id\").toString()) &amp;&amp; nameE.equals(name))&#123; nameExist=true; break; &#125; if( typeId.equals(typeByCode.get(\"id\").toString()) &amp;&amp; dataNameE.equals(dataName))&#123; dataNameExist=true; break; &#125; &#125; if( nameExist )&#123; if (addError) &#123; MetadataObj.put(\"errInfo\", \"中文简称已存在\"); &#125; errorList.add(MetadataObj); continue; &#125; if( dataNameExist )&#123; if (addError) &#123; MetadataObj.put(\"errInfo\", \"数据项名已存在\"); &#125; errorList.add(MetadataObj); continue; &#125; //进入这里说明校验结束，开始填充添加的数据 String type_id = typeByCode.get(\"id\").toString();//元数据所属分类id String dataType = MetadataObj.get(\"dataType\").toString().trim(); //元数据类型 String dataLength = MetadataObj.get(\"dataLength\").toString().trim(); //元数据长度 String code = \"\"; //// if( codeMap.get(dataCode) == null||StringUtil.isEmpty(codeMap.get(dataCode)) )&#123;//表示当前分类不存在已经添加的元数据--因为编码map中不存在对应分类的最大编码 Map maxCodeByPid = this.selectMetadataMaxCode(type_id); if( maxCodeByPid == null )&#123;//表示当前分类下不存在任何子分类 code = StringUtil.getCode(\"0\", dataCode);//则从01开始编号 codeMap.put(dataCode, \"01\");//保存当前分类下元数据编号最大值 &#125;else&#123; String object = (String) maxCodeByPid.get(\"codeNum\");//当前分类节点下的元数据的编号最大值。 int pSituation = object.indexOf(dataCode); int pLength = pSituation+dataCode.length() ; String substring = object.substring(pLength); //截取出最大编号值得最大值 code = StringUtil.getCode(substring, dataCode); int temp = Integer.parseInt(substring);//保存当前分类下元数据编号最大值 temp+=1; codeMap.put(dataCode, temp+\"\"); &#125; &#125;else&#123; String maxCode = codeMap.get(dataCode); code = StringUtil.getCode(maxCode, dataCode); //保存当前分类下元数据编号最大值 int temp = Integer.parseInt(maxCode); temp+=1; codeMap.put(dataCode, temp+\"\"); &#125; /// Map&lt;String, Object&gt; metadatList = new LinkedHashMap&lt;String, Object&gt;(); metadatList.put(\"id\", metadatId); metadatList.put(\"name\",name); metadatList.put(\"dataType\",dataType); metadatList.put(\"code\",code); metadatList.put(\"typeId\",type_id); metadatList.put(\"dataLength\",dataLength); metadatList.put(\"dataName\",dataName); metadatList.put(\"valueArea\", MetadataObj.get(\"valueArea\")==null?\"\":MetadataObj.get(\"valueArea\") ); metadatList.put(\"dataRestrict\",MetadataObj.get(\"dataRestrict\")==null?\"\":MetadataObj.get(\"dataRestrict\")); metadatList.put(\"dataRemark\",MetadataObj.get(\"dataRemark\")==null?\"\":MetadataObj.get(\"dataRemark\")); metadatList.put(\"mdDate\",new Date()); addMetadataList.add(metadatList); &#125; catch (Exception e)&#123; if(addError) &#123; MetadataObj.put(\"errInfo\", e.getMessage()); &#125; errorList.add(MetadataObj); &#125; &#125; /*数据分析结束*/ /*往数据库写数据开始*/ Connection conn=null; PreparedStatement idsUserAdd=null; try &#123; Class.forName(\"com.mysql.jdbc.Driver\") ; conn = DriverManager.getConnection(ConfigTool.getProperty(\"jdbc.url\").toString() , ConfigTool.getProperty(\"jdbc.username\").toString() , ConfigTool.getProperty(\"jdbc.password\").toString()); conn.setAutoCommit(false); //构造预处理statement idsUserAdd = conn.prepareStatement(\"INSERT INTO dc_matedata (\"+ \" ID,`NAME`, DATATYPE,`CODE`,TYPE_ID,`LENGTH`, \"+ \" DATANAME, VALUEAREA,`RESTRICT`, REMARK,MD_DATE)\"+ \" values(?,?,?,?,?,?,?,?,?,?,now())\"); //最大列表的数目当做循环次数 int xhcs=addMetadataList.size(); for(int i=0;i&lt;xhcs;i++)&#123; idsUserAdd.setString(1,addMetadataList.get(i).get(\"id\").toString()); idsUserAdd.setString(2,addMetadataList.get(i).get(\"name\").toString()); idsUserAdd.setString(3,addMetadataList.get(i).get(\"dataType\").toString()); idsUserAdd.setString(4,addMetadataList.get(i).get(\"code\").toString()); idsUserAdd.setString(5,addMetadataList.get(i).get(\"typeId\").toString()); idsUserAdd.setString(6,addMetadataList.get(i).get(\"dataLength\").toString()); idsUserAdd.setString(7,addMetadataList.get(i).get(\"dataName\").toString()); idsUserAdd.setString(8,addMetadataList.get(i).get(\"valueArea\").toString()); idsUserAdd.setString(9,addMetadataList.get(i).get(\"dataRestrict\").toString()); idsUserAdd.setString(10,addMetadataList.get(i).get(\"dataRemark\").toString()); idsUserAdd.addBatch(); //每10000次提交一次 if(i%10000==0||i==xhcs-1)&#123;//可以设置不同的大小；如50，100，500，1000等等 idsUserAdd.executeBatch(); conn.commit(); idsUserAdd.clearBatch(); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); throw e; &#125;finally &#123; try &#123; if(idsUserAdd!=null) idsUserAdd.close(); if(conn!=null) conn.close(); &#125;catch(Exception e)&#123; e.printStackTrace(); throw e; &#125; &#125; /*往数据库写数据结束*/ return errorList; &#125; 总结 有些网友发现使用StringBuffer 来拼接入参，不通过prepareStatement的预处理，虽然前者速度很快，但是使用prepareStatement可以防止SQL注入 有的好的建议大家都可以提出来","categories":[{"name":"JDBC","slug":"JDBC","permalink":"http://kingge.top/categories/JDBC/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://kingge.top/tags/Mysql/"},{"name":"JDBC","slug":"JDBC","permalink":"http://kingge.top/tags/JDBC/"},{"name":"批量导入","slug":"批量导入","permalink":"http://kingge.top/tags/批量导入/"},{"name":"SSM","slug":"SSM","permalink":"http://kingge.top/tags/SSM/"},{"name":"项目经验","slug":"项目经验","permalink":"http://kingge.top/tags/项目经验/"}]},{"title":"Mysql索引详解","slug":"Mysql索引详解","date":"2016-08-01T02:37:15.000Z","updated":"2017-08-17T09:35:34.792Z","comments":true,"path":"2016/08/01/Mysql索引详解/","link":"","permalink":"http://kingge.top/2016/08/01/Mysql索引详解/","excerpt":"","text":"前言 索引对查询的速度有着至关重要的影响，理解索引也是进行数据库性能调优的起点。考虑如下情况，假设数据库中一个表有10^6条记录，DBMS的页面大小为4K，并存储100条记录。如果没有索引，查询将对整个表进行扫描，最坏的情况下，如果所有数据页都不在内存，需要读取10^4个页面，如果这10^4个页面在磁盘上随机分布，需要进行10^4次I/O，假设磁盘每次I/O时间为10ms(忽略数据传输时间)，则总共需要100s(但实际上要好很多很多)。如果对之建立B-Tree索引，则只需要进行log100(10^6)=3次页面读取，最坏情况下耗时30ms。这就是索引带来的效果，很多时候，当你的应用程序进行SQL查询速度很慢时，应该想想是否可以建索引。进入正题： 有些硬啃的干货还是得了解的，下面先了解索引的基本知识 索引分类 单列索引 主键索引 唯一索引 普通索引 组合索引用到的表CREATE TABLE `award` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '用户id', `aty_id` varchar(100) NOT NULL DEFAULT '' COMMENT '活动场景id', `nickname` varchar(12) NOT NULL DEFAULT '' COMMENT '用户昵称', `is_awarded` tinyint(1) NOT NULL DEFAULT 0 COMMENT '用户是否领奖', `award_time` int(11) NOT NULL DEFAULT 0 COMMENT '领奖时间', `account` varchar(12) NOT NULL DEFAULT '' COMMENT '帐号', `password` char(32) NOT NULL DEFAULT '' COMMENT '密码', `message` varchar(255) NOT NULL DEFAULT '' COMMENT '获奖信息', `created_time` int(11) NOT NULL DEFAULT 0 COMMENT '创建时间', `updated_time` int(11) NOT NULL DEFAULT 0 COMMENT '更新时间', PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT='获奖信息表'; 单列索引普通索引 这个是最基本的索引 创建语法：其sql格式是： 第一种方式 : CREATE INDEX IndexName ON `TableName`(`字段名`(length)) 第二种方式 : ALTER TABLE TableName ADD INDEX IndexName(`字段名`(length)) 创建例子：第一种方式 : CREATE INDEX account_Index ON `award`(`account`);第二种方式: ALTER TABLE award ADD INDEX account_Index(`account`) 唯一索引 与普通索引类似,但是不同的是唯一索引要求所有的类的值是唯一的,这一点和主键索引一样.但是他允许有空值 创建语法：其sql格式是： 第一种方式 : CREATE UNIQUE INDEX IndexName ON `TableName`(`字段名`(length)); 第二种方式 : ALTER TABLE TableName ADD UNIQUE (column_list) 创建例子：CREATE UNIQUE INDEX account_UNIQUE_Index ON `award`(`account`); 主键索引 他与唯一索引的不同在于不允许有空值(在B+TREE中的InnoDB引擎中,主键索引起到了至关重要的地位) 创建语法：其sql格式是： 第一种方式 : CREATE UNIQUE INDEX IndexName ON `TableName`(`字段名`(length)); 第二种方式 : ALTER TABLE TableName ADD UNIQUE (column_list) 创建例子：CREATE UNIQUE INDEX account_UNIQUE_Index ON `award`(`account`); 单列索引的总结mysql&gt;SELECT ｀uid｀ FROM people WHERE lname｀='Liu' AND ｀fname｀='Zhiqun' AND ｀age｀=26因为我们不想扫描整表，故考虑用索引。单列索引：ALTER TABLE people ADD INDEX lname (lname);将lname列建索引，这样就把范围限制在lname='Liu'的结果集1上，之后扫描结果集1，产生满足fname='Zhiqun'的结果集2，再扫描结果集2，找到 age=26的结果集3，即最终结果。由 于建立了lname列的索引，与执行表的完全扫描相比，效率提高了很多，但我们要求扫描的记录数量仍旧远远超过了实际所需 要的。虽然我们可以删除lname列上的索引，再创建fname或者age 列的索引，但是，不论在哪个列上创建索引搜索效率仍旧相似。&gt; 所以就需要组合索引 组合索引 一个表中含有多个单列索引不代表是组合索引,通俗一点讲 组合索引是:包含多个字段但是只有索引名称 创建语法：其sql格式是： CREATE INDEX IndexName On `TableName`(`字段名`(length),`字段名`(length),...); 创建例子：CREATE INDEX nickname_account_createdTime_Index ON `award`(`nickname`, `account`, `created_time`); 如果你建立了 组合索引(nickname_account_createdTime_Index) 那么他实际包含的是3个索引 (nickname) (nickname,account)(nickname,account,created_time) 组合索引的最左前缀 上面的例子中给nickname,account,created_time 这三个字段建立索引他会去创建三个索引，但是在执行查询的时候只会用其中一个索引去查询，mysql会选择一个最严格(获得结果集记录数最少)的索引，所以where子句中使用最频繁的一列放在最左边。所谓最左前缀原则就是先要看第一列，在第一列满足的条件下再看左边第二列 全文索引 文本字段上(text)如果建立的是普通索引,那么只有对文本的字段内容前面的字符进行索引,其字符大小根据索引建立索引时申明的大小来规定.如果文本中出现多个一样的字符,而且需要查找的话,那么其条件只能是 where column lick &apos;%xxxx%&apos; 这样做会让索引失效.这个时候全文索引就祈祷了作用了ALTER TABLE tablename ADD FULLTEXT(column1, column2)有了全文索引，就可以用SELECT查询命令去检索那些包含着一个或多个给定单词的数据记录了。ELECT * FROM tablenameWHERE MATCH(column1, column2) AGAINST(‘xxx′, ‘sss′, ‘ddd′)这条命令将把column1和column2字段里有xxx、sss和ddd的数据记录全部查询出来。 总结使用索引的优点 可以通过建立唯一索引或者主键索引,保证数据库表中每一行数据的唯一性. 建立索引可以大大提高检索的数据,以及减少表的检索行数 在表连接的连接条件 可以加速表与表直接的相连 在分组和排序字句进行数据检索,可以减少查询时间中 分组 和 排序时所消耗的时间(数据库的记录会重新排序) 建立索引,在查询中使用索引 可以提高性能 使用索引的缺点 在创建索引和维护索引 会耗费时间,随着数据量的增加而增加 索引文件会占用物理空间,除了数据表需要占用物理空间之外,每一个索引还会占用一定的物理空间 当对表的数据进行 INSERT,UPDATE,DELETE 的时候,索引也要动态的维护,这样就会降低数据的维护速度,(建立索引会占用磁盘空间的索引文件。一般情况这个问题不太严重，但如果你在一个大表上创建了多种组合索引，索引文件的会膨胀很快)。 使用索引需要注意的地方 在经常需要搜索的列上,可以加快索引的速度 主键列上可以确保列的唯一性 在表与表的而连接条件上加上索引,可以加快连接查询的速度 在经常需要排序(order by),分组(group by)和的distinct 列上加索引 可以加快排序查询的时间, (单独order by 用不了索引，索引考虑加where 或加limit) 在一些where 之后的 &lt; &lt;= &gt; &gt;= BETWEEN IN 以及某个情况下的like 建立字段的索引(B-TREE) like语句的 如果你对nickname字段建立了一个索引.当查询的时候的语句是 nickname lick ‘%ABC%’ 那么这个索引讲不会起到作用.而nickname lick ‘ABC%’ 那么将可以用到索引 索引不会包含NULL列,如果列中包含NULL值都将不会被包含在索引中,复合索引中如果有一列含有NULL值那么这个组合索引都将失效,一般需要给默认值0或者 ‘ ‘字符串 使用短索引,如果你的一个字段是Char(32)或者int(32),在创建索引的时候指定前缀长度 比如前10个字符 (前提是多数值是唯一的..)那么短索引可以提高查询速度,并且可以减少磁盘的空间,也可以减少I/0操作. 不要在列上进行运算,这样会使得mysql索引失效,也会进行全表扫描 选择越小的数据类型越好,因为通常越小的数据类型通常在磁盘,内存,cpu,缓存中 占用的空间很少,处理起来更快 什么情况下不建立索引 查询中很少使用到的列 不应该创建索引,如果建立了索引然而还会降低mysql的性能和增大了空间需求. 很少数据的列也不应该建立索引,比如 一个性别字段 0或者1,在查询中,结果集的数据占了表中数据行的比例比较大,mysql需要扫描的行数很多,增加索引,并不能提高效率 定义为text和image和bit数据类型的列不应该增加索引 当表的修改(UPDATE,INSERT,DELETE)操作远远大于检索(SELECT)操作时不应该创建索引,这两个操作是互斥的关系 好的文章转：SQL优化转：MySQL索引原理及慢查询优化","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://kingge.top/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://kingge.top/tags/Mysql/"},{"name":"索引","slug":"索引","permalink":"http://kingge.top/tags/索引/"}]},{"title":"C++文件流操作的读与写","slug":"C-文件流操作的读与写","date":"2014-11-08T13:04:00.000Z","updated":"2017-08-17T06:33:56.710Z","comments":true,"path":"2014/11/08/C-文件流操作的读与写/","link":"","permalink":"http://kingge.top/2014/11/08/C-文件流操作的读与写/","excerpt":"","text":"对文件的写入put和&lt;&lt; 写入方式 put的操作：是对文件进行写入的操作，写入一个字符（可以使字母也可以是asci码值） file.put(' A');file.put('\\n');file &lt;&lt; \"xiezejing1994\"; 输出： &nbsp;&nbsp;&nbsp;&nbsp;A// 注意到A这里有几个空格 但是不影响左对齐xiezejing1994// 也就是说A的前面不会有空格 ##操作和&lt;&lt; 读写方式区别 put操作和 file &lt;&lt;‘A’这个基本上是一样的，但是有个区别就是他不可以这样file &lt;&lt;’ A’;（A的前面有空格）因为他是格式化输入 所以中间不能有”空格“但是这样file &lt;&lt;”‘ A”;（也就是以字符串的格式输入则会有空格） 文件的读操作1.getline（） getline（ cin ，string类型 ） getline( cin, z ); file1 &lt;&lt; z; （file1 为文件流对象） 例子： char c[100]; while ( !file.eof() ) &#123; file.getline( c,100 ); cout &lt;&lt; c; &#125; 假设文件1.txt内有' A xiezejing1994 这样文本它的输出：' Axiezejing1994 也就是说他没有读到换行的功能 不会输出' A xiezejing1994（原因就是getlibe其实里面有三个参数，第三个参数默认为'\\n'） 2.getline（ fstream，string ）while ( getline( file,z ) )&#123; cout &lt;&lt; z;&#125; 3.get（） char c[100]; while ( !file.eof() ) &#123; //file.getline( c,100 ,'\\0'); file.get( c,100 ,'\\0'); cout &lt;&lt; c; &#125;输出同getline一样----必须要写三个参数 否则只会输出一行（第三个参数为'\\n'也是只会输出一行）。非常严格的输出。 4.get操作 char c; file.get(c); while ( !file.eof() ) &#123; cout &lt;&lt; c; file.get(c); &#125;-----和getline的区别在于 他是读取单个字符的，所以会读取到结束符号故会输出' Axiezejing1994 对文件是否读到末尾的判断1.feof（） 该函数只有“已经读取了”结束标志时 feof（）才会返回非零值 也就是说当文件读取到文件结束标志位时他的返回值不是非零还是零 故还要在进行一次读. 例子 假设在1.txt中只有abc三个字符在进行 while（！feof(fp)） &#123; ch = getc(fp); putchar(ch); &#125;//实际上输出的是四个字符改为ch = getc（fp）；while （ ！feof（fp））&#123; putchar（ch）； ch = getc（fp）；&#125;// 这样就可以正常运行3. 可以不调用函数eof 直接就是 while （ file ） // file 就是文件流的对象&#123; 。。。。操作&#125;4.char c[100]; while ( !file.eof() ) &#123; file.getline( c,100 ,'\\0'); cout &lt;&lt; c; &#125;这个 和char c[100]; while ( !file.eof() ) &#123; file.getline( c,100 ,'\\n'); cout &lt;&lt; c; &#125;假设文本为上面的。输出分别为' A xiezejing1994' Axiezejing1994 读写1.read( 数组名，接收的个数 )2.write( 数组名，gcount函数 )#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;string&gt;using namespace std;int main()&#123; ifstream file( \"D:\\\\jjj.txt\"); ofstream file1( \"D:\\\\j.txt\" , ios::app); string z; if ( !file ) &#123; cout &lt;&lt; \" 无法打开\\n \"; return 1; &#125; char c[100]; while ( !file.eof() ) &#123; file.read( c,100 ); file1.write( c, file.gcount() ); &#125; file.close(); file.close(); return 0;&#125; **判断打开是否正确** 1. if( !file )2.if ( !file.good() ) &#123; cout &lt;&lt; \" 无法打开\\n \"; return 1; &#125;3. if ( !file.is_open() ) &#123; cout &lt;&lt; \" 无法打开\\n \"; return 1; &#125;4. if ( file.fail() ) &#123; cout &lt;&lt; \" 无法打开\\n \"; return 1; &#125;","categories":[{"name":"c++","slug":"c","permalink":"http://kingge.top/categories/c/"}],"tags":[{"name":"文件","slug":"文件","permalink":"http://kingge.top/tags/文件/"},{"name":"C++","slug":"C","permalink":"http://kingge.top/tags/C/"},{"name":"文件读写","slug":"文件读写","permalink":"http://kingge.top/tags/文件读写/"}]},{"title":"文章例子","slug":"ceshi","date":"2013-12-02T07:30:16.000Z","updated":"2017-08-16T02:36:44.437Z","comments":true,"path":"2013/12/02/ceshi/","link":"","permalink":"http://kingge.top/2013/12/02/ceshi/","excerpt":"前言使用github pages服务搭建博客的好处有： 全是静态文件，访问速度快； 免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台； 可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的；","text":"前言使用github pages服务搭建博客的好处有： 全是静态文件，访问速度快； 免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台； 可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的； 数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行； 博客内容可以轻松打包、转移、发布到其它平台； 等等；","categories":[{"name":"默认分类","slug":"默认分类","permalink":"http://kingge.top/categories/默认分类/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://kingge.top/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://kingge.top/tags/tag2/"},{"name":"tag3","slug":"tag3","permalink":"http://kingge.top/tags/tag3/"}]}]}