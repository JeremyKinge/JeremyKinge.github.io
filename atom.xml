<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>King哥</title>
  <subtitle>To know everything, no words don&#39;t talk, listening to people is enough to cause alarm（知无不言，言无不尽 言者无罪，闻者足戒）</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://kingge.top/"/>
  <updated>2020-05-04T08:28:49.785Z</updated>
  <id>http://kingge.top/</id>
  
  <author>
    <name>Jeremy Kinge</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>下个开源项目的计划</title>
    <link href="http://kingge.top/2020/04/28/%E4%B8%8B%E4%B8%AA%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AE%A1%E5%88%92/"/>
    <id>http://kingge.top/2020/04/28/下个开源项目的计划/</id>
    <published>2020-04-28T12:59:59.000Z</published>
    <updated>2020-05-04T08:28:49.785Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-已经做的事"><a href="#1-已经做的事" class="headerlink" title="1.已经做的事"></a>1.已经做的事</h1><p>​    首先我们不会重复造轮子，因为如果市面上已经存在很好很优秀的框架或者解决方案，那么我建议使用那些成熟的解决方案。</p>
<p>​    那么比如说，我之前实现的<strong>可靠消息最终一致性方案（rtm）</strong>，就是利用了<strong>其他mq没有事务消息这个特征(Rocketmq独有)</strong>，但是又想在<strong>不改用mq</strong>的前提下，那么<strong>又想保证数据最终一致性</strong>，那么就可以<strong>使用rtm系统</strong>来作为<code>中间商</code> <strong>协调上下游系统的事务处理</strong>，保证了数据的最终一致性。</p>
<p>​        话句话说，<strong>RTM实际上是基于本地消息表这种解决方案来实现的</strong>。 而且实际上rtm的理念其实就是跟rocketmq的事务消息类似，但是rtm更加全面。</p>
<p>​    </p>
<h2 id="rocketmq事务消息的弊端"><a href="#rocketmq事务消息的弊端" class="headerlink" title="rocketmq事务消息的弊端"></a>rocketmq事务消息的弊端</h2><p>​    我们知道， <code>事务消息</code> 仅仅只是保证本地事务和MQ消息发送形成整体的 <code>原子性</code>，而投递到MQ服务器后，并无法保证消费者一定能消费成功！<strong>也就是下游系统可能会发送失败</strong>。</p>
<p>​    如果 <strong>消费端消费失败</strong> 后的处理方式，建议是记录异常信息然后 <strong>人工处理</strong>，并不建议回滚上游服务的数据(因为两者是 <strong>解耦</strong> 的，而且 <strong>回滚复杂度</strong> 太高) </p>
<p>​    <strong>那么如果使用事务消息怎么解决下游系统消费失败的问题呢？</strong></p>
<p><strong>常见两个解决方案：</strong></p>
<p>  我们可以利用 <code>MQ</code> 的两个特性 <code>重试</code> 和 <code>死信队列</code> 来协助消费端处理：</p>
<ol>
<li><p>消费失败后mq进行<strong>一定次数</strong>的 <code>重试</code></p>
</li>
<li><p>重试后也失败的话该消息丢进 <code>死信队列</code> 里</p>
</li>
<li><p>另外起一个线程监听消费 <code>死信队列</code> 里的消息，记录日志并且预警！</p>
<p>因为有 <code>重试</code> 所以消费者需要实现 <code>幂等性</code></p>
</li>
</ol>
<h2 id="RTM系统优点-广告一波"><a href="#RTM系统优点-广告一波" class="headerlink" title="RTM系统优点 - 广告一波"></a>RTM系统优点 - 广告一波</h2><p>​    在兼有rocketmq事务消息的同时，能够<strong>保证下游系统一定能消费消息（提供消费失败一定次数和时间间隔重试以及记录超过重试次数的消息）</strong>，从而保证了数据的最终一致性，同时提供管理界面，管理已经超过重发次数上限的消息，重新发送。</p>
<p>​    所以说，当你的项目架构在最初的技术选型时，并没有使用rocketmq，那么又想保证数据最终一致性，那么就可以引入rtm系统，非常方便快捷。</p>
<h1 id="2-分布式事务选型"><a href="#2-分布式事务选型" class="headerlink" title="2.分布式事务选型"></a>2.分布式事务选型</h1><p>分布式解决方案，一般有如下几种：</p>
<ul>
<li>XA分布式协议<ul>
<li>2pc    - 一般不适用</li>
<li>3pc</li>
</ul>
</li>
</ul>
<ul>
<li><p>TCC</p>
<ul>
<li><p>Try、Confirm、Cancel，实际上用到了补偿的概念</p>
</li>
<li><p>这种方案说实话几乎很少用人使用，我问过得人，用的也比较少，但是也有使用的场景。因为这个事务回滚实际上是<strong>严重依赖于你自己写代码来回滚和补偿</strong>，会造成补偿代码巨大，非常之恶心。</p>
<p>​    <strong>比如说我们，一般来说跟钱相关的，跟钱打交道的，支付、交易相关的场景，我们会用TCC，严格严格保证分布式事务要么全部成功，要么全部自动回滚，严格保证资金的正确性，在资金上出现问题。</strong></p>
<ul>
<li><strong>阿里开源的seata</strong>，但是阿里的seata并不是纯正的tcc框架，因为 纯正的tcc框架，很麻烦，需要你手动把各种接口实现出来3个接口，try，confirm，cancel。bytetcc框架，就是一个纯的tcc框架，可以了解一下。 </li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>可靠消息最终一致性</p>
<ul>
<li><strong>推荐使用</strong></li>
</ul>
</li>
<li><p>本地消息表</p>
</li>
<li><p>最大努力通知方案</p>
<ul>
<li><p>这个方案的大致意思就是：</p>
<p>1）系统A本地事务执行完之后，发送个消息到MQ</p>
<p>2）这里会有个专门消费MQ的<strong>最大努力通知服务</strong>，这个服务会消费MQ然后<strong>写入数据库中记录下来</strong>，或者是放入个<strong>内存队列（DelayQueue）</strong>也可以，接着调用系统B的接口</p>
<p>3）要是系统B执行成功就ok了；要是系统B执行失败了，那么最大努力通知服务就定时尝试重新调用系统B，反复N次，最后还是不行就放弃。</p>
</li>
</ul>
</li>
</ul>
<p><strong>实际上rtm系统，已经实现了可靠消息最终一致性和本地消息表这两种方案。</strong></p>
<h1 id="3-自我实现最大努力通知方案"><a href="#3-自我实现最大努力通知方案" class="headerlink" title="3.自我实现最大努力通知方案"></a>3.自我实现最大努力通知方案</h1><p><strong>最大努力通知与可靠消息一致性有什么不同</strong></p>
<p>1、解决方案思想不同</p>
<p>​    可靠消息一致性，发起通知方需要保证将消息发出去，并且将消息发到接收通知方，消息的可靠性关键由发起通知 方来保证。</p>
<p>​    最大努力通知，发起通知方尽最大的努力将业务处理结果通知给接收通知方，但是可能消息接收不到，此时需要接收通知方<strong>主动调用发起通知方的接口查询业务处理结果</strong>，通知的可靠性关键在接收通知方。</p>
<p>2、两者的业务应用场景不同</p>
<p>​    可靠消息一致性关注的是交易过程的事务一致，以异步的方式完成交易。</p>
<p>​    最大努力通知关注的是交易后的通知事务，即将交易结果可靠的通知出去。</p>
<p>3、技术解决方向不同</p>
<p>​    可靠消息一致性要解决消息从发出到接收的一致性，即消息发出并且被接收到。</p>
<p>​    最大努力通知无法保证消息从发出到接收的一致性，只提供消息接收的可靠性机制。可靠机制是，最大努力的将消 息通知给接收方，当消息无法被接收方接收时，由接收方主动查询消息（业务处理结果）。</p>
<p>也就是我们<strong>要实现的最大通知服务关注</strong>的是<strong>跟下游服务之间的可靠性通信</strong>，而可靠消息一致性中可靠消息服务（rtm）关注的是跟上游的数据一致性，同时保证消息一定能发送到下游。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-已经做的事&quot;&gt;&lt;a href=&quot;#1-已经做的事&quot; class=&quot;headerlink&quot; title=&quot;1.已经做的事&quot;&gt;&lt;/a&gt;1.已经做的事&lt;/h1&gt;&lt;p&gt;​    首先我们不会重复造轮子，因为如果市面上已经存在很好很优秀的框架或者解决方案，那么我建议使用
    
    </summary>
    
      <category term="开源项目" scheme="http://kingge.top/categories/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"/>
    
    
      <category term="开源项目" scheme="http://kingge.top/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"/>
    
      <category term="最大努力通知方案" scheme="http://kingge.top/tags/%E6%9C%80%E5%A4%A7%E5%8A%AA%E5%8A%9B%E9%80%9A%E7%9F%A5%E6%96%B9%E6%A1%88/"/>
    
  </entry>
  
  <entry>
    <title>可靠消息解决数据最终一致性-开源项目rtm</title>
    <link href="http://kingge.top/2020/04/18/rtm%E6%95%B0%E6%8D%AE%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    <id>http://kingge.top/2020/04/18/rtm数据最终一致性/</id>
    <published>2020-04-18T14:57:58.000Z</published>
    <updated>2020-05-04T08:15:02.308Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><h2 id="为什么使用消息队列？"><a href="#为什么使用消息队列？" class="headerlink" title="为什么使用消息队列？"></a>为什么使用消息队列？</h2><h3 id="MQ出现的原因-优点"><a href="#MQ出现的原因-优点" class="headerlink" title="MQ出现的原因/优点"></a>MQ出现的原因/优点</h3><p>在回答这个问题之前，我们想一下，在没有消息队列之前我们的多个<strong>业务相互调用</strong>时他的逻辑实现是怎么样的？</p>
<p>画个图：</p>
<p><img src="/2020/04/18/rtm数据最终一致性/image-20200424172621286.png" alt="image-20200424172621286"></p>
<p>​    这是一个很普通的业务调用，也是我们写的比较多的。整个业务逻辑是这样的，<strong>客户下订单，调用订单服务生成订单，那么在生成订单的时候，会去调用库存服务减少库存，再去调用用户服务查询用户信息</strong>。</p>
<p>​    这样咋一看没有什么问题，但是如果后面订单服务业务改进，需要在下订单的同时，需要查询<strong>优惠券服务</strong>，查询下订单时所使用的优惠券信息。那么这个时候，你必然要修改订单服务，然后增加调用的代码逻辑。</p>
<p>​    如下图：</p>
<p><img src="/2020/04/18/rtm数据最终一致性/image-20200424173159358.png" alt="image-20200424173159358"></p>
<p><strong>而且后面如果订单服务还需要去调用其他服务，那么你就还需要疯狂的修改订单服务。</strong></p>
<p>而且，例如后面业务改进，订单服务不需要再调用优惠券服务了？那么你又得在订单服务中移除该服务。</p>
<p>非但如此，订单服务要时时刻刻考虑调用的库存服务、用户服务等等系统如果挂了咋办？我要不要重发？我要不要把消息存起来？？？？</p>
<p> 总而言之，订单服务所需要承载的责任太重了，而且需要负责的东西太多，这就是<strong>耦合</strong>。</p>
<p><strong>那么MQ的第一个作用就体现出来了：解耦</strong></p>
<p>上面的服务使用MQ后：</p>
<p><img src="/2020/04/18/rtm数据最终一致性/image-20200424173753186.png" alt="image-20200424173753186"></p>
<p>那么经过改进后，整个订单服务就舒服多了，也清净了。订单服务处理完用户下单请求后，只需要发送一条消息到MQ中，代表我下单了，然后整个订单服务就结束了，<strong>不需要同步等待</strong>库存服务等等其他服务的响应。</p>
<p>​    库存服务，只需要订阅MQ的主题，然后完成自己的业务逻辑即可。</p>
<p>那么MQ还有其他什么优点呢？</p>
<p>其实在上面我已经说出来了，你有没有发现，在上面的例图中，我们引入了MQ，<strong>使得订单服务不再需要同步等待调用其他服务的返回结果。</strong></p>
<p>所以<strong>MQ的第二个优点就是</strong>：<strong>异步</strong></p>
<p>​    画个图来说明一下，A系统接收一个请求，需要在自己本地写库，还需要在BCD三个系统写库，自己本地写库要3ms，BCD三个系统分别写库要300ms、450ms、200ms。最终请求总延时是3 + 300 + 450 + 200 = 953ms，接近1s，用户感觉搞个什么东西，慢死了慢死了。</p>
<blockquote>
<p><strong>未使用MQ前</strong></p>
</blockquote>
<p><img src="/2020/04/18/rtm数据最终一致性/5.png" alt="5"></p>
<blockquote>
<p><strong>使用MQ后</strong></p>
</blockquote>
<p><img src="/2020/04/18/rtm数据最终一致性/2.png" alt="2"></p>
<p><strong>MQ的第三个优点：削峰</strong></p>
<p>​    每天0点到11点，A系统风平浪静，每秒并发请求数量就100个（qps=100）。结果每次一到11点~1点，每秒并发请求数量突然会暴增到1万条。但是系统最大的处理能力就只能是每秒钟处理1000个请求啊。。。尴尬了，系统会死。。。</p>
<pre><code>**所以MQ充当的角色类似于一个水库。汛期来临时水库首当其冲，起到缓冲作用，避免大量水流冲击下游。这个时候水库只需要开放部分出口，然后水流慢慢的留向下游，最后把水库里的水慢慢消耗最终接近平缓即可。**
</code></pre><blockquote>
<p><strong>未用MQ前？</strong></p>
</blockquote>
<p><img src="/2020/04/18/rtm数据最终一致性/6.png" alt="6"></p>
<blockquote>
<p><strong>使用mq后</strong></p>
</blockquote>
<p><img src="/2020/04/18/rtm数据最终一致性/7.png" alt="7"></p>
<p>总而言之：    <strong>队列的常见使用场景吧，其实场景有很多，但是比较核心的优点有3个：解耦、异步、削峰</strong></p>
<h3 id="MQ缺点"><a href="#MQ缺点" class="headerlink" title="MQ缺点"></a>MQ缺点</h3><p>缺点呢？显而易见的</p>
<ul>
<li>系统可用性降低：系统引入的外部依赖越多，越容易挂掉，本来你就是A系统调用BCD三个系统的接口就好了，人ABCD四个系统好好的，没啥问题，你偏加个MQ进来，万一MQ挂了咋整？MQ挂了，整套系统崩溃了，你不就完了么。（<strong>需要保证MQ高可用 - 增加系统复杂程度</strong>）</li>
</ul>
<ul>
<li>系统复杂性提高：硬生生加个MQ进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已，搞什么捏。（<strong>消息可靠性和消费幂等性</strong>）</li>
</ul>
<ul>
<li>一致性问题：A系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是BCD三个系统那里，BD两个系统写库成功了，结果C系统写库失败了，咋整？你这数据就不一致了。（<strong>分布式事务/数据最终一致性</strong>）</li>
</ul>
<p>​    <strong>所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，最好之后，你会发现，妈耶，系统复杂度提升了一个数量级，也许是复杂了10倍。但是关键时刻，用，还是得用的。。。但是得想好。</strong></p>
<p><a href="https://www.showdoc.cc/rmq?page_id=1796661553395018" target="_blank" rel="external">https://www.showdoc.cc/rmq?page_id=1796661553395018</a></p>
<h2 id="怎么解决数据的一致性"><a href="#怎么解决数据的一致性" class="headerlink" title="怎么解决数据的一致性"></a>怎么解决数据的一致性</h2><h3 id="分布式事务-强一致性"><a href="#分布式事务-强一致性" class="headerlink" title="分布式事务 - 强一致性"></a>分布式事务 - 强一致性</h3><h3 id="数据最终一致性-弱一致性"><a href="#数据最终一致性-弱一致性" class="headerlink" title="数据最终一致性 - 弱一致性"></a>数据最终一致性 - 弱一致性</h3><h2 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h2><p>​    2000年7月，加州大学伯克利分校的Eric Brewer教授在ACM PODC会议上提出CAP猜想。Brewer认为在设计一个大规模的分布式系统时会遇到三个特性：一致性（consistency）、可用性（Availability）、分区容错（partition-tolerance），而一个分布式系统最多只能满足其中的2项。2年后，麻省理工学院的Seth Gilbert和Nancy Lynch从理论上证明了CAP。之后，CAP理论正式成为分布式计算领域的公认定理。</p>
<p><img src="/2020/04/18/rtm数据最终一致性/10708517-72259de731fcf8a9.png" alt="img"></p>
<p>C：数据一致性（强一致性），<strong>集群中同一数据的多个副本是否实时相同</strong>。（一致性也分为，强一致性和弱一致性）</p>
<p>A：可用性，指系统提供的服务必须一直处于可用的状态，<strong>对于用户的每一个操作请求总是能够在有限的时间内返回结果。</strong></p>
<p> P:分区容错性，也就是如果出现网络震荡的时候，服务集群不能够全部挂掉，保证高可用。<strong>将同一服务分布在多个系统中，从而保证某一个系统宕机，仍然有其他系统提供相同的服务。</strong></p>
<p>​    <strong>在分布式系统中，P肯定要保证的。</strong></p>
<blockquote>
<p>​    <strong>为什么要保证p呢？</strong></p>
</blockquote>
<pre><code>当业务量猛增，单个服务器已经无法满足我们的业务需求的时候，就需要使用分布式系统，使用多个节点提供相同的功能（需要部署服务集群），从而整体上提升系统的性能，这就是使用分布式系统的第一个原因。那么分区容错性就必须满足。
</code></pre><p>​        那么我们只能在C和A中二选一，为什么A和C不能够同时选择呢？举个简单例子。我们在部署了五个订单服务，组成了集群。有一天需求修改了，那么需要更新这五个订单服务。这个时候，我们为了保证客户还是能够访问系统，那么就升级部分服务器，也就意味着，必然存在客户调用了新旧订单服务。那么这个时候数据肯定是不一致的。反之亦然，为了保证数据一致性，我们关闭五个服务器，然后更新后再重启，那么在这期间服务对外是不可用的，无法保证系统可用性。</p>
<p>​    例如我们在使用springcloud的Eureka服务注册中心时，他实现的机制就是 AP，能够保证服务的使用。</p>
<p>​    DUbbo的服务注册中心采用的是Zookeeper，那么因为zookeeper集群（选举机制），他实现的机制是CP（但是他的C数据一致性是，数据弱一致性，也就是存在某个时间salve的数据是不一致的–因为zk 的是更新操作是采取投票过半机制决定本次更新是否成功。）</p>
<p>​    所以具体的业务场景采用不同的策略，<strong>不过大多数互联网项目采用的是AP机制</strong>，以能够保证服务的使用为主。    <strong>因为在大谈用户体验的今天，如果业务系统时常出现“系统异常”、响应时间过长等情况，这使得用户对系统的好感度大打折扣。所以可用性还是要保证的</strong></p>
<h2 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h2><p>​    CAP理论告诉我们一个悲惨但不得不接受的事实——我们只能在C、A、P中选择两个条件。而对于业务系统而言，我们往往选择<strong>牺牲一致性来换取系统的可用性和分区容错性</strong>。不过这里要指出的是，所谓的“牺牲一致性”并不是完全放弃数据一致性，而是牺牲强一致性换取弱一致性     </p>
<p>​    BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency，CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（Eventual Consitency）。</p>
<p>​    BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短语的缩写。</p>
<ol>
<li><strong>BA：</strong>基本可用（Basically Available）</li>
</ol>
<p>​        指分布式系统在出现不可预知故障的时候，允许损失部分可用性。</p>
<ol>
<li><strong>S：</strong>软状态（ Soft State）</li>
</ol>
<p>​        指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性。</p>
<ol>
<li><strong>E：</strong>最终一致（ Eventual Consistency）</li>
</ol>
<p>​      </p>
<p>  强调的是所有的数据更新操作，在经过一段时间的同步之后，最终都能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。</p>
<p>base理论的核心就是，<strong>经过一段时间后，能够保证数据的强一致性，在这之前，数据的一致性不是那么的强调</strong>。</p>
<p>​    举个简单的例子，例如在双十一购物中心，某件商品的点赞数量我们需不需要它实时的显示数量？很明显是不需要的，我们显示的数量可以使几个小时之前的。我们只需要在双十一过后，再去统计出最终该商品的点赞数量，然后显示即可。</p>
<p>​    <strong>其实大部分最终一致性是通过消息队列的方式实现的。例如我们对商品的点赞，发送一条消息到消息队列，然后消息消费者消费消息，实现点赞数量增加。这样的流程肯定会存在一定的延时，但是最终结果肯定是正确的，所以实现了最终一致性。</strong></p>
<h2 id="rocketmq事务消息"><a href="#rocketmq事务消息" class="headerlink" title="rocketmq事务消息"></a>rocketmq事务消息</h2><p><strong>设么是事务消息？</strong>先看案例场景</p>
<p>例如下图的场景：生成订单记录 -&gt; MQ -&gt; 增加积分</p>
<p><img src="/2020/04/18/rtm数据最终一致性/image-20191211155712515.png" alt="image-20191211155712515"></p>
<p>我们是应该先 <strong>创建订单记录</strong>，还是先 <strong>发送MQ消息</strong> 呢？</p>
<ol>
<li><strong>先发送MQ消息</strong>：这个明显是不行的，因为如果消息发送成功，而订单创建失败的话是没办法把消息收回来的。因为发送消息后，下游消费者，已经消费提交。</li>
<li><strong>先创建订单记录</strong>：如果订单创建成功后MQ消息发送失败 <strong>抛出异常</strong>，因为两个操作都在本地事务中所以订单数据是可以 <strong>回滚</strong> 的。</li>
</ol>
<p>上面的 <strong>方式二</strong> 看似没问题，但是 <strong>网络是不可靠的</strong>！如果 <code>MQ</code> 的响应因为网络原因没有收到，所以在面对不确定的结果只好进行回滚；但是 <code>MQ</code> 端又确实是收到了这条消息的，只是回给客户端的 <strong>响应丢失</strong> 了！</p>
<p>所以 <code>事务消息</code> 就是用来保证 <strong>本地事务</strong> 与 <strong>MQ消息发送</strong> 的原子性！</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>图一</p>
<p><img src="/2020/04/18/rtm数据最终一致性/image-20191211161342571.png" alt="image-20191211161342571"></p>
<p> <img src="/2020/04/18/rtm数据最终一致性/image-20191211161426489.png" alt="image-20191211161426489"> </p>
<p>主要的逻辑分为两个流程：</p>
<ul>
<li><strong>事务消息发送及提交</strong>：<ol>
<li>发送 <code>half消息</code></li>
<li><code>MQ服务端</code> 响应消息写入结果</li>
<li>根据发送结果执行 <code>本地事务</code>（如果写入失败，此时half消息对业务 <strong>不可见</strong>，本地逻辑不执行）</li>
<li>根据本地事务状态执行 <code>Commit</code> 或者 <code>Rollback</code>（Commit操作生成消息索引，消息对消费者 <strong>可见</strong>）</li>
</ol>
</li>
</ul>
<ul>
<li><strong>回查流程</strong>：<ol>
<li>对于长时间没有 <code>Commit/Rollback</code> 的事务消息（<code>pending</code> 状态的消息），mq服务端发起一次 <strong>回查</strong></li>
<li><code>Producer</code> 收到回查消息，检查回查消息对应的 <code>本地事务状态</code></li>
<li>根据本地事务状态，重新 <code>Commit</code> 或者 <code>Rollback</code></li>
</ol>
</li>
</ul>
<p><strong>逻辑时序图</strong></p>
<p><img src="/2020/04/18/rtm数据最终一致性/image-20191211161601632.png" alt="image-20191211161601632"></p>
<h3 id="rocketmq事务消息的弊端"><a href="#rocketmq事务消息的弊端" class="headerlink" title="rocketmq事务消息的弊端"></a>rocketmq事务消息的弊端</h3><p>根据图1，你会发现，存在一个问题，那就是假设库存服务成功消费到了消息，但是删减库存失败。那么因为删除失败也是属于业务的一部分，那么他就会返回ack消息给，mq。那么整个流程结束。</p>
<p> <strong>从上面的原理可以发现 <code>事务消息</code> 仅仅只是保证本地事务和MQ消息发送形成整体的 <code>原子性</code>，而投递到MQ服务器后，并无法保证消费者一定能消费成功！</strong></p>
<p>如果 <strong>消费端消费失败</strong> 后的处理方式，建议是记录异常信息然后 <strong>人工处理</strong>，并不建议回滚上游服务的数据(因为两者是 <strong>解耦</strong> 的，而且 <strong>复杂度</strong> 太高) </p>
<p>我们可以利用 <code>MQ</code> 的两个特性 <code>重试</code> 和 <code>死信队列</code> 来协助消费端处理：</p>
<ol>
<li>消费失败后进行一定次数的 <code>重试</code></li>
<li>重试后也失败的话该消息丢进 <code>死信队列</code> 里</li>
<li>另外起一个线程监听消费 <code>死信队列</code> 里的消息，记录日志并且预警！</li>
</ol>
<p>因为有 <code>重试</code> 所以消费者需要实现 <code>幂等性</code></p>
<p>总而言之，rocketmq实现事务消息的两个核心概念：<strong>两阶段提交、事务状态定时回查</strong></p>
<h1 id="我要做什么？项目介绍"><a href="#我要做什么？项目介绍" class="headerlink" title="我要做什么？项目介绍"></a>我要做什么？项目介绍</h1><p>​    因为我们知道rocketmq是<strong>原生支持事务消息</strong>的，但是如果项目中，最初选型的时候，并没有选用rmq，而是选用了其他的MQ，例如rabbitmq，activemq，kafka等等，但是又想保<strong>证最终一致性事务呢</strong>？</p>
<p>​    <strong>那么我们仿照上面rmq的事务消息的原理，来自己实现一个提供事务消息的项目工程。</strong></p>
<p>​    那么这个项目我决定命名为<strong>RTM</strong>（滑稽脸）。    </p>
<p><strong>RTM( Reliable transaction message )</strong>是<strong>基于可靠消息的最终一致性</strong>的分布式事务解决方案。</p>
<blockquote>
<p><strong>框架定位</strong></p>
</blockquote>
<p><strong>RTM本身不生产消息队列，只是消息的搬运工。</strong><br><strong>RTM框架提供消息预发送、消息发送、消息确认、消息恢复、消息管理等功能，结合成熟的消息中间件，解决分布式事务，达到数据最终一致性。</strong></p>
<h1 id="RTM解决的问题"><a href="#RTM解决的问题" class="headerlink" title="RTM解决的问题"></a>RTM解决的问题</h1><blockquote>
<p><strong>引入消息中间件的场景</strong></p>
</blockquote>
<p><img src="/2020/04/18/rtm数据最终一致性/image-20200426092909056.png" alt="image-20200426093019755"></p>
<p>​    存在问题，1处和2处，可能因为网络原因，导致数据一致性的问题产生，<strong>也就是无法保证A系统和B系统数据的一致性</strong>，无法保证。</p>
<p>​    举个例子，A系统发送完消息到MQ后，在执行自己业务过程中出现异常，本地事务回滚。但是此时消息已经发到MQ，下游服务B系统已经消费消息，B系统执行完自己的业务。那么此时A系统失败，B系统成功。这样就造成了整个业务流不是原子的，存在数据不一致性。</p>
<p>​    上面的场景还存在着很多数据不一致性的场景。这里就不一一列举，下面在讲解到RTM的细节时会一一说明。</p>
<blockquote>
<p><strong>引入RTM后的场景</strong></p>
</blockquote>
<p><img src="/2020/04/18/rtm数据最终一致性/image-20200426095618201.png" alt="image-20200426095618201"></p>
<p>​    <strong>可以看到我们在RTM中引进了，rocketmq的事务消息的概念，RTM在这里仅仅只是作为一个协调者，协调上下游服务的业务操作。确保了是上下游服务能够保证数据的一致性，达到数据最终一致性，符合BASE理论。</strong></p>
<p>​    </p>
<p> RTM提供了，<strong>发送半消息、半消息确认、消息发送到MQ、消息消费确认、消息重复投递等等功能</strong>。</p>
<h1 id="RTM详细流程介绍"><a href="#RTM详细流程介绍" class="headerlink" title="RTM详细流程介绍"></a>RTM详细流程介绍</h1><p>​    通过上面的阐述，我们大概知道了RTM在分布式系统中的地位，<strong>协调者</strong>。但是至于他的请求流程，怎么保证数据一致性，下面我们拉一一说明。</p>
<p>​    我们将从三个方面来说明</p>
<ul>
<li>正常使用流程</li>
<li>消息发送到RTM，RTM成功投递流程</li>
<li>RTM确认消费者成功消费流程</li>
</ul>
<h2 id="正常流程"><a href="#正常流程" class="headerlink" title="正常流程"></a>正常流程</h2><p><img src="/2020/04/18/rtm数据最终一致性/image-20200426102034824.png" alt="image-20200426103349050"></p>
<p>梳理一下流程：</p>
<p>（1）首先A系统在执行业务之前，先投递半消息到RTM，RTM持久化成功后（这里使用mysql），发送成功消息给A系统，紧接着A系统执行本地业务。（一般这段逻辑需要开启本地事务，这样可以保证了消息发送成功后再执行本地业务，消息发送失败那么也就没有必要执行A系统本地业务了）</p>
<p>（2）接着A系统在执行完本地业务后，<strong>异步</strong>发送确认消息给RTM，然后RTM标记半消息为确认可投递，接着RTM会把消息发送给MQ。</p>
<p>（3）系统B收到MQ的消息，然后执行自己的业务逻辑，之后再调用RTM接口，确认消息已经消费，接着RTM会把该消息从数据库中删除。到这里整个流程结束</p>
<blockquote>
<p><strong>解释几个问题。</strong></p>
</blockquote>
<ul>
<li><p>在步骤二中，为什么需要异步通知RTM消息可投递。</p>
<ul>
<li><p>我们反过来想，如果用同步会发生什么？首先来看一下A系统调用RTM系统的伪代码</p>
</li>
<li><figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="meta">@Transactional</span>(rollbackFor = RuntimeException.class)<span class="comment">//开启事务</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addOrder</span><span class="params">(Order order)</span> </span>&#123;</div><div class="line"></div><div class="line">      <span class="comment">// 1.调用RMQ，创建预发送消息</span></div><div class="line">      String msgID = rtmService.addHalfMessage(order);</div><div class="line">      <span class="comment">// 2.执行业务</span></div><div class="line">         。。。。。</div><div class="line">      <span class="comment">// 3.同步调用RTM，确认发送消息</span></div><div class="line">      rtmService.confirmHalfMessage(msgID);</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>假设在第三处，调用RTM时，因为网络延迟或者其他原因，导致confirmHalfMessage()抛出异常，那么addOrder()方法回滚<strong>，A系统执行失败</strong>。但是实际上RTM还是调用成功了，也就是意味着RTM会往MQ发送消息，然后<strong>B系统收到消息后成功执行</strong>。那么此时A、B系统的数据是不一致性。</p>
</li>
<li><p>所以这里需要异步调用RTM，确认消息。目的就是解耦，保证了A系统的正常执行。</p>
</li>
<li><p><strong>但是如果使用异步后？出现A系统成功执行，但是调用RTM确认消息发送失败时，怎么处理呢？这个问题RTM会提供回查机制，确认半消息是删除还是确认投递。</strong></p>
</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>​        可以看到整个RTM正常流程下是能够保证数据的一致性的，满足base理论。</p>
<h2 id="消息发送到RTM，RTM成功投递流程"><a href="#消息发送到RTM，RTM成功投递流程" class="headerlink" title="消息发送到RTM，RTM成功投递流程"></a>消息发送到RTM，RTM成功投递流程</h2><p>​    上面我们只是把整个RTM使用的正常流程梳理了一遍，但是在使用过程中肯定会出现很多问题，出现问题的同时可能还会造成数据的不一致性问题，那么怎么保证数据的一致性呢？出现问题怎么解决呢？</p>
<p>​        </p>
<p>​    接下来我们来看一下，A系统在跟RTM通信这个阶段出现问题怎么解决？怎么保证数据一致性？</p>
<p><img src="/2020/04/18/rtm数据最终一致性/image-20200426113538315.png" alt="image-20200426113538315"></p>
<p>​    接下来我们就来分析一下如果上面这六步如果出现了问题，那么RTM是怎么解决的，只要保证了这六步的正确性，那么我们也就保证了消息发送阶段的一致性。</p>
<ul>
<li><p>1处发送异常，A系统发送半消息失败。那么因为<strong>A系统</strong>还<strong>没执行本业务</strong>（没有执行到4处），而且<strong>RTM系统</strong>也<strong>没有持久化半消息</strong>。那么此时不会产生数据不一致，<strong>那么RTM系统不需要做处理。</strong></p>
<ul>
<li><figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="meta">@Transactional</span>(rollbackFor = RuntimeException.class)<span class="comment">//开启事务</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addOrder</span><span class="params">(Order order)</span> </span>&#123;<span class="comment">//A系统调用RTM，伪代码</span></div><div class="line">      <span class="comment">// 1.调用RMQ，创建预发送消息</span></div><div class="line">      String msgID = rtmService.addHalfMessage(order);<span class="comment">//上面1处，实际上就是对应这里的代码段，假设这里发生异常，因为addOrder()方法添加了事务，所以addORder()执行失败。数据一致性没有问题。</span></div><div class="line">      <span class="comment">// 2.执行业务</span></div><div class="line">         。。。。。</div><div class="line">      <span class="comment">// 3.同步调用RTM，确认发送消息</span></div><div class="line">      rtmService.confirmHalfMessage(msgID);</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<ul>
<li>2发生异常，RTM持久化半消息失败。同理，因为<strong>A系统</strong>还<strong>没执行本业务</strong>（没有执行到4处），而且<strong>RTM系统</strong>也<strong>没有持久化半消息</strong>。那么此时不会产生数据不一致，<strong>那么RTM系统不需要做处理</strong>。</li>
</ul>
<ul>
<li><p>3.处发生异常，RTM持久化消息成功。但是<strong>A系统</strong>还<strong>没执行本业务</strong>（没有执行到4处），这个时候数据不一致。那么RTM<strong>提供回查机制</strong>，RTM的会<strong>有定时器定时检查RTM系统中没有确认的消息</strong>，向A系统发起请求，请求检查A系统业务状态，如果执行业务失败，那么RTM删除持久化的半消息，否则A系统执行业务成功，那么RTM确认投递消息到MQ。</p>
<ul>
<li><p>什么情况下执行2处代码成功，但是上游却报异常呢？例如A系统设定调用 rtmService.addHalfMessage(order)的超时时间是5s，（也就是说在5s内addHalfMessage方法要给我响应，否则我就抛异常），但是addHalfMessage()方法执行需要7s，那么很明显A系统执行addHalfMessage()方法就会超时，然后A系统请求超时抛异常，<strong>A系统业务执行失败</strong>。但是A系统报异常并不影响RTM继续执行addHalfMessage()的逻辑，此时过了7s，addHalfMessage()执行成功。<strong>RTM成功持久化半消息</strong>。</p>
</li>
<li><p><strong>所以我们A系统需要提供回查的接口给RTM系统调用，让给RTM系统确认半消息是删除还是投递。</strong></p>
</li>
</ul>
</li>
</ul>
<ul>
<li>4处发生异常，也就是A系统执行本地业务失败。此时RTM系统已经持久化半消息，那么数据是不一致的。<ul>
<li>怎么解决？<strong>跟解决上面的问题三一样，也是需要RTM的回查机制，进行回查A系统确定当前持久化的半消息是删除还是投递。</strong></li>
</ul>
</li>
</ul>
<ul>
<li>5处发生异常，A系统业务执行成功。但是RTM系统的半消息没有确认投递，数据不一致。<ul>
<li>解决办法，还是需要RTM系统的回查功能，<strong>进行回查A系统确定当前持久化的半消息是删除还是投递。</strong></li>
</ul>
</li>
</ul>
<ul>
<li>6处发生异常，A系统业务执行成功，RTM确认投递消息失败，数据不一致。<ul>
<li>解决办法，还是需要RTM系统的回查功能，<strong>进行回查A系统确定当前持久化的半消息是删除还是投递。</strong></li>
</ul>
</li>
</ul>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>​    我们发现，除了一二处的异常，未产生数据不一致，不需要RTM系统进行干预外，3456处的异常需要RTM系统的回查机制进行确认RTM系统已经持久化的半消息是删除 还是投递。</p>
<p>​    这个时候，我们就应该得出，RTM系统需要具备一个<strong>定时回查A系统的模块</strong></p>
<p>分析到这里，我们发现。</p>
<ul>
<li><strong>上游系统A需要提供一个查询本地业务执行结果的接口。</strong></li>
<li><strong>RTM系统提供，创建半消息接口，确认半消息接口，定时回查A系统业务功能</strong></li>
</ul>
<h2 id="RTM确认消费者成功消费流程"><a href="#RTM确认消费者成功消费流程" class="headerlink" title="RTM确认消费者成功消费流程"></a>RTM确认消费者成功消费流程</h2><p>我们上面解决了上游系统跟RTM系统交互的可靠性，那么RTM系统跟下游系统的数据一致性，在呢么解决呢？请看流程图。</p>
<p><img src="/2020/04/18/rtm数据最终一致性/image-20200426145201920.png" alt="image-20200426151609573"></p>
<p>同理我们来分析，下面这几处的如果出现了异常RTM系统是如何处理的？</p>
<ul>
<li>7处发生异常，RTM系统的<strong>确认是否消费功能</strong>，会<strong>定时检查</strong>RTM系统中已经确认可以投递的消息（也即是经过操作6之后的消息），如果存在，那么就会<strong>重新投递到MQ中</strong>。（也就是说，<strong>B系统必须保证接口服务的幂等性，因为可能存在重复消费</strong>）</li>
</ul>
<ul>
<li>8处发生异常，同理RTM系统也会通过<strong>确认是否消费功能</strong>，<strong>定时重发</strong>RTM系统中<strong>未被B系统确认消费的消息</strong>。</li>
</ul>
<ul>
<li>9处发生异常，同理RTM系统也会通过<strong>确认是否消费功能</strong>，<strong>定时重发</strong>RTM系统中<strong>未被B系统确认消费的消息</strong>。</li>
</ul>
<ul>
<li>10处发生异常，同理RTM系统也会通过<strong>确认是否消费功能</strong>，<strong>定时重发</strong>RTM系统中<strong>未被B系统确认消费的消息</strong>。</li>
</ul>
<p><strong>总而言之，如果下游B系统如果没有向RTM系统确认消费消息，那么RTM系统就会通过定时器反复向MQ重发消息。（B系统必须保证接口服务的幂等性，因为可能存在重复消费）</strong></p>
<h3 id="超时重试次数和重试时间"><a href="#超时重试次数和重试时间" class="headerlink" title="超时重试次数和重试时间"></a>超时重试次数和重试时间</h3><p><strong>但是有个问题，那就是，无限次重发么？</strong>  <strong>隔几秒发一次呢？</strong></p>
<p>关于这个问题，我们可以仿照Rocketmq的重试逻辑<strong>，重试多次次后，那么就标记消息为死亡。（类似于rocketmq的死信队列）</strong></p>
<p>​    <strong>同时重试的时间间隔，也是采取递增的方式</strong>。例如重复通知时间间隔（单位：分钟） 举例： [0, 1, 4, 10, 30, 60] 第一次立即通知，如果业务方没有返回成功，则1分钟后再次通知。如果业务方还是没有返回成功，则4分钟后再次通知（<strong>此时距离第一次通知已经过了5分钟</strong>）。以此类推。<strong>那么这里一共可以重试几次呢？7次。</strong>  <strong>七次后还是没有得到下游B系统的确认消费通知，那么就标记当前消息为死亡。</strong></p>
<h3 id="那么消息死亡后怎么办？"><a href="#那么消息死亡后怎么办？" class="headerlink" title="那么消息死亡后怎么办？"></a>那么消息死亡后怎么办？</h3><p>消息重试次数超过限制次数后，消息就会被移动到死亡表中，然后你可以在后台进行人工重试。</p>
<h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><p>  经过上面的分析，我们知道，<strong>RTM系统需要提供一个接口，给下游服务B系统，确认消费成功。</strong></p>
<p>到这里，我们RTM系统一共需要哪些接口服务，我们再总结一下：</p>
<ul>
<li><strong>上游系统A需要提供一个查询本地业务执行结果的接口。</strong></li>
<li><p><strong>RTM系统提供，创建半消息接口，确认半消息接口，定时回查A系统业务功能</strong></p>
</li>
<li><p>RTM系统提供，确认消费成功接口，定时重发消息功能，定时</p>
</li>
</ul>
<h2 id="RTM项目总结"><a href="#RTM项目总结" class="headerlink" title="RTM项目总结"></a>RTM项目总结</h2><p>​    经过上面的总结，我想你应该对于RTM系统的定位，已经流程都已经有了一个比较充分的了解。那么我们接下来就总结一下实现RTM项目所需要的功能模块。</p>
<p>​    </p>
<h3 id="项目模块"><a href="#项目模块" class="headerlink" title="项目模块"></a>项目模块</h3><blockquote>
<p><strong>首先上游系统需要提供什么？</strong></p>
</blockquote>
<p>需要提供一个可以查询本地事务结果的接口，方便RTM回查上游系统业务结果，来决定持久化在RTM的半消息是删除还是确认投递。</p>
<blockquote>
<p><strong>RTM系统需要提供什么？</strong></p>
</blockquote>
<p><strong>（1）message-lifecycle-management模块（消息生命周期管理模块）</strong></p>
<ul>
<li>创建半消息的接口 <ul>
<li>提供上游系统在进行本地业务之前进行调用添加半消息。</li>
</ul>
</li>
</ul>
<ul>
<li>确认半消息投递接口<ul>
<li>提供给上游系统在执行成功本地业务后，调用该接口，实现确认半消息为可投递，并投递消息到MQ中。</li>
</ul>
</li>
</ul>
<ul>
<li>确认消息消费接口<ul>
<li>提供给下游系统，在成功消费MQ中的消息后，调用确认消息已经消费。</li>
</ul>
</li>
</ul>
<p><strong>（2）period-check-message模块（定时检查消息模块）</strong></p>
<ul>
<li>定时回查上游系统业务处理结果接口功能<ul>
<li>RTM系统定时调用，确认是否需要投递消息到MQ</li>
</ul>
</li>
</ul>
<ul>
<li>定时检查RTM持久化的消息是否已经被下游系统消费功能<ul>
<li>RTM系统定时调用，如果没有被消费，那么重复投递到MQ中</li>
</ul>
</li>
</ul>
<ul>
<li>定时检查RTM持久化的消息是否超过投递次数（也即是重复发送到mq次数达到上限，需要标记消息为死亡）<ul>
<li>RTM系统定时调用，同时把消息移动到死亡表中</li>
</ul>
</li>
</ul>
<ul>
<li>定时检查RTM持久化的消息是否已经被下游系统消费（如果是那么把已经消费的消息从系统中移除，放到消息历史表中）<ul>
<li>RTM系统定时调用</li>
</ul>
</li>
</ul>
<p>​    <strong>也就是说，这个模块需要提供四个定时器。</strong></p>
<blockquote>
<p><strong>下游系统需要提供什么？</strong></p>
</blockquote>
<p>不需要提供什么，但是需要保证消息消费的幂等性。</p>
<h3 id="数据库表（第一版）"><a href="#数据库表（第一版）" class="headerlink" title="数据库表（第一版）"></a><strong>数据库表（第一版）</strong></h3><p>第一版，因为时间关系，暂时没有提供前台界面，进行管理消息，后面有时间了，会加上去。</p>
<blockquote>
<p><strong>（1）数据库rtm</strong></p>
</blockquote>
<p>创建数据库rtm</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">CREATE DATABASE /*!32312 IF NOT EXISTS*/`rtm` /*!40100 DEFAULT CHARACTER SET utf8mb4 */;</div><div class="line"></div><div class="line">USE `rtm`;</div></pre></td></tr></table></figure>
<blockquote>
<p><strong>（2）数据库表</strong></p>
</blockquote>
<p><strong>消息表</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> t_k_message;</div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_k_message</div><div class="line">(</div><div class="line">   msg_id               <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">not</span> <span class="literal">null</span> <span class="keyword">comment</span> <span class="string">'id'</span>,</div><div class="line">   msg_name             <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息所属业务'</span>,</div><div class="line">   topic                <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息所属主题(看对接mq使用)'</span>,</div><div class="line">   quene_name           <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息所属队列(看对接mq使用)'</span>,</div><div class="line">   msg_content          <span class="built_in">varchar</span>(<span class="number">300</span>) <span class="keyword">comment</span> <span class="string">'消息内容'</span>,</div><div class="line">   msg_status           <span class="built_in">varchar</span>(<span class="number">7</span>) <span class="keyword">comment</span> <span class="string">'消息状态，0-待确认，1-已确认发送中，2-已消费'</span>,</div><div class="line">   msg_d_status         <span class="built_in">varchar</span>(<span class="number">7</span>) <span class="keyword">comment</span> <span class="string">'消息是否死亡，0-正常，1-已死亡'</span>,</div><div class="line">   retry_counts         <span class="built_in">varchar</span>(<span class="number">20</span>) <span class="keyword">comment</span> <span class="string">'重试次数'</span>,</div><div class="line">   check_url            <span class="built_in">varchar</span>(<span class="number">300</span>) <span class="keyword">comment</span> <span class="string">'消息回查地址'</span>,</div><div class="line">   check_timeout        <span class="built_in">varchar</span>(<span class="number">10</span>) <span class="keyword">comment</span> <span class="string">'消息回查超时时间'</span>,</div><div class="line">   check_duration       <span class="built_in">varchar</span>(<span class="number">10</span>) <span class="keyword">comment</span> <span class="string">'消息回查周期时间，消息未确认时在这时间内需要回查'</span>,</div><div class="line">   create_msg_uid       <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息创建人id'</span>,</div><div class="line">   create_msg_time      datetime <span class="keyword">comment</span> <span class="string">'消息创建时间'</span>,</div><div class="line">   update_msg_uid       <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息更新人id'</span>,</div><div class="line">   update_msg_time      datetime <span class="keyword">comment</span> <span class="string">'消息更新时间'</span>,</div><div class="line">   confirm_msg_time     datetime <span class="keyword">comment</span> <span class="string">'消息确认投递时间'</span>,</div><div class="line">   resend_msg_uid       <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息重发人id'</span>,</div><div class="line">   resend_msg_time      datetime <span class="keyword">comment</span> <span class="string">'消息重发时间'</span>,</div><div class="line">   primary <span class="keyword">key</span> (msg_id)</div><div class="line">)<span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8mb4;</div><div class="line"></div><div class="line"><span class="keyword">alter</span> <span class="keyword">table</span> t_k_message <span class="keyword">comment</span> <span class="string">'消息表'</span>;</div></pre></td></tr></table></figure>
<p><strong>确认消费消息表（历史表）也就是保存的是msg_status==2的消息</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> t_k_message_consumed;</div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_k_message_consumed</div><div class="line">(</div><div class="line">   msg_id               <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">not</span> <span class="literal">null</span> <span class="keyword">comment</span> <span class="string">'id'</span>,</div><div class="line">   msg_name             <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息所属业务'</span>,</div><div class="line">   topic                <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息所属主题(看对接mq使用)'</span>,</div><div class="line">   quene_name           <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息所属队列(看对接mq使用)'</span>,</div><div class="line">   msg_content          <span class="built_in">varchar</span>(<span class="number">300</span>) <span class="keyword">comment</span> <span class="string">'消息内容'</span>,</div><div class="line">   msg_status           <span class="built_in">varchar</span>(<span class="number">7</span>) <span class="keyword">comment</span> <span class="string">'消息状态，0-待确认，1-已确认发送中，2-已消费'</span>,</div><div class="line">   msg_d_status         <span class="built_in">varchar</span>(<span class="number">7</span>) <span class="keyword">comment</span> <span class="string">'消息是否死亡，0-正常，1-已死亡'</span>,</div><div class="line">   retry_counts         <span class="built_in">varchar</span>(<span class="number">20</span>) <span class="keyword">comment</span> <span class="string">'重试次数'</span>,</div><div class="line">   check_url            <span class="built_in">varchar</span>(<span class="number">300</span>) <span class="keyword">comment</span> <span class="string">'消息回查地址'</span>,</div><div class="line">   check_timeout        <span class="built_in">varchar</span>(<span class="number">10</span>) <span class="keyword">comment</span> <span class="string">'消息回查超时时间'</span>,</div><div class="line">   check_duration       <span class="built_in">varchar</span>(<span class="number">10</span>) <span class="keyword">comment</span> <span class="string">'消息回查周期时间，消息未确认时在这时间内需要回查'</span>,</div><div class="line">   create_msg_uid       <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息创建人id'</span>,</div><div class="line">   create_msg_time      datetime <span class="keyword">comment</span> <span class="string">'消息创建时间'</span>,</div><div class="line">   update_msg_uid       <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息更新人id'</span>,</div><div class="line">   update_msg_time      datetime <span class="keyword">comment</span> <span class="string">'消息更新时间'</span>,</div><div class="line">   confirm_msg_time     datetime <span class="keyword">comment</span> <span class="string">'消息确认投递时间'</span>,</div><div class="line">   resend_msg_uid       <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息重发人id'</span>,</div><div class="line">   resend_msg_time      datetime <span class="keyword">comment</span> <span class="string">'消息重发时间'</span>,</div><div class="line">   primary <span class="keyword">key</span> (msg_id)</div><div class="line">)<span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8mb4;</div><div class="line"></div><div class="line"><span class="keyword">alter</span> <span class="keyword">table</span> t_k_message <span class="keyword">comment</span> <span class="string">'已消费消息历史表'</span>;</div></pre></td></tr></table></figure>
<p><strong>超时死亡消息表 - 保存的是msg_d_status==1的消息</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> t_k_dead_message;</div><div class="line"><span class="keyword">create</span> <span class="keyword">table</span> t_k_dead_message</div><div class="line">(</div><div class="line">   msg_id               <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">not</span> <span class="literal">null</span> <span class="keyword">comment</span> <span class="string">'id'</span>,</div><div class="line">   msg_name             <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息所属业务'</span>,</div><div class="line">   topic                <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息所属主题(看对接mq使用)'</span>,</div><div class="line">   quene_name           <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息所属队列(看对接mq使用)'</span>,</div><div class="line">   msg_content          <span class="built_in">varchar</span>(<span class="number">300</span>) <span class="keyword">comment</span> <span class="string">'消息内容'</span>,</div><div class="line">   msg_status           <span class="built_in">varchar</span>(<span class="number">7</span>) <span class="keyword">comment</span> <span class="string">'消息状态，0-待确认，1-已确认发送中，2-已消费'</span>,</div><div class="line">   msg_d_status         <span class="built_in">varchar</span>(<span class="number">7</span>) <span class="keyword">comment</span> <span class="string">'消息是否死亡，0-正常，1-已死亡'</span>,</div><div class="line">   retry_counts         <span class="built_in">varchar</span>(<span class="number">20</span>) <span class="keyword">comment</span> <span class="string">'重试次数'</span>,</div><div class="line">   check_url            <span class="built_in">varchar</span>(<span class="number">300</span>) <span class="keyword">comment</span> <span class="string">'消息回查地址'</span>,</div><div class="line">   check_timeout        <span class="built_in">varchar</span>(<span class="number">10</span>) <span class="keyword">comment</span> <span class="string">'消息回查超时时间'</span>,</div><div class="line">   check_duration       <span class="built_in">varchar</span>(<span class="number">10</span>) <span class="keyword">comment</span> <span class="string">'消息回查周期时间，消息未确认时在这时间内需要回查'</span>,</div><div class="line">   create_msg_uid       <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息创建人id'</span>,</div><div class="line">   create_msg_time      datetime <span class="keyword">comment</span> <span class="string">'消息创建时间'</span>,</div><div class="line">   update_msg_uid       <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息更新人id'</span>,</div><div class="line">   update_msg_time      datetime <span class="keyword">comment</span> <span class="string">'消息更新时间'</span>,</div><div class="line">   confirm_msg_time     datetime <span class="keyword">comment</span> <span class="string">'消息确认投递时间'</span>,</div><div class="line">   resend_msg_uid       <span class="built_in">varchar</span>(<span class="number">70</span>) <span class="keyword">comment</span> <span class="string">'消息重发人id'</span>,</div><div class="line">   resend_msg_time      datetime <span class="keyword">comment</span> <span class="string">'消息重发时间'</span>,</div><div class="line">   primary <span class="keyword">key</span> (msg_id)</div><div class="line">)<span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span> <span class="keyword">DEFAULT</span> <span class="keyword">CHARSET</span>=utf8mb4;</div><div class="line"></div><div class="line"><span class="keyword">alter</span> <span class="keyword">table</span> t_k_message <span class="keyword">comment</span> <span class="string">'消息表'</span>;</div></pre></td></tr></table></figure>
<h3 id="项目代码模块结构"><a href="#项目代码模块结构" class="headerlink" title="项目代码模块结构"></a>项目代码模块结构</h3><p><img src="/2020/04/18/rtm数据最终一致性/image-20200428162644118.png" alt="image-20200428162644118"></p>
<h3 id="RTM项目使用环境"><a href="#RTM项目使用环境" class="headerlink" title="RTM项目使用环境"></a>RTM项目使用环境</h3><blockquote>
<p><strong>依赖环境</strong></p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:left">环境</th>
<th style="text-align:left">版本</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">JDK</td>
<td style="text-align:left">1.8</td>
<td></td>
</tr>
<tr>
<td style="text-align:left">MySQL</td>
<td style="text-align:left">5.7.25</td>
<td></td>
</tr>
<tr>
<td style="text-align:left">Zookeeper</td>
<td style="text-align:left">3.4.14</td>
<td></td>
</tr>
<tr>
<td style="text-align:left">kafka</td>
<td style="text-align:left">5.15.6</td>
<td>因为原先上下游系统使用的是kafka，所以这里接入的就是kafka（如果是其他的mq则接入你自己的mq即可） -可选</td>
</tr>
<tr>
<td style="text-align:left">Maven</td>
<td style="text-align:left">3.3.9</td>
</tr>
</tbody>
</table>
<h1 id="RTM代码实现"><a href="#RTM代码实现" class="headerlink" title="RTM代码实现"></a>RTM代码实现</h1><h2 id="父工程-rtm"><a href="#父工程-rtm" class="headerlink" title="父工程 rtm"></a>父工程 rtm</h2><h3 id="接口层-rtm-api"><a href="#接口层-rtm-api" class="headerlink" title="接口层 rtm-api"></a>接口层 rtm-api</h3><p>保存rtm，对外暴露的接口</p>
<p><strong>依赖 rtm-pojo</strong></p>
<p>实现三个接口：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="keyword">package</span> com.kingge.rtm.api;</div><div class="line"></div><div class="line"><span class="keyword">import</span> com.kingge.rtm.pojo.TKMessage;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * <span class="doctag">@program</span>: rtm</span></div><div class="line"><span class="comment"> * <span class="doctag">@description</span>: rtm暴露接口，提供上下游服务调用</span></div><div class="line"><span class="comment"> * <span class="doctag">@author</span>: JeremyKing</span></div><div class="line"><span class="comment"> * <span class="doctag">@create</span>: 2020-04-27 11:26</span></div><div class="line"><span class="comment"> **/</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IRtmService</span> </span>&#123;</div><div class="line"></div><div class="line"></div><div class="line">     <span class="comment">/**</span></div><div class="line"><span class="comment">     * <span class="doctag">@Description</span>: 创建半消息</span></div><div class="line"><span class="comment">     * <span class="doctag">@Param</span>: 消息实体</span></div><div class="line"><span class="comment">     * <span class="doctag">@return</span>: 消息id</span></div><div class="line"><span class="comment">     * <span class="doctag">@Author</span>: JeremyKing</span></div><div class="line"><span class="comment">     * <span class="doctag">@Date</span>: 2020/4/27 0027</span></div><div class="line"><span class="comment">     */</span></div><div class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">addHalfMessage</span><span class="params">(TKMessage message)</span></span>;</div><div class="line"></div><div class="line"></div><div class="line">     <span class="comment">/**</span></div><div class="line"><span class="comment">     * <span class="doctag">@Description</span>: 根据消息id，确认并发送半消息到mq</span></div><div class="line"><span class="comment">     * <span class="doctag">@Param</span>: 消息id</span></div><div class="line"><span class="comment">     * <span class="doctag">@return</span>: void</span></div><div class="line"><span class="comment">     * <span class="doctag">@Author</span>: JeremyKing</span></div><div class="line"><span class="comment">     * <span class="doctag">@Date</span>: 2020/4/27 0027</span></div><div class="line"><span class="comment">     */</span></div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">submitAndSendHalfMessage</span><span class="params">(String msg_id)</span></span>;</div><div class="line"></div><div class="line"></div><div class="line">     <span class="comment">/**</span></div><div class="line"><span class="comment">      * <span class="doctag">@Description</span>: 根据消息id，确认消费消息</span></div><div class="line"><span class="comment">      * <span class="doctag">@Param</span>: 消息id</span></div><div class="line"><span class="comment">      * <span class="doctag">@return</span>: void</span></div><div class="line"><span class="comment">      * <span class="doctag">@Author</span>: JeremyKing</span></div><div class="line"><span class="comment">      * <span class="doctag">@Date</span>: 2020/4/27 0027</span></div><div class="line"><span class="comment">      */</span></div><div class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">confirmConsumeMessage</span><span class="params">(String msg_id)</span></span>;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="实体类-rtm-pojo"><a href="#实体类-rtm-pojo" class="headerlink" title="实体类 rtm-pojo"></a>实体类 rtm-pojo</h3><p>保存rtm项目的实体类</p>
<p>根据mybatis-reverse，逆向生成数据库表对应的实体类和mapper、xml文件。</p>
<h3 id="工具层-rtm-common"><a href="#工具层-rtm-common" class="headerlink" title="工具层 rtm-common"></a>工具层 rtm-common</h3><h3 id="消息生命周期管理服务-rtm-mlm"><a href="#消息生命周期管理服务-rtm-mlm" class="headerlink" title="消息生命周期管理服务 rtm-mlm"></a>消息生命周期管理服务 rtm-mlm</h3><p><strong>message-lifecycle-management模块（消息生命周期管理模块）</strong> -  的简写，mlm</p>
<h3 id="定时检查消息模块-rtm-pcm"><a href="#定时检查消息模块-rtm-pcm" class="headerlink" title="定时检查消息模块 rtm-pcm"></a>定时检查消息模块 rtm-pcm</h3><p>period-check-message模块（定时检查消息模块） - 简写，pcm</p>
<h2 id="github地址"><a href="#github地址" class="headerlink" title="github地址"></a>github地址</h2><p><a href="https://github.com/JeremyKinge/rtm.git" target="_blank" rel="external">https://github.com/JeremyKinge/rtm.git</a></p>
<h1 id="怎么使用rtm"><a href="#怎么使用rtm" class="headerlink" title="怎么使用rtm"></a>怎么使用rtm</h1><p>目前rtm只提供了，dubbo版本，那么也就是在使用时，你需要配置dubbo环境。</p>
<h2 id="上游系统怎么使用？"><a href="#上游系统怎么使用？" class="headerlink" title="上游系统怎么使用？"></a>上游系统怎么使用？</h2><p>只需要在业务类中，通过dubbo的方式注入rtm服务即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">import com.alibaba.dubbo.config.annotation.Reference;</div><div class="line">import com.kingge.rtm.api.IRtmService;</div><div class="line"></div><div class="line">@Reference</div><div class="line">IRtmService iRtmService;</div></pre></td></tr></table></figure>
<p>例如你的业务逻辑如下：订单支付后，需要给用户增加积分</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="meta">@Transactional</span>(rollbackFor = RuntimeException.class)<span class="comment">//开启事务</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">payOrder</span><span class="params">(Order order)</span> </span>&#123;</div><div class="line">      <span class="comment">// 1.调用RMQ，创建预发送消息</span></div><div class="line">       TKMessage message = <span class="keyword">new</span> TKMessage();</div><div class="line">      String msgID = iRtmService.addHalfMessage(TKMessage message);</div><div class="line">      <span class="comment">// 2.执行业务</span></div><div class="line">         。。。。。</div><div class="line">      <span class="comment">// 3.异步调用RTM，确认发送消息</span></div><div class="line">      iRtmService.submitAndSendHalfMessage(message.getMsgid());</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h2 id="下游系统怎么用？"><a href="#下游系统怎么用？" class="headerlink" title="下游系统怎么用？"></a>下游系统怎么用？</h2><p>根据上面的例子，下游会去mq订阅积分消息，那么需要在处理订阅的消息方法中。下游服务在处理完消息后，调用：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">iRtmService.confirmConsumeMessage(message.getMsgid());</div></pre></td></tr></table></figure>
<p>完成确认消息已经消费即可。</p>
<p><strong>需要注意的是：下游消费服务时，需要注意保证消息幂等性，因为可能因为网络等等原因，可能rtm会重发消息。</strong></p>
<h1 id="RTM项目亮点"><a href="#RTM项目亮点" class="headerlink" title="RTM项目亮点"></a>RTM项目亮点</h1><p>0.首先是给没有提供事务消息机制的mq提供了事务消息的方式</p>
<p>1.超时重试机制，类似rocketmq，根据时间递增间隔重试</p>
<p>2.死亡消息，可以在后台进行重发，手动干预</p>
<p>3.消息重试，采取线程池的方式，根据<strong>线程池的coresize大小（避免线程递增到maxsize）</strong>，去数据库中<strong>取相应数量</strong>需要重复发送搭到mq的消息。</p>
<p>4.重发消息时，从重发次数大到小进行重发（<strong>例如，RTM支持的最大重试次数是7。那么就先查重发次数是6的消息，处理完后。再接着查重发次数是5的消息</strong>），保证了优先处理快要到重试次数上限的消息，优先处理。</p>
<h2 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h2><p>​    也就是说rtm系统 在兼有rocketmq事务消息的同时，能够<strong>保证下游系统一定能消费消息（提供消费失败一定次数和时间间隔重试以及记录超过重试次数的消息）</strong>，从而保证了数据的最终一致性，同时提供管理界面，管理已经超过重发次数上限的消息，重新发送。</p>
<p>​    所以说，当你的项目架构在最初的技术选型时，并没有使用rocketmq，那么又想保证数据最终一致性，那么就可以引入rtm系统，非常方便快捷。</p>
<h1 id="RTM项目存在的缺点"><a href="#RTM项目存在的缺点" class="headerlink" title="RTM项目存在的缺点"></a>RTM项目存在的缺点</h1><p>1.<strong>目前没有支持多种</strong>mq的版本（现在只是实现了对接kafka版本）</p>
<p>2.分布式集群的搭建测试</p>
<p>3.项目模块的拆分还不够清晰，例如rtm-pcm模块，可以拆分成两个模块，一个是rtm-pcm-api模块（提供接口，他的实现类在rtm-pcm中），一个是rtm-pcm模块（真正的业务放到这里）</p>
<p>4.rtm-pcm或者rtm-web 模块过于依赖rtm-mlm模块，导致前两者，都需要在application.yaml中配置跟rtm-mlm相同的数据库数据源信息（因为前两者使用了rtm-mlm的mapper调用数据库。）。后面考虑由rtm-mlm提供数据库操作接口，让前两者通过dubbo的方式调用mapper调用数据库。 而不用直接使用rtm-mlm的mapper去调用。</p>
<p>在前两者移除 rtm-mlm依赖，依赖rtm-mlm-api</p>
<p>也就是说在增加一个rtm-mlm-api模块。里面提供操作数据库的接口，rtm-mlm实现接口。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;基础概念&quot;&gt;&lt;a href=&quot;#基础概念&quot; class=&quot;headerlink&quot; title=&quot;基础概念&quot;&gt;&lt;/a&gt;基础概念&lt;/h1&gt;&lt;h2 id=&quot;为什么使用消息队列？&quot;&gt;&lt;a href=&quot;#为什么使用消息队列？&quot; class=&quot;headerlink&quot; titl
    
    </summary>
    
      <category term="开源项目" scheme="http://kingge.top/categories/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"/>
    
    
      <category term="开源项目" scheme="http://kingge.top/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"/>
    
      <category term="事务消息" scheme="http://kingge.top/tags/%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/"/>
    
      <category term="kafka" scheme="http://kingge.top/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>king-spring</title>
    <link href="http://kingge.top/2019/06/12/kingspring%E6%80%BB%E7%BB%93%E6%96%87%E6%A1%A3/"/>
    <id>http://kingge.top/2019/06/12/kingspring总结文档/</id>
    <published>2019-06-12T02:21:59.000Z</published>
    <updated>2020-05-04T01:32:48.237Z</updated>
    
    <content type="html"><![CDATA[<h1 id="编写king-spring的目的"><a href="#编写king-spring的目的" class="headerlink" title="编写king-spring的目的"></a>编写king-spring的目的</h1><p>旨在能够了解spring整个架构核心的脉络，从而更好的理解spring的架构精神和底层原理</p>
<p><strong>A tiny IoC container refer to Spring</strong></p>
<h1 id="king-spring的结构逻辑"><a href="#king-spring的结构逻辑" class="headerlink" title="king-spring的结构逻辑"></a>king-spring的结构逻辑</h1><p><img src="/2019/06/12/kingspring总结文档/image-20200503162236006.png" alt="image-20200503162330790"></p>
<p>可以看到整个spring的简化版逻辑就是这样子的，核心就是<strong>IOC/DI，MVC。</strong></p>
<p>那么我们接下来就模拟spring实现我们的king-spring</p>
<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="配置阶段-做准备工作"><a href="#配置阶段-做准备工作" class="headerlink" title="配置阶段-做准备工作"></a>配置阶段-做准备工作</h2><h3 id="配置web-xml和配置控制类-KDispatcherServlet"><a href="#配置web-xml和配置控制类-KDispatcherServlet" class="headerlink" title="配置web.xml和配置控制类 - KDispatcherServlet"></a>配置web.xml和配置控制类 - KDispatcherServlet</h3><blockquote>
<p><strong>创建web请求控制类 - KDispatcherServlet</strong></p>
</blockquote>
<p><img src="/2019/06/12/kingspring总结文档/image-20200503165359658.png" alt="image-20200503165359658"></p>
<blockquote>
<p><strong>配置到web.xml中</strong></p>
</blockquote>
<figure class="highlight xml"><table><tr><td class="code"><pre><div class="line"><span class="meta">&lt;!DOCTYPE web-app PUBLIC</span></div><div class="line"><span class="meta"> "-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN"</span></div><div class="line"><span class="meta"> "http://java.sun.com/dtd/web-app_2_3.dtd" &gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;<span class="name">web-app</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">display-name</span>&gt;</span>king-srping project<span class="tag">&lt;/<span class="name">display-name</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;<span class="name">servlet</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>kc<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">servlet-class</span>&gt;</span>com.kingge.spring.web.servlet.KDispatcherServlet<span class="tag">&lt;/<span class="name">servlet-class</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">init-param</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">param-name</span>&gt;</span>contextConfigLocation<span class="tag">&lt;/<span class="name">param-name</span>&gt;</span></div><div class="line">      <span class="tag">&lt;<span class="name">param-value</span>&gt;</span>classpath:application.properties<span class="tag">&lt;/<span class="name">param-value</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">init-param</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">load-on-startup</span>&gt;</span>1<span class="tag">&lt;/<span class="name">load-on-startup</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">servlet</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;<span class="name">servlet-mapping</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>kc<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/*<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">servlet-mapping</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;/<span class="name">web-app</span>&gt;</span></div></pre></td></tr></table></figure>
<h3 id="配置application-properties"><a href="#配置application-properties" class="headerlink" title="配置application.properties"></a>配置application.properties</h3><p>这里采用的是properties的方式进行spring项目的配置（后期可以能会扩展成xml方式）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">scanPackage=com.kingge.spring</div></pre></td></tr></table></figure>
<p>目前就配置一项，项目扫描根目录</p>
<h3 id="实现扫描注解"><a href="#实现扫描注解" class="headerlink" title="实现扫描注解"></a>实现扫描注解</h3><p>​    我们应该知道，spring是通过校验某个bean是否加了特定的注解，从而决定是否加入到IOC容器中，也即是：<strong>bean的生命周期管理是否托管给spring。</strong></p>
<p>​    常用的注解有这几个：@Component、@Service、@Controller、@Repository，后三个实际上都是基于Component的实现，所以他们的效果等同@Component，但是后三个出现的目的是<strong>为了标识业务层次</strong>，所以在使用过程中，我们最好是按照不同的业务层次使用不同的注解，<strong>而且在spring官网上提到，后面这三个注解在以后可能还会赋予其他的含义。</strong></p>
<p>逐层分为两个层次(包)：</p>
<p> <img src="/2019/06/12/kingspring总结文档/image-20200503164323048.png" alt="image-20200503164323048"></p>
<p><strong>业务层和web控制层</strong></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>​    做完这一步，我们基本把king-spring的整体架构搭建出来了，而且某些注解类和控制类也已经建立，但是某些细节实现还是没有完成，例如KDispatcherServlet内部还没有实现。</p>
<p>​    <strong>接下来就实现，具体的解析配置信息（application.properties）</strong></p>
<h2 id="初始化IOC容器-解析配置类"><a href="#初始化IOC容器-解析配置类" class="headerlink" title="初始化IOC容器-解析配置类"></a>初始化IOC容器-解析配置类</h2><p><strong>首先我们把这段代码逻辑是声明在了KDispatcherServlet的init方法中，也即是项目启动过程中就会去执行</strong></p>
<p><strong>这个过程分为四步</strong></p>
<h3 id="根据web-xml配置的contextConfigLocation解析配置类"><a href="#根据web-xml配置的contextConfigLocation解析配置类" class="headerlink" title="根据web.xml配置的contextConfigLocation解析配置类"></a>根据web.xml配置的contextConfigLocation解析配置类</h3><figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="comment">//1.加载配置文件</span></div><div class="line">    loadConfig(config.getInitParameter(CONFIG_PROPERTIES_LOCATION));<span class="comment">//CONFIG_PROPERTIES_LOCATION的值等于"contextConfigLocation"</span></div><div class="line"></div><div class="line"><span class="comment">//2. 将配置类映射到Properties中</span></div><div class="line"><span class="comment">//保存解析application.properties 的配置文件信息</span></div><div class="line">    <span class="keyword">private</span> Properties contextConfig = <span class="keyword">new</span> Properties();</div></pre></td></tr></table></figure>
<h3 id="根据配置类获取扫描包的路径"><a href="#根据配置类获取扫描包的路径" class="headerlink" title="根据配置类获取扫描包的路径"></a>根据配置类获取扫描包的路径</h3><figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="comment">//2.根据配置文件配置的扫描路径，扫描类</span></div><div class="line">    scanPackage(contextConfig.getProperty(<span class="string">"scanPackages"</span>));</div><div class="line"><span class="comment">//经过这个方法会把递归把包路径下的所有类都放到下面的list中</span></div><div class="line"></div><div class="line">    <span class="comment">//3.保存扫描到的所有bean的全类名（还未过滤，可能包含不需要注入到ioc容器的bean）</span></div><div class="line">    <span class="keyword">private</span> List&lt;String&gt; classNames = <span class="keyword">new</span> ArrayList&lt;String&gt;();</div></pre></td></tr></table></figure>
<p>需要注意的是，扫描到的类，可能存在某些类需要过滤掉，并不是都需要加到IOC容器中，判断是否加入IOC容器中的依据是：<strong>是否被我们上面定义的注解所修饰</strong></p>
<h3 id="解析需要注入到ioc容器中的bean"><a href="#解析需要注入到ioc容器中的bean" class="headerlink" title="解析需要注入到ioc容器中的bean"></a>解析需要注入到ioc容器中的bean</h3><figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="comment">//3.筛选上面扫描的所有类，将标有注入注解的类，放到IOC容器中</span></div><div class="line">        <span class="comment">//类似于解析xml的bean标签</span></div><div class="line">            initContext();</div><div class="line"></div><div class="line"><span class="comment">//最终根据注解筛选出需要放到IOC容器中的bean。classNames经过了过滤后得到的bean放入下面的map中</span></div><div class="line"><span class="keyword">private</span> Map&lt;String,Object&gt; beanDefinitionMap = <span class="keyword">new</span> ConcurrentHashMap&lt;String,Object&gt;(<span class="number">256</span>);</div></pre></td></tr></table></figure>
<h3 id="解决IOC容器中bean-的依赖问题"><a href="#解决IOC容器中bean-的依赖问题" class="headerlink" title="解决IOC容器中bean 的依赖问题"></a>解决IOC容器中bean 的依赖问题</h3><p><strong>也就是DI依赖注入阶段</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="comment">//4.解析IOC容器中的bean，并设置依赖 - DI阶段</span></div><div class="line">    diBean();</div></pre></td></tr></table></figure>
<h3 id="控制层的url绑定处理方法"><a href="#控制层的url绑定处理方法" class="headerlink" title="控制层的url绑定处理方法"></a>控制层的url绑定处理方法</h3><p>​    <strong>实际上就是处理IOC容器中被@KController注解修饰的类，然后再根据@KRequestMapping获取映射的url，然后再绑定url对应的处理方法。</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="comment">//5.初始化handlerMapping，解析所有控制类的url地址和相关联的处理method</span></div><div class="line">    initHandlerMapping();<span class="comment">//解析出来的映射关系，保存到下面的handlerMapping中</span></div><div class="line"></div><div class="line">    <span class="comment">//保存控制层，url跟处理方法的映射关系</span></div><div class="line">    <span class="keyword">private</span> Map&lt;String,Method&gt; handlerMapping = <span class="keyword">new</span> ConcurrentHashMap&lt;String,Method&gt;();</div></pre></td></tr></table></figure>
<h2 id="处理请求"><a href="#处理请求" class="headerlink" title="处理请求"></a>处理请求</h2><p><strong>实际上就是根据请求的url，然后从上面的handlerMapping中，获取url对应的处理方法，然后执行，返回结果。</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="comment">//客户端处理请求</span></div><div class="line">doDispatcher(req, resp);</div></pre></td></tr></table></figure>
<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>​    <strong>IOC容器</strong>在上面我们是使用<code>private Map&lt;String,Object&gt; beanDefinitionMap = new ConcurrentHashMap&lt;String,Object&gt;(256);</code>  <strong>key是beanName（默认是类名首字母小写），value是bean的实例</strong></p>
<p>​    </p>
<p>​    url映射关系我们使用的是<strong>handlerMapping</strong>，他的类型是：<code>private Map&lt;String,Method&gt; handlerMapping = new ConcurrentHashMap&lt;String,Method&gt;();</code>     <strong>key就是请求url，value就是url映射的method</strong></p>
<blockquote>
<p><strong>自我实现的king-spring 使用了那些设计模式</strong></p>
</blockquote>
<p>模板模式：init方法，把初始化分为了多个步骤，每个步骤自己实现自己的逻辑</p>
<p>策略模式：根据注解类型选择不同的操作方式。</p>
<p>委托模式：doGet()、doPost().</p>
<p>单例模式：Constants类</p>
<blockquote>
<p><strong>项目地址</strong></p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">https://github.com/JeremyKinge/king-spring.git //项目地址</div></pre></td></tr></table></figure>
<h1 id="回过头来查看spring源码"><a href="#回过头来查看spring源码" class="headerlink" title="回过头来查看spring源码"></a>回过头来查看spring源码</h1><h2 id="spring的ioc容器怎么实现的呢？跟我们自己的实现有何不同"><a href="#spring的ioc容器怎么实现的呢？跟我们自己的实现有何不同" class="headerlink" title="spring的ioc容器怎么实现的呢？跟我们自己的实现有何不同"></a>spring的ioc容器怎么实现的呢？跟我们自己的实现有何不同</h2><p>通过查看我们发现，spring在启动时，假设是注解版本那么，使用的context是</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line">AnnotationConfigApplicationContext context</div><div class="line">      = <span class="keyword">new</span> AnnotationConfigApplicationContext();</div><div class="line">那么也就意味着，最终扫描包下的类，然后放到IOC容器中的逻辑肯定在其中</div></pre></td></tr></table></figure>
<p>最后跟踪到，DefaultListableBeanFactory的registerBeanDefinition()方法，最后调用了<code>this.beanDefinitionMap.put(beanName, beanDefinition);</code></p>
<p>也就是说BeanDefinitionMap就是我们需要查找的IOC容器</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">/** Map of bean definition objects, keyed by bean name */</div><div class="line">private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;&gt;(256);</div></pre></td></tr></table></figure>
<p>可以看到，他的key跟我们的定义的一样，也是通过beanName方式，<strong>但是value跟我们却不同</strong>。</p>
<blockquote>
<p><strong>BeanDefinition</strong></p>
</blockquote>
<p>​    他实际上就是spring对于注解的描述类。我们还记不记得，在使用@Service这样的注解时，我们是可以配置作用域，生命周期，是否懒加载等等信息。那么这些信息就是保存在BeanDefinition中。</p>
<p>​    换句话说，spring的BeanDefinition实现，更加全面，而且更加面对对对象。 <strong>我们上面的做法是直接把实例化的bean当做value，那么这样势必会造成内存的浪费。</strong></p>
<h2 id="spring的handlermapping是怎么实现的呢？"><a href="#spring的handlermapping是怎么实现的呢？" class="headerlink" title="spring的handlermapping是怎么实现的呢？"></a>spring的handlermapping是怎么实现的呢？</h2><p>那么这个属性的定义肯定是在DispatcherServlet中的。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="comment">/** List of HandlerMappings used by this servlet */</span></div><div class="line"><span class="meta">@Nullable</span></div><div class="line"><span class="keyword">private</span> List&lt;HandlerMapping&gt; handlerMappings;</div></pre></td></tr></table></figure>
<p>可以看到spring他的实现，是一个list，值得类型是HandlerMapping，在handlerMapping维护URl跟method 的映射关系。</p>
<p><strong>我们的实现是map数据结构，key是url，value是url映射的method</strong></p>
<p>那为什么不用我们的map结构呢？map架构取数据不是更加清晰么？</p>
<p>我觉得spring应该是考虑到冗余原则，因为如果用map方式，那么key的值就只能是url。为了保证能够获取更多的信息，那么就封装成对象，然后使用list保存 - <strong>满足单一原则</strong>，就是我所有信息都可以用一个对象保存，干嘛还要分开成key-value的形式呢？。<strong>其实我觉得map也很不错，选择不同而已</strong></p>
<p>那为什么不用map<string,handlermapping>呢？其实也可以。</string,handlermapping></p>
<h1 id="目前存在的缺点"><a href="#目前存在的缺点" class="headerlink" title="目前存在的缺点"></a>目前存在的缺点</h1><p><strong>1.在doDispatcher方法中，调用处理方法时，请求参数的拼接是静态写死的，后期需要修改成动态拼接</strong></p>
<h1 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h1><h2 id="spring中的bean是线程安全的么？"><a href="#spring中的bean是线程安全的么？" class="headerlink" title="spring中的bean是线程安全的么？"></a>spring中的bean是线程安全的么？</h2><p>​    首先，我们要知道，spring的bean是在spring启动时，通过反射实例化出来，然后放到IOC容器中的，也就是说spring中的bean只是帮你管理而已，并没有做什么增强或者修改工作。</p>
<p>​    也就是说，bean的是不是线程安全的，那么取决于你对于bean的实现，跟spring没有任何关系。</p>
<p> 所以这个思考题的答案是：spring中的bean是否线程安全，是这个bean的问题，如果你在bean中有操作共享资源的操作，那么就有线程安全的问题，如果没有那么就是跟线程安全的。所以bean是否是线程安全的取决于bean自身的实现，而不是spring的问题。</p>
<p>​    <strong>虽然IOC容器是基于chm实现的。</strong> 应该说，spring存取bean的操作是线程安全的。这样的因为会比较好点。</p>
<h2 id="spring中的bean什么时候被回收"><a href="#spring中的bean什么时候被回收" class="headerlink" title="spring中的bean什么时候被回收"></a>spring中的bean什么时候被回收</h2><p>这个跟bean的生命周期 有关系，spring的bean生命周期有：singleton、prototype、request、session。</p>
<p>所以什么时候被回收，取决于，你设定的生命周期类型</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;编写king-spring的目的&quot;&gt;&lt;a href=&quot;#编写king-spring的目的&quot; class=&quot;headerlink&quot; title=&quot;编写king-spring的目的&quot;&gt;&lt;/a&gt;编写king-spring的目的&lt;/h1&gt;&lt;p&gt;旨在能够了解spring整个
    
    </summary>
    
      <category term="king-spring" scheme="http://kingge.top/categories/king-spring/"/>
    
    
      <category term="spring" scheme="http://kingge.top/tags/spring/"/>
    
      <category term="spring源码" scheme="http://kingge.top/tags/spring%E6%BA%90%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>Hessian 多系统访问</title>
    <link href="http://kingge.top/2019/06/01/Hessian%20%E5%A4%9A%E7%B3%BB%E7%BB%9F%E8%AE%BF%E9%97%AE/"/>
    <id>http://kingge.top/2019/06/01/Hessian 多系统访问/</id>
    <published>2019-06-01T04:58:04.630Z</published>
    <updated>2017-08-31T09:44:24.038Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>项目全局异常处理</title>
    <link href="http://kingge.top/2019/05/11/%E9%A1%B9%E7%9B%AE%E5%85%A8%E5%B1%80%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/"/>
    <id>http://kingge.top/2019/05/11/项目全局异常处理/</id>
    <published>2019-05-11T02:21:59.000Z</published>
    <updated>2019-09-03T13:24:12.946Z</updated>
    
    <content type="html"><![CDATA[<h1 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h1><p><img src="/2019/05/11/项目全局异常处理/1567479454980.png" alt="1567479454980"></p>
<p>这是service层的一个业务方法，业务功能是：查询某些二维码数据。可以看到我们在这个方法里面除了<code>主要的业务逻辑</code>，还有数据非空判断，以及异常处理等等。</p>
<p>如果我们不仅仅是在service层添加try catch异常处理，在controller层调用service方法的地方也添加了try catch这样的异常处理代码，<strong>那么代码冗余严重且不易维护</strong></p>
<blockquote>
<p>总结-上诉代码存在两个问题</p>
</blockquote>
<p>1、上边的代码只要操作不成功仅向用户返回“错误代码：-1，失败信息：操作失败”，无法区别具体的错误信<br>息。–参见第三处代码<br>2、service方法在执行过程出现异常在哪捕获？在service中需要都加try/catch，如果在controller也需要添加<br>try/catch，代码冗余严重且不易维护。</p>
<blockquote>
<p><strong>以下项目是 springboot2.0.1 下开发</strong></p>
</blockquote>
<h1 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h1><p>1、在Service方法中的编码顺序是先校验判断，有问题则抛出具体的异常信息，最后执行具体的业务操作，返回成<br>功信息。</p>
<p>2、在统一异常处理类中去捕获异常，无需controller捕获异常，向用户返回统一规范的响应信息。</p>
<h2 id="异常处理流程"><a href="#异常处理流程" class="headerlink" title="异常处理流程"></a>异常处理流程</h2><blockquote>
<p>系统对异常的处理使用统一的异常处理流程：</p>
</blockquote>
<p>1、自定义异常类型。</p>
<p>2、自定义错误代码及错误信息。</p>
<p>3、对于可预知的异常由程序员在代码中主动抛出，由SpringMVC统一捕获。可预知异常是程序员在代码中手动抛出本系统定义的特定异常类型，由于是程序员抛出的异常，通常异常信息比较齐全，程序员在抛出时会指定错误代码及错误信息，获取异常信息也比较方便。</p>
<p>4、对于不可预知的异常（运行时异常）由SpringMVC统一捕获Exception类型的异常。不可预知异常通常是由于系统出现bug、或一些不要抗拒的错误（比如网络中断、服务器宕机等），异常类型为<br>RuntimeException类型（运行时异常）。</p>
<p>5、可预知的异常及不可预知的运行时异常最终会采用统一的信息格式（错误代码+错误信息）来表示，最终也会随请求响应给客户端。</p>
<p><img src="/2019/05/11/项目全局异常处理/1567479831709.png" alt="1567479831709"></p>
<p>1、在controller、service、dao中程序员抛出自定义异常；springMVC框架抛出框架异常类型<br>2、统一由异常捕获类捕获异常，并进行处理<br>3、捕获到自定义异常则直接取出错误代码及错误信息，响应给用户。</p>
<p>4、捕获到非自定义异常类型首先从Map中找该异常类型是否对应具体的错误代码，如果有则取出错误代码和错误<br>信息并响应给用户，如果从Map中找不到异常类型所对应的错误代码则统一为99999错误代码并响应给用户。</p>
<p>5、将错误代码及错误信息以Json格式响应给用户。</p>
<blockquote>
<p>特别解释</p>
</blockquote>
<p>不可知异常我们在上图中有两个分支，左边的分支表示的是有些不可知异常我们是知道的（这个可能比较拗口），例如SQLException，HttpMessageNotReadableException（消息转化异常），这些异常我们是可以特别处理的，可以给其标注响应的错误信息，而不用走右边的99999默认消息异常处理分支。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="定义常用错误代码接口-错误信息格式"><a href="#定义常用错误代码接口-错误信息格式" class="headerlink" title="定义常用错误代码接口-错误信息格式"></a>定义常用错误代码接口-错误信息格式</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">public interface ResultCode &#123;</div><div class="line">    //操作是否成功,true为成功，false操作失败</div><div class="line">    boolean success();</div><div class="line">    //操作代码</div><div class="line">    int code();</div><div class="line">    //提示信息</div><div class="line">    String message();</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>根据这个信息格式我们可以自定义我们的错误实现。例如通用的消息模块CommonCode里面包含了常用的错误消息例子、文件上传消息模块FileSystemCode、认证消息模块AuthCode等等。满足我们自己业务的相关提示和异常提示。</p>
<h3 id="定义通用的消息模块CommonCode"><a href="#定义通用的消息模块CommonCode" class="headerlink" title="定义通用的消息模块CommonCode"></a>定义通用的消息模块CommonCode</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">public enum CommonCode implements ResultCode&#123;</div><div class="line">    INVALID_PARAM(false,10003,&quot;非法参数！&quot;),</div><div class="line">    SUCCESS(true,10000,&quot;操作成功！&quot;),</div><div class="line">    FAIL(false,11111,&quot;操作失败！&quot;),</div><div class="line">    UNAUTHENTICATED(false,10001,&quot;此操作需要登陆系统！&quot;),</div><div class="line">    UNAUTHORISE(false,10002,&quot;权限不足，无权操作！&quot;),</div><div class="line">    SERVER_ERROR(false,99999,&quot;抱歉，系统繁忙，请稍后重试！&quot;);</div><div class="line">    //操作是否成功</div><div class="line">    boolean success;</div><div class="line">    //操作代码</div><div class="line">    int code;</div><div class="line">    //提示信息</div><div class="line">    String message;</div><div class="line">    private CommonCode(boolean success,int code, String message)&#123;</div><div class="line">        this.success = success;</div><div class="line">        this.code = code;</div><div class="line">        this.message = message;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    @Override</div><div class="line">    public boolean success() &#123;</div><div class="line">        return success;</div><div class="line">    &#125;</div><div class="line">    @Override</div><div class="line">    public int code() &#123;</div><div class="line">        return code;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    @Override</div><div class="line">    public String message() &#123;</div><div class="line">        return message;</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="文件上传消息模块FileSystemCode-可选"><a href="#文件上传消息模块FileSystemCode-可选" class="headerlink" title="文件上传消息模块FileSystemCode-可选"></a>文件上传消息模块FileSystemCode-可选</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">public enum FileSystemCode implements ResultCode &#123;</div><div class="line">    FS_UPLOADFILE_FILEISNULL(false,25001,&quot;上传文件为空！&quot;),</div><div class="line">    FS_UPLOADFILE_BUSINESSISNULL(false,25002,&quot;业务Id为空！&quot;),</div><div class="line">    FS_UPLOADFILE_SERVERFAIL(false,25003,&quot;上传文件服务器失败！&quot;),</div><div class="line">    FS_DELETEFILE_NOTEXISTS(false,25004,&quot;删除的文件不存在！&quot;),</div><div class="line">    FS_DELETEFILE_DBFAIL(false,25005,&quot;删除文件信息失败！&quot;),</div><div class="line">    FS_DELETEFILE_SERVERFAIL(false,25006,&quot;删除文件失败！&quot;),</div><div class="line">    FS_UPLOADFILE_METAERROR(false,25007,&quot;上传文件的元信息请使用json格式！&quot;),</div><div class="line">    FS_UPLOADFILE_USERISNULL(false,25008,&quot;上传文件用户为空！&quot;);</div><div class="line"></div><div class="line">    //操作代码</div><div class="line">    boolean success;</div><div class="line"></div><div class="line">    //操作代码</div><div class="line">    int code;</div><div class="line">    //提示信息</div><div class="line">    String message;</div><div class="line">    private FileSystemCode(boolean success, int code, String message)&#123;</div><div class="line">        this.success = success;</div><div class="line">        this.code = code;</div><div class="line">        this.message = message;</div><div class="line">    &#125;</div><div class="line">   </div><div class="line">    @Override</div><div class="line">    public boolean success() &#123;</div><div class="line">        return success;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    @Override</div><div class="line">    public int code() &#123;</div><div class="line">        return code;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    @Override</div><div class="line">    public String message() &#123;</div><div class="line">        return message;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>基础的消息格式我们已经做完了，那么接下来就是定义我们的异常</p>
<h3 id="可预知异常和不可预知异常处理"><a href="#可预知异常和不可预知异常处理" class="headerlink" title="可预知异常和不可预知异常处理"></a><strong>可预知异常和不可预知异常处理</strong></h3><p>（1）<strong>自定义异常类</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">/**</div><div class="line"> * 自定义异常类型</div><div class="line"> **/</div><div class="line">public class CustomException extends RuntimeException &#123;</div><div class="line"></div><div class="line">    //错误代码</div><div class="line">    ResultCode resultCode;</div><div class="line"></div><div class="line">    public CustomException(ResultCode resultCode)&#123;</div><div class="line">        this.resultCode = resultCode;</div><div class="line">    &#125;</div><div class="line">    public ResultCode getResultCode()&#123;</div><div class="line">        return resultCode;</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（2）<strong>异常抛出类</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">/**</div><div class="line"> * 异常抛出类，业务端代码直接调用即可</div><div class="line"> * 避免在service或者controller端书写throw new CustomException(resultCode);这样的重复性代码</div><div class="line"> *可以直接使用ExceptionCast.cast（）的方式直接抛出异常</div><div class="line"> **/</div><div class="line">public class ExceptionCast &#123;</div><div class="line"></div><div class="line">    public static void cast(ResultCode resultCode)&#123;</div><div class="line">        throw new CustomException(resultCode);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（3）<strong>异常捕获类</strong></p>
<p>使用 @ControllerAdvice和@ExceptionHandler注解来捕获指定类型的异常</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">/**</div><div class="line"> * 统一异常捕获类</div><div class="line"> **/</div><div class="line">@ControllerAdvice//控制器增强</div><div class="line">public class ExceptionCatch &#123;</div><div class="line"></div><div class="line">    private static final Logger LOGGER = LoggerFactory.getLogger(ExceptionCatch.class);</div><div class="line"></div><div class="line">    //定义map，配置异常类型所对应的错误代码 - 这个就是存储我们在不可预知异常的左边分支的异常</div><div class="line">    private static ImmutableMap&lt;Class&lt;? extends Throwable&gt;,ResultCode&gt; EXCEPTIONS;</div><div class="line">    //定义map的builder对象，去构建ImmutableMap</div><div class="line">    protected static ImmutableMap.Builder&lt;Class&lt;? extends Throwable&gt;,ResultCode&gt; builder = ImmutableMap.builder();</div><div class="line"></div><div class="line">    //捕获CustomException此类异常 -处理可预知异常关键方法（1）</div><div class="line">    @ExceptionHandler(CustomException.class)</div><div class="line">    @ResponseBody//返回给controller的json串格式的异常消息格式</div><div class="line">    public ResponseResult customException(CustomException customException)&#123;</div><div class="line">        customException.printStackTrace();</div><div class="line">        //记录日志</div><div class="line">        LOGGER.error(&quot;catch exception:&#123;&#125;&quot;,customException.getMessage());</div><div class="line">        ResultCode resultCode = customException.getResultCode();</div><div class="line">        return new ResponseResult(resultCode);</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    //捕获Exception此类异常 - 处理不可预知异常关键方法（2）</div><div class="line">    //里面包含我们在异常处理流程中&lt;处理不可预知异常&gt;的左右两个分支</div><div class="line">    //根据异常的全类名在我们自定义的异常map中查找是否存在已经自定义的不可预知异常，存在直接返回，不存在则当做99999全局异常处理</div><div class="line">    @ExceptionHandler(Exception.class)</div><div class="line">    @ResponseBody</div><div class="line">    public ResponseResult exception(Exception exception)&#123;</div><div class="line">        exception.printStackTrace();</div><div class="line">        //记录日志</div><div class="line">        LOGGER.error(&quot;catch exception:&#123;&#125;&quot;,exception.getMessage());</div><div class="line">        if(EXCEPTIONS == null)&#123;</div><div class="line">            EXCEPTIONS = builder.build();//EXCEPTIONS构建成功</div><div class="line">        &#125;</div><div class="line">        //从EXCEPTIONS中找异常类型所对应的错误代码，如果找到了将错误代码响应给用户，如果找不到给用户响应99999异常</div><div class="line">        ResultCode resultCode = EXCEPTIONS.get(exception.getClass());</div><div class="line">        if(resultCode !=null)&#123;</div><div class="line">            return new ResponseResult(resultCode);</div><div class="line">        &#125;else&#123;</div><div class="line">            //返回99999异常</div><div class="line">            return new ResponseResult(CommonCode.SERVER_ERROR);</div><div class="line">        &#125;</div><div class="line"></div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    static &#123;</div><div class="line">        //定义异常类型所对应的错误代码</div><div class="line">        builder.put(HttpMessageNotReadableException.class,CommonCode.INVALID_PARAM);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="测试使用"><a href="#测试使用" class="headerlink" title="测试使用"></a>测试使用</h3><p>改造上诉代码，try catch语句可以去掉，而且可以返回我们精准自定义的错误信息</p>
<p><img src="/2019/05/11/项目全局异常处理/1567481359314.png" alt="1567481359314"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>实现的关键点在于，<code>使用 @ControllerAdvice和@ExceptionHandler注解来捕获指定类型的异常</code></p>
<blockquote>
<p><strong>@ExceptionHandler</strong></p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">//该注解作用对象为方法</div><div class="line">@Target(&#123;ElementType.METHOD&#125;)</div><div class="line">//在运行时有效</div><div class="line">@Retention(RetentionPolicy.RUNTIME)</div><div class="line">@Documented</div><div class="line">public @interface ExceptionHandler &#123;</div><div class="line">	//value()可以指定异常类</div><div class="line">    Class&lt;? extends Throwable&gt;[] value() default &#123;&#125;;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<blockquote>
<p><strong>@ControllerAdvice</strong> 增强版控制器</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Target(&#123;ElementType.TYPE&#125;)</div><div class="line">@Retention(RetentionPolicy.RUNTIME)</div><div class="line">@Documented</div><div class="line">@Component</div><div class="line">public @interface ControllerAdvice &#123;</div><div class="line">    @AliasFor(&quot;basePackages&quot;)</div><div class="line">    String[] value() default &#123;&#125;;</div><div class="line"></div><div class="line">    @AliasFor(&quot;value&quot;)</div><div class="line">    String[] basePackages() default &#123;&#125;;</div><div class="line"></div><div class="line">    Class&lt;?&gt;[] basePackageClasses() default &#123;&#125;;</div><div class="line"></div><div class="line">    Class&lt;?&gt;[] assignableTypes() default &#123;&#125;;</div><div class="line"></div><div class="line">    Class&lt;? extends Annotation&gt;[] annotations() default &#123;&#125;;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;起因&quot;&gt;&lt;a href=&quot;#起因&quot; class=&quot;headerlink&quot; title=&quot;起因&quot;&gt;&lt;/a&gt;起因&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2019/05/11/项目全局异常处理/1567479454980.png&quot; alt=&quot;1567479454980&quot;&gt;
    
    </summary>
    
      <category term="springboot项目常用技术实现" scheme="http://kingge.top/categories/springboot%E9%A1%B9%E7%9B%AE%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0/"/>
    
    
      <category term="异常处理" scheme="http://kingge.top/tags/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/"/>
    
      <category term="ControllerAdvice注解" scheme="http://kingge.top/tags/ControllerAdvice%E6%B3%A8%E8%A7%A3/"/>
    
      <category term="ExceptionHandler注解" scheme="http://kingge.top/tags/ExceptionHandler%E6%B3%A8%E8%A7%A3/"/>
    
  </entry>
  
  <entry>
    <title>SpringCloud个人总结</title>
    <link href="http://kingge.top/2019/05/01/SpringCloud%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/"/>
    <id>http://kingge.top/2019/05/01/SpringCloud个人总结/</id>
    <published>2019-05-01T02:21:59.000Z</published>
    <updated>2019-09-03T13:09:54.499Z</updated>
    
    <content type="html"><![CDATA[<p>一下内容就是个人学习sc微服务架构中的学习总结，整个架构的东西很多，大家可以在需要某个组件时再去学习。</p>
<p>一、为什么需要微服务</p>
<p>我么那首先思考下面这些问题，为什么需要微服务，微服务能够解决什么痛点，它有什么优缺点？微服务和微服务架构是什么关系？什么是分布式？什么是集群？为了解决这些问题我们得从实现一个系统的架构的到底发生了那些演变说起。</p>
<h2 id="1-1分布式的演化"><a href="#1-1分布式的演化" class="headerlink" title="1.1分布式的演化"></a>1.1分布式的演化</h2><p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-16_15-07-20.png" alt=""></p>
<h3 id="1-1-1单一应用架构"><a href="#1-1-1单一应用架构" class="headerlink" title="1.1.1单一应用架构"></a>1.1.1单一应用架构</h3><p>当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的数据访问框架(ORM)是关键。</p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-16_15-10-27.png" alt=""></p>
<p>优点：</p>
<blockquote>
<p>适用于小型网站，小型管理系统，将所有功能都部署到一个工程里，简单易用，易于开发</p>
</blockquote>
<p>缺点：</p>
<blockquote>
<p>  1、性能扩展比较难 </p>
<p>  2、协同开发问题</p>
<p>  3、不利于升级维护</p>
<p>  4、  只能采用同一种技术，很难用不同的语言或者语言不同版本开发不同模块；</p>
<p>  5、系统耦合性强，一旦其中一个模块有问题，整个系统就瘫痪了；一旦升级其中一个模块，整个系统就停机了；</p>
<p>  6、  <strong>集群只能是复制整个系统，即使只是其中一个模块压力大</strong>。（可能整个订单处理，仅仅是支付模块压力过大，按道理只需要升级支付模块，但是在单一场景里面是不能的）</p>
</blockquote>
<p>那么这个时候我么那肯定产生了想法，就是把所有功能模块切开，分而治之，那么就演变成了下面的架构。</p>
<h3 id="1-1-2-垂直应用架构"><a href="#1-1-2-垂直应用架构" class="headerlink" title="1.1.2 垂直应用架构"></a>1.1.2 垂直应用架构</h3><pre><code>当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用**拆成互不相干**的几个应用，以提升效率，**这样就可以单独修改某个模块而不用重启或者影响其他模块，同时也可以给某个访问量剧增的模块，单独添加服务器部署集群**。此时，用于加速前端页面开发的Web框架(MVC)是关键。
</code></pre><p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-16_15-15-13.png" alt=""></p>
<pre><code>通过切分业务来实现各个模块独立部署，降低了维护和部署的难度，团队各司其职更易管理，性能扩展也更方便，更有针对性。
</code></pre><p>缺点： </p>
<blockquote>
<p>公用模块无法重复利用，开发性的浪费（存在重复开发的问题）</p>
<p>面对突变的应用场景，可能某个模块对于web界面会频繁修改，但是模块业务功能没有变化，这样会造成单个应用频繁修改。所以需要<strong>界面+业务逻辑的实现分离。</strong></p>
<p>没有处理好应用之间的交互问题，系统之间相互独立，例如订单模块可能会需要查询商品模块的信息。</p>
</blockquote>
<p>这个时候，虽然切分了各个模块，但是没有很好地考虑到服务之间的引用等等问题。</p>
<h3 id="1-1-3-分布式服务架构"><a href="#1-1-3-分布式服务架构" class="headerlink" title="1.1.3 分布式服务架构"></a>1.1.3 分布式服务架构</h3><p>当垂直应用越来越多，<strong>应用之间交互不可避免</strong>，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的<strong>分布式服务框架(RPC)是关键。</strong></p>
<p>例如我们常见的springcloud和dubbo就是属于分布式服务架构，但是严格上来讲dubbo并不是属于分布式架构，因为他并不具备分布式架构的某些特性，例如服务的分布式配置，服务网关，数据流，批量任务等等。一般认为Dubbo只是相当于SpringCloud中的Eureka模块（服务注册中心）</p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-16_15-28-15.png" alt=""></p>
<p><a href=""><strong>分布式服务框架很好的解决了垂直应用架构的缺点，实现界面和服务的分离，实现界面和服务，以及服务与服务之间的调度。</strong></a></p>
<pre><code>但是存在问题，那就是没有一个**统一管理服务的机制和基于访问压力的调度中心(服务注册中心，负载均衡)**，容易造成资源浪费，什么意思呢？假设用户服务部署了200台服务器，但是在某个时间段，他的访问压力很小，订单服务的访问压力剧增，服务器不够用。那么就会造成资源浪费和倾斜，存在服务器闲置或者请求量少的情况。
</code></pre><h3 id="1-1-4-流动计算架构"><a href="#1-1-4-流动计算架构" class="headerlink" title="1.1.4 流动计算架构"></a>1.1.4 流动计算架构</h3><p>当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个<strong>调度中心</strong>基于访问压力实时管理集群容量，提高集群利用率。此时，用于<strong>提高机器利用率的资源调度和治理中心</strong>(SOA)<a href="">Service Oriented Architecture]</a><strong>是关键</strong>。</p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-16_15-32-41.png" alt=""></p>
<p><img src="/2019/05/01/SpringCloud个人总结/1525530804753.png" alt="1525530804753"></p>
<p>以前出现了什么问题？</p>
<ul>
<li>服务越来越多，需要管理每个服务的地址</li>
<li>调用关系错综复杂，难以理清依赖关系</li>
<li>服务过多，服务状态难以管理，无法根据服务情况动态管理</li>
</ul>
<p>服务治理要做什么？</p>
<ul>
<li>服务注册中心，实现服务自动注册和发现，无需人为记录服务地址</li>
<li>服务自动订阅，服务列表自动推送，服务调用透明化，无需关心依赖关系</li>
<li>动态监控服务状态监控报告，人为控制服务状态</li>
</ul>
<p>缺点：</p>
<ul>
<li>服务间会有依赖关系，一旦某个环节出错会影响较大</li>
<li>服务关系复杂，运维、测试部署困难，不符合DevOps思想</li>
</ul>
<p></p>
<h3 id="1-1-5-微服务架构"><a href="#1-1-5-微服务架构" class="headerlink" title="1.1.5 微服务架构"></a>1.1.5 微服务架构</h3><p>前面说的SOA，英文翻译过来是面向服务。微服务，似乎也是服务，都是对系统进行拆分。因此两者非常容易混淆，但其实却有一些差别：</p>
<p>微服务的特点：</p>
<ul>
<li>单一职责：微服务中每一个服务都对应唯一的业务能力，做到单一职责</li>
<li>微：微服务的服务拆分粒度很小，例如一个用户管理就可以作为一个服务。每个服务虽小，但“五脏俱全”。</li>
<li>面向服务：面向服务是说每个服务都要对外暴露Rest风格服务接口API。并不关心服务的技术实现，做到与平台和语言无关，也不限定用什么技术实现，只要提供Rest的接口即可。</li>
<li>自治：自治是说服务间互相独立，互不干扰<ul>
<li>团队独立：每个服务都是一个独立的开发团队，人数不能过多。</li>
<li>技术独立：因为是面向服务，提供Rest接口，使用什么技术没有别人干涉</li>
<li>前后端分离：采用前后端分离开发，提供统一Rest接口，后端不用再为PC、移动段开发不同接口</li>
<li>数据库分离：每个服务都使用自己的数据源</li>
<li>部署独立，服务间虽然有调用，但要做到服务重启不影响其它服务。有利于持续集成和持续交付。每个服务都是独立的组件，可复用，可替换，降低耦合，易维护</li>
</ul>
</li>
</ul>
<p>微服务结构图：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/1526860071166.png" alt="1526860071166"></p>
<h2 id="1-2-基本概念梳理"><a href="#1-2-基本概念梳理" class="headerlink" title="1.2 基本概念梳理"></a>1.2 基本概念梳理</h2><blockquote>
<p>分布式：一个业务分拆多个子业务，部署在不同的服务器上</p>
<p>集群：  同一个业务，部署在多个服务器上</p>
<p>微服务： 微服务化的核心就是<strong>将传统的一站式应用,根据业务拆分成一个一个的服务</strong>,彻底地去耦合,每一个微服务提供<strong>单个业务功能的服务</strong>,一个服务做一件事,从技术角度看就是一种小而独立的处理过程,类似进程概念,能够自行单独启动或销毁，可以拥有自己独立的数据库。（我们之前使用springboot开发的项目就是属于一个微服务，他是单一进程，处理单一服务。-<strong>他关注的是单一业务的实现细节</strong>）    </p>
<p>微服务架构：微服务架构是一种架构模式,它提倡将单一应用程序划分成一组小的服务,服务之间互相协调、互相配合,为用户提供最终价值.每个服务运行在其独立的进程中,服务与服务间采用轻量级的通信机制互相协作(通常是基于HTTP协议的RESTful API).每个服务都围绕着具体业务进行构建,并且能够被独立的部署到生产环境、类生产环境等.另外,应当尽量避免统一的、集中式的服务管理机制,对具体的一个服务而言,应根据业务上下文,选择合适的语言、工具对其进行构建.（springcloud就是一个微服务架构，通过一系列措施，管理微服务，实现系统整体的功能-<strong>他关注的是整体项目的实现和架构</strong>）</p>
</blockquote>
<p>微服务提出者：马丁.福勒(Martin Fowler) </p>
<p>论文网址:<a href="https://martinfowler.com/articles/microservices.html" target="_blank" rel="external">https://martinfowler.com/articles/microservices.html</a></p>
<p>​    </p>
<p><img src="/2019/05/01/SpringCloud个人总结/Topic17NotesImage48.jpg" alt=""></p>
<h2 id="1-3-微服务优缺点"><a href="#1-3-微服务优缺点" class="headerlink" title="1.3 微服务优缺点"></a>1.3 微服务优缺点</h2><p>优点：</p>
<blockquote>
<p>每个服务足够内聚,足够小,代码容易理解这样能聚焦一个指定的业务功能或业务需求</p>
<p>开发简单、开发效率提高,一个服务可能就是专一的只干一件事.</p>
<p>微服务能够被小团队单独开服,这个小团队是2到5人的开发人员组成</p>
<p>微服务是松耦合的,是有功能意义的服务,无论是在开发阶段或部署阶段都是独立的.</p>
<p>微服务能试用不同的语言开发</p>
<p>易于和第三方集成,微服务允许容易且灵活的方式集成自动部署,通过持续集成工具,如Jenkins,Hudson,bamboo.</p>
<p>微服务易于被一个开发人员理解,修改和维护,这样小团队能够更关注自己的工作成果.无需通过合作才能体现价值</p>
<p>微服务允许你利用融合最新技术.</p>
<p>微服务只是业务逻辑的代码,不会和HTML,CSS或其他界面组件混合.</p>
<p>每个微服务都有自己的存储能力,可以有自己的数据库.也可以有统一的数据库</p>
</blockquote>
<p>缺点：</p>
<blockquote>
<p>开发人员要处理分布式系统的复杂性</p>
<p>多服务运维难度,随着服务的增加,运维的压力也在增大</p>
<p>系统部署依赖</p>
<p>服务间通信成本</p>
<p>数据一致性</p>
<p>系统集成测试</p>
<p>性能监控</p>
</blockquote>
<h2 id="1-4-常见微服务架构"><a href="#1-4-常见微服务架构" class="headerlink" title="1.4 常见微服务架构"></a>1.4 常见微服务架构</h2><table>
<thead>
<tr>
<th style="text-align:center">微服务条目</th>
<th style="text-align:center">落地技术</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">服务开发</td>
<td style="text-align:center">SpringBoot,Spring,SpringMVC</td>
</tr>
<tr>
<td style="text-align:center">服务配置与管理</td>
<td style="text-align:center">Netflix公司的Archaius、阿里的Diamond等</td>
</tr>
<tr>
<td style="text-align:center">服务注册与发现</td>
<td style="text-align:center">Eureka、Consul、Zookeeper等</td>
</tr>
<tr>
<td style="text-align:center">服务调用</td>
<td style="text-align:center">Rest、RPC、gRPC</td>
</tr>
<tr>
<td style="text-align:center">服务熔断器</td>
<td style="text-align:center">Hystrix、Envoy等</td>
</tr>
<tr>
<td style="text-align:center">负载均衡</td>
<td style="text-align:center">Ribbon、Nginx等</td>
</tr>
<tr>
<td style="text-align:center">服务接口调用（客户端调用服务的简化工具）</td>
<td style="text-align:center">Feign等</td>
</tr>
<tr>
<td style="text-align:center">消息队列</td>
<td style="text-align:center">Kafka、RabbitMQ、ActiveMQ等</td>
</tr>
<tr>
<td style="text-align:center">服务配置中心管理</td>
<td style="text-align:center">SpringCloudConfig、Chef等</td>
</tr>
<tr>
<td style="text-align:center">服务路由（API网关）</td>
<td style="text-align:center">Zuul等</td>
</tr>
<tr>
<td style="text-align:center">服务监控</td>
<td style="text-align:center">Zabbix、Nagios、Metrics、Specatator等</td>
</tr>
<tr>
<td style="text-align:center">全链路追踪</td>
<td style="text-align:center">Zipkin、Brave、Dapper等</td>
</tr>
<tr>
<td style="text-align:center">服务部署</td>
<td style="text-align:center">Docker、OpenStack、Kubernetes等</td>
</tr>
<tr>
<td style="text-align:center">数据流操作开发包</td>
<td style="text-align:center">SpringCloud Stream(封装与Redis，Rabbit，Kafka等发送接收消息)</td>
</tr>
<tr>
<td style="text-align:center">事件消息总线</td>
<td style="text-align:center">SpringCloud Bus</td>
</tr>
</tbody>
</table>
<h1 id="二-springcloud和dubbo"><a href="#二-springcloud和dubbo" class="headerlink" title="二.springcloud和dubbo"></a>二.springcloud和dubbo</h1><p>为什么现在流行的微服务架构是springcloud而不是dubbo，最主要的是dubbo在这之前停止更新过几年的时间，这个时候springcloud异军突起，很好地抢占了先机，整体解决方案和框架成熟度，社区热度，可维护性，学习曲线也是它更加火爆的原因：</p>
<p>最主要的是，Dubbo 的定位始终是一款 RPC 框架，目的是提<a href=""><strong>供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案</strong></a></p>
<p>然而：Spring Cloud 的目标是微服务架构下的一站式解决方案，换句话说，dubbo更像是springcloud的Eureka模块。</p>
<p>接下来我么你看一段关于Dubbo目前负责人刘军的一段采访</p>
<p><a href="https://www.oschina.net/question/2896879_2272652?sort=time" target="_blank" rel="external">https://www.oschina.net/question/2896879_2272652?sort=time</a></p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-16_16-01-12.png" alt=""></p>
<p>当前各大IT公司用的微服务架构有哪些</p>
<blockquote>
<p>阿里Dubbo/HSF<br>京东JSF<br>新浪微博Motan<br>当当网DubboX</p>
</blockquote>
<h2 id="1-各微服务的框架对比"><a href="#1-各微服务的框架对比" class="headerlink" title="1.各微服务的框架对比"></a>1.各微服务的框架对比</h2><table>
<thead>
<tr>
<th style="text-align:center">功能点/服务框架</th>
<th style="text-align:center">Netflix/SpringCloud</th>
<th style="text-align:center">Motan</th>
<th style="text-align:center">gRPC</th>
<th style="text-align:center">Thrift</th>
<th style="text-align:center">Dubbo/DubboX</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">功能定位</td>
<td style="text-align:center">完整的微服务架构</td>
<td style="text-align:center">RPC框架，但整合了ZK或Consul，实现集群环境的基本服务注册/发现</td>
<td style="text-align:center">RPC框架</td>
<td style="text-align:center">RPC框架</td>
<td style="text-align:center">服务框架</td>
</tr>
<tr>
<td style="text-align:center">支持Rest</td>
<td style="text-align:center">是，Ribbon支持多种可插拔的序列化选择</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">支持RPC</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">支持多语言</td>
<td style="text-align:center">是（Rest形式）</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
<td style="text-align:center">是</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">服务注册/发现</td>
<td style="text-align:center">是（Eureka） Eureka服务注册表，Karyon服务端框架支持服务自注册和健康检查</td>
<td style="text-align:center">是（zookeeper/consul）</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是</td>
</tr>
<tr>
<td style="text-align:center">负载均衡</td>
<td style="text-align:center">是（服务端zuul+客户端Ribbon） zuul-服务，动态路由 云端负载均衡  Eureka（针对中间层服务器）</td>
<td style="text-align:center">是（客户端）</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是（客户端）</td>
</tr>
<tr>
<td style="text-align:center">配置服务</td>
<td style="text-align:center">Netflix Archaius SpringCloud Config Server集中配置</td>
<td style="text-align:center">是（zookeeper提供）</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">服务调用链监控</td>
<td style="text-align:center">是（zuul） Zuul提供边缘服务，API网关</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
</tr>
<tr>
<td style="text-align:center">高可用/容错</td>
<td style="text-align:center">是（服务端Hystrix+客户端Ribbon）</td>
<td style="text-align:center">是（客户端）</td>
<td style="text-align:center">否</td>
<td style="text-align:center">否</td>
<td style="text-align:center">是（客户端）</td>
</tr>
<tr>
<td style="text-align:center">典型应用案例</td>
<td style="text-align:center">Netflix</td>
<td style="text-align:center">Sina</td>
<td style="text-align:center">Google</td>
<td style="text-align:center">Facebook</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">社区活跃度</td>
<td style="text-align:center">高</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">高</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">2017年7月才重启</td>
</tr>
<tr>
<td style="text-align:center">学习难度</td>
<td style="text-align:center">中等</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">高</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">低</td>
</tr>
<tr>
<td style="text-align:center">文档丰富度</td>
<td style="text-align:center">高</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">一般</td>
<td style="text-align:center">高</td>
</tr>
<tr>
<td style="text-align:center">其他</td>
<td style="text-align:center">Spring Cloud Bus为我们应用程序带来了更多管理端点</td>
<td style="text-align:center">支持降级</td>
<td style="text-align:center">Netflix内部在开发集成gRPC</td>
<td style="text-align:center">IDL定义</td>
<td style="text-align:center">实践公司比较多</td>
</tr>
</tbody>
</table>
<h2 id="2-springcloud-VS-Dubbo"><a href="#2-springcloud-VS-Dubbo" class="headerlink" title="2. springcloud VS Dubbo"></a>2. springcloud VS Dubbo</h2><p>社区活跃度</p>
<p><a href="https://github.com/dubbo" target="_blank" rel="external">https://github.com/dubbo</a><br><a href="https://github.com/springcloud" target="_blank" rel="external">https://github.com/springcloud</a></p>
<p>功能对比</p>
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">Dubbo</th>
<th style="text-align:center">Spring</th>
</tr>
</thead>
<tbody>
<tr>
<td>服务注册中心</td>
<td style="text-align:center">Zookeeper</td>
<td style="text-align:center">Spring Cloud Netfilx Eureka</td>
</tr>
<tr>
<td>服务调用方式</td>
<td style="text-align:center">RPC</td>
<td style="text-align:center">REST API</td>
</tr>
<tr>
<td>服务监控</td>
<td style="text-align:center">Dubbo-monitor</td>
<td style="text-align:center">Spring Boot Admin</td>
</tr>
<tr>
<td>断路器</td>
<td style="text-align:center">不完善</td>
<td style="text-align:center">Spring Cloud Netflix Hystrix</td>
</tr>
<tr>
<td>服务网关</td>
<td style="text-align:center">无</td>
<td style="text-align:center">Spring Cloud Netflix Zuul</td>
</tr>
<tr>
<td>分布式配置</td>
<td style="text-align:center">无</td>
<td style="text-align:center">Spring Cloud Config</td>
</tr>
<tr>
<td>服务跟踪</td>
<td style="text-align:center">无</td>
<td style="text-align:center">Spring Cloud Sleuth</td>
</tr>
<tr>
<td>消息总线</td>
<td style="text-align:center">无</td>
<td style="text-align:center">Spring Cloud Bus</td>
</tr>
<tr>
<td>数据流</td>
<td style="text-align:center">无</td>
<td style="text-align:center">Spring Cloud Stream</td>
</tr>
<tr>
<td>批量任务</td>
<td style="text-align:center">无</td>
<td style="text-align:center">Spring Cloud Task</td>
</tr>
</tbody>
</table>
<p><strong>最大区别：</strong></p>
<ul>
<li>Spring Cloud抛弃了RPC通讯，采用基于HTTP的REST方式。Spring Cloud牺牲了服务调用的性能，但是同时也避免了原生RPC带来的问题。REST比RPC更为灵活，不存在代码级别的强依赖，在强调快速演化的微服务环境下，显然更合适。</li>
<li>==一句话：Dubbo像组装机，Spring Cloud像一体机==</li>
<li>社区的支持与力度：Dubbo曾经停运了5年，虽然重启了，但是对于技术发展的新需求，还是需要开发者自行去拓展，对于中小型公司，显然显得比较费时费力，也不一定有强大的实力去修改源码</li>
</ul>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ol>
<li>解决的问题域不一样：Dubbo的定位是一款RPC框架，Spring Cloud的目标是微服务架构下的一站式解决方案</li>
</ol>
<h1 id="三-服务调用方式"><a href="#三-服务调用方式" class="headerlink" title="三.服务调用方式"></a>三.服务调用方式</h1><h2 id="1-RPC和HTTP"><a href="#1-RPC和HTTP" class="headerlink" title="1.RPC和HTTP"></a>1.RPC和HTTP</h2><p>无论是微服务还是SOA，都面临着服务间的远程调用。那么服务间的远程调用方式有哪些呢？</p>
<p>常见的远程调用方式有以下2种：</p>
<ul>
<li><p>RPC：Remote Produce Call远程过程调用，类似的还有RMI。自定义数据格式，基于原生TCP通信，速度快，效率高。早期的webservice，现在热门的dubbo，都是RPC的典型代表</p>
</li>
<li><p>Http：http其实是一种网络传输协议，基于TCP，规定了数据传输的格式。现在客户端浏览器与服务端通信基本都是采用Http协议，也可以用来进行远程服务调用。缺点是消息封装臃肿，优势是对服务的提供和调用方没有任何技术限定，自由灵活，更符合微服务理念。</p>
<p>现在热门的Rest风格，就可以通过http协议来实现。</p>
</li>
</ul>
<p>如果你们公司全部采用Java技术栈，那么使用Dubbo作为微服务架构是一个不错的选择。</p>
<p>相反，如果公司的技术栈多样化，而且你更青睐Spring家族，那么SpringCloud搭建微服务是不二之选。在我们的项目中，我们会选择SpringCloud套件，因此我们会使用Http方式来实现服务间调用。</p>
<h2 id="2-Http客户端工具"><a href="#2-Http客户端工具" class="headerlink" title="2.Http客户端工具"></a>2.Http客户端工具</h2><p>既然微服务选择了Http，那么我们就需要考虑自己来实现对请求和响应的处理。不过开源世界已经有很多的http客户端工具，能够帮助我们做这些事情，例如：</p>
<ul>
<li>HttpClient</li>
<li>OKHttp</li>
<li>URLConnection</li>
</ul>
<p>接下来，不过这些不同的客户端，API各不相同</p>
<h2 id="3-Spring的RestTemplate"><a href="#3-Spring的RestTemplate" class="headerlink" title="3.Spring的RestTemplate"></a>3.Spring的RestTemplate</h2><p>Spring提供了一个RestTemplate模板工具类，对基于Http的客户端进行了封装，并且实现了对象与json的序列化和反序列化，非常方便。RestTemplate并没有限定Http的客户端类型，而是进行了抽象，目前常用的3种都有支持：</p>
<ul>
<li>HttpClient</li>
<li>OkHttp</li>
<li>JDK原生的URLConnection（默认的）</li>
</ul>
<p>RestTemplate简单使用</p>
<p>首先在项目中注册一个<code>RestTemplate</code>对象，可以在启动类位置注册：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="meta">@SpringBootApplication</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HttpDemoApplication</span> </span>&#123;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">		SpringApplication.run(HttpDemoApplication.class, args);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="meta">@Bean</span></div><div class="line">	<span class="function"><span class="keyword">public</span> RestTemplate <span class="title">restTemplate</span><span class="params">()</span> </span>&#123;</div><div class="line">   </div><div class="line">		<span class="keyword">return</span> <span class="keyword">new</span> RestTemplate();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在测试类中直接<code>@Autowired</code>注入：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="meta">@RunWith</span>(SpringRunner.class)</div><div class="line"><span class="meta">@SpringBootTest</span>(classes = HttpDemoApplication.class)</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HttpDemoApplicationTests</span> </span>&#123;</div><div class="line"></div><div class="line">	<span class="meta">@Autowired</span></div><div class="line">	<span class="keyword">private</span> RestTemplate restTemplate;</div><div class="line"></div><div class="line">	<span class="meta">@Test</span></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">httpGet</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="comment">// 调用springboot案例中的rest接口</span></div><div class="line">		User user = <span class="keyword">this</span>.restTemplate.getForObject(<span class="string">"http://localhost/user/1"</span>, User.class);</div><div class="line">		System.out.println(user);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li>通过RestTemplate的getForObject()方法，传递url地址及实体类的字节码，RestTemplate会自动发起请求，接收响应，并且帮我们对响应结果进行反序列化。</li>
</ul>
<p><img src="/2019/05/01/SpringCloud个人总结/1525573702492.png" alt="1525573702492"></p>
<p>学习完了Http客户端工具，接下来就可以正式学习微服务了。</p>
<h1 id="四-初识SpringCloud"><a href="#四-初识SpringCloud" class="headerlink" title="四.初识SpringCloud"></a>四.初识SpringCloud</h1><p>微服务是一种架构方式，最终肯定需要技术架构去实施。</p>
<p>微服务的实现方式很多，但是最火的莫过于Spring Cloud了。为什么？</p>
<ul>
<li>后台硬：作为Spring家族的一员，有整个Spring全家桶靠山，背景十分强大。</li>
<li>技术强：Spring作为Java领域的前辈，可以说是功力深厚。有强力的技术团队支撑，一般人还真比不了</li>
<li>群众基础好：可以说大多数程序员的成长都伴随着Spring框架，试问：现在有几家公司开发不用Spring？SpringCloud与Spring的各个框架无缝整合，对大家来说一切都是熟悉的配方，熟悉的味道。</li>
<li>使用方便：相信大家都体会到了SpringBoot给我们开发带来的便利，而SpringCloud完全支持SpringBoot的开发，用很少的配置就能完成微服务框架的搭建</li>
</ul>
<h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h2><p>SpringCloud是Spring旗下的项目之一，<a href="http://projects.spring.io/spring-cloud/" target="_blank" rel="external">官网地址：http://projects.spring.io/spring-cloud/</a></p>
<p>官网介绍:<a href="https://spring.io/" target="_blank" rel="external">https://spring.io/</a></p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-16_16-08-43.png" alt=""></p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-16_16-09-14.png" alt=""></p>
<p>SpringCloud,基于springboot提供了一套为服务解决方案.</p>
<p>Spring最擅长的就是集成，把世界上最好的框架拿过来，集成到自己的项目中。</p>
<p>SpringCloud也是一样，它将现在非常流行的一些技术整合到一起，实现了诸如：配置管理，服务发现，智能路由，负载均衡，熔断器，控制总线，集群状态等等功能。其主要涉及的组件包括：</p>
<ul>
<li>Eureka：服务治理组件，包含服务注册中心，服务注册与发现机制的实现。（服务治理，服务注册/发现） </li>
<li>Zuul：网关组件，提供智能路由，访问过滤功能 </li>
<li>Ribbon：客户端负载均衡的服务调用组件（客户端负载） </li>
<li>Feign：服务调用，给予Ribbon和Hystrix的声明式服务调用组件 （声明式服务调用） </li>
<li>Hystrix：容错管理组件，实现断路器模式，帮助服务依赖中出现的延迟和为故障提供强大的容错能力。(熔断、断路器，容错) </li>
</ul>
<p>架构图：</p>
<p> <img src="/SpringCloud个人总结/1525575656796.png" alt="1525575656796"></p>
<p>以上只是其中一部分。</p>
<blockquote>
<p>SpringCloud,基于springboot提供了一套为服务解决方案,包括服务注册与发现,配置中心,全链路监控,服务网关,负载均衡,熔断器等组件,除了基于NetFlix的开源组件做高度抽象封装之外,还有一些选型中立的开源组件.</p>
<p>SpringCloud利用springboot的开发便利性巧妙地简化了分布式系统基础设施的开发,SpringCloud为开发人员提供了快速构建分布式系统的一些工具,包括配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等,它们都可以利用Springboot的开发风格做到一键启动和部署.</p>
<p>SpringBoot并没有重复制造轮子,它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来,通过Springboot风格进行再封装屏蔽掉了复杂的配置和实现原理,最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包.</p>
</blockquote>
<h2 id="2-SpringCloud和springboot是什么关系"><a href="#2-SpringCloud和springboot是什么关系" class="headerlink" title="2.SpringCloud和springboot是什么关系"></a>2.SpringCloud和springboot是什么关系</h2><p><strong>Springboot专注于快速方便的开发单个个体微服务.</strong></p>
<p>SpringCloud是<strong>关注全局的微服务协调整理治理框架</strong>,它将Springboot开发的一个个单体微服务整合并管理起来,为各个微服务质检提供,配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等集成服务</p>
<p><strong>Springboot可以离开SpringCloud独立使用开发项目,但是SpringCloud离不开Springboot,属于依赖的关系.</strong><br><strong>Springboot专注于快速、方便的开发单个微服务个体,SpringCloud关注全局的服务治理框架.</strong></p>
<h2 id="3-springcloud的版本"><a href="#3-springcloud的版本" class="headerlink" title="3.springcloud的版本"></a>3.springcloud的版本</h2><p>因为Spring Cloud不同其他独立项目，它拥有很多子项目的大项目。所以它的版本是版本名+版本号 （如Angel.SR6）。  </p>
<p>版本名：是伦敦的地铁名  </p>
<p>版本号：SR（Service Releases）是固定的 ,大概意思是稳定版本。后面会有一个递增的数字。 </p>
<p>所以 Edgware.SR3就是Edgware的第3个Release版本。  </p>
<p> <img src="/2019/05/01/SpringCloud个人总结/1528263985902.png" alt="1528263985902"></p>
<p>我们在项目中，会是以Finchley的版本。</p>
<p>其中包含的组件，也都有各自的版本，如下表：</p>
<table>
<thead>
<tr>
<th>Component</th>
<th>Edgware.SR3</th>
<th>Finchley.RC1</th>
<th>Finchley.BUILD-SNAPSHOT</th>
</tr>
</thead>
<tbody>
<tr>
<td>spring-cloud-aws</td>
<td>1.2.2.RELEASE</td>
<td>2.0.0.RC1</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-cloud-bus</td>
<td>1.3.2.RELEASE</td>
<td>2.0.0.RC1</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-cloud-cli</td>
<td>1.4.1.RELEASE</td>
<td>2.0.0.RC1</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-cloud-commons</td>
<td>1.3.3.RELEASE</td>
<td>2.0.0.RC1</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-cloud-contract</td>
<td>1.2.4.RELEASE</td>
<td>2.0.0.RC1</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-cloud-config</td>
<td>1.4.3.RELEASE</td>
<td>2.0.0.RC1</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-cloud-netflix</td>
<td>1.4.4.RELEASE</td>
<td>2.0.0.RC1</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-cloud-security</td>
<td>1.2.2.RELEASE</td>
<td>2.0.0.RC1</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-cloud-cloudfoundry</td>
<td>1.1.1.RELEASE</td>
<td>2.0.0.RC1</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-cloud-consul</td>
<td>1.3.3.RELEASE</td>
<td>2.0.0.RC1</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-cloud-sleuth</td>
<td>1.3.3.RELEASE</td>
<td>2.0.0.RC1</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-cloud-stream</td>
<td>Ditmars.SR3</td>
<td>Elmhurst.RELEASE</td>
<td>Elmhurst.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-cloud-zookeeper</td>
<td>1.2.1.RELEASE</td>
<td>2.0.0.RC1</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-boot</td>
<td>1.5.10.RELEASE</td>
<td>2.0.1.RELEASE</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-cloud-task</td>
<td>1.2.2.RELEASE</td>
<td>2.0.0.RC1</td>
<td>2.0.0.RELEASE</td>
</tr>
<tr>
<td>spring-cloud-vault</td>
<td>1.1.0.RELEASE</td>
<td>2.0.0.RC1</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-cloud-gateway</td>
<td>1.0.1.RELEASE</td>
<td>2.0.0.RC1</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
<tr>
<td>spring-cloud-openfeign</td>
<td></td>
<td>2.0.0.RC1</td>
<td>2.0.0.BUILD-SNAPSHOT</td>
</tr>
</tbody>
</table>
<p><img src="/2019/05/01/SpringCloud个人总结/1528263942152.png" alt="1528263942152"></p>
<h2 id="4-SpringCloud的参考资料"><a href="#4-SpringCloud的参考资料" class="headerlink" title="4.SpringCloud的参考资料"></a>4.SpringCloud的参考资料</h2><h1 id="五-springcloud的实现准备"><a href="#五-springcloud的实现准备" class="headerlink" title="五.springcloud的实现准备"></a>五.springcloud的实现准备</h1><p>为了下面使用springcloud微服务架构各个优秀的组件，我们先搭建一个基本的分布式项目工程。</p>
<p>案例使用的springcloud和springboot版本分别是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;Dalston.SR1&lt;/version&gt;</div><div class="line">    &lt;type&gt;pom&lt;/type&gt;</div><div class="line">    &lt;scope&gt;import&lt;/scope&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;</div><div class="line">    &lt;type&gt;pom&lt;/type&gt;</div><div class="line">    &lt;scope&gt;import&lt;/scope&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<h2 id="1-新建父工程-microservicecloud"><a href="#1-新建父工程-microservicecloud" class="headerlink" title="1 新建父工程-microservicecloud"></a>1 新建父工程-microservicecloud</h2><p>microservicecloud</p>
<p> <img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-16_16-24-07.png" alt=""></p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image003.jpg" alt="img"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image005.jpg" alt="img"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image007.jpg" alt="img"></p>
<p><strong>打包方式设置为pom</strong></p>
<p> 设置pom.xml文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</div><div class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;</div><div class="line">         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</div><div class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</div><div class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</div><div class="line"></div><div class="line">    &lt;groupId&gt;com.kingge.springcloud&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;microservicecloud&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;</div><div class="line">    &lt;packaging&gt;pom&lt;/packaging&gt;</div><div class="line">    &lt;properties&gt;</div><div class="line">        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;</div><div class="line">        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;</div><div class="line">        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;</div><div class="line">        &lt;junit.version&gt;4.12&lt;/junit.version&gt;</div><div class="line">        &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt;</div><div class="line">        &lt;lombok.version&gt;1.16.18&lt;/lombok.version&gt;</div><div class="line">    &lt;/properties&gt;</div><div class="line"></div><div class="line">    &lt;dependencyManagement&gt;</div><div class="line">        &lt;dependencies&gt;</div><div class="line">            &lt;dependency&gt;</div><div class="line">                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;</div><div class="line">                &lt;version&gt;Dalston.SR1&lt;/version&gt;</div><div class="line">                &lt;type&gt;pom&lt;/type&gt;</div><div class="line">                &lt;scope&gt;import&lt;/scope&gt;</div><div class="line">            &lt;/dependency&gt;</div><div class="line">            &lt;dependency&gt;</div><div class="line">                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">                &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;</div><div class="line">                &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;</div><div class="line">                &lt;type&gt;pom&lt;/type&gt;</div><div class="line">                &lt;scope&gt;import&lt;/scope&gt;</div><div class="line">            &lt;/dependency&gt;</div><div class="line">            &lt;dependency&gt;</div><div class="line">                &lt;groupId&gt;mysql&lt;/groupId&gt;</div><div class="line">                &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</div><div class="line">                &lt;version&gt;5.0.4&lt;/version&gt;</div><div class="line">            &lt;/dependency&gt;</div><div class="line">            &lt;dependency&gt;</div><div class="line">                &lt;groupId&gt;com.alibaba&lt;/groupId&gt;</div><div class="line">                &lt;artifactId&gt;druid&lt;/artifactId&gt;</div><div class="line">                &lt;version&gt;1.0.31&lt;/version&gt;</div><div class="line">            &lt;/dependency&gt;</div><div class="line">            &lt;dependency&gt;</div><div class="line">                &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;</div><div class="line">                &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;</div><div class="line">                &lt;version&gt;1.3.0&lt;/version&gt;</div><div class="line">            &lt;/dependency&gt;</div><div class="line">            &lt;dependency&gt;</div><div class="line">                &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;</div><div class="line">                &lt;artifactId&gt;logback-core&lt;/artifactId&gt;</div><div class="line">                &lt;version&gt;1.2.3&lt;/version&gt;</div><div class="line">            &lt;/dependency&gt;</div><div class="line">            &lt;dependency&gt;</div><div class="line">                &lt;groupId&gt;junit&lt;/groupId&gt;</div><div class="line">                &lt;artifactId&gt;junit&lt;/artifactId&gt;</div><div class="line">                &lt;version&gt;$&#123;junit.version&#125;&lt;/version&gt;</div><div class="line">                &lt;scope&gt;test&lt;/scope&gt;</div><div class="line">            &lt;/dependency&gt;</div><div class="line">            &lt;dependency&gt;</div><div class="line">                &lt;groupId&gt;log4j&lt;/groupId&gt;</div><div class="line">                &lt;artifactId&gt;log4j&lt;/artifactId&gt;</div><div class="line">                &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt;</div><div class="line">            &lt;/dependency&gt;</div><div class="line">        &lt;/dependencies&gt;</div><div class="line">    &lt;/dependencyManagement&gt;</div><div class="line"></div><div class="line">&lt;/project&gt;</div></pre></td></tr></table></figure>
<p>查看项目</p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image008.png" alt="img"></p>
<p>新建父工程目的：定义pom文件，统一各个子模块的jar依赖版本，方面管理，避免每个子模块使用相同组件不同版本，造成项目测试运行出现问题。</p>
<h2 id="2-根据父工程，新建api公共模块-microservicecloud-api"><a href="#2-根据父工程，新建api公共模块-microservicecloud-api" class="headerlink" title="2 根据父工程，新建api公共模块-microservicecloud-api"></a>2 根据父工程，新建api公共模块-microservicecloud-api</h2><p>目的：抽取出所有子项目公共的bean或者方法。例如在下面的创建的服务提供者和服务消费者都是用到了Person这个javabean，那么我们就需要把这个bean放在这里。然后服务提供者和消费者就可以依赖这个api公共模块，从而实用Person实体类。</p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image010.jpg" alt="img"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image012.jpg" alt="img"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image014.jpg" alt="img"></p>
<p>创建完毕</p>
<h3 id="2-1-查看父工程pom"><a href="#2-1-查看父工程pom" class="headerlink" title="2.1 查看父工程pom"></a>2.1 查看父工程pom</h3><p><img src="/2019/05/01/SpringCloud个人总结/clip_image015.png" alt="img"></p>
<p>发现多了这一行，因为我们是在父工程microserviceproject下新建的，表示microservicecloud-api工程为父工程子模块。</p>
<h3 id="2-2-修改microservicecloud-api的pom文件"><a href="#2-2-修改microservicecloud-api的pom文件" class="headerlink" title="2.2 修改microservicecloud-api的pom文件"></a>2.2 修改microservicecloud-api的pom文件</h3><p>修改内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</div><div class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;</div><div class="line">         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</div><div class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</div><div class="line">    &lt;parent&gt;</div><div class="line">        &lt;artifactId&gt;microservicecloud&lt;/artifactId&gt;</div><div class="line">        &lt;groupId&gt;com.kingge.springcloud&lt;/groupId&gt;</div><div class="line">        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;</div><div class="line">    &lt;/parent&gt;</div><div class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</div><div class="line">    &lt;packaging&gt;jar&lt;/packaging&gt;</div><div class="line"></div><div class="line">    &lt;artifactId&gt;microservicecloud-api&lt;/artifactId&gt;</div><div class="line">    &lt;dependencies&gt;&lt;!-- 当前Module需要用到的jar包，按自己需求添加，如果父类已经包含了，可以不用写版本号 --&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;lombok&lt;/artifactId&gt;  </div><div class="line">        &lt;/dependency&gt;//这个组件可用可不用</div><div class="line">    &lt;/dependencies&gt;</div><div class="line"></div><div class="line">&lt;/project&gt;</div></pre></td></tr></table></figure>
<p>Lombok组件在真实项目中不建议使用，虽然他简化了javabean的开发，但是代码的可读性也产生了严重的影响。</p>
<h3 id="2-3-新建公共bean-Person"><a href="#2-3-新建公共bean-Person" class="headerlink" title="2.3 新建公共bean-Person"></a>2.3 新建公共bean-Person</h3><p><img src="/2019/05/01/SpringCloud个人总结/clip_image017.jpg" alt="img"></p>
<p>生成get/set方法</p>
<h3 id="2-4-项目结构"><a href="#2-4-项目结构" class="headerlink" title="2.4 项目结构"></a>2.4 项目结构</h3><p><img src="/2019/05/01/SpringCloud个人总结/clip_image018.png" alt="img"></p>
<h2 id="3-根据父工程，新建微服务提供者-provider"><a href="#3-根据父工程，新建微服务提供者-provider" class="headerlink" title="3 根据父工程，新建微服务提供者-provider"></a>3 根据父工程，新建微服务提供者-provider</h2><p>microservicecloud-provider-person-8001 –&gt; 8001表示服务暴露的端口号</p>
<p>新建方法同新建-microservicecloud-api 模块</p>
<h3 id="3-1-修改pom文件"><a href="#3-1-修改pom文件" class="headerlink" title="3.1 修改pom文件"></a>3.1 修改pom文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</div><div class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;</div><div class="line">         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</div><div class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</div><div class="line">    &lt;parent&gt;</div><div class="line">        &lt;artifactId&gt;microservicecloud&lt;/artifactId&gt;</div><div class="line">        &lt;groupId&gt;com.kingge.springcloud&lt;/groupId&gt;</div><div class="line">        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;</div><div class="line">    &lt;/parent&gt;</div><div class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</div><div class="line"></div><div class="line">    &lt;artifactId&gt;microservicecloud-provider-person-8001&lt;/artifactId&gt;</div><div class="line"></div><div class="line">    &lt;dependencies&gt;</div><div class="line">        &lt;!-- 引入自己定义的api通用包，可以使用Person用户Entity --&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;com.kingge.springcloud&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;microservicecloud-api&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">       </div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;junit&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;junit&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;mysql&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;druid&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;logback-core&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;!-- 修改后立即生效，热部署 --&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.springframework&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;springloaded&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">    &lt;/dependencies&gt;</div><div class="line">&lt;/project&gt;</div></pre></td></tr></table></figure>
<h3 id="3-2-新建application-yml文件"><a href="#3-2-新建application-yml文件" class="headerlink" title="3.2 新建application.yml文件"></a>3.2 新建application.yml文件</h3><p><img src="/2019/05/01/SpringCloud个人总结/clip_image019.png" alt="img"></p>
<p>内容是：详细的参见代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">server:</div><div class="line">  port: 8001</div><div class="line"></div><div class="line">mybatis:</div><div class="line">  config-location: classpath:mybatis/mybatis.cfg.xml        # mybatis配置文件所在路径</div><div class="line">  type-aliases-package: com.kingge.entity    # 所有Entity别名类所在包</div><div class="line">  mapper-locations:</div><div class="line">  - classpath:mybatis/mapper/**/*.xml                       # mapper映射文件</div><div class="line"></div><div class="line"></div><div class="line">spring:</div><div class="line">   application:</div><div class="line">    name: microservicecloud-person                          #很重要，对外暴露的微服务的名称</div><div class="line">   datasource:</div><div class="line">    type: com.alibaba.druid.pool.DruidDataSource            # 当前数据源操作类型</div><div class="line">    driver-class-name: org.gjt.mm.mysql.Driver              # mysql驱动包</div><div class="line">    url: jdbc:mysql://127.0.0.1:3306/test              # 数据库名称</div><div class="line">    username: root</div><div class="line">    password: 123</div><div class="line">    dbcp2:</div><div class="line">      min-idle: 5                                           # 数据库连接池的最小维持连接数</div><div class="line">      initial-size: 5                                       # 初始化连接数</div><div class="line">      max-total: 5                                          # 最大连接数</div><div class="line">      max-wait-millis: 200</div></pre></td></tr></table></figure>
<p><strong>注意每个属性后面必须是有空格-yml文件的格式</strong></p>
<h3 id="3-3-新建person数据表"><a href="#3-3-新建person数据表" class="headerlink" title="3.3 新建person数据表"></a>3.3 新建person数据表</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">DROP TABLE IF EXISTS `person`;</div><div class="line">CREATE TABLE `person` (</div><div class="line">  `deptno` int(255) NOT NULL AUTO_INCREMENT,</div><div class="line">  `dname` varchar(255) DEFAULT NULL,</div><div class="line">  `db_source` varchar(255) DEFAULT NULL, //这和字段标识当前数据来源于那个数据库，后面讲解Eureka集群时会使用到</div><div class="line">  PRIMARY KEY (`deptno`)</div><div class="line">) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8;</div><div class="line"></div><div class="line">-- ----------------------------</div><div class="line">-- Records of person</div><div class="line">-- ----------------------------</div><div class="line">INSERT INTO `person` VALUES (&apos;1&apos;, &apos;开发部&apos;, &apos;test&apos;);</div><div class="line">INSERT INTO `person` VALUES (&apos;2&apos;, &apos;人事部&apos;, &apos;test&apos;);</div><div class="line">INSERT INTO `person` VALUES (&apos;3&apos;, &apos;集成部&apos;, &apos;test&apos;);</div><div class="line">INSERT INTO `person` VALUES (&apos;4&apos;, &apos;市场部&apos;, &apos;test&apos;);</div></pre></td></tr></table></figure>
<h3 id="3-4-新建dao和mapper"><a href="#3-4-新建dao和mapper" class="headerlink" title="3.4 新建dao和mapper"></a>3.4 新建dao和mapper</h3><p><img src="/2019/05/01/SpringCloud个人总结/clip_image020.png" alt="img"></p>
<p>内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">import com.kingge.entity.Person;</div><div class="line">import org.apache.ibatis.annotations.Mapper;</div><div class="line"></div><div class="line">import java.util.List;</div><div class="line"></div><div class="line">@Mapper</div><div class="line">public interface PersonDao &#123;</div><div class="line">    public boolean addDept(Person dept);</div><div class="line"></div><div class="line">    public Person findById(Long id);</div><div class="line"></div><div class="line">    public List&lt;Person&gt; findAll();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="3-4-1-新建mybatis-cfg-xml"><a href="#3-4-1-新建mybatis-cfg-xml" class="headerlink" title="3.4.1 新建mybatis.cfg.xml"></a>3.4.1 新建mybatis.cfg.xml</h3><p>实际上我们不需要这个xml文件，因为我们的配置一般都是已经放置在了application.yml文件中，但是为了整体架构的扩展性，这里也新建了改文件</p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image021.png" alt="img"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image023.jpg" alt="img"></p>
<h3 id="3-5-新建PersonMapper-xml"><a href="#3-5-新建PersonMapper-xml" class="headerlink" title="3.5 新建PersonMapper.xml"></a>3.5 新建PersonMapper.xml</h3><p><img src="/2019/05/01/SpringCloud个人总结/clip_image024.png" alt="img"></p>
<p>存放mapper.xml文件的位置我们在上面application.yml中已经声明</p>
<p>内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;</div><div class="line">&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;</div><div class="line">&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;</div><div class="line"></div><div class="line">&lt;mapper namespace=&quot;com.kingge.dao.PersonDao&quot;&gt;</div><div class="line"></div><div class="line">	&lt;select id=&quot;findById&quot; resultType=&quot;Person&quot; parameterType=&quot;Long&quot;&gt;</div><div class="line">		select deptno,dname,db_source from person where deptno=#&#123;deptno&#125;;</div><div class="line">	&lt;/select&gt;</div><div class="line">	&lt;select id=&quot;findAll&quot; resultType=&quot;Person &quot;&gt;</div><div class="line">		select deptno,dname,db_source from person;</div><div class="line">	&lt;/select&gt;</div><div class="line">	&lt;insert id=&quot;addDept&quot; parameterType=&quot;Person &quot;&gt;</div><div class="line">		INSERT INTO person(dname,db_source) VALUES(#&#123;dname&#125;,DATABASE());</div><div class="line">	&lt;/insert&gt;</div><div class="line"></div><div class="line">&lt;/mapper&gt;</div></pre></td></tr></table></figure>
<h3 id="3-6-新建PersonService接口和接口实现类impl"><a href="#3-6-新建PersonService接口和接口实现类impl" class="headerlink" title="3.6 新建PersonService接口和接口实现类impl"></a>3.6 新建PersonService接口和接口实现类impl</h3><p><img src="/2019/05/01/SpringCloud个人总结/clip_image025.png" alt="img"></p>
<p>PersonService 接口</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">public interface PersonService&#123;</div><div class="line">       publicboolean add(Person dept);</div><div class="line">       public Personget(Long id);</div><div class="line">       publicList&lt;Person&gt; list();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>PersonServiceImpl 实现类</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Service</div><div class="line">public class PersonServiceImpl implements PersonService&#123;</div><div class="line">	@Autowired</div><div class="line">	private PersonDao dao;</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	public boolean add(Person person)&#123;</div><div class="line">		return dao.addDept(person);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public Person get(Long id)&#123;</div><div class="line">		return dao.findById(id);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public List&lt;Person&gt; list()&#123;</div><div class="line">		return dao.findAll();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="3-7-controller控制层-PersonController"><a href="#3-7-controller控制层-PersonController" class="headerlink" title="3.7 controller控制层-PersonController"></a>3.7 controller控制层-PersonController</h3><p>代码实现：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"></div><div class="line">@RestController</div><div class="line">public class PersonController</div><div class="line">&#123;</div><div class="line">	@Autowired</div><div class="line">	private PersonService service;</div><div class="line">//全部使用restful风格，返回json字符串</div><div class="line">	@RequestMapping(value = &quot;/person/add&quot;, method = RequestMethod.POST)</div><div class="line">	public boolean add(@RequestBody Person person)</div><div class="line">	&#123;</div><div class="line">		return service.add(person);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@RequestMapping(value = &quot;/person/get/&#123;id&#125;&quot;, method = RequestMethod.GET)</div><div class="line">	public Person get(@PathVariable(&quot;id&quot;) Long id)</div><div class="line">	&#123;</div><div class="line">		return service.get(id);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@RequestMapping(value = &quot;/person/list&quot;, method = RequestMethod.GET)</div><div class="line">	public List&lt;Person&gt; list()</div><div class="line">	&#123;</div><div class="line">		return service.list();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="3-8-springboot启动类"><a href="#3-8-springboot启动类" class="headerlink" title="3.8 springboot启动类"></a>3.8 springboot启动类</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">public class ApplicationBootStart &#123;</div><div class="line">    public static void main(String[] args)</div><div class="line">    &#123;</div><div class="line">        SpringApplication.run(ApplicationBootStart.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>启动服务并测试访问。</p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image027.jpg" alt="img"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image029.jpg" alt="img"></p>
<h3 id="3-9-项目整体结构"><a href="#3-9-项目整体结构" class="headerlink" title="3.9 项目整体结构"></a>3.9 项目整体结构</h3><p><img src="/2019/05/01/SpringCloud个人总结/clip_image030.png" alt="img"></p>
<h2 id="4-根据父工程，新建微服务消费者-consumer"><a href="#4-根据父工程，新建微服务消费者-consumer" class="headerlink" title="4 根据父工程，新建微服务消费者-consumer"></a>4 根据父工程，新建微服务消费者-consumer</h2><p>microservicecloud-consumer-person-80 方法同上</p>
<h3 id="4-1-修改pom文件"><a href="#4-1-修改pom文件" class="headerlink" title="4.1 修改pom文件"></a>4.1 修改pom文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;dependencies&gt;</div><div class="line">	&lt;dependency&gt;&lt;!-- 自己定义的api --&gt;</div><div class="line">		&lt;groupId&gt;com.kingge.springcloud&lt;/groupId&gt;</div><div class="line">		&lt;artifactId&gt;microservicecloud-api&lt;/artifactId&gt;</div><div class="line">		&lt;version&gt;$&#123;project.version&#125;&lt;/version&gt;</div><div class="line">	&lt;/dependency&gt;</div><div class="line">	        &lt;dependency&gt;</div><div class="line">           &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">           &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</div><div class="line">       &lt;/dependency&gt;</div><div class="line"></div><div class="line">       &lt;dependency&gt;</div><div class="line">           &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">           &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</div><div class="line">           &lt;version&gt;2.1.7.RELEASE&lt;/version&gt;</div><div class="line">           &lt;scope&gt;test&lt;/scope&gt;</div><div class="line">       &lt;/dependency&gt;</div><div class="line">	&lt;!-- 修改后立即生效，热部署 --&gt;</div><div class="line">	&lt;dependency&gt;</div><div class="line">		&lt;groupId&gt;org.springframework&lt;/groupId&gt;</div><div class="line">		&lt;artifactId&gt;springloaded&lt;/artifactId&gt;</div><div class="line">	&lt;/dependency&gt;</div><div class="line">	&lt;dependency&gt;</div><div class="line">		&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">		&lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;</div><div class="line">	&lt;/dependency&gt;</div><div class="line">&lt;/dependencies&gt;</div></pre></td></tr></table></figure>
<h3 id="4-2-添加application-yml文件"><a href="#4-2-添加application-yml文件" class="headerlink" title="4.2 添加application.yml文件"></a>4.2 添加application.yml文件</h3><p>添加端口配置</p>
<p>server:</p>
<p>  port: 80</p>
<h3 id="4-3-新建-Configuration注解的配置类"><a href="#4-3-新建-Configuration注解的配置类" class="headerlink" title="4.3 新建@Configuration注解的配置类"></a>4.3 新建@Configuration注解的配置类</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Configuration</div><div class="line">public class ConfigBean</div><div class="line">&#123; </div><div class="line">	@Bean</div><div class="line">	public RestTemplate getRestTemplate()</div><div class="line">	&#123;</div><div class="line">		return new RestTemplate();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>它的作用就是我们整合SSM的时候，对应的applicationContext.xml</p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image032.jpg" alt="img"></p>
<h3 id="4-4-新建消费者控制器，访问服务提供者获取数据"><a href="#4-4-新建消费者控制器，访问服务提供者获取数据" class="headerlink" title="4.4 新建消费者控制器，访问服务提供者获取数据"></a>4.4 新建消费者控制器，访问服务提供者获取数据</h3><p>通过RestTemplate获取消息提供者暴露的服务信息。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@RestController</div><div class="line">public class ConsumerController &#123;</div><div class="line"></div><div class="line">    @Autowired</div><div class="line">    private RestTemplate restTemplate;</div><div class="line"></div><div class="line">    private static final String REST_URL_PREFIX = &quot;http://localhost:8001&quot;;//这里通过书写固定的服务提供者的地址，后面我们学习到了Eureka服务注册中心，那么注重修改这里</div><div class="line"></div><div class="line">    @RequestMapping(value = &quot;/consumer/person/add&quot;)</div><div class="line">    public boolean add(Person person)</div><div class="line">    &#123;</div><div class="line">        return restTemplate.postForObject(REST_URL_PREFIX + &quot;/person/add&quot;, person, Boolean.class);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    @RequestMapping(value = &quot;/consumer/person/get/&#123;id&#125;&quot;)</div><div class="line">    public Person get(@PathVariable(&quot;id&quot;) Long id)</div><div class="line">    &#123;</div><div class="line">        return restTemplate.getForObject(REST_URL_PREFIX + &quot;/person/get/&quot; + id, Person.class);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    @SuppressWarnings(&quot;unchecked&quot;)</div><div class="line">    @RequestMapping(value = &quot;/consumer/person/list&quot;)</div><div class="line">    public List&lt;Person&gt; list()</div><div class="line">    &#123;</div><div class="line">        return restTemplate.getForObject(REST_URL_PREFIX + &quot;/person/list&quot;, List.class);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="4-5-新建启动类"><a href="#4-5-新建启动类" class="headerlink" title="4.5 新建启动类"></a>4.5 新建启动类</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">public class ApplicationBootStart &#123;</div><div class="line">    public static void main(String[] args)&#123;</div><div class="line">        SpringApplication.run(ApplicationBootStart.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="4-6-完整项目结构"><a href="#4-6-完整项目结构" class="headerlink" title="4.6 完整项目结构"></a>4.6 完整项目结构</h3><p><img src="/2019/05/01/SpringCloud个人总结/C1565962178357.png" alt="1565962178357"></p>
<h2 id="5-同时启动服务提供者和服务消费者"><a href="#5-同时启动服务提供者和服务消费者" class="headerlink" title="5 同时启动服务提供者和服务消费者"></a>5 同时启动服务提供者和服务消费者</h2><p>也就是运行ApplicationBootStart8001和ApplicationBootStart80启动类即可</p>
<p>测试服务是否可以消费，访问消费者</p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image034.jpg" alt="img"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image036.jpg" alt="img"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image038.jpg" alt="img"></p>
<p>测试成功,以上就是成功的搭建了一个简单的微服务架构，下面我们会逐步的加入springcloud的其他组件，完善这个架构</p>
<h2 id="5-上面的项目存在什么问题"><a href="#5-上面的项目存在什么问题" class="headerlink" title="5.上面的项目存在什么问题"></a>5.上面的项目存在什么问题</h2><p>存在什么问题？</p>
<ul>
<li>在consumer中，我们把url地址硬编码到了代码中，不方便后期维护</li>
<li>consumer需要记忆provider的地址，如果出现变更，可能得不到通知，地址将失效</li>
<li>consumer不清楚provider的状态，服务宕机也不知道</li>
<li>provider只有1台服务，不具备高可用性</li>
<li>即便provider形成集群，consumer还需自己实现负载均衡</li>
</ul>
<p>其实上面说的问题，概括一下就是分布式服务必然要面临的问题：</p>
<ul>
<li>服务管理<ul>
<li>如何自动注册和发现</li>
<li>如何实现状态监管</li>
<li>如何实现动态路由</li>
</ul>
</li>
<li>服务如何实现负载均衡</li>
<li>服务如何解决容灾问题</li>
<li>服务如何实现统一配置</li>
</ul>
<p>以上的问题，我们都将在SpringCloud中得到答案。</p>
<h1 id="六-Eureka注册中心"><a href="#六-Eureka注册中心" class="headerlink" title="六.Eureka注册中心"></a>六.Eureka注册中心</h1><pre><code>**首先我们来解决第一问题，服务的管理 - 利用Eureka解决服务治理问题**
</code></pre><h2 id="1-Eureka概念"><a href="#1-Eureka概念" class="headerlink" title="1.Eureka概念"></a>1.Eureka概念</h2><p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-17_11-15-12.png" alt=""></p>
<pre><code>Eureka是Netflix的一个子模块，也是核心模块之一。Eureka是一个基于REST的服务，用于定位服务，以实现云端中间层服务发现和故障转移。**服务注册与发现对于微服务架构来说是非常重要的，有了服务发现与注册，只需要使用服务的标识符，就可以访问到服务(解决上诉案例在consumer中，我们把服务提供者的url地址硬编码到了代码中)**，而不需要修改服务调用的配置文件了。功能类似于dubbo的注册中心，比如Zookeeper。



Netflix在设计Eureka时遵守的就是CAP规则中的AP原则。
</code></pre><blockquote>
<p>CAP原则又称CAP定理，指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可兼得</p>
</blockquote>
<p>特别提示：同样作为dubbo服务注册中心的zookeeper遵守的是CP原则。</p>
<h2 id="2-Eureka架构和原理"><a href="#2-Eureka架构和原理" class="headerlink" title="2.Eureka架构和原理"></a>2.Eureka架构和原理</h2><p>Spring Cloud 封装了 Netflix 公司开发的 Eureka 模块来实现服务注册和发现(请对比Zookeeper)。</p>
<p><strong>Eureka 采用了 C-S 的设计架构。Eureka Server 作为服务注册功能的服务器，它是服务注册中心</strong>。</p>
<p>而系统中的其他微服务，使用 <strong>Eureka 的客户端（上诉案例中的，服务提供者和服务消费者相对于EurekaServer都是属于客户端，前者是向EurekaServer注册服务，后者是向EurekaServer获取服务）</strong>连接到 Eureka Server并维持心跳连接。这样系统的维护人员就可以通过 Eureka Server 来监控系统中各个微服务是否正常运行。SpringCloud 的一些其他模块（比如Zuul）就可以通过 Eureka Server 来发现系统中的其他微服务，并执行相关的逻辑。</p>
<blockquote>
<p>基本架构：</p>
</blockquote>
<p><img src="/SpringCloud个人总结/1525597885059.png" alt="1525597885059"></p>
<p>Eureka包含两个组件：Eureka Server和Eureka Client</p>
<blockquote>
<p>Eureka Server提供服务注册服务<br>各个节点启动后，会在EurekaServer中进行注册，这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到</p>
<p>EurekaClient是一个Java客户端，用于简化Eureka Server的交互，客户端同时也具备一个内置的、使用轮询(round-robin)负载算法的负载均衡器。在应用启动后，将会向Eureka Server发送心跳(默认周期为30秒)。如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，EurekaServer将会从服务注册表中把这个服务节点移除（默认90秒）         </p>
</blockquote>
<ul>
<li>Eureka：就是服务注册中心（可以是一个集群），对外暴露自己的地址</li>
<li>提供者：启动后向Eureka注册自己信息（地址，提供什么服务）</li>
<li>消费者：向Eureka订阅服务，Eureka会将对应服务的所有提供者地址列表发送给消费者，并且定期更新</li>
<li>心跳(续约)：提供者定期通过http方式向Eureka刷新自己的状态</li>
</ul>
<h2 id="3-实现EurekaServer"><a href="#3-实现EurekaServer" class="headerlink" title="3. 实现EurekaServer"></a>3. 实现EurekaServer</h2><p>接下来我们通过加入springcloud的Eureka服务治理组件，改造之前的例子，解决动态路由（上个例子中我们是把服务提供者的url硬编码到消费者中）、注册发现，动态监管的问题</p>
<h3 id="3-1-根据父工程实现单节点Eureka服务注册中心"><a href="#3-1-根据父工程实现单节点Eureka服务注册中心" class="headerlink" title="3.1 根据父工程实现单节点Eureka服务注册中心"></a>3.1 根据父工程实现单节点Eureka服务注册中心</h3><p>根据父工程microservicecloud  创建 microservicecloud-eureka-7001模块</p>
<h4 id="3-1-1-修改pom文件导入EurekaServer依赖"><a href="#3-1-1-修改pom文件导入EurekaServer依赖" class="headerlink" title="3.1.1 修改pom文件导入EurekaServer依赖"></a>3.1.1 修改pom文件导入EurekaServer依赖</h4><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;dependencies&gt;</div><div class="line">       &lt;!--eureka-server服务端 --&gt;</div><div class="line">       &lt;dependency&gt;</div><div class="line">           &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">           &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt;</div><div class="line">       &lt;/dependency&gt;</div><div class="line">       &lt;!-- 修改后立即生效，热部署 --&gt;</div><div class="line">       &lt;dependency&gt;</div><div class="line">           &lt;groupId&gt;org.springframework&lt;/groupId&gt;</div><div class="line">           &lt;artifactId&gt;springloaded&lt;/artifactId&gt;</div><div class="line">       &lt;/dependency&gt;</div><div class="line">       &lt;dependency&gt;</div><div class="line">           &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">           &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;</div><div class="line">       &lt;/dependency&gt;</div><div class="line">   &lt;/dependencies</div></pre></td></tr></table></figure>
<h4 id="3-1-2-修改application-yml配置文件"><a href="#3-1-2-修改application-yml配置文件" class="headerlink" title="3.1.2 修改application.yml配置文件"></a>3.1.2 修改application.yml配置文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">server:</div><div class="line">  port: 7001</div><div class="line"></div><div class="line">eureka:</div><div class="line">  instance:</div><div class="line">    hostname: localhost #eureka服务端的实例名称</div><div class="line">  client:</div><div class="line">    register-with-eureka: false     #false表示不向注册中心注册自己。</div><div class="line">    fetch-registry: false     #false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务</div><div class="line">    service-url:</div><div class="line">       defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/</div><div class="line">       # #设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址。</div><div class="line">       #等同于 http://localhost:7001/eureka/</div></pre></td></tr></table></figure>
<h4 id="3-1-3-创建启动类并添加-EnableEurekaServer注解"><a href="#3-1-3-创建启动类并添加-EnableEurekaServer注解" class="headerlink" title="3.1.3 创建启动类并添加@EnableEurekaServer注解"></a>3.1.3 创建启动类并添加@EnableEurekaServer注解</h4><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.entity;</div><div class="line"></div><div class="line">import org.springframework.boot.SpringApplication;</div><div class="line">import org.springframework.boot.autoconfigure.SpringBootApplication;</div><div class="line">import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;</div><div class="line"></div><div class="line"></div><div class="line">@SpringBootApplication</div><div class="line">@EnableEurekaServer ////EurekaServer服务器端启动类,接受其它微服务注册进来</div><div class="line">public class ApplicationBootStart7001 &#123;</div><div class="line">    public static void main(String[] args)</div><div class="line">    &#123;</div><div class="line"></div><div class="line">        SpringApplication.run(ApplicationBootStart7001.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="3-1-4-完整项目结构"><a href="#3-1-4-完整项目结构" class="headerlink" title="3.1.4 完整项目结构"></a>3.1.4 完整项目结构</h4><p><img src="/2019/05/01/SpringCloud个人总结/5C1565961802586.png" alt="1565961802586"></p>
<h4 id="3-1-5-运行启动类，启动EurekaServer"><a href="#3-1-5-运行启动类，启动EurekaServer" class="headerlink" title="3.1.5 运行启动类，启动EurekaServer"></a>3.1.5 运行启动类，启动EurekaServer</h4><p>访问网址：<strong><a href="http://localhost:7001/" target="_blank" rel="external">http://localhost:7001/</a></strong></p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-17_11-16-35.png" alt=""></p>
<p><strong>No application available 没有服务被发现 —- 因为没有注册服务进来当然不可能有服务被发现</strong></p>
<p>接下来我门把8001模块服务注册进来</p>
<h3 id="3-2-修改-服务提供者"><a href="#3-2-修改-服务提供者" class="headerlink" title="3.2 修改 服务提供者"></a>3.2 修改 服务提供者</h3><p>也就是修改上面我们实现的：microservicecloud-provider-person-8001 模块，将人员服务注册进EurekaServer中</p>
<h4 id="3-2-1-修改pom文件"><a href="#3-2-1-修改pom文件" class="headerlink" title="3.2.1 修改pom文件"></a>3.2.1 修改pom文件</h4><p>修改内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!-- 将微服务provider端注册进eureka --&gt;</div><div class="line">       &lt;dependency&gt;</div><div class="line">           &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">           &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;</div><div class="line">       &lt;/dependency&gt;</div><div class="line">       &lt;dependency&gt;</div><div class="line">           &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">           &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;</div><div class="line">       &lt;/dependency&gt;</div></pre></td></tr></table></figure>
<h4 id="3-2-2-修改application-yml配置文件"><a href="#3-2-2-修改application-yml配置文件" class="headerlink" title="3.2.2 修改application.yml配置文件"></a>3.2.2 修改application.yml配置文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">eureka:</div><div class="line">  client: #客户端注册进eureka服务列表内</div><div class="line">    service-url: </div><div class="line">      defaultZone: http://localhost:7001/eureka #这个地址就是我们在3.1.2定义的EurekaServer对外暴露的连接地址。</div></pre></td></tr></table></figure>
<h4 id="3-2-3-修改启动类添加-EnableEurekaClient注解"><a href="#3-2-3-修改启动类添加-EnableEurekaClient注解" class="headerlink" title="3.2.3 修改启动类添加@EnableEurekaClient注解"></a>3.2.3 修改启动类添加@EnableEurekaClient注解</h4><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">@EnableEurekaClient////本服务启动后会自动注册进 eureka服务中</div><div class="line">public class ApplicationBootStart8001 &#123;</div><div class="line">    public static void main(String[] args)</div><div class="line">    &#123;</div><div class="line"></div><div class="line">        SpringApplication.run(ApplicationBootStart8001.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="3-3-修改服务消费者"><a href="#3-3-修改服务消费者" class="headerlink" title="3.3 修改服务消费者"></a>3.3 修改服务消费者</h3><p><strong>通过访问服务名称的方式消费服务，解决硬编码服务提供者url的问题</strong></p>
<p>也就是修改上面我们实现的：microservicecloud-consumer-person-80 模块</p>
<h4 id="3-3-1-修改pom文件"><a href="#3-3-1-修改pom文件" class="headerlink" title="3.3.1 修改pom文件"></a>3.3.1 修改pom文件</h4><p>修改内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!-- 将微服务provider端注册进eureka --&gt;</div><div class="line">       &lt;dependency&gt;</div><div class="line">           &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">           &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;</div><div class="line">       &lt;/dependency&gt;</div><div class="line">       &lt;dependency&gt;</div><div class="line">           &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">           &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;</div><div class="line">       &lt;/dependency&gt;</div></pre></td></tr></table></figure>
<h4 id="3-3-2-修改application-yml配置文件"><a href="#3-3-2-修改application-yml配置文件" class="headerlink" title="3.3.2 修改application.yml配置文件"></a>3.3.2 修改application.yml配置文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">eureka:</div><div class="line">  client:</div><div class="line">    register-with-eureka: false</div><div class="line">    service-url:</div><div class="line">      defaultZone: http://localhost:7001/eureka/</div></pre></td></tr></table></figure>
<h4 id="3-3-3-修改启动类添加-EnableEurekaClient注解"><a href="#3-3-3-修改启动类添加-EnableEurekaClient注解" class="headerlink" title="3.3.3 修改启动类添加@EnableEurekaClient注解"></a>3.3.3 修改启动类添加@EnableEurekaClient注解</h4><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">@EnableEurekaClient//</div><div class="line">public class ApplicationBootStart80 &#123;</div><div class="line">    public static void main(String[] args)</div><div class="line">    &#123;</div><div class="line"></div><div class="line">        SpringApplication.run(ApplicationBootStart80.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="3-3-4修改ConsumerController代码"><a href="#3-3-4修改ConsumerController代码" class="headerlink" title="3.3.4修改ConsumerController代码"></a>3.3.4修改ConsumerController代码</h4><p>修改内容如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">//    private static final String REST_URL_PREFIX = &quot;http://localhost:8001&quot;;</div><div class="line">    private static final String REST_URL_PREFIX = &quot;http://MICROSERVICECLOUD-PERSON&quot;;</div></pre></td></tr></table></figure>
<p>把url更改为服务名称。</p>
<h3 id="3-4-启动EurekaServer和服务提供者，以及服务消费者"><a href="#3-4-启动EurekaServer和服务提供者，以及服务消费者" class="headerlink" title="3.4 启动EurekaServer和服务提供者，以及服务消费者"></a>3.4 启动EurekaServer和服务提供者，以及服务消费者</h3><p>运行ApplicationBootStart7001和ApplicationBootStart8001、ApplicationBootStart80</p>
<p>查看地址：<strong><a href="http://localhost:7001/" target="_blank" rel="external">http://localhost:7001/</a></strong></p>
<p><img src="/2019/05/01/SpringCloud个人总结/65963220408.png" alt="1565963220408"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/966479080.png" alt="1565966479080"></p>
<p>注册成功！！！</p>
<p>服务名称就是我们在服务提供者的application.yml配置文件中配置的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">spring:</div><div class="line">   application:</div><div class="line">    name: microservicecloud-person                          #很重要，对外暴露的微服务的名称</div></pre></td></tr></table></figure>
<p>我们发现生成的实例名称是没有任何意义的，而且实例的介绍地址不是ip的形式</p>
<p><img src="/2019/05/01/SpringCloud个人总结/963618268.png" alt="1565963618268"></p>
<p>下面就讲解修改这些小细节</p>
<h2 id="4-actuator与注册微服务信息完善"><a href="#4-actuator与注册微服务信息完善" class="headerlink" title="4.actuator与注册微服务信息完善"></a>4.<strong>actuator与注册微服务信息完善</strong></h2><h3 id="4-1-修改服务实例名和实例名访问路径显示ip"><a href="#4-1-修改服务实例名和实例名访问路径显示ip" class="headerlink" title="4.1 修改服务实例名和实例名访问路径显示ip"></a>4.1 修改服务实例名和实例名访问路径显示ip</h3><p>修改microservicecloud-provider-person-8001 模块的配置文件，添加以下内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">instance:</div><div class="line">  instance-id: microservicecloud-person8001</div><div class="line">  prefer-ip-address: true     #访问路径可以显示IP地址</div></pre></td></tr></table></figure>
<p>注意instance属性是eureka的子属性</p>
<p><img src="/2019/05/01/SpringCloud个人总结/565964019636.png" alt="1565964019636"></p>
<p>重启服务提供者ApplicationBootStart8001</p>
<p>查看EurekaServer</p>
<p><img src="/2019/05/01/SpringCloud个人总结/565964513626.png" alt="1565964513626"></p>
<p>这里涉及到了Eureka 的自我保护机制，下一章节我们会讲到。</p>
<h3 id="4-2-修改服务实例的详情页info"><a href="#4-2-修改服务实例的详情页info" class="headerlink" title="4.2 修改服务实例的详情页info"></a>4.2 修改服务实例的详情页info</h3><p>默认我么你点击服务实例名，跳转到的界面是：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/64617801.png" alt="1565964617801"></p>
<p>接下来我们要定制一下这界面，显示一下当前服务实例的一些说明信息。</p>
<p>（1）修改microservicecloud-provider-person-8001 模块的pom文件，添加以下内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!-- actuator监控信息完善 --&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p>（2）修改microservicecloud-provider-person-8001 模块的配置文件，添加以下内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">info:</div><div class="line">  app.name: $&#123;spring.application.name&#125;</div><div class="line">  company.name: kingge.top</div><div class="line">  build.artifactId: $&#123;project.artifactId&#125;</div><div class="line">  build.version: $&#123;project.version&#125;</div><div class="line">  app.desc: 这是一个提供查询部门人员信息的服务</div></pre></td></tr></table></figure>
<p>（3）修改父工程的pom文件，添加以下内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;build&gt;</div><div class="line">        &lt;finalName&gt;microservicecloud&lt;/finalName&gt;</div><div class="line">        &lt;resources&gt;</div><div class="line">            &lt;resource&gt;</div><div class="line">                &lt;directory&gt;src/main/resources&lt;/directory&gt;</div><div class="line">                &lt;filtering&gt;true&lt;/filtering&gt;</div><div class="line">            &lt;/resource&gt;</div><div class="line">        &lt;/resources&gt;</div><div class="line">        &lt;plugins&gt;</div><div class="line">            &lt;plugin&gt;</div><div class="line">                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</div><div class="line">                &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;</div><div class="line">                &lt;configuration&gt;</div><div class="line">                    &lt;delimiters&gt;</div><div class="line">                        &lt;delimit&gt;$&lt;/delimit&gt;</div><div class="line">                    &lt;/delimiters&gt;</div><div class="line">                &lt;/configuration&gt;</div><div class="line">            &lt;/plugin&gt;</div><div class="line">        &lt;/plugins&gt;</div><div class="line">    &lt;/build&gt;</div></pre></td></tr></table></figure>
<p>如果不添加那么就无法解析像这样的动态赋值${spring.application.name}</p>
<p>重启EurekaServer和服务提供者</p>
<p>再次查看服务实例名的info界面</p>
<p><img src="/2019/05/01/SpringCloud个人总结/C1565965118437.png" alt="1565965118437"></p>
<h2 id="5-Eureka详解"><a href="#5-Eureka详解" class="headerlink" title="5.Eureka详解"></a>5.Eureka详解</h2><h3 id="5-1-基础架构"><a href="#5-1-基础架构" class="headerlink" title="5.1.基础架构"></a>5.1.基础架构</h3><p>Eureka架构中的三个核心角色：</p>
<ul>
<li><p>服务注册中心</p>
<p>Eureka的服务端应用，提供服务注册和发现功能，就是刚刚我们建立的7001模块。</p>
</li>
<li><p>服务提供者</p>
<p>提供服务的应用，可以是SpringBoot应用，也可以是其它任意技术实现，只要对外提供的是Rest风格服务即可。本例中就是我们实现的8001模块。</p>
</li>
<li><p>服务消费者</p>
<p>消费应用从注册中心获取服务列表，从而得知每个服务方的信息，知道去哪里调用服务方。本例中就是我们实现的80模块。</p>
</li>
</ul>
<p><strong>服务提供和服务消费者相对于服务注册中心，他们都是客户端。所以他们访问EurekaServer导入的依赖是相同的都是spring-cloud-starter-netflix-eureka-client</strong></p>
<h3 id="5-2-服务提供者"><a href="#5-2-服务提供者" class="headerlink" title="5.2.服务提供者"></a>5.2.服务提供者</h3><p>服务提供者要向EurekaServer注册服务，并且完成服务续约等工作。</p>
<blockquote>
<p>服务注册</p>
</blockquote>
<p>服务提供者在启动时，会检测配置属性中的：<code>eureka.client.register-with-eureka=true</code>参数是否正确，事实上默认就是true。如果值确实为true，则会向EurekaServer发起一个Rest请求，并携带自己的元数据信息，Eureka Server会把这些信息保存到一个双层Map结构中。</p>
<ul>
<li>第一层Map的Key就是服务id，一般是配置中的<code>spring.application.name</code>属性</li>
<li>第二层Map的key是服务的实例id。一般host+ serviceId + port，例如：<code>locahost:service-provider:8081</code></li>
<li>值则是服务的实例对象，也就是说一个服务，可以同时启动多个不同实例，形成集群。</li>
</ul>
<blockquote>
<p>服务续约</p>
</blockquote>
<p>在注册服务完成以后，服务提供者会维持一个心跳（定时向EurekaServer发起Rest请求），告诉EurekaServer：“我还活着”。这个我们称为服务的续约（renew）；</p>
<p>有两个重要参数可以修改服务续约的行为：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><div class="line"><span class="attr">eureka:</span></div><div class="line"><span class="attr">  instance:</span></div><div class="line"><span class="attr">    lease-expiration-duration-in-seconds:</span> <span class="number">90</span></div><div class="line"><span class="attr">    lease-renewal-interval-in-seconds:</span> <span class="number">30</span></div></pre></td></tr></table></figure>
<ul>
<li>lease-renewal-interval-in-seconds：服务续约(renew)的间隔，默认为30秒</li>
<li>lease-expiration-duration-in-seconds：服务失效时间，默认值90秒</li>
</ul>
<p>也就是说，默认情况下每个30秒服务会向注册中心发送一次心跳，证明自己还活着。如果超过90秒没有发送心跳，EurekaServer就会认为该服务宕机，会从服务列表中移除，这两个值在生产环境不要修改，默认即可。</p>
<p>但是在开发时，这个值有点太长了，经常我们关掉一个服务，会发现Eureka依然认为服务在活着。所以我们在开发阶段可以适当调小。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><div class="line"><span class="attr">eureka:</span></div><div class="line"><span class="attr">  instance:</span></div><div class="line"><span class="attr">    lease-expiration-duration-in-seconds:</span> <span class="number">10</span> <span class="comment"># 10秒即过期</span></div><div class="line"><span class="attr">    lease-renewal-interval-in-seconds:</span> <span class="number">5</span> <span class="comment"># 5秒一次心跳</span></div></pre></td></tr></table></figure>
<h3 id="5-3-服务消费者"><a href="#5-3-服务消费者" class="headerlink" title="5.3.服务消费者"></a>5.3.服务消费者</h3><blockquote>
<p>获取服务列表</p>
</blockquote>
<p>当服务消费者启动时，会检测<code>eureka.client.fetch-registry=true</code>参数的值，如果为true，则会拉取Eureka Server服务的列表只读备份，然后缓存在本地。并且<code>每隔30秒</code>会重新获取并更新数据。我们可以通过下面的参数来修改：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><div class="line"><span class="attr">eureka:</span></div><div class="line"><span class="attr">  client:</span></div><div class="line"><span class="attr">    registry-fetch-interval-seconds:</span> <span class="number">5</span></div></pre></td></tr></table></figure>
<p>生产环境中，我们不需要修改这个值。</p>
<p>但是为了开发环境下，能够快速得到服务的最新状态，我们可以将其设置小一点。</p>
<h3 id="5-4-失效剔除和自我保护"><a href="#5-4-失效剔除和自我保护" class="headerlink" title="5.4.失效剔除和自我保护"></a>5.4.失效剔除和自我保护</h3><blockquote>
<p>服务下线</p>
</blockquote>
<p>当服务进行正常关闭操作时，它会触发一个服务下线的REST请求给Eureka Server，告诉服务注册中心：“我要下线了”。服务中心接受到请求之后，将该服务置为下线状态。</p>
<blockquote>
<p>失效剔除</p>
</blockquote>
<p>有些时候，我们的服务提供方并不一定会正常下线，可能因为内存溢出、网络故障等原因导致服务无法正常工作。Eureka Server需要将这样的服务剔除出服务列表。因此它会开启一个定时任务，每隔60秒对所有失效的服务（超过90秒未响应）进行剔除。</p>
<p>可以通过<code>eureka.server.eviction-interval-timer-in-ms</code>参数对其进行修改，单位是毫秒，生产环境不要修改。</p>
<p>这个会对我们开发带来极大的不变，你对服务重启，隔了60秒Eureka才反应过来。开发阶段可以适当调整，比如：10秒</p>
<p><img src="/2019/05/01/SpringCloud个人总结/1528696142799.png" alt="1528696142799"></p>
<blockquote>
<p>自我保护</p>
</blockquote>
<p>我们关停一个服务，就会在Eureka面板看到一条警告：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/1525618396076.png" alt="1525618396076"></p>
<p>这是触发了Eureka的自我保护机制。当一个服务未按时进行心跳续约时，Eureka会统计最近15分钟心跳失败的服务实例的比例是否超过了85%。在生产环境下，因为网络延迟等原因，心跳失败实例的比例很有可能超标，但是此时就把服务剔除列表并不妥当，因为服务可能没有宕机。Eureka就会把当前实例的注册信息保护起来，不予剔除。生产环境下这很有效，保证了大多数服务依然可用。</p>
<p><strong>也就是好死不如赖活着，这个就是用EurekaServer的AP原则，保证可用性</strong></p>
<p>但是这给我们的开发带来了麻烦， 因此开发阶段我们都会关闭自我保护模式：（itcast-eureka）</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><div class="line"><span class="attr">eureka:</span></div><div class="line"><span class="attr">  server:</span></div><div class="line"><span class="attr">    enable-self-preservation:</span> <span class="literal">false</span> <span class="comment"># 关闭自我保护模式（缺省为打开）</span></div><div class="line"><span class="attr">    eviction-interval-timer-in-ms:</span> <span class="number">1000</span> <span class="comment"># 扫描失效服务的间隔时间（缺省为60*1000ms）</span></div></pre></td></tr></table></figure>
<p><strong>综上，自我保护模式是一种应对网络异常的安全保护措施。它的架构哲学是宁可同时保留所有微服务（健康的微服务和不健康的微服务都会保留），也不盲目注销任何健康的微服务。使用自我保护模式，可以让Eureka集群更加的健壮、稳定。</strong></p>
<p><strong>一句话：某时刻某一个微服务不可用了，eureka不会立刻清理，依旧会对该微服务的信息进行保存</strong></p>
<h2 id="6-消费者获取服务信息"><a href="#6-消费者获取服务信息" class="headerlink" title="6.消费者获取服务信息"></a>6.消费者获取服务信息</h2><p>如果我们想要在消费者端获取服务者提供的服务实例列表，那么应该怎么做？<strong>对于注册进eureka里面的微服务，可以通过服务发现来获得该服务的信息</strong></p>
<p>既然是消费者端想查看服务端暴露的服务信息，那么就需要在服务提供者实现一个查询暴露服务实例的列表的接口</p>
<p>1.修改服务端PersonController</p>
<p>添加如下代码，查询服务名称为MICROSERVICECLOUD-PERSON的服务实例列表信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Autowired</div><div class="line">private DiscoveryClient client;</div><div class="line">@RequestMapping(value = &quot;/person/discovery&quot;, method = RequestMethod.GET)</div><div class="line">public Object discovery()</div><div class="line">&#123;</div><div class="line">	List&lt;String&gt; list = client.getServices();</div><div class="line">	System.out.println(&quot;**********&quot; + list);</div><div class="line"></div><div class="line">	List&lt;ServiceInstance&gt; srvList = client.getInstances(&quot;MICROSERVICECLOUD-PERSON&quot;);</div><div class="line">	for (ServiceInstance element : srvList) &#123;</div><div class="line">		System.out.println(element.getServiceId() + &quot;\t&quot; + element.getHost() + &quot;\t&quot; + element.getPort() + &quot;\t&quot;</div><div class="line">				+ element.getUri());</div><div class="line">	&#125;</div><div class="line">	return this.client;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>2.服务提供者启动类添加注解@EnableDiscoveryClient （后来测试发现其实这一步是多余的）</p>
<p><img src="/2019/05/01/SpringCloud个人总结/5C1565967990809.png" alt="1565967990809"></p>
<p>因为@EnableEurekaClient注解已经包含了@EnableDiscoveryClient 注解</p>
<p><img src="/2019/05/01/SpringCloud个人总结/1565968096288.png" alt="1565968096288"></p>
<p><strong>也就是说当服务注册中心是Eureka的时候那么官方已经为了包装了一个注解替代了@EnableDiscoveryClient，但是如果注册中心不是Eureka的话，那么建议使用@EnableDiscoveryClient注解实现服务发现，因为这里注册中心是Eureka那么就是用官方推荐的@EnableEurekaClient</strong></p>
<p>3.修改ConsumerController代码，访问服务提供者提供的接口：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"> <span class="comment">// 测试@EnableDiscoveryClient,消费端可以调用服务发现</span></div><div class="line"><span class="meta">@RequestMapping</span>(value = <span class="string">"/consumer/person/discovery"</span>)</div><div class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">discovery</span><span class="params">()</span></span></div><div class="line"><span class="function"></span>&#123;</div><div class="line">    <span class="keyword">return</span> restTemplate.getForObject(REST_URL_PREFIX + <span class="string">"/person/discovery"</span>, Object.class);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>4.启动服务提供者和服务消费者</p>
<p>消费者访问接口</p>
<p><img src="/2019/05/01/SpringCloud个人总结/C1565968242592.png" alt="1565968242592"></p>
<h2 id="7-EurekaServer集群"><a href="#7-EurekaServer集群" class="headerlink" title="7.EurekaServer集群"></a>7.EurekaServer集群</h2><p>单个的EurekaServer很明显是不符合HA，高可用原则，所以下面再加两台EurekaServer-8002和8003构成EurekaServer集群</p>
<p><img src="/2019/05/01/SpringCloud个人总结/1565970421791.png" alt="1565970421791"></p>
<p>基本原理</p>
<blockquote>
<p> 上图是来自eureka的官方架构图，这是基于集群配置的eureka； </p>
<p> - 处于不同节点的eureka通过Replicate进行数据同步 </p>
<p> - Application Service为服务提供者 </p>
<p> - Application Client为服务消费者 </p>
<p> - Make Remote Call完成一次服务调用</p>
<p> 服务启动后向Eureka注册，Eureka Server会将注册信息向其他Eureka Server进行同步，当服务消费者要调用服务提供者，则向服务注册中心获取服务提供者地址，然后会将服务提供者地址缓存在本地，下次再调用时，则直接从本地缓存中取，完成一次调用。</p>
<p> 当服务注册中心Eureka Server检测到服务提供者因为宕机、网络原因不可用时，则在服务注册中心将服务置为DOWN状态，并把当前服务提供者状态向订阅者发布，订阅过的服务消费者更新本地缓存。</p>
<p> 服务提供者在启动后，周期性（默认30秒）向Eureka Server发送心跳，以证明当前服务是可用状态。Eureka Server在一定的时间（默认90秒）未收到客户端的心跳，则认为服务宕机，注销该实例。</p>
</blockquote>
<h3 id="7-1-根据microservicecloud-eureka-7001创建两个相同的工程"><a href="#7-1-根据microservicecloud-eureka-7001创建两个相同的工程" class="headerlink" title="7.1 根据microservicecloud-eureka-7001创建两个相同的工程"></a>7.1 根据microservicecloud-eureka-7001创建两个相同的工程</h3><p>分别是microservicecloud-eureka-7002和microservicecloud-eureka-7003</p>
<p>按照7001为模板粘贴POM</p>
<p>修改7002和7003的主启动类</p>
<p>完整工程如下</p>
<p><img src="/2019/05/01/SpringCloud个人总结/1565970941327.png" alt="1565970941327"></p>
<h3 id="7-2-修改映射配置-实现唯一的eureka服务端的实例名称"><a href="#7-2-修改映射配置-实现唯一的eureka服务端的实例名称" class="headerlink" title="7.2 修改映射配置-实现唯一的eureka服务端的实例名称"></a>7.2 修改映射配置-实现唯一的eureka服务端的实例名称</h3><p>为了模拟EurekaServer集群，不同的EurekaServer在不同的机器，而且拥有不同的实例名称</p>
<p><strong>找到C:\Windows\System32\drivers\etc路径下的hosts文件</strong></p>
<table>
<thead>
<tr>
<th><strong>修改映射配置添加进hosts文件</strong></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>127.0.0.1  peer1</strong></td>
<td></td>
</tr>
<tr>
<td><strong>127.0.0.1  peer2</strong></td>
<td></td>
</tr>
<tr>
<td><strong>127.0.0.1  peer3</strong></td>
</tr>
</tbody>
</table>
<h3 id="7-3-修改7001-7003三台EurekaServer的配置文件"><a href="#7-3-修改7001-7003三台EurekaServer的配置文件" class="headerlink" title="7.3 修改7001-7003三台EurekaServer的配置文件"></a>7.3 修改7001-7003三台EurekaServer的配置文件</h3><p>7001 修改内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">server:</div><div class="line">  port: 7001</div><div class="line"></div><div class="line">eureka:</div><div class="line">  instance:</div><div class="line">    hostname: peer1 #peer1 #eureka服务端的实例名称</div><div class="line">  client:</div><div class="line">    register-with-eureka: false     #false表示不向注册中心注册自己。</div><div class="line">    fetch-registry: false     #false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务</div><div class="line">    service-url:</div><div class="line">       defaultZone: http://peer2:7002/eureka/,http://peer3:7003/eureka/ #注册7002和7003 自己不用声明</div></pre></td></tr></table></figure>
<p>7002 修改内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">server:</div><div class="line">  port: 7002</div><div class="line"></div><div class="line">eureka:</div><div class="line">  instance:</div><div class="line">    hostname: peer2 #eureka服务端的实例名称</div><div class="line">  client:</div><div class="line">    register-with-eureka: false     #false表示不向注册中心注册自己。</div><div class="line">    fetch-registry: false     #false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务</div><div class="line">    service-url:</div><div class="line">       defaultZone: http://peer1:7001/eureka/,http://peer3:7003/eureka/ #注册7001和7003 自己不用声明</div><div class="line">       #等同于http://localhost:7001/eureka/</div></pre></td></tr></table></figure>
<p>7003修改内容如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">server:</div><div class="line">  port: 7003</div><div class="line"></div><div class="line">eureka:</div><div class="line">  instance:</div><div class="line">    hostname: peer3 #eureka服务端的实例名称</div><div class="line">  client:</div><div class="line">    register-with-eureka: false     #false表示不向注册中心注册自己。</div><div class="line">    fetch-registry: false     #false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务</div><div class="line">    service-url:</div><div class="line">       defaultZone: http://peer1:7001/eureka/,http://peer2:7002/eureka/ #注册7001和7002 自己不用声明</div><div class="line">       #等同于http://localhost:7001/eureka/</div></pre></td></tr></table></figure>
<p>需要注意的是service-url:defaultZone的值，都是包含其他EurekaServer的值，不用书写自己的。</p>
<h3 id="7-4-修改服务提供者的配置文件"><a href="#7-4-修改服务提供者的配置文件" class="headerlink" title="7.4 修改服务提供者的配置文件"></a>7.4 修改服务提供者的配置文件</h3><p>也就是修改microservicecloud-provider-person-8001模块修改内容如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">server:</div><div class="line">  port: 8001</div><div class="line"></div><div class="line">mybatis:</div><div class="line">  config-location: classpath:mybatis/mybatis.cfg.xml        # mybatis配置文件所在路径</div><div class="line">  type-aliases-package: com.kingge.entity    # 所有Entity别名类所在包</div><div class="line">  mapper-locations:</div><div class="line">  - classpath:mybatis/mapper/**/*.xml                       # mapper映射文件</div><div class="line"></div><div class="line">spring:</div><div class="line">   application:</div><div class="line">    name: microservicecloud-person                          #很重要，对外暴露的微服务的名称</div><div class="line">   datasource:</div><div class="line">    type: com.alibaba.druid.pool.DruidDataSource            # 当前数据源操作类型</div><div class="line">    driver-class-name: org.gjt.mm.mysql.Driver              # mysql驱动包</div><div class="line">    url: jdbc:mysql://127.0.0.1:3306/test              # 数据库名称</div><div class="line">    username: root</div><div class="line">    password: 123</div><div class="line">    dbcp2:</div><div class="line">      min-idle: 5                                           # 数据库连接池的最小维持连接数</div><div class="line">      initial-size: 5                                       # 初始化连接数</div><div class="line">      max-total: 5                                          # 最大连接数</div><div class="line">      max-wait-millis: 200                                  # 等待连接获取的最大超时时间</div><div class="line">#</div><div class="line">eureka:</div><div class="line">  client: #客户端注册进eureka服务列表内</div><div class="line">    service-url:</div><div class="line">      defaultZone: http://peer1:7001/eureka/,http://peer2:7002/eureka/,http://peer3:7003/eureka/</div><div class="line">#      http://localhost:7001/eureka #单机版本使用</div><div class="line">#      defaultZone: http://peer1:7001/eureka/,http://peer2:7002/eureka/,http://peer3:7003/eureka/</div><div class="line">  instance:</div><div class="line">    instance-id: microservicecloud-person8001 #自定义服务实例名</div><div class="line">    prefer-ip-address: true     #访问路径可以显示IP地址</div><div class="line">#</div><div class="line">info:</div><div class="line">  app.name: $&#123;spring.application.name&#125;</div><div class="line">  company.name: kingge.top</div><div class="line">  build.artifactId: $&#123;project.artifactId&#125;</div><div class="line">  build.version: $&#123;project.version&#125;</div><div class="line">  app.desc: 这是一个提供查询部门人员信息的服务</div></pre></td></tr></table></figure>
<p>实际上就是修改了service-url:defaultZone的值，修改为了EurekaServer集群的地址，其他配置没有改变</p>
<h3 id="7-5重启7001-7003服务器"><a href="#7-5重启7001-7003服务器" class="headerlink" title="7.5重启7001-7003服务器"></a>7.5重启7001-7003服务器</h3><p>也就是分别运行ApplicationBootStart7001、ApplicationBootStart7002、ApplicationBootStart7003</p>
<p>访问查看</p>
<p><img src="/2019/05/01/SpringCloud个人总结/565971841015.png" alt="1565971841015"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/1565972117167.png" alt="1565972117167"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/963618212368.png" alt="1565972150084"></p>
<p>部署成功！！！！！！！</p>
<h2 id="8-Eureka和Zookeeper-服务注册中心比较"><a href="#8-Eureka和Zookeeper-服务注册中心比较" class="headerlink" title="8.Eureka和Zookeeper-服务注册中心比较"></a>8.<strong>Eureka和Zookeeper-服务注册中心比较</strong></h2><p>著名的CAP理论指出，一个分布式系统不可能同时满足C(一致性)、A(可用性)和P(分区容错性)。由于分区容错性P在是分布式系统中必须要保证的，因此我们只能在A和C之间进行权衡。</p>
<p>那么分布式系统，必然要求分区容错性，也就是P原则，那么Zookeeper选择了C，Eureka选择了A</p>
<p> 因此Zookeeper保证的是CP,Eureka则是AP。</p>
<h3 id="8-1-Zookeeper保证CP"><a href="#8-1-Zookeeper保证CP" class="headerlink" title="8.1 Zookeeper保证CP"></a>8.1 Zookeeper保证CP</h3><pre><code>当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的注册信息，但不能接受服务直接down掉不可用。也就是说，服务注册功能对可用性的要求要高于一致性。但是zk会出现这样一种情况，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新进行leader选举。问题在于，选举leader的时间太长，30 ~ 120s, 且选举期间整个zk集群都是不可用的，这就导致在选举期间注册服务瘫痪。在云部署的环境下，因网络问题使得zk集群失去master节点是较大概率会发生的事，虽然服务能够最终恢复，但是漫长的选举时间导致的注册长期不可用是不能容忍的。
</code></pre><h3 id="8-2-Eureka保证AP"><a href="#8-2-Eureka保证AP" class="headerlink" title="8.2 Eureka保证AP"></a>8.2 Eureka保证AP</h3><pre><code>Eureka看明白了这一点，因此在设计时就优先保证可用性。Eureka各个节点都是平等的 ，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而Eureka的客户端在向某个Eureka注册或时如果发现连接失败，则会自动切换至其它节点，只要有一台Eureka还在，就能保证注册服务可用(保证可用性)，只不过查到的信息可能不是最新的(不保证强一致性)。除此之外，Eureka还有一种自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，此时会出现以下几种情况： 
</code></pre><blockquote>
<pre><code>Eureka不再从注册列表中移除因为长时间没收到心跳而应该过期的服务 

Eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其它节点上(即保证当前节点依然可用)

当网络稳定时，当前实例新的注册信息会被同步到其它节点中
</code></pre><p>因此， Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使整个注册服务瘫痪。</p>
</blockquote>
<p> 那么既然保证了保证了可用性，那么数据的一致性肯定是不能够保证了，所以这个就是自我保护的机制。所以到底是AP还是CP，又或者是AC（数据库），要看业务场景来定。</p>
<h1 id="七-Ribbon负载均衡"><a href="#七-Ribbon负载均衡" class="headerlink" title="七.Ribbon负载均衡"></a>七.<strong>Ribbon负载均衡</strong></h1><p><strong>接下来解决第二个问题，那就是假设在多个服务提供者提供服务的情况下，怎么做到负载均衡，解决需要把服务提供者url硬编码到消费者端的问题。</strong></p>
<h2 id="7-1-Ribbon概念"><a href="#7-1-Ribbon概念" class="headerlink" title="7.1 Ribbon概念"></a>7.1 Ribbon概念</h2><p>Spring Cloud Ribbon是基于Netflix Ribbon实现的一套<strong>客户端 负载均衡的工具</strong> 。</p>
<pre><code>简单的说，Ribbon是Netflix发布的开源项目，主要功能是提供**客户端**的**软件负载**均衡算法，将Netflix的中间层服务连接在一起。Ribbon客户端组件提供一系列完善的配置项如连接超时，重试等。简单的说，就是在配置文件中列出Load Balancer（简称LB）后面所有的机器，Ribbon会自动的帮助你基于某种规则（如简单轮询，随机连接等）去连接这些机器。我们也很容易使用Ribbon**实现自定义的负载均衡算法**。
</code></pre><h2 id="7-2-什么叫LB（负载均衡）"><a href="#7-2-什么叫LB（负载均衡）" class="headerlink" title="7.2 什么叫LB（负载均衡）"></a>7.2 什么叫<strong>LB（负载均衡）</strong></h2><p> LB，即负载均衡(Load Balance)，在微服务或分布式集群中经常用的一种应用。</p>
<p>负载均衡简单的说就是将用户的请求平摊的分配到多个服务上，从而达到系统的HA。</p>
<p>常见的负载均衡有软件Nginx，LVS，硬件 F5等。</p>
<p>相应的在中间件，例如：dubbo和SpringCloud中均给我们提供了负载均衡，SpringCloud的负载均衡算法可以自定义。 </p>
<p> 两种负载均衡：</p>
<ol>
<li>集中式LB：偏硬件，服务的消费方和提供方之间使用独立的LB设施，由该设施负责把访问请求以某种策略转发至服务的提供方。</li>
<li><p>进程内LB：偏软件， 将LB逻辑集成到消费方，消费方从服务注册中心指导哪些地址可用，再自己选择一个合适的服务器。</p>
<p><strong>Ribbon就属于进程内LB，它只是一个类库，集成于消费方进程，消费方通过它来获取到服务提供方的地址。</strong></p>
</li>
</ol>
<h2 id="7-3-Ribbon负载均衡实现"><a href="#7-3-Ribbon负载均衡实现" class="headerlink" title="7.3 Ribbon负载均衡实现"></a>7.3 Ribbon负载均衡实现</h2><p>因为在上面的例子中只存在一个8001模块在提供服务，那么为了能够演示负载均衡的例子，这里需要再增加两个服务提供者8002和8003</p>
<h3 id="7-3-1-根据8001模块复制新建两份分别命名为8002和8003"><a href="#7-3-1-根据8001模块复制新建两份分别命名为8002和8003" class="headerlink" title="7.3.1 根据8001模块复制新建两份分别命名为8002和8003"></a>7.3.1 根据8001模块复制新建两份分别命名为8002和8003</h3><p>请看完整项目结构图</p>
<p>8002模块</p>
<p><img src="/2019/05/01/SpringCloud个人总结/C1566008410173.png" alt="1566008410173"></p>
<p>8003模块</p>
<p><img src="/2019/05/01/SpringCloud个人总结/566008463016.png" alt="1566008463016"></p>
<h3 id="7-3-2-新建数据库test2、test3，让各自微服务分别连各自的数据库"><a href="#7-3-2-新建数据库test2、test3，让各自微服务分别连各自的数据库" class="headerlink" title="7.3.2 新建数据库test2、test3，让各自微服务分别连各自的数据库"></a>7.3.2 新建数据库test2、test3，<strong>让各自微服务分别连各自的数据库</strong></h3><p>我们知道一个微服务可能是一套完整的系统，那么也就意味着他可能拥有自己的数据库。而且为了方便测试负载均衡，我们让8001-8003这三个服务提供者各自连接自己的数据库，也方便验证负载均衡是否实现。</p>
<p>给test2数据库导入数据：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">DROP TABLE IF EXISTS `person`;</div><div class="line">CREATE TABLE `person` (</div><div class="line">  `deptno` int(255) NOT NULL AUTO_INCREMENT,</div><div class="line">  `db_source` varchar(255) DEFAULT NULL,</div><div class="line">  `dname` varchar(255) DEFAULT NULL,</div><div class="line">  PRIMARY KEY (`deptno`)</div><div class="line">) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=utf8;</div><div class="line"></div><div class="line">-- ----------------------------</div><div class="line">-- Records of person</div><div class="line">-- ----------------------------</div><div class="line">INSERT INTO `person` VALUES (&apos;5&apos;, &apos;test2&apos;, &apos;开发部&apos;);</div><div class="line">INSERT INTO `person` VALUES (&apos;6&apos;, &apos;test2&apos;, &apos;人事部&apos;);</div><div class="line">INSERT INTO `person` VALUES (&apos;7&apos;, &apos;test2&apos;, &apos;集成部&apos;);</div><div class="line">INSERT INTO `person` VALUES (&apos;8&apos;, &apos;test2&apos;, &apos;市场部&apos;);</div><div class="line">INSERT INTO `person` VALUES (&apos;9&apos;, &apos;test2&apos;, &apos;hr&apos;);</div></pre></td></tr></table></figure>
<p>db_source字段标识，数据来源那个数据库</p>
<p>给test3数据库导入数据：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">DROP TABLE IF EXISTS `person`;</div><div class="line">CREATE TABLE `person` (</div><div class="line">  `deptno` int(255) NOT NULL AUTO_INCREMENT,</div><div class="line">  `db_source` varchar(255) DEFAULT NULL,</div><div class="line">  `dname` varchar(255) DEFAULT NULL,</div><div class="line">  PRIMARY KEY (`deptno`)</div><div class="line">) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=utf8;</div><div class="line"></div><div class="line">-- ----------------------------</div><div class="line">-- Records of person</div><div class="line">-- ----------------------------</div><div class="line">INSERT INTO `person` VALUES (&apos;5&apos;, &apos;test3&apos;, &apos;开发部&apos;);</div><div class="line">INSERT INTO `person` VALUES (&apos;6&apos;, &apos;test3&apos;, &apos;人事部&apos;);</div><div class="line">INSERT INTO `person` VALUES (&apos;7&apos;, &apos;test3&apos;, &apos;集成部&apos;);</div><div class="line">INSERT INTO `person` VALUES (&apos;8&apos;, &apos;test3&apos;, &apos;市场部&apos;);</div><div class="line">INSERT INTO `person` VALUES (&apos;9&apos;, &apos;test3&apos;, &apos;hr&apos;);</div></pre></td></tr></table></figure>
<p><img src="/2019/05/01/SpringCloud个人总结/6009325282.png" alt="1566009325282"></p>
<h3 id="7-3-3-修改8002-8003各自application-yml配置文件"><a href="#7-3-3-修改8002-8003各自application-yml配置文件" class="headerlink" title="7.3.3 修改8002/8003各自application.yml配置文件"></a>7.3.3 <strong>修改8002/8003各自application.yml配置文件</strong></h3><p>实际上只需要修改三个地方：服务暴露的端口号，服务连接的数据库，服务的实例名</p>
<p><strong>注意：服务名称不能够修改</strong></p>
<p><img src="/2019/05/01/SpringCloud个人总结/566008980542.png" alt="1566008980542"></p>
<p><strong><em>因为这三个服务都是提供同样的业务，那么就不会归属到一个服务组下，也就是说我们想要的是：microservicecloud-person 这个服务名称（服务组）下面有三个服务实例（8001-8003）提供服务，这样负载均衡才能够演示</em></strong></p>
<blockquote>
<p>8002模块修改如下</p>
</blockquote>
<p><img src="/2019/05/01/SpringCloud个人总结/66009196970.png" alt="1566009196970"></p>
<blockquote>
<p>8003模块修改如下</p>
</blockquote>
<p><img src="/2019/05/01/SpringCloud个人总结/1566009240467.png" alt="1566009240467"></p>
<h3 id="7-3-4-启动EurekaServer集群和8001-8003服务模块"><a href="#7-3-4-启动EurekaServer集群和8001-8003服务模块" class="headerlink" title="7.3.4 启动EurekaServer集群和8001-8003服务模块"></a>7.3.4 启动EurekaServer集群和8001-8003服务模块</h3><p><img src="/2019/05/01/SpringCloud个人总结/6009501569.png" alt="1566009501569"></p>
<p>查看EurekaServer</p>
<p><a href="http://peer1:7001/" target="_blank" rel="external">http://peer1:7001/</a></p>
<p><img src="/2019/05/01/SpringCloud个人总结/6009599956.png" alt="1566009599956"></p>
<p><a href="http://peer2:7002/" target="_blank" rel="external">http://peer2:7002/</a></p>
<p><img src="/2019/05/01/SpringCloud个人总结/566009617535.png" alt="1566009617535"></p>
<p><a href="http://peer3:7003/" target="_blank" rel="external">http://peer3:7003/</a></p>
<p><img src="/2019/05/01/SpringCloud个人总结/C1566009632534.png" alt="1566009632534"></p>
<p>服务提供者集群创建成功</p>
<h3 id="7-3-5-自测启动的服务是否可用"><a href="#7-3-5-自测启动的服务是否可用" class="headerlink" title="7.3.5 自测启动的服务是否可用"></a>7.3.5 自测启动的服务是否可用</h3><p><img src="/2019/05/01/SpringCloud个人总结/1566009826135.png" alt="1566009826135"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/566009838479.png" alt="1566009838479"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/1566009865015.png" alt="1566009865015"></p>
<h3 id="7-3-6-修改服务消费者-采取负载均衡方式访问服务"><a href="#7-3-6-修改服务消费者-采取负载均衡方式访问服务" class="headerlink" title="7.3.6 修改服务消费者-采取负载均衡方式访问服务"></a>7.3.6 修改服务消费者-采取负载均衡方式访问服务</h3><p>也就是修改microservicecloud-consumer-person-80模块</p>
<p><strong>（1）修改pom文件添加Robbin依赖</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!-- Ribbon相关 --&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p><strong>（2）修改application.yml文件</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">server:</div><div class="line">  port: 80</div><div class="line">  </div><div class="line">#</div><div class="line">eureka:</div><div class="line">  client:</div><div class="line">    register-with-eureka: false</div><div class="line">    service-url:</div><div class="line">      defaultZone: http://peer1:7001/eureka/,http://peer2:7002/eureka/,http://peer3:7003/eureka/</div></pre></td></tr></table></figure>
<p>也就是修改服务注册中心地址为集群地址</p>
<p><strong>（3）修改ConfigBean配置类添加@LoadBalanced注解，获取rest服务的时候添加ribbon</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Configuration</div><div class="line">public class ConfigBean</div><div class="line">&#123; </div><div class="line">	@Bean</div><div class="line">	@LoadBalanced</div><div class="line">	public RestTemplate getRestTemplate()</div><div class="line">	&#123;</div><div class="line">		return new RestTemplate();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><strong>（4）主启动类ApplicationBootStart80添加@EnableEurekaClient</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">@EnableEurekaClient//这里建议使用@EnableDiscoveryClient 替换@EnableEurekaClient</div><div class="line">public class ApplicationBootStart80 &#123;</div><div class="line">    public static void main(String[] args)</div><div class="line">    &#123;</div><div class="line"></div><div class="line">        SpringApplication.run(ApplicationBootStart80.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="7-3-7-修改服务消费者"><a href="#7-3-7-修改服务消费者" class="headerlink" title="7.3.7 修改服务消费者"></a>7.3.7 修改服务消费者</h3><p>修改ConsumerController代码</p>
<p>修改内容如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">//    private static final String REST_URL_PREFIX = &quot;http://localhost:8001&quot;;</div><div class="line">    private static final String REST_URL_PREFIX = &quot;http://MICROSERVICECLOUD-PERSON&quot;;</div></pre></td></tr></table></figure>
<p>把url更改为服务名称</p>
<p><strong>Ribbon和Eureka整合后Consumer可以直接调用服务而不用再关心地址和端口号</strong></p>
<h3 id="7-3-8-启动7001-7003-8001-8003，80"><a href="#7-3-8-启动7001-7003-8001-8003，80" class="headerlink" title="7.3.8 启动7001-7003,8001-8003，80"></a>7.3.8 启动7001-7003,8001-8003，80</h3><p><img src="/2019/05/01/SpringCloud个人总结/566010881201.png" alt="1566010881201"></p>
<p>启动完成后测试：</p>
<p>第一次访问</p>
<p><img src="/2019/05/01/SpringCloud个人总结/566011120741.png" alt="1566011120741"></p>
<p>第二次访问：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/1566011157293.png" alt="1566011157293"></p>
<p>第三次访问：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/6011173416.png" alt="1566011173416"></p>
<p>第四次访问：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/66011196418.png" alt="1566011196418"></p>
<p>我们注意db_source的值是变换的，说明负载均衡成功。但是当我们访问一轮后，发现他又从头开始：</p>
<p>test2-&gt;test3-&gt;test-&gt;test2-&gt;test3-&gt;test  说明Ribbon默认采用的是轮询的负载均衡策略</p>
<h3 id="7-3-9-总结"><a href="#7-3-9-总结" class="headerlink" title="7.3.9 总结"></a>7.3.9 总结</h3><p><img src="/2019/05/01/SpringCloud个人总结/1566011028903.png" alt="1566011028903"></p>
<p>Ribbon在工作时分成两步</p>
<blockquote>
<p>第一步先选择 EurekaServer ,它优先选择在同一个区域内负载较少的server. </p>
<p>第二步再根据用户指定的策略，在从server取到的服务注册列表中选择一个地址。</p>
</blockquote>
<p>其中Ribbon提供了多种策略：比如轮询、随机和根据响应时间加权。</p>
<p><strong>Ribbon其实就是一个软负载均衡的客户端组件， 他可以和其他所需请求的客户端结合使用，和eureka结合只是其中的一个实例。</strong></p>
<h2 id="7-4-Ribbon负载均衡实现核心接口IRule"><a href="#7-4-Ribbon负载均衡实现核心接口IRule" class="headerlink" title="7.4 Ribbon负载均衡实现核心接口IRule"></a>7.4 Ribbon负载均衡实现核心接口IRule</h2><h3 id="7-4-1-源码跟踪"><a href="#7-4-1-源码跟踪" class="headerlink" title="7.4.1.源码跟踪"></a>7.4.1.源码跟踪</h3><p>为什么我们只输入了service名称就可以访问了呢？之前还要获取ip和端口。</p>
<p>显然有人帮我们根据service名称，获取到了服务实例的ip和端口。它就是<code>LoadBalancerInterceptor</code></p>
<p>在consumer的ConsumerController如下代码打断点：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/566012847807.png" alt="1566012847807"></p>
<p>一路源码跟踪：RestTemplate.getForObject –&gt; RestTemplate.execute –&gt; RestTemplate.doExecute：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/1566013203247.png" alt="1566013203247"></p>
<p>点击进入AbstractClientHttpRequest.execute –&gt; AbstractBufferingClientHttpRequest.executeInternal –&gt; InterceptingClientHttpRequest.executeInternal –&gt; InterceptingClientHttpRequest.execute:</p>
<p><img src="/2019/05/01/SpringCloud个人总结/1528776489965.png" alt="1528776489965"></p>
<p>继续跟入：LoadBalancerInterceptor.intercept方法</p>
<p><img src="/2019/05/01/SpringCloud个人总结/66013476262.png" alt="1566013476262"></p>
<p>获取请求的服务名称，我们发现执行this.loadBalancer.execute()方法的loadBalancer是一个接口LoadBalancerClient，那么很明显执行execute（）方法的只能是LoadBalancerClient的实现类。</p>
<p>继续跟入execute方法发现执行该方法的类是：RibbonLoadBalancerClient负载均衡客户端类：</p>
<p>发现获取了8003端口的服务</p>
<p><img src="/2019/05/01/SpringCloud个人总结/566013958604.png" alt="1566013958604"></p>
<p>我们查看一下获取的负载均衡器的信息：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/1566014122746.png" alt="1566014122746"></p>
<h3 id="7-4-2-负载均衡策略"><a href="#7-4-2-负载均衡策略" class="headerlink" title="7.4.2.负载均衡策略"></a>7.4.2.负载均衡策略</h3><p>Ribbon默认的负载均衡策略是简单的轮询，我们可以测试一下：</p>
<p>编写测试类，在刚才的源码中我们看到拦截中是使用RibbonLoadBalanceClient来进行负载均衡的，其中有一个choose方法，找到choose方法的接口方法，是这样介绍的：</p>
<p> <img src="/2019/05/01/SpringCloud个人总结/1525622320277.png" alt="1525622320277"></p>
<p>现在这个就是负载均衡获取实例的方法。</p>
<p>我们注入这个类的对象，然后对其测试：</p>
<p> <img src="/2019/05/01/SpringCloud个人总结/C1566014544201.png" alt="1566014544201"></p>
<p>测试内容：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="meta">@RunWith</span>(SpringRunner.class)</div><div class="line"><span class="meta">@SpringBootTest</span>(classes = ApplicationBootStart80.class)</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoadBalanceTest</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="meta">@Autowired</span></div><div class="line">    <span class="keyword">private</span> RibbonLoadBalancerClient client;</div><div class="line"></div><div class="line">    <span class="meta">@Test</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testLoadBalance</span><span class="params">()</span></span>&#123;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</div><div class="line">            ServiceInstance instance = <span class="keyword">this</span>.client.choose(<span class="string">"MICROSERVICECLOUD-PERSON"</span>);</div><div class="line">            System.out.println(instance.getHost() + <span class="string">":"</span> +instance.getPort());</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>结果：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/C1566015460435.png" alt="1566015460435"></p>
<p>符合了我们的预期推测，确实是轮询方式。</p>
<p>我们是否可以修改负载均衡的策略呢？</p>
<p>继续跟踪源码，发现这么一段代码：</p>
<p> <img src="/2019/05/01/SpringCloud个人总结/1525622652849.png" alt="1525622652849"></p>
<p>我们看看这个rule是谁：</p>
<p> <img src="/2019/05/01/SpringCloud个人总结/1525622699666.png" alt="1525622699666"></p>
<p>这里的rule默认值是一个<code>RoundRobinRule</code>，看类的介绍：</p>
<p> <img src="/2019/05/01/SpringCloud个人总结/1525622754316.png" alt="1525622754316"></p>
<p>这不就是轮询的意思嘛。</p>
<p>我们注意到，这个类其实是实现了接口IRule的，查看一下：</p>
<p> <img src="/2019/05/01/SpringCloud个人总结/1525622817451.png" alt="1525622817451"></p>
<p>定义负载均衡的规则接口。</p>
<p>它有以下实现：</p>
<p> <img src="/2019/05/01/SpringCloud个人总结/1528782624098.png" alt="1528782624098"></p>
<h4 id="七大方法"><a href="#七大方法" class="headerlink" title="七大方法"></a>七大方法</h4><p>IRule是一个接口，七大方法是其实现类</p>
<ul>
<li>RoundRobinRule：轮询（默认方法）</li>
<li>RandomRule：随机</li>
<li>AvailabilityFilteringRule：先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，还有并发的连接数量超过阈值的服务，然后对剩余的服务进行轮询</li>
<li>WeightedResponseTimeRule：根据平均响应时间计算服务的权重。统计信息不足时会按照轮询，统计信息足够会按照响应的时间选择服务</li>
<li>RetryRule：正常时按照轮询选择服务，若过程中有服务出现故障，在轮询一定次数后依然故障，则会跳过故障的服务继续轮询。</li>
<li>BestAvailableRule：先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，然后选择一个并发量最小的服务</li>
<li>ZoneAvoidanceRule：默认规则，符合判断server所在的区域的性能和server的可用性选择服务</li>
</ul>
<p><img src="/2019/05/01/SpringCloud个人总结/5C1566022083352.png" alt="1566022083352"></p>
<h3 id="7-4-3-负载均衡自定义"><a href="#7-4-3-负载均衡自定义" class="headerlink" title="7.4.3 负载均衡自定义"></a>7.4.3 负载均衡自定义</h3><h4 id="1-修改某个服务的负载均衡策略"><a href="#1-修改某个服务的负载均衡策略" class="headerlink" title="1.修改某个服务的负载均衡策略"></a>1.修改某个服务的负载均衡策略</h4><p>例如我们只想修改 MICROSERVICECLOUD-PERSON服务的负载均衡策略</p>
<p><strong>这里一共有两种方法实现一种是使用yml配置的方式声明-一种是使用注解的方式声明</strong></p>
<h5 id="第一种使用配置方式（建议使用）"><a href="#第一种使用配置方式（建议使用）" class="headerlink" title="第一种使用配置方式（建议使用）"></a>第一种使用配置方式（建议使用）</h5><p>（1）修改消费者端（microservicecloud-consumer-person-80）的application.yml配置文件</p>
<p>修改内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">MICROSERVICECLOUD-PERSON: </div><div class="line">  ribbon:</div><div class="line">    NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule</div></pre></td></tr></table></figure>
<p>格式是：<code>{服务名称}.ribbon.NFLoadBalancerRuleClassName</code>，值就是IRule的实现类。</p>
<p>（2）运行上面的LoadBalanceTest</p>
<p><img src="/2019/05/01/SpringCloud个人总结/19186732.png" alt="1566019186732"></p>
<h5 id="第二种使用配置方式"><a href="#第二种使用配置方式" class="headerlink" title="第二种使用配置方式"></a>第二种使用配置方式</h5><p><strong>前提：注释掉第一种方式实现的 配置信息（不注释掉也可以，因为第一种方式跟第二种方式同时存在时，以第二种方式为主）</strong></p>
<p>（1）修改消费者端启动类</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">#@EnableEurekaClient</div><div class="line">@EnableDiscoveryClient //服务发现</div><div class="line">@RibbonClient(name = &quot;MICROSERVICECLOUD-PERSON&quot;,configuration = OwnRule.class)</div><div class="line">public class ApplicationBootStart80 &#123;</div><div class="line">    public static void main(String[] args)</div><div class="line">    &#123;</div><div class="line"></div><div class="line">        SpringApplication.run(ApplicationBootStart80.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>添加一下注解</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@RibbonClient(name = &quot;MICROSERVICECLOUD-PERSON&quot;,configuration = OwnRule.class)</div></pre></td></tr></table></figure>
<p>（2）新建OwnRule自定义侧略类</p>
<p>首先新建包com.myrule</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Configuration</div><div class="line">public class OwnRule &#123;</div><div class="line">    @Bean</div><div class="line">    public IRule getIuIRule()&#123;</div><div class="line">        System.out.println(&quot;进入了自定义负载均衡策略&quot;);</div><div class="line">        return new RandomRule();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><img src="/2019/05/01/SpringCloud个人总结/5C1566019594262.png" alt="1566019594262"></p>
<p><strong>注意：</strong></p>
<blockquote>
<p>官方文档明确给出了警告：</p>
<p>这个自定义配置类不能放在@ComponentScan所扫描的当前包下以及子包下，</p>
<p>否则我们自定义的这个配置类就会被所有的Ribbon客户端所共享，也就是说</p>
<p>我们达不到特殊化定制的目的了。</p>
<p>所以上面的OwnRule类是不在启动类同级包或者子包下的。</p>
</blockquote>
<p><img src="/2019/05/01/SpringCloud个人总结/5C1566019672480.png" alt="1566019672480"></p>
<p>所以我们也可以利用这个特性，修改全局的所有服务的获取策略为某个策略</p>
<p>（3）运行上面的LoadBalanceTest</p>
<p><img src="/2019/05/01/SpringCloud个人总结/19186732.png" alt="1566019186732"></p>
<h4 id="2-修改全局的服务访问策略（替换默认的轮询策略）"><a href="#2-修改全局的服务访问策略（替换默认的轮询策略）" class="headerlink" title="2. 修改全局的服务访问策略（替换默认的轮询策略）"></a>2. 修改全局的服务访问策略（替换默认的轮询策略）</h4><p>很简单，直接在IOC容器注入想要替换成的负载均衡策略即可</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Configuration</div><div class="line">public class ConfigBean</div><div class="line">applicationContext.xml</div><div class="line">&#123; </div><div class="line">	@Bean</div><div class="line">	@LoadBalanced</div><div class="line">	public RestTemplate getRestTemplate()</div><div class="line">	&#123;</div><div class="line">		return new RestTemplate();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Bean</div><div class="line">	public IRule getIuIRule()&#123;</div><div class="line">		return new RandomRule();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="3-自定义负载均衡策略"><a href="#3-自定义负载均衡策略" class="headerlink" title="3.自定义负载均衡策略"></a>3.自定义负载均衡策略</h4><p>上上面的两个章节实际上使用的都是Ribbon提供的负载均衡策略，所以接下来我们要实现一个负载均衡策略</p>
<blockquote>
<p>提出需求：</p>
</blockquote>
<p><strong>问题：修改MICROSERVICECLOUD-PERSON服务的负载均衡策略：依旧使用轮询策略，但是加上新需求，每个服务器（现在有三台8001-8003）要求被调用5次。也即 以前是每台机器一次，现在是每台机器5次</strong></p>
<p>在实现之前拜读一下官方的RandomRule 源代码，然后再修改出符合我们需求的策略类</p>
<p><a href="https://github.com/Netflix/ribbon/blob/master/ribbon-loadbalancer/src/main/java/com/netflix/loadbalancer/RandomRule.java" target="_blank" rel="external">https://github.com/Netflix/ribbon/blob/master/ribbon-loadbalancer/src/main/java/com/netflix/loadbalancer/RandomRule.java</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">public class RandomRule extends AbstractLoadBalancerRule &#123;</div><div class="line"></div><div class="line">    /**</div><div class="line"></div><div class="line">     * Randomly choose from all living servers</div><div class="line"></div><div class="line">     */</div><div class="line"></div><div class="line">    @edu.umd.cs.findbugs.annotations.SuppressWarnings(value = &quot;RCN_REDUNDANT_NULLCHECK_OF_NULL_VALUE&quot;)</div><div class="line"></div><div class="line">    public Server choose(ILoadBalancer lb, Object key) &#123;</div><div class="line">        if (lb == null) &#123;</div><div class="line">            return null;</div><div class="line">        &#125;</div><div class="line">        Server server = null;//需要返回的服务</div><div class="line"></div><div class="line">        while (server == null) &#123;//使用while循环知道获取服务</div><div class="line"></div><div class="line">            if (Thread.interrupted()) &#123;//如果当前线程已经中断，那么直接返回null</div><div class="line"></div><div class="line">                return null;</div><div class="line"></div><div class="line">            &#125;</div><div class="line"></div><div class="line">            List&lt;Server&gt; upList = lb.getReachableServers();//获取所有可达的服务列表</div><div class="line">            List&lt;Server&gt; allList = lb.getAllServers();//获取所有服务列表</div><div class="line"></div><div class="line">            int serverCount = allList.size();//得到服务列表里服务实例的数量</div><div class="line"></div><div class="line">            if (serverCount == 0) &#123;</div><div class="line"></div><div class="line">                /*</div><div class="line"></div><div class="line">                 * No servers. End regardless of pass, because subsequent passes</div><div class="line"></div><div class="line">                 * only get more restrictive.</div><div class="line"></div><div class="line">                 */</div><div class="line"></div><div class="line">                return null;</div><div class="line"></div><div class="line">            &#125;</div><div class="line"></div><div class="line">            int index = chooseRandomInt(serverCount);//根据服务数量所及获取服务下标</div><div class="line">           等同于Random.rand.nextInt(serverCount);</div><div class="line"></div><div class="line">            server = upList.get(index);//根据随机获取到的下标，从可用服务列表实例中获取服务</div><div class="line">            if (server == null) &#123;//获取不到时，暂停当前正在执行的线程对象(及放弃当前拥有的cup资源),并执行其他线程</div><div class="line">            //然后继续while循环获取</div><div class="line"></div><div class="line">                /*</div><div class="line"></div><div class="line">                 * The only time this should happen is if the server list were</div><div class="line"></div><div class="line">                 * somehow trimmed. This is a transient condition. Retry after</div><div class="line"></div><div class="line">                 * yielding.</div><div class="line"></div><div class="line">                 */</div><div class="line"></div><div class="line">                Thread.yield();</div><div class="line"></div><div class="line">                continue;</div><div class="line"></div><div class="line">            &#125;</div><div class="line"></div><div class="line">            if (server.isAlive()) &#123;</div><div class="line"></div><div class="line">                return (server);</div><div class="line"></div><div class="line">            &#125;</div><div class="line"></div><div class="line">            // Shouldn&apos;t actually happen.. but must be transient or a bug.</div><div class="line"></div><div class="line">            server = null;</div><div class="line">            Thread.yield();</div><div class="line"></div><div class="line">        &#125;</div><div class="line"></div><div class="line">        return server;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">    protected int chooseRandomInt(int serverCount) &#123;</div><div class="line"></div><div class="line">        return ThreadLocalRandom.current().nextInt(serverCount);</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">	@Override</div><div class="line"></div><div class="line">	public Server choose(Object key) &#123;</div><div class="line"></div><div class="line">		return choose(getLoadBalancer(), key);</div><div class="line"></div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>代码其实很简单</p>
<h5 id="（1）新建RandomRuleModify类"><a href="#（1）新建RandomRuleModify类" class="headerlink" title="（1）新建RandomRuleModify类"></a>（1）新建RandomRuleModify类</h5><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.myrule;</div><div class="line"></div><div class="line">import java.util.List;</div><div class="line"></div><div class="line">        import com.netflix.client.config.IClientConfig;</div><div class="line">        import com.netflix.loadbalancer.AbstractLoadBalancerRule;</div><div class="line">        import com.netflix.loadbalancer.ILoadBalancer;</div><div class="line">        import com.netflix.loadbalancer.Server;</div><div class="line"></div><div class="line">public class RandomRuleModify extends AbstractLoadBalancerRule</div><div class="line">&#123;</div><div class="line"></div><div class="line">    // total = 0 // 当total==5以后，我们指针才能往下走，</div><div class="line">    // index = 0 // 当前对外提供服务的服务器地址，</div><div class="line">    // total需要重新置为零，但是已经达到过一个5次，我们的index = 1</div><div class="line">    // 分析：我们5次，但是微服务只有8001 8002 8003 三台，OK？</div><div class="line">    //</div><div class="line"></div><div class="line"></div><div class="line">    private int total = 0; 			// 总共被调用的次数，目前要求每台被调用5次</div><div class="line">    private int currentIndex = 0;	// 当前提供服务的机器号</div><div class="line"></div><div class="line">    public Server choose(ILoadBalancer lb, Object key)</div><div class="line">    &#123;</div><div class="line">        if (lb == null) &#123;</div><div class="line">            return null;</div><div class="line">        &#125;</div><div class="line">        Server server = null;</div><div class="line"></div><div class="line">        while (server == null) &#123;</div><div class="line">            if (Thread.interrupted()) &#123;</div><div class="line">                return null;</div><div class="line">            &#125;</div><div class="line">            List&lt;Server&gt; upList = lb.getReachableServers();</div><div class="line">            List&lt;Server&gt; allList = lb.getAllServers();</div><div class="line"></div><div class="line">            int serverCount = allList.size();</div><div class="line">            if (serverCount == 0) &#123;</div><div class="line">                return null;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            if(total &lt; 5)</div><div class="line">            &#123;</div><div class="line">                server = upList.get(currentIndex);</div><div class="line">                total++;</div><div class="line">            &#125;else &#123;</div><div class="line">                total = 0;</div><div class="line">                currentIndex++;</div><div class="line">                if(currentIndex &gt;= upList.size())</div><div class="line">                &#123;</div><div class="line">                    currentIndex = 0;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            if (server == null) &#123;</div><div class="line">                Thread.yield();</div><div class="line">                continue;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            if (server.isAlive()) &#123;</div><div class="line">                return (server);</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            // Shouldn&apos;t actually happen.. but must be transient or a bug.</div><div class="line">            server = null;</div><div class="line">            Thread.yield();</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        return server;</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    @Override</div><div class="line">    public Server choose(Object key)</div><div class="line">    &#123;</div><div class="line">        return choose(getLoadBalancer(), key);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    @Override</div><div class="line">    public void initWithNiwsConfig(IClientConfig clientConfig)</div><div class="line">    &#123;</div><div class="line">        // TODO Auto-generated method stub</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><strong>这个类不能够放在启动类的同级或者子包下，否则将被设置为全局的负载均衡策略，起不到为MICROSERVICECLOUD-PERSON服务定制策略的作用</strong></p>
<p><img src="/2019/05/01/SpringCloud个人总结/5C1566021323120.png" alt="1566021323120"></p>
<h5 id="（2）OwnRule返回我们实现的RandomRuleModify"><a href="#（2）OwnRule返回我们实现的RandomRuleModify" class="headerlink" title="（2）OwnRule返回我们实现的RandomRuleModify"></a>（2）OwnRule返回我们实现的RandomRuleModify</h5><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Configuration</div><div class="line">public class OwnRule &#123;</div><div class="line">    @Bean</div><div class="line">    public IRule getIuIRule()&#123;</div><div class="line">        System.out.println(&quot;进入了自定义负载均衡策略&quot;);</div><div class="line">        return new RandomRuleModify();//RandomRule();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h5 id="（3）修改启动类"><a href="#（3）修改启动类" class="headerlink" title="（3）修改启动类"></a>（3）修改启动类</h5><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">//@EnableEurekaClient</div><div class="line">@EnableDiscoveryClient //服务发现</div><div class="line">@RibbonClient(name = &quot;MICROSERVICECLOUD-PERSON&quot;,configuration = OwnRule.class)</div><div class="line">public class ApplicationBootStart80 &#123;</div><div class="line">    public static void main(String[] args)</div><div class="line">    &#123;</div><div class="line"></div><div class="line">        SpringApplication.run(ApplicationBootStart80.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h5 id="（4）运行测试类LoadBalanceTest"><a href="#（4）运行测试类LoadBalanceTest" class="headerlink" title="（4）运行测试类LoadBalanceTest"></a>（4）运行测试类LoadBalanceTest</h5><p><img src="/2019/05/01/SpringCloud个人总结/5C1566021621272.png" alt="1566021621272"></p>
<p>轮询的同时每个服务器调用五次！！！</p>
<h5 id="（5）总结"><a href="#（5）总结" class="headerlink" title="（5）总结"></a>（5）总结</h5><p>我们也可以使用配置类的方式为某个服务配置特定的负载均衡策略实现类（参考7.4.3.1 章节的第一种配置方式），这样就可以省略上面的第二和第三步骤</p>
<p>通过配置的方式更加，灵活</p>
<p><img src="/2019/05/01/SpringCloud个人总结/1566021993675.png" alt="1566021993675"></p>
<p>然后运行测试类LoadBalanceTest，结果一模一样。</p>
<h1 id="八-Feign负载均衡"><a href="#八-Feign负载均衡" class="headerlink" title="八. Feign负载均衡"></a>八. <strong>Feign负载均衡</strong></h1><h2 id="8-1-简介"><a href="#8-1-简介" class="headerlink" title="8.1.简介"></a>8.1.简介</h2><p>Feign出现的原因是什么，既然他也是提供负载均衡的功能，那么他跟Ribbon有什么区别？</p>
<blockquote>
<p>项目主页：</p>
</blockquote>
<p><a href="https://github.com/OpenFeign/feign" target="_blank" rel="external">https://github.com/OpenFeign/feign</a></p>
<blockquote>
<p>官网解释：</p>
</blockquote>
<p><a href="http://projects.spring.io/spring-cloud/spring-cloud.html#spring-cloud-feign" target="_blank" rel="external">http://projects.spring.io/spring-cloud/spring-cloud.html#spring-cloud-feign</a></p>
<blockquote>
<p> Feign是一个声明式WebService客户端。使用Feign能让编写Web Service客户端更加简单, <strong>它的使用方法是定义一个接口，然后在上面添加注解</strong>，同时也支持JAX-RS标准的注解。Feign也支持可拔插式的编码器和解码器。Spring Cloud对Feign进行了封装，使其支持了Spring MVC标准注解和HttpMessageConverters。Feign<strong>可以与Eureka和Ribbon组合使用以支持负载均衡</strong>。</p>
</blockquote>
<p> <img src="/2019/05/01/SpringCloud个人总结/566106445678.png" alt="1566106445678"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/5C1566106480369.png" alt="1566106480369"></p>
<p>Feign的出现的目的是：为了迎合我们平时面向接口编程和调用的习惯。例如我们在Controller通过注入Service层的接口调用相关的业务。但是在上面的Ribbon例子中我们是通过RestTemplate和URL的方式调用某个服务：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/566106719992.png" alt="1566106719992"></p>
<p>Feign的实现其实也很简单：<strong>只需要创建一个接口，然后在上面添加注解即可。</strong></p>
<p>有道词典的英文解释：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image0ee02.png" alt="img"></p>
<p>为什么叫伪装？</p>
<p><strong>Feign可以把Rest的请求进行隐藏，伪装成类似SpringMVC的Controller一样。你不用再自己拼接url，拼接参数等等操作，一切都交给Feign去做。</strong></p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image0ee04.png" alt="img"></p>
<p><strong>总的来说：Feign通过封装Ribbon实现了我们常用的面向接口编程</strong></p>
<h2 id="8-2-实现Feign"><a href="#8-2-实现Feign" class="headerlink" title="8.2 实现Feign"></a>8.2 实现Feign</h2><p>其实就是复制microservicecloud-consumer-person-80工程代码，在做一些修改。</p>
<h3 id="（1）根据父工程新建microservicecloud-consumer-person-80-feign模块"><a href="#（1）根据父工程新建microservicecloud-consumer-person-80-feign模块" class="headerlink" title="（1）根据父工程新建microservicecloud-consumer-person-80-feign模块"></a>（1）根据父工程新建microservicecloud-consumer-person-80-feign模块</h3><h3 id="（2）复制80模块代码到80-feign模块"><a href="#（2）复制80模块代码到80-feign模块" class="headerlink" title="（2）复制80模块代码到80-feign模块"></a>（2）复制80模块代码到80-feign模块</h3><p><img src="/2019/05/01/SpringCloud个人总结/C1566107268418.png" alt="1566107268418"></p>
<p>修改启动类的名字。</p>
<h3 id="（3）修改80-feign模块的pom文件，添加Feign依赖"><a href="#（3）修改80-feign模块的pom文件，添加Feign依赖" class="headerlink" title="（3）修改80-feign模块的pom文件，添加Feign依赖"></a>（3）修改80-feign模块的pom文件，添加Feign依赖</h3><p>添加如下内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">       &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">       &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;</div><div class="line">   &lt;/dependency&gt;</div></pre></td></tr></table></figure>
<h3 id="（4）修改api公共模块"><a href="#（4）修改api公共模块" class="headerlink" title="（4）修改api公共模块"></a>（4）修改api公共模块</h3><p><strong>也就是修改microservicecloud-api，因为我们知道我们抽象出来的服务，有可能其他模块也会调用，不仅仅是80-feign模块。所以公共的东西我们都放在api模块</strong></p>
<p><strong>1.修改pom文件，添加feign依赖</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">     &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">     &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;</div><div class="line"> &lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p>2.<strong>新建PersonClientService接口并新增注解@FeignClient</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@FeignClient(value = &quot;MICROSERVICECLOUD-PERSON&quot;)</div><div class="line">public interface PersonClientService</div><div class="line">&#123;</div><div class="line">   @RequestMapping(value = &quot;/person/get/&#123;id&#125;&quot;, method = RequestMethod.GET)</div><div class="line">   public Person get(@PathVariable(&quot;id&quot;) long id);</div><div class="line"></div><div class="line">   @RequestMapping(value = &quot;/person/list&quot;, method = RequestMethod.GET)</div><div class="line">   public List&lt;Person&gt; list();</div><div class="line"></div><div class="line">   @RequestMapping(value = &quot;/person/add&quot;, method = RequestMethod.POST)</div><div class="line">   public boolean add(Person person);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<blockquote>
<p><strong>•               首先这是一个接口，Feign会通过动态代理，帮我们生成实现类。这点跟mybatis的mapper很像</strong></p>
<p><strong>•               @FeignClient，声明这是一个Feign客户端，类似@Mapper注解。同时通过value属性指定服务名称</strong></p>
<p><strong>•               接口中的定义方法，完全采用SpringMVC的注解，Feign会根据注解帮我们生成URL，并访问获取结果</strong></p>
</blockquote>
<h3 id="（5）feign工程修改Controller，添加上一步新建的PersonClientService接口"><a href="#（5）feign工程修改Controller，添加上一步新建的PersonClientService接口" class="headerlink" title="（5）feign工程修改Controller，添加上一步新建的PersonClientService接口"></a>（5）<strong>feign工程修改Controller，添加上一步新建的PersonClientService接口</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@RestController</div><div class="line">public class ConsumerController &#123;</div><div class="line"></div><div class="line">//    @Autowired</div><div class="line">//    private RestTemplate restTemplate;</div><div class="line"></div><div class="line">//    private static final String REST_URL_PREFIX = &quot;http://localhost:8001&quot;;</div><div class="line">//    private static final String REST_URL_PREFIX = &quot;http://MICROSERVICECLOUD-PERSON&quot;;</div><div class="line">@Autowired</div><div class="line">private PersonClientService personClientService;</div><div class="line">    @RequestMapping(value = &quot;/consumer/person/add&quot;)</div><div class="line">    public boolean add(Person person)</div><div class="line">    &#123;</div><div class="line">//        return restTemplate.postForObject(REST_URL_PREFIX + &quot;/person/add&quot;, person, Boolean.class);</div><div class="line">        return personClientService.add(person);</div><div class="line">    &#125;</div><div class="line">    @RequestMapping(value = &quot;/consumer/person/list&quot;)</div><div class="line">    public List&lt;Person&gt; list()</div><div class="line">    &#123;</div><div class="line">//        return restTemplate.getForObject(REST_URL_PREFIX + &quot;/person/list&quot;, List.class);</div><div class="line">        return personClientService.list();</div><div class="line">    &#125;</div><div class="line">        @RequestMapping(value = &quot;/consumer/person/get/&#123;id&#125;&quot;)</div><div class="line">    public Person get(@PathVariable(&quot;id&quot;) Long id)</div><div class="line">    &#123;</div><div class="line">        return this.personClientService.get(id);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>可以看到我们注释掉了以往的RestTemplate+URL请求服务的方式，通过注入接口调用的方式，实现了面向借口编程。</p>
<h3 id="（6）feign工程修改主启动类"><a href="#（6）feign工程修改主启动类" class="headerlink" title="（6）feign工程修改主启动类"></a>（6）<strong>feign工程修改主启动类</strong></h3><p>添加@EnableFeignClients // 开启feign客户端</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">@EnableDiscoveryClient //服务发现</div><div class="line">@EnableFeignClients // 开启feign客户端</div><div class="line">public class ApplicationBootStart80feign &#123;</div><div class="line">    public static void main(String[] args)</div><div class="line">    &#123;</div><div class="line"></div><div class="line">        SpringApplication.run(ApplicationBootStart80feign.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="（7）启动EurekaServer7001-7003和服务提供集群8001-8003，启动feign工程进行测试"><a href="#（7）启动EurekaServer7001-7003和服务提供集群8001-8003，启动feign工程进行测试" class="headerlink" title="（7）启动EurekaServer7001-7003和服务提供集群8001-8003，启动feign工程进行测试"></a><strong>（7）启动EurekaServer7001-7003和服务提供集群8001-8003，启动feign工程进行测试</strong></h3><p><img src="/2019/05/01/SpringCloud个人总结/566108827974.png" alt="1566108827974"></p>
<p>请求</p>
<p><img src="/2019/05/01/SpringCloud个人总结/C1566108849361.png" alt="1566108849361"></p>
<p><strong>默认使用轮询的负载均衡方式</strong></p>
<h2 id="8-3-总结"><a href="#8-3-总结" class="headerlink" title="8.3 总结"></a>8.3 总结</h2><p> Feign通过接口的方法调用Rest服务（之前是Ribbon+RestTemplate） ，</p>
<p>该请求发送给Eureka服务器（<a href="http://MICROSERVICECLOUD-PERSON/person/list）" target="_blank" rel="external">http://MICROSERVICECLOUD-PERSON/person/list）</a>,</p>
<p>通过Feign直接找到服务接口，由于在进行服务调用的时候融合了Ribbon技术，所以也支持负载均衡作用。</p>
<p>也就是说Feign只是封装了Ribbon，改造成了我们习惯的面向接口编程的方式。</p>
<p><strong>自定义负载均衡的方式跟之前使用Ribbon 的一样，也就是支持注解和配置两种方式实现某个服务或者全局服务的负载均衡策略自定义</strong></p>
<p>例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">@EnableDiscoveryClient //服务发现</div><div class="line">@EnableFeignClients // 开启feign客户端</div><div class="line">@RibbonClient(name = &quot;MICROSERVICECLOUD-PERSON&quot;,configuration = OwnRule.class)</div><div class="line">public class ApplicationBootStart80feign &#123;</div><div class="line">    public static void main(String[] args)</div><div class="line">    &#123;</div><div class="line"></div><div class="line">        SpringApplication.run(ApplicationBootStart80feign.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="8-4-请求压缩-了解"><a href="#8-4-请求压缩-了解" class="headerlink" title="8.4.请求压缩(了解)"></a>8.4.请求压缩(了解)</h2><p>Spring Cloud Feign 支持对请求和响应进行GZIP压缩，以减少通信过程中的性能损耗。通过下面的参数即可开启请求与响应的压缩功能：</p>
<p>feign:<br>   compression:<br>     request:<br>       enabled: true # 开启请求压缩<br>     response:<br>       enabled: true # 开启响应压缩</p>
<p>同时，我们也可以对请求的数据类型，以及触发压缩的大小下限进行设置：</p>
<p>feign:<br>   compression:<br>     request:<br>       enabled: true # 开启请求压缩<br>       mime-types: text/html,application/xml,application/json # 设置压缩的数据类型<br>       min-request-size: 2048 # 设置触发压缩的大小下限</p>
<p>注：上面的数据类型、压缩大小下限均为默认值。</p>
<h2 id="8-5-日志级别-了解"><a href="#8-5-日志级别-了解" class="headerlink" title="8.5.日志级别(了解)"></a>8.5.日志级别(了解)</h2><p>前面讲过，通过logging.level.xx=debug来设置日志级别。然而这个对Fegin客户端而言不会产生效果。因为@FeignClient注解修改的客户端在被代理时，都会创建一个新的Fegin.Logger实例。我们需要额外指定这个日志的级别才可以。</p>
<p>1）设置com.kingge包下的日志级别都为debug</p>
<p>logging:<br>   level:<br>     com.kingge: debug</p>
<p>2）新建FeignLogConfiguration配置类，定义日志级别</p>
<p>内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Configuration</div><div class="line">public class FeignLogConfiguration &#123;</div><div class="line"></div><div class="line">    @Bean</div><div class="line">    Logger.Level feignLoggerLevel()&#123;</div><div class="line">        return Logger.Level.FULL;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里指定的Level级别是FULL，Feign支持4种级别：</p>
<p>•               NONE：不记录任何日志信息，这是默认值。</p>
<p>•               BASIC：仅记录请求的方法，URL以及响应状态码和执行时间</p>
<p>•               HEADERS：在BASIC的基础上，额外记录了请求和响应的头信息</p>
<p>•               FULL：记录所有请求和响应的明细，包括头信息、请求体、元数据。</p>
<p>3）在FeignClient中指定配置类：</p>
<p>@FeignClient(value = “MICROSERVICECLOUD-PERSON” configuration = FeignLogConfiguration.class)<br> public interface UserFeignClient {<br>     @GetMapping(“/user/{id}”)<br>     User queryUserById(@PathVariable(“id”) Long id);<br> }</p>
<p>4）重启项目，即可看到每次访问的日志：</p>
<h2 id="8-6-Hystrix支持"><a href="#8-6-Hystrix支持" class="headerlink" title="8.6.Hystrix支持"></a>8.6.Hystrix支持</h2><p>参加下面服务降级的案例</p>
<h1 id="九-Hystrix断路器"><a href="#九-Hystrix断路器" class="headerlink" title="九.Hystrix断路器"></a>九.Hystrix断路器</h1><pre><code>**首先我们来解决第三问题，服务的容灾处理**
</code></pre><p><strong>跟Ribbon和Feign是客户端技术不同的是Hystrix是服务端的技术，也就是他是作用在服务提供端</strong></p>
<h2 id="1-分布式系统面临的问题"><a href="#1-分布式系统面临的问题" class="headerlink" title="1.分布式系统面临的问题"></a>1.<strong>分布式系统面临的问题</strong></h2><p><strong>复杂分布式体系结构中的应用程序有数十个依赖关系，每个依赖关系在某些时候将不可避免地失败</strong></p>
<p><strong>1.雪崩问题</strong></p>
<p>微服务中，服务间调用关系错综复杂，一个请求，可能需要调用多个微服务接口才能实现，会形成非常复杂的调用链路：</p>
<p> <img src="/2019/05/01/SpringCloud个人总结/646178ttttt01.png" alt="标题: fig:"></p>
<p>如图，一次业务请求，需要调用A、P、H、I四个服务，这四个服务又可能调用其它服务（这个就是所谓的<strong>扇出</strong>）。</p>
<p>如果此时，某个服务出现异常：</p>
<p> <img src="/2019/05/01/SpringCloud个人总结/64rrrttt01.png" alt="标题: fig:"></p>
<p>例如微服务I发生异常，请求阻塞，用户不会得到响应，则tomcat的这个线程不会释放，于是越来越多的用户请求到来，越来越多的线程会阻塞：</p>
<p> <img src="/2019/05/01/SpringCloud个人总结/565964513rrr626.png" alt="标题: fig:"></p>
<p>服务器支持的线程和并发数有限，请求一直阻塞，会导致服务器资源耗尽，从而导致所有其它服务都不可用，形成<strong>雪崩效应</strong>，<strong>所以我们需要阻断故障的传播，这个就是断路器</strong>。</p>
<p>这就好比，一个汽车生产线，生产不同的汽车，需要使用不同的零件，如果某个零件因为种种原因无法使用，那么就会造成整台车无法装配，陷入等待零件的状态，直到零件到位，才能继续组装。 此时如果有很多个车型都需要这个零件，那么整个工厂都将陷入等待的状态，导致所有生产都陷入瘫痪。一个零件的波及范围不断扩大。 </p>
<p>备注：一般情况对于服务依赖的保护主要有3中解决方案：</p>
<blockquote>
<p><strong>（1）熔断模式：这种模式主要是参考电路熔断，如果一条线路电压过高，保险丝会熔断，防止火灾。放到我们的系统中，如果某个目标服务调用慢或者有大量超时，此时，熔断该服务的调用，对于后续调用请求，不在继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用。</strong></p>
<p><strong>（2）（降级）隔离模式：这种模式就像对系统请求按类型划分成一个个小岛的一样，当某个小岛被火少光了，不会影响到其他的小岛。例如可以对不同类型的请求使用线程池来资源隔离，每种类型的请求互不影响，如果一种类型的请求线程资源耗尽，则对后续的该类型请求直接返回，不再调用后续资源。这种模式使用场景非常多，例如将一个服务拆开，对于重要的服务使用单独服务器来部署，再或者公司最近推广的多中心。</strong></p>
<p><strong>（3）限流模式：上述的熔断模式和隔离模式都属于出错后的容错处理机制，而限流模式则可以称为预防模式。限流模式主要是提前对各个类型的请求设置最高的QPS阈值，若高于设置的阈值则对该请求直接返回，不再调用后续资源。这种模式不能解决服务依赖的问题，只能解决系统整体资源分配问题，因为没有被限流的请求依然有可能造成雪崩效应。</strong></p>
</blockquote>
<p> springcloud的Hystrix就是提供了前两种解决方式：</p>
<p><strong>Hystix解决雪崩问题的手段有两个：</strong></p>
<p><strong>•               线程隔离（降级）</strong></p>
<p><strong>•               服务熔断</strong></p>
<h2 id="2-Hystrix简介"><a href="#2-Hystrix简介" class="headerlink" title="2.Hystrix简介"></a>2.Hystrix简介</h2><pre><code>Hystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时、异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障，以提高分布式系统的弹性。

 Hystix是Netflix开源的一个延迟和容错库，用于隔离访问远程服务、第三方库，防止出现级联失败。

“断路器”本身是一种开关装置，当某个服务单元发生故障之后，**通过断路器的故障监控（类似熔断保险丝），向调用方返回一个符合预期的、可处理的备选响应（FallBack）（解决思路）** ，**而不是长时间的等待或者抛出调用方无法处理的异常** ，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。
</code></pre><blockquote>
<p> 官网资料 </p>
</blockquote>
<p><a href="https://github.com/Netflix/Hystrix/wiki/How-To-Use" target="_blank" rel="external">https://github.com/Netflix/Hystrix/wiki/How-To-Use</a></p>
<h2 id="3-服务端的服务熔断"><a href="#3-服务端的服务熔断" class="headerlink" title="3.服务端的服务熔断"></a>3.服务端的服务熔断</h2><p><strong>熔断机制是应对雪崩效应的一种微服务链路保护机制。他是在服务端实现。</strong></p>
<pre><code>**当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回&quot;错误&quot;的响应信息**。 当检测到该节点微服务调用响应正常后恢复调用链路。在SpringCloud框架里熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是5秒内20次调用失败就会启动熔断机制。**熔断机制的注解是@HystrixCommand。**
</code></pre><h3 id="3-1-熔断原理"><a href="#3-1-熔断原理" class="headerlink" title="3.1 熔断原理"></a>3.1 熔断原理</h3><p>熔断器，也叫断路器，其英文单词为：Circuit Breaker </p>
<p><img src="/2019/05/01/SpringCloud个人总结/6009599rrr956.png" alt="img"></p>
<p>熔断状态机3个状态：</p>
<p>•               Closed：关闭状态，所有请求都正常访问。</p>
<p>•               Open：打开状态，所有请求都会被降级。Hystix会对请求情况计数，当一定时间内失败请求百分比达到阈值，则触发熔断，断路器会完全打开。默认失败比例的阈值是50%，请求次数最少不低于20次。</p>
<p>•               Half Open：半开状态，open状态不是永久的，打开后会进入休眠时间（默认是5S）。随后断路器会自动进入半开状态。此时会释放部分请求通过，若这些请求都是健康的，则会完全关闭断路器，否则继续保持打开，再次进行休眠计时</p>
<pre><code>当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回&quot;错误&quot;的响应信息。 当检测到该节点微服务调用响应正常后恢复调用链路。在SpringCloud框架里熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是5秒内20次调用失败就会启动熔断机制。熔断机制的注解是@HystrixCommand。
</code></pre><h3 id="3-2-案例演示"><a href="#3-2-案例演示" class="headerlink" title="3.2 案例演示"></a>3.2 案例演示</h3><h4 id="3-2-1-参考microservicecloud-provider-person-8001-新建microservicecloud-provider-person-hystrix-8001"><a href="#3-2-1-参考microservicecloud-provider-person-8001-新建microservicecloud-provider-person-hystrix-8001" class="headerlink" title="3.2.1 参考microservicecloud-provider-person-8001 新建microservicecloud-provider-person-hystrix-8001"></a>3.2.1 参考microservicecloud-provider-person-8001 新建microservicecloud-provider-person-hystrix-8001</h4><p>赋值pom文件和代码已经application.yml文件</p>
<h4 id="3-2-2-修改新建hystrix-8001模块的pom文件和启动类"><a href="#3-2-2-修改新建hystrix-8001模块的pom文件和启动类" class="headerlink" title="3.2.2 修改新建hystrix-8001模块的pom文件和启动类"></a>3.2.2 修改新建hystrix-8001模块的pom文件和启动类</h4><p>（1）pom文件添加hystrix依赖</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!--  hystrix --&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p>（2）修改启动类名称并添加<strong>@EnableCircuitBreaker注解</strong>//对hystrixR熔断机制的支持</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">//@EnableEurekaClient</div><div class="line">@EnableDiscoveryClient //服务发现</div><div class="line">@EnableCircuitBreaker//对hystrixR熔断机制的支持</div><div class="line">public class ApplicationBootStart8001hystrix &#123;</div><div class="line">    public static void main(String[] args)</div><div class="line">    &#123;</div><div class="line"></div><div class="line">        SpringApplication.run(ApplicationBootStart8001hystrix.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="3-2-3-修改配置文件"><a href="#3-2-3-修改配置文件" class="headerlink" title="3.2.3 修改配置文件"></a>3.2.3 修改配置文件</h4><p>其实就是修改服务实例名字，避免跟8001模块冲突</p>
<p><img src="/2019/05/01/SpringCloud个人总结/5C1566145616539.png" alt="1566145616539"></p>
<h4 id="3-2-4-修改PersonController，添加熔断处理"><a href="#3-2-4-修改PersonController，添加熔断处理" class="headerlink" title="3.2.4 修改PersonController，添加熔断处理"></a>3.2.4 修改PersonController，添加熔断处理</h4><p>在某个方法使用<strong>@HystrixCommand</strong>注解，模拟报异常后如何处理</p>
<p><strong>一旦调用服务方法失败并抛出了错误信息/请求超时后，会自动调用@HystrixCommand标注好的fallbackMethod调用类中的指定方法</strong> </p>
<p>下面以get方法为例，代码内容（下面模拟的是出现异常）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@RestController</div><div class="line">public class PersonController</div><div class="line">&#123;</div><div class="line">   @Autowired</div><div class="line">   private PersonService service;</div><div class="line"></div><div class="line">//全部使用restful风格，返回json字符串</div><div class="line">   @RequestMapping(value = &quot;/person/add&quot;, method = RequestMethod.POST)</div><div class="line">   public boolean add(@RequestBody Person person)</div><div class="line">   &#123;</div><div class="line">      return service.add(person);</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   @RequestMapping(value = &quot;/person/get/&#123;id&#125;&quot;, method = RequestMethod.GET)</div><div class="line">   @HystrixCommand(fallbackMethod = &quot;processHystrix_Get&quot;) //关键代码</div><div class="line">   public Person get(@PathVariable(&quot;id&quot;) Long id)</div><div class="line">   &#123;</div><div class="line">      Person person = service.get(id);</div><div class="line">      if(null == person)</div><div class="line">      &#123;</div><div class="line">         throw new RuntimeException(&quot;该ID：&quot;+id+&quot;没有没有对应的信息&quot;);</div><div class="line">      &#125;</div><div class="line">      return person;</div><div class="line"></div><div class="line">   &#125;</div><div class="line">   public Person processHystrix_Get(@PathVariable(&quot;id&quot;) Long id)//关键代码</div><div class="line">   &#123;</div><div class="line">      Person person =    new Person();</div><div class="line">      person.setDeptno(id);person.setDname(&quot;该ID：&quot;+id+&quot;没有没有对应的信息,null--@HystrixCommand&quot;);</div><div class="line">      person.setDb_source(&quot;no this database in MySQL&quot;);</div><div class="line">      return person;</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   @RequestMapping(value = &quot;/person/list&quot;, method = RequestMethod.GET)</div><div class="line">   public List&lt;Person&gt; list()</div><div class="line">   &#123;</div><div class="line">      return service.list();</div><div class="line">   &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>注意，配置的fallbackMethod方法必须与被@HystrixCommand注解的方法有相同的入参和返回值</p>
<h4 id="3-2-5-启动EurekaServer集群和8001-hystrix模块、80模块"><a href="#3-2-5-启动EurekaServer集群和8001-hystrix模块、80模块" class="headerlink" title="3.2.5 启动EurekaServer集群和8001-hystrix模块、80模块"></a>3.2.5 启动EurekaServer集群和8001-hystrix模块、80模块</h4><p><img src="/2019/05/01/SpringCloud个人总结/5C1566146282120.png" alt="1566146282120"></p>
<p>消费者访问</p>
<p><a href="http://localhost/consumer/person/get/5" target="_blank" rel="external">http://localhost/consumer/person/get/5</a></p>
<p>输出：{“deptno”:5,”dname”:”开发部”,”db_source”:”test”}</p>
<p>我们假设获取某个不存在的用户</p>
<p><a href="http://localhost/consumer/person/get/55" target="_blank" rel="external">http://localhost/consumer/person/get/55</a></p>
<p>输出：{“deptno”:55,”dname”:”该ID：55没有没有对应的信息,null–@HystrixCommand”,”db_source”:”no this database in MySQL”}</p>
<h2 id="4-客户端的服务降级"><a href="#4-客户端的服务降级" class="headerlink" title="4.客户端的服务降级"></a>4.客户端的服务降级</h2><pre><code>既然有了服务熔断，为什么还需要服务降级？
</code></pre><p>   <strong>服务降级处理是在客户端实现完成的,与服务端没有关系，客户端自带一个异常处理机制。上面的服务熔断是在服务端实现</strong></p>
<p>  <strong>客户端的服务降级，能够快速的响应用户的请求，当服务不可达，那么立即返回定制的错误信息。</strong> </p>
<p> 整体资源快不够了,忍痛将某些服务先关掉,待渡过难关,再开启回来</p>
<p>优先保证核心服务，而非核心服务不可用或弱可用。</p>
<p>用户的请求故障时，不会被阻塞，更不会无休止的等待或者看到系统崩溃，至少可以看到一个执行结果（例如返回友好的提示信息 。</p>
<p><strong>服务降级虽然会导致请求失败，但是不会导致阻塞，而且最多会影响这个依赖服务对应的线程池中的资源，对其它服务没有响应。</strong></p>
<p><strong>而且上面的服务端熔断案例存在一些缺点：控制层每实现一个方法，就要实现对应的fallBack方法处理相关的异常逻辑，那么代码量会越来越大，而且跟业务逻辑偶合在一起。所以我们需要解耦，我们把熔断的的fallback方法都放在一个类中，去除控制层的@HystrixCommand，这样能够保证业务的纯粹。</strong></p>
<h3 id="4-1-案例演示"><a href="#4-1-案例演示" class="headerlink" title="4.1 案例演示"></a>4.1 案例演示</h3><h4 id="4-1-1-修改microservicecloud-api的工程-根据已有的PersonClientService接口新建一个实现类-FallbackFactory接口的类PersonClientServiceFallbackFactory"><a href="#4-1-1-修改microservicecloud-api的工程-根据已有的PersonClientService接口新建一个实现类-FallbackFactory接口的类PersonClientServiceFallbackFactory" class="headerlink" title="4.1.1 修改microservicecloud-api的工程, 根据已有的PersonClientService接口新建一个实现类 FallbackFactory接口的类PersonClientServiceFallbackFactory"></a>4.1.1 修改microservicecloud-api的工程, 根据已有的PersonClientService接口新建一个实现类 FallbackFactory接口的类PersonClientServiceFallbackFactory</h4><p>​    </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Component//不要忘记添加</div><div class="line">public class PersonClientServiceFallbackFactory implements FallbackFactory&lt;PersonClientService&gt; &#123;</div><div class="line">    @Override</div><div class="line">    public PersonClientService create(Throwable throwable) &#123;</div><div class="line">        return new PersonClientService() &#123;</div><div class="line">            @Override</div><div class="line">            public Person get(long id) &#123;</div><div class="line">                Person person = 	new Person();</div><div class="line">                person.setDeptno(id);person.setDname(&quot;该ID&quot;+id+&quot;没有对应的信息,Consumer客户端提供的降级信息,此服务Provider已经关闭&quot;);</div><div class="line">                person.setDb_source(&quot;no this database in MySQL&quot;);</div><div class="line">                return person;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            @Override</div><div class="line">            public List&lt;Person&gt; list() &#123;</div><div class="line">                return null;</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            @Override</div><div class="line">            public boolean add(Person person) &#123;</div><div class="line">                return false;</div><div class="line">            &#125;</div><div class="line">        &#125;;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>​    </p>
<h4 id="4-1-2-修改microservicecloud-api工程-PersonClientService接口在注解-FeignCLient中添加fallbackFactory属性值"><a href="#4-1-2-修改microservicecloud-api工程-PersonClientService接口在注解-FeignCLient中添加fallbackFactory属性值" class="headerlink" title="4.1.2  修改microservicecloud-api工程,PersonClientService接口在注解@FeignCLient中添加fallbackFactory属性值"></a>4.1.2  修改microservicecloud-api工程,PersonClientService接口在注解@FeignCLient中添加fallbackFactory属性值</h4><p>​    </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@FeignClient(value = &quot;MICROSERVICECLOUD-PERSON&quot;,fallbackFactory = PersonClientServiceFallbackFactory.class)</div><div class="line">public interface PersonClientService</div><div class="line">&#123;</div><div class="line">	@RequestMapping(value = &quot;/person/get/&#123;id&#125;&quot;, method = RequestMethod.GET)</div><div class="line">	public Person get(@PathVariable(&quot;id&quot;) long id);</div><div class="line"></div><div class="line">	@RequestMapping(value = &quot;/person/list&quot;, method = RequestMethod.GET)</div><div class="line">	public List&lt;Person&gt; list();</div><div class="line"></div><div class="line">	@RequestMapping(value = &quot;/person/add&quot;, method = RequestMethod.POST)</div><div class="line">	public boolean add(Person person);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>​    </p>
<h4 id="4-1-3-修改80-feign消费者端配置文件，开启服务熔断"><a href="#4-1-3-修改80-feign消费者端配置文件，开启服务熔断" class="headerlink" title="4.1.3 修改80-feign消费者端配置文件，开启服务熔断"></a>4.1.3 修改80-feign消费者端配置文件，开启服务熔断</h4><pre><code>microservicecloud-consumer-person-80-feign工程修改YML 
</code></pre><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">feign:</div><div class="line">  hystrix:</div><div class="line">    enabled: true</div></pre></td></tr></table></figure>
<h4 id="4-1-4-测试"><a href="#4-1-4-测试" class="headerlink" title="4.1.4 测试"></a>4.1.4 测试</h4><pre><code>启动3个eureka先启动和微服务microservicecloud-provider-person-8001启动                                    microservicecloud-consumer-person-80-feign启动      
</code></pre><p> 正常访问测试      <a href="http://localhost/consumer/dept/get/5" target="_blank" rel="external">http://localhost/consumer/dept/get/5</a>        </p>
<p>  输出：{“deptno”:5,”dname”:”hr”,”db_source”:”test”}</p>
<p>​                  </p>
<p> 故意关闭微服务microservicecloud-provider-person-8001                                   </p>
<p> 访问测试     <a href="http://localhost/consumer/dept/get/5" target="_blank" rel="external">http://localhost/consumer/dept/get/5</a></p>
<p>输出：”deptno”:5,”dname”:”该ID5没有对应的信息,Consumer客户端提供的降级信息,此服务Provider已经关闭”,”db_source”:”no this database in MySQL”}</p>
<p>成功！！！</p>
<pre><code>**此时服务端provider已经down了,但是我们做了服务降级处理,让客户端在服务端不可用时也会获得提示信息而不会挂起耗死服务器**
</code></pre><p><strong>也就是说，如果服务端能够正常调用那么就返回值，如果不能够调用那么就返回由fallbackFactory定义的值</strong></p>
<h2 id="5-服务监控HystrixDashboard"><a href="#5-服务监控HystrixDashboard" class="headerlink" title="5. 服务监控HystrixDashboard"></a>5. 服务监控HystrixDashboard</h2><blockquote>
<pre><code>除了隔离依赖服务的调用以外,Hystrix还提供了准实时的调用监控(Hystrix      Dashboard),Hystrix      会持续地**记录所有通过Hystrix发起的请求的执行信息**,并以统计报表和图形的形式展示给用户,包括每秒执行多少请求多少成功,多少失败等.Netflix通过hystrix-metrics-event-stream项目实现了对以上指标的监控.Spring Cloud也提供了Hystrix Dashboard的整合.对监控内容转化成可视化界面.     
</code></pre></blockquote>
<p><strong>也就是说，服务端必须是集成了Hystrix组件，才能够被监控，也即是：启动类添加@EnableCircuitBreaker//对hystrixR熔断机制的支持。例如我们的服务8002和8003是监控不到的</strong></p>
<pre><code>记下来看案例实现
</code></pre><h3 id="5-1-案例实现"><a href="#5-1-案例实现" class="headerlink" title="5.1   案例实现"></a>5.1   案例实现</h3><h4 id="5-1-1-新建-microservicecloud-consumer-hystrix-dashboard-9001-模块"><a href="#5-1-1-新建-microservicecloud-consumer-hystrix-dashboard-9001-模块" class="headerlink" title="5.1.1 新建    microservicecloud-consumer-hystrix-dashboard-9001    模块"></a>5.1.1 新建    microservicecloud-consumer-hystrix-dashboard-9001    模块</h4><p>根据父工程 microservicecloud新建服务监控模块（ 参考microservicecloud-consumer-person-80-feign ）          </p>
<pre><code>（1）复制80-feign模块pom文件并添加dashboard依赖
</code></pre><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!-- hystrix和 hystrix-dashboard相关--&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<pre><code>（2）修改application.yml配置文件          
</code></pre><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">server:</div><div class="line">  port: 9001</div></pre></td></tr></table></figure>
<pre><code>（3）启动类ApplicationBootStart9001dashboard添加@EnableHystrixDashboard         
</code></pre><p>​    </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">@EnableHystrixDashboard</div><div class="line">public class ApplicationBootStart9001dashboard &#123;</div><div class="line">    public static void main(String[] args)</div><div class="line">    &#123;</div><div class="line"></div><div class="line">        SpringApplication.run(ApplicationBootStart9001dashboard.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>​    </p>
<p>  （4）所有Provider微服务提供类(8001/8002/8003)都需要监控依赖配置       </p>
<p>​         </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!-- actuator监控信息完善 --&gt;</div><div class="line"> &lt;dependency&gt;</div><div class="line">   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">   &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;</div><div class="line"> &lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p>​    </p>
<p>   （5）完整工程                        </p>
<pre><code>![](SpringCloud个人总结/Snipaste_2019-08-19_16-34-32.png)
</code></pre><p>​                            </p>
<h4 id="5-1-2-启动dashboard-9001模块"><a href="#5-1-2-启动dashboard-9001模块" class="headerlink" title="5.1.2 启动dashboard-9001模块"></a>5.1.2 启动dashboard-9001模块</h4><pre><code>http://localhost:9001/hystrix 
</code></pre><p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-19_16-36-15.png" alt=""></p>
<p>部署成功</p>
<h4 id="5-1-3-启动3个eureka集群"><a href="#5-1-3-启动3个eureka集群" class="headerlink" title="5.1.3 启动3个eureka集群"></a>5.1.3 启动3个eureka集群</h4><h4 id="5-1-4启动microservicecloud-provider-person-hystrix-8001和microservicecloud-consumer-person-80-feign-服务端和消费者"><a href="#5-1-4启动microservicecloud-provider-person-hystrix-8001和microservicecloud-consumer-person-80-feign-服务端和消费者" class="headerlink" title="5.1.4启动microservicecloud-provider-person-hystrix-8001和microservicecloud-consumer-person-80-feign 服务端和消费者"></a>5.1.4启动microservicecloud-provider-person-hystrix-8001和microservicecloud-consumer-person-80-feign 服务端和消费者</h4><h4 id="5-1-4dashboard填写需要监控的服务地址"><a href="#5-1-4dashboard填写需要监控的服务地址" class="headerlink" title="5.1.4dashboard填写需要监控的服务地址"></a>5.1.4dashboard填写需要监控的服务地址</h4><p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-19_16-46-55.png" alt=""></p>
<p>1：Delay：该参数用来控制服务器上轮询监控信息的延迟时间，默认为2000毫秒，可以通过配置该属性来降低客户端的网络和CPU消耗。</p>
<p>2：Title：该参数对应了头部标题Hystrix Stream之后的内容，默认会使用具体监控实例的URL，可以通过配置该信息来展示更合适的标题。 </p>
<p>点击Monitor Stream  开始监控</p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-19_16-49-56.png" alt=""></p>
<p><strong>怎么查看这张图：关键的部位我已经用红色方框，框住。核心就是：7色（服务的状态），1圈，1线。</strong>                           </p>
<pre><code>   1圈                   

      实心圆:共有两种含义.它通过颜色的变化代表了 实例健康程度,它的健康度从绿色&lt;黄色&lt;橙色&lt;红色递减.该实心圆除了颜色的变化之外,它的大小也会根据实例的请求流量发生变化,流量越大该实心圆就越大.所以通过该实心圆的展示,就可以在大量的实例中快速的发现故障实例和高压力实例.              

1线                   

     曲线:用来记录2分钟内流量的相对变化,可以通过它来观察到流量的上升和下降趋势.
</code></pre><p><img src="/2019/05/01/SpringCloud个人总结/dashbnoars.png" alt=""></p>
<h4 id="5-1-5-多次刷新http-localhost-consumer-person-get-1"><a href="#5-1-5-多次刷新http-localhost-consumer-person-get-1" class="headerlink" title="5.1.5 多次刷新http://localhost/consumer/person/get/1"></a>5.1.5 多次刷新<a href="http://localhost/consumer/person/get/1" target="_blank" rel="external">http://localhost/consumer/person/get/1</a></h4><p>也即是多次请求8001服务，然后查看监控的状态</p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-19_16-53-58.png" alt=""></p>
<p>显示请求的get方法的情况。圆圈变大，曲线上升。（<strong>如果请求多个方法会增加图形说明</strong>）</p>
<h1 id="十-zuul路由网关"><a href="#十-zuul路由网关" class="headerlink" title="十. zuul路由网关"></a>十. zuul路由网关</h1><pre><code>通过前面的学习，使用Spring Cloud实现微服务的架构基本成型，大致是这样的：
</code></pre><p><img src="/2019/05/01/SpringCloud个人总结/C1566221714611.png" alt="1566221714611"></p>
<p><strong>我们使用Spring Cloud Netflix中的Eureka实现了服务注册中心以及服务注册与发现；而服务间通过Ribbon或Feign实现服务的消费以及均衡负载。为了使得服务集群更为健壮，使用Hystrix的融断机制来避免在微服务架构中个别服务出现异常时引起的故障蔓延。</strong></p>
<p> 在该架构中，我们的服务集群包含：内部服务Service A和Service B，他们都会注册与订阅服务至Eureka Server，而Open Service是一个对外的服务，通过均衡负载公开至服务调用方。我们把焦点聚集在对外服务这块，直接暴露我们的服务地址，这样的实现是否合理，或者是否有更好的实现方式呢？</p>
<p>先来说说这样架构需要做的一些事儿以及存在的不足：</p>
<p>•               破坏了服务无状态特点。</p>
<pre><code>为了保证对外服务的安全性，我们需要实现对服务访问的权限控制，而开放服务的权限控制机制将会贯穿并污染整个开放服务的业务逻辑，这会带来的最直接问题是，破坏了服务集群中REST API无状态的特点。

  从具体开发和测试的角度来说，在工作中除了要考虑实际的业务逻辑之外，还需要额外考虑对接口访问的控制处理。
</code></pre><p>•               无法直接复用既有接口。</p>
<pre><code>当我们需要对一个即有的集群内访问接口，实现外部服务访问时，我们不得不通过在原有接口上增加校验逻辑，或增加一个代理调用来实现权限控制，无法直接复用原有的接口。
</code></pre><p>面对类似上面的问题，我们要如何解决呢？答案是：服务网关！</p>
<p>为了解决上面这些问题，我们需要将权限控制这样的东西从我们的服务单元中抽离出去，而最适合这些逻辑的地方就是处于对外访问最前端的地方，我们需要一个更强大一些的均衡负载器的 服务网关。</p>
<p>服务网关是微服务架构中一个不可或缺的部分。通过服务网关统一向外系统提供REST API的过程中，除了具备服务路由、均衡负载功能之外，它还具备了权限控制等功能。Spring Cloud Netflix中的Zuul就担任了这样的一个角色，为微服务架构提供了前门保护的作用，同时将权限控制这些较重的非业务逻辑内容迁移到服务路由层面，使得服务集群主体能够具备更高的可复用性和可测试性。</p>
<p>Zuul包含了对请求的路由和过滤两个最主要的功能：</p>
<p><strong>其中路由功能负责将外部请求转发到具体的微服务实例上，是实现外部访问统一入口的基础而过滤器功能则负责对请求的处理过程进行干预，是实现请求校验、服务聚合等功能的基础.Zuul和Eureka进行整合，将Zuul自身注册为Eureka服务治理下的应用，同时从Eureka中获得其他微服务的消息，也即以后的访问微服务都是通过Zuul跳转后获得。</strong></p>
<pre><code>**注意：Zuul服务最终还是会注册进Eureka**

提供=代理+路由+过滤三大功能
</code></pre><h2 id="1-简介-1"><a href="#1-简介-1" class="headerlink" title="1.简介"></a>1.简介</h2><p>官网：<a href="https://github.com/Netflix/zuul" target="_blank" rel="external">https://github.com/Netflix/zuul</a></p>
<p> <img src="/2019/05/01/SpringCloud个人总结/njl002.png" alt="标题: fig:"></p>
<p>Zuul：维基百科</p>
<p>电影《捉鬼敢死队》中的怪兽，Zuul，在纽约引发了巨大骚乱。</p>
<p>事实上，在微服务架构中，Zuul就是守门的大Boss！一夫当关，万夫莫开！</p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image0yy04.png" alt="img"></p>
<h2 id="2-Zuul加入后的架构"><a href="#2-Zuul加入后的架构" class="headerlink" title="2.Zuul加入后的架构"></a>2.Zuul加入后的架构</h2><p> <img src="file:///C:/Users/JEREMY~1/AppData/Local/Temp/msohtmlclip1/01/clip_image006.png" alt="标题: fig:"></p>
<p>不管是来自于客户端（PC或移动端）的请求，还是服务内部调用。一切对服务的请求都会经过Zuul这个网关，然后再由网关来实现 鉴权、动态路由等等操作。Zuul就是我们服务的统一入口。</p>
<p>​        </p>
<h2 id="3-路由基本配置（例子）"><a href="#3-路由基本配置（例子）" class="headerlink" title="3.路由基本配置（例子）"></a>3.路由基本配置（例子）</h2><h3 id="3-1新建Module模块microservicecloud-zuul-gateway-9999"><a href="#3-1新建Module模块microservicecloud-zuul-gateway-9999" class="headerlink" title="3.1新建Module模块microservicecloud-zuul-gateway-9999"></a>3.1<strong>新建Module模块microservicecloud-zuul-gateway-9999</strong></h3><h3 id="3-2-修改pom文件"><a href="#3-2-修改pom文件" class="headerlink" title="3.2 修改pom文件"></a>3.2 修改pom文件</h3><p>主要添加：</p>
<pre><code>&lt;!-- zuul路由网关 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>完整内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;dependencies&gt;</div><div class="line">    &lt;!-- zuul路由网关 --&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;!-- actuator监控 --&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;!--  hystrix容错--&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;!-- 日常标配 --&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;com.kingge.springcloud&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;microservicecloud-api&lt;/artifactId&gt;</div><div class="line">        &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;!-- 热部署插件 --&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;springloaded&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">&lt;/dependencies&gt;</div></pre></td></tr></table></figure>
<h3 id="3-3-修改application-yml"><a href="#3-3-修改application-yml" class="headerlink" title="3.3 修改application.yml"></a>3.3 修改application.yml</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">server:</div><div class="line">  port: 9999</div><div class="line"></div><div class="line">spring:</div><div class="line">  application:</div><div class="line">    name: microservicecloud-zuul-gateway</div><div class="line"></div><div class="line">eureka:</div><div class="line">  client:</div><div class="line">    service-url:</div><div class="line">      defaultZone: http://peer1:7001/eureka/,http://peer2:7002/eureka/,http://peer3:7003/eureka/</div><div class="line">  instance:</div><div class="line">    instance-id: microservicecloud-zuul-gateway9999</div><div class="line">    prefer-ip-address: true</div><div class="line"></div><div class="line"></div><div class="line">info:</div><div class="line">  app.name: $&#123;spring.application.name&#125;</div><div class="line">  company.name: kingge.top</div><div class="line">  build.artifactId: $&#123;project.artifactId&#125;</div><div class="line">  build.version: $&#123;project.version&#125;</div><div class="line">  app.desc: 这是一个zuul</div></pre></td></tr></table></figure>
<h3 id="3-4-修改主启动类ApplicationBootStart9999zuul"><a href="#3-4-修改主启动类ApplicationBootStart9999zuul" class="headerlink" title="3.4 修改主启动类ApplicationBootStart9999zuul"></a>3.4 修改主启动类ApplicationBootStart9999zuul</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">@EnableZuulProxy</div><div class="line">public class ApplicationBootStart9999zuul &#123;</div><div class="line">    public static void main(String[] args)</div><div class="line">    &#123;</div><div class="line"></div><div class="line">        SpringApplication.run(ApplicationBootStart9999zuul.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="3-4-1完整工程展示"><a href="#3-4-1完整工程展示" class="headerlink" title="3.4.1完整工程展示"></a>3.4.1完整工程展示</h3><p><img src="/2019/05/01/SpringCloud个人总结/C1566226205578.png" alt="1566226205578"></p>
<h3 id="3-5启动三个eureka集群-、一个服务提供类microservicecloud-provider-person-8001-、9999模块路由"><a href="#3-5启动三个eureka集群-、一个服务提供类microservicecloud-provider-person-8001-、9999模块路由" class="headerlink" title="3.5启动三个eureka集群 、一个服务提供类microservicecloud-provider-person-8001 、9999模块路由"></a>3.5启动三个eureka集群 、一个服务提供类microservicecloud-provider-person-8001 、9999模块路由</h3><p><img src="/2019/05/01/SpringCloud个人总结/566222721701.png" alt="1566222721701"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/C1566222752232.png" alt="1566222752232"></p>
<h3 id="3-6-测试"><a href="#3-6-测试" class="headerlink" title="3.6 测试"></a>3.6 测试</h3><p>不用路由访问：<a href="http://localhost:8001/person/get/2" target="_blank" rel="external">http://localhost:8001/person/get/2</a><br>启用路由访问 <a href="http://localhost:9999/microservicecloud-person/person/get/2" target="_blank" rel="external">http://localhost:9999/microservicecloud-person/person/get/2</a></p>
<p>输出都是：{“deptno”:5,”dname”:”开发部”,”db_source”:”test”}</p>
<h2 id="4-路由访问映射规则"><a href="#4-路由访问映射规则" class="headerlink" title="4.路由访问映射规则"></a>4.<strong>路由访问映射规则</strong></h2><p>上面的案例存在一个问题，那就是使用路由访问服务的时候</p>
<p><a href="http://localhost:9999/microservicecloud-person/person/get/2" target="_blank" rel="external">http://localhost:9999/microservicecloud-person/person/get/2</a></p>
<p>我们暴露了 服务名称：microservicecloud-person ，所以我们想隐藏他。</p>
<h3 id="4-1-修改9999模块配置文件"><a href="#4-1-修改9999模块配置文件" class="headerlink" title="4.1 修改9999模块配置文件"></a>4.1 修改9999模块配置文件</h3><p>添加如下内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">zuul: </div><div class="line">  routes: </div><div class="line">    myperson.serviceId: microservicecloud-person</div><div class="line">    myperson.path: /myperson/**</div></pre></td></tr></table></figure>
<p><strong><em>重要</em></strong></p>
<p><strong>规则说明</strong>：</p>
<p>•   zuul.routes.<route>.path=/xxx/**： 来指定映射路径。<route>是自定义的路由名（在上面是myperson）</route></route></p>
<p>•   zuul.routes.<route>.serviceId=service-provider：来指定服务名。</route></p>
<p><strong>而大多数情况下，我们的<route>路由名称往往和服务名会写成一样的。因此Zuul就提供了一种简化的配置语法：zuul.routes.<serviceid>=<path></path></serviceid></route></strong></p>
<p><strong>比方说上面我们关于microservicecloud-person的配置可以简化为一条：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">zuul:</div><div class="line">  routes:</div><div class="line">    microservicecloud-person: /myperson/** # 这里是映射路径</div><div class="line">#    myperson.serviceId: microservicecloud-person</div><div class="line">#    myperson.path: /myperson/**</div></pre></td></tr></table></figure>
<p>省去了对服务名称的配置。</p>
<h3 id="4-2-重启9999模块"><a href="#4-2-重启9999模块" class="headerlink" title="4.2 重启9999模块"></a>4.2 重启9999模块</h3><p>访问如下两个网址</p>
<p>（1）服务名称映射后路由访问OK<br><a href="http://localhost:9999/myperson/person/get/5" target="_blank" rel="external">http://localhost:9999/myperson/person/get/5</a></p>
<p>（2）未映射服务名称原路径访问OK  - <strong>默认的路由规则</strong><br><a href="http://localhost:9999/microservicecloud-person/person/get/5" target="_blank" rel="external">http://localhost:9999/microservicecloud-person/person/get/5</a></p>
<p><strong>如果在保留第一种方式的情况下，禁止第二种方式的访问。</strong></p>
<h3 id="4-3-原真实服务名忽略-关闭默认的路由规则"><a href="#4-3-原真实服务名忽略-关闭默认的路由规则" class="headerlink" title="4.3 原真实服务名忽略-关闭默认的路由规则"></a>4.3 <strong>原真实服务名忽略-关闭默认的路由规则</strong></h3><p>增你家该属性即可：ignored-services:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">zuul:</div><div class="line">  ignored-services: microservicecloud-person #单个具体，多个可以用&quot;*&quot; ignored-services: *</div><div class="line">  routes:</div><div class="line">    myperson.serviceId: microservicecloud-person</div><div class="line">    myperson.path: /myperson/**</div></pre></td></tr></table></figure>
<p>重启9999zuul模块：</p>
<p>访问：<a href="http://localhost:9999/microservicecloud-person/person/get/5" target="_blank" rel="external">http://localhost:9999/microservicecloud-person/person/get/5</a> </p>
<p>访问失败</p>
<p><img src="/2019/05/01/SpringCloud个人总结/C1566223608884.png" alt="1566223608884"></p>
<h3 id="4-4-设置统一公共前缀"><a href="#4-4-设置统一公共前缀" class="headerlink" title="4.4 设置统一公共前缀"></a>4.4 <strong>设置统一公共前缀</strong></h3><p>增加prefix属性即可</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">zuul:</div><div class="line">  ignored-services: microservicecloud-person #单个具体，多个可以用&quot;*&quot; ignored-services: *</div><div class="line">  routes:</div><div class="line">    myperson.serviceId: microservicecloud-person</div><div class="line">    myperson.path: /myperson/**</div><div class="line">  prefix: /sb  #必须有反斜杠</div></pre></td></tr></table></figure>
<p><a href="http://localhost:9999/sb/myperson/person/get/5" target="_blank" rel="external">http://localhost:9999/sb/myperson/person/get/5</a> //访问成功</p>
<p><a href="http://localhost:9999/myperson/person/get/5" target="_blank" rel="external">http://localhost:9999/myperson/person/get/5</a> //不加前缀访问失败</p>
<h2 id="5-默认的路由规则"><a href="#5-默认的路由规则" class="headerlink" title="5 .默认的路由规则"></a>5 .默认的路由规则</h2><p>在使用Zuul的过程中，上面讲述的规则（<strong>也就是上面4.1小节的规则</strong>）已经大大的简化了配置项。但是当服务较多时，配置也是比较繁琐的。因此Zuul就指定了默认的路由规则：</p>
<p>•               默认情况下，一切服务的映射路径就是服务名本身。例如服务名为：service-provider，则默认的映射路径就 是：/service-provider/**</p>
<p>也就是说，刚才的映射规则我们完全不配置也是OK的，不信就试试看。</p>
<p>终极简化版本</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">zuul:</div><div class="line">#  routes:</div><div class="line">#    microservicecloud-person: /myperson/** # 这里是映射路径</div><div class="line">#    myperson.serviceId: microservicecloud-person</div><div class="line">#    myperson.path: /myperson/**</div></pre></td></tr></table></figure>
<p>那么默认microservicecloud-person服务的映射路径是：/microservicecloud-person/**</p>
<p>为了不暴露服务名称，那么我么你需要关闭默认的路由规则：见4.3小节</p>
<h2 id="6-过滤器"><a href="#6-过滤器" class="headerlink" title="6.过滤器"></a>6.过滤器</h2><p>Zuul作为网关的其中一个重要功能，就是实现请求的鉴权。而这个动作我们往往是通过Zuul提供的过滤器来实现的。</p>
<h3 id="6-1-ZuulFilter"><a href="#6-1-ZuulFilter" class="headerlink" title="6.1.ZuulFilter"></a>6.1.ZuulFilter</h3><p>ZuulFilter是过滤器的顶级父类。在这里我们看一下其中定义的4个最重要的方法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">public abstract ZuulFilter implements IZuulFilter&#123;</div><div class="line"> </div><div class="line">     abstract public String filterType();</div><div class="line"> </div><div class="line">     abstract public int filterOrder();</div><div class="line">     </div><div class="line">     boolean shouldFilter();// 来自IZuulFilter</div><div class="line"> </div><div class="line">     Object run() throws ZuulException;// IZuulFilter</div><div class="line"> &#125;</div></pre></td></tr></table></figure>
<p>•               shouldFilter：返回一个Boolean值，判断该过滤器是否需要执行。返回true执行，返回false不执行。</p>
<p>•               run：过滤器的具体业务逻辑。</p>
<p>•               filterType：返回字符串，代表过滤器的类型。包含以下4种：</p>
<p>–               pre：请求在被路由之前执行</p>
<p>–               route：在路由请求时调用</p>
<p>–               post：在route和errror过滤器之后调用</p>
<p>–               error：处理请求时发生错误调用</p>
<p>•               filterOrder：通过返回的int值来定义过滤器的执行顺序，数字越小优先级越高。</p>
<h3 id="6-2-过滤器执行生命周期"><a href="#6-2-过滤器执行生命周期" class="headerlink" title="6.2.过滤器执行生命周期"></a>6.2.过滤器执行生命周期</h3><p>这张是Zuul官网提供的请求生命周期图，清晰的表现了一个请求在各个过滤器的执行顺序。</p>
<p><img src="/2019/05/01/SpringCloud个人总结/clip_image002yyyy.png" alt="img"></p>
<p>正常流程：</p>
<p>•               请求到达首先会经过pre类型过滤器，而后到达route类型，进行路由，请求就到达真正的服务提供者，执行请求，返回结果后，会到达post过滤器。而后返回响应。</p>
<p>异常流程：</p>
<p>•               整个过程中，pre或者route过滤器出现异常，都会直接进入error过滤器，在error处理完毕后，会将请求交给POST过滤器，最后返回给用户。</p>
<p>•               如果是error过滤器自己出现异常，最终也会进入POST过滤器，将最终结果返回给请求客户端。</p>
<p>•               如果是POST过滤器出现异常，会跳转到error过滤器，但是与pre和route不同的是，请求不会再到达POST过滤器了。</p>
<p>所有内置过滤器列表：</p>
<p> <img src="/2019/05/01/SpringCloud个人总结/clip_imaggggge004.png" alt="标题: fig:"></p>
<h3 id="6-3-使用场景"><a href="#6-3-使用场景" class="headerlink" title="6.3.使用场景"></a>6.3.使用场景</h3><p>场景非常多：</p>
<p>•               请求鉴权：一般放在pre类型，如果发现没有访问权限，直接就拦截了</p>
<p>•               异常处理：一般会在error类型和post类型过滤器中结合来处理。</p>
<p>•               服务调用时长统计：pre和post结合使用。</p>
<h2 id="7-自定义过滤器"><a href="#7-自定义过滤器" class="headerlink" title="7.自定义过滤器"></a>7.自定义过滤器</h2><p>接下来我们来自定义一个过滤器，模拟一个登录的校验。基本逻辑：如果请求中有access-token参数，则认为请求有效，放行。</p>
<h3 id="7-1-定义过滤器类"><a href="#7-1-定义过滤器类" class="headerlink" title="7.1.定义过滤器类"></a>7.1.定义过滤器类</h3><p><img src="/2019/05/01/SpringCloud个人总结/5C1566226606544.png" alt="1566226606544"></p>
<p>内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.filter;</div><div class="line"></div><div class="line">import com.netflix.zuul.ZuulFilter;</div><div class="line">import com.netflix.zuul.context.RequestContext;</div><div class="line">import com.netflix.zuul.exception.ZuulException;</div><div class="line">import org.apache.commons.lang.StringUtils;</div><div class="line">import org.springframework.http.HttpStatus;</div><div class="line">import org.springframework.stereotype.Component;</div><div class="line"></div><div class="line">import javax.servlet.http.HttpServletRequest;</div><div class="line"></div><div class="line">@Component</div><div class="line">public class LoginFilter extends ZuulFilter &#123;</div><div class="line">    /**</div><div class="line">     * 过滤器类型，前置过滤器</div><div class="line">     * @return</div><div class="line">     */</div><div class="line">    @Override</div><div class="line">    public String filterType() &#123;</div><div class="line">        return &quot;pre&quot;;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /**</div><div class="line">     * 过滤器的执行顺序</div><div class="line">     * @return</div><div class="line">     */</div><div class="line">    @Override</div><div class="line">    public int filterOrder() &#123;</div><div class="line">        return 1;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /**</div><div class="line">     * 该过滤器是否生效</div><div class="line">     * @return</div><div class="line">     */</div><div class="line">    @Override</div><div class="line">    public boolean shouldFilter() &#123;</div><div class="line">        return true;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /**</div><div class="line">     * 登陆校验逻辑</div><div class="line">     * @return</div><div class="line">     * @throws ZuulException</div><div class="line">     */</div><div class="line">    @Override</div><div class="line">    public Object run() &#123;</div><div class="line">        // 获取zuul提供的上下文对象</div><div class="line">        RequestContext context = RequestContext.getCurrentContext();</div><div class="line">        // 从上下文对象中获取请求对象</div><div class="line">        HttpServletRequest request = context.getRequest();</div><div class="line">        // 获取token信息</div><div class="line">        String token = request.getParameter(&quot;access-token&quot;);</div><div class="line">        // 判断</div><div class="line">        if (StringUtils.isBlank(token)) &#123;</div><div class="line">            // 过滤该请求，不对其进行路由</div><div class="line">            context.setSendZuulResponse(false);</div><div class="line">            // 设置响应状态码，401</div><div class="line">            context.setResponseStatusCode(401);</div><div class="line">            // 设置响应信息</div><div class="line">            context.setResponseBody(&quot;&#123;\&quot;status\&quot;:\&quot;401\&quot;, \&quot;text\&quot;:\&quot;request error!\&quot;&#125;&quot;);</div><div class="line">        &#125;</div><div class="line">        // 校验通过，把登陆信息放入上下文信息，继续向后执行</div><div class="line">        context.set(&quot;token&quot;, token);</div><div class="line">        return null;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="7-2-测试"><a href="#7-2-测试" class="headerlink" title="7.2.测试"></a>7.2.测试</h3><p>没有token参数时，访问失败：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/5C1566226821375.png" alt="1566226821375"></p>
<p>添加token参数后：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/1566226885002.png" alt="1566226885002"></p>
<h2 id="8-负载均衡和熔断"><a href="#8-负载均衡和熔断" class="headerlink" title="8.负载均衡和熔断"></a>8.负载均衡和熔断</h2><p>Zuul中默认就已经集成了Ribbon负载均衡和Hystix熔断机制。但是所有的超时策略都是走的默认值，比如熔断超时时间只有1S，很容易就触发了。因此建议我们手动进行配置：</p>
<p>hystrix:<br>   command:<br>     default:<br>       execution:<br>         isolation:<br>           thread:<br>             timeoutInMilliseconds: 2000 # 设置hystrix的超时时间为6000ms</p>
<h1 id="十一-SpringCloud-Config-分布式配置中心"><a href="#十一-SpringCloud-Config-分布式配置中心" class="headerlink" title="十一.SpringCloud Config 分布式配置中心"></a>十一.<strong>SpringCloud Config 分布式配置中心</strong></h1><pre><code>**解决第四个问题，统一配置的问题**
</code></pre><h2 id="1-为什么需要配置中心"><a href="#1-为什么需要配置中心" class="headerlink" title="1.为什么需要配置中心"></a>1.为什么需要配置中心</h2><p>   举个简单的例子，我们想要修改8001模块的服务名称的值（spring.application.name），那么我们首先得找到8001模块，然后找到配置文件，然后再进去修改。如果修改修改8003模块的配置信息，重复之前的步骤。</p>
<p> 所以我们需要一个集中管理所有微服务配置信息的地方。</p>
<pre><code>微服务意味着要将单体应用中的业务拆分成一个个子服务,每个服务的粒度相对较小,因此系统中会出现大量的服务.由于每个服务都需要必要的配置信息才能运行（application.yml）,所以一套集中式的、动态的配置管理设施是必不可少的.SpringCloud提供了ConfigServer来解决这个问题(我们每一个微服务自己带着一个application.yml,上百个配置文件的管理的问题)
</code></pre><p>​         </p>
<pre><code>**总而言之：是为了更加方便的帮助我们集中式的管理微服务架构里面微服务的配置信息。**
</code></pre><h2 id="2-config配置中心"><a href="#2-config配置中心" class="headerlink" title="2. config配置中心"></a>2. config配置中心</h2><p><strong>SpringCloud Config 为微服务架构中的微服务提供集中化的外部配置支持,配置服务器为各个不同微服务应用的所有环境提供了一个中心化的外部配置，方便我们集中式的修改微服务的配置</strong></p>
<p><strong>SpringCloud Config分为服务端和客户端两部分.</strong></p>
<p><strong>服务端也称为分布式配置中心,它是一个独立的微服务应用,用来连接配置服务器并为客户端提供获取配置信息,加密/解密信息等访问接口</strong></p>
<p><strong>客户端则是通过制定的配置中心来管理应用资源,以及业务相关的配置内容,并在启动的时候从配置中心获取和加载配置信息配置服务器默认采用git来存储配置信息,这样就有助于对环境配置进行版本管理,并且可以通过git客户端工具来方便的管理和访问配置内容.（客户端可以是我们的8001,8003模块，也即是需要获取配置信息的微服务都是客户端）</strong></p>
<blockquote>
<p>功能：</p>
</blockquote>
<ul>
<li>1.集中管理配置文件</li>
<li>2.不同环境不同配置,动态化的配置更新,分环境部署比如dev/test/prod/beta/release</li>
<li>3.运行期间动态调整配置,不再需要在每个服务部署的机器上编写配置文件,服务会向配置中心统一拉取配置自己的信息</li>
<li>4.当配置发生变动时,服务不需要重启即可感知到配置的变化并应用新的配置</li>
<li>5.将配置信息以REST接口的形式暴露</li>
</ul>
<blockquote>
<p>配置中心配置文件放置的位置：与GitHub整合配置</p>
</blockquote>
<p>由于SpringCloudConfig默认使用Git来存储配置文件(也有其他方式,比如支持SVN和本地文件),<br>但最推荐的还是使用Git,而且使用的是http/https访问形式</p>
<h2 id="3-SpringCloud-Config服务端配置"><a href="#3-SpringCloud-Config服务端配置" class="headerlink" title="3.SpringCloud Config服务端配置"></a>3.SpringCloud Config服务端配置</h2><h3 id="3-1-在GitHub上新建一个名为springcloud-config-server的新Repository"><a href="#3-1-在GitHub上新建一个名为springcloud-config-server的新Repository" class="headerlink" title="3.1 在GitHub上新建一个名为springcloud-config-server的新Repository"></a>3.1 在GitHub上新建一个名为springcloud-config-server的新Repository</h3><p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-20_09-42-33.png" alt=""></p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-20_09-59-45.png" alt=""></p>
<p>git@github.com:JeremyKinge/springcloud-config-server.git</p>
<h3 id="3-2-本地磁盘获取上述创建的仓库"><a href="#3-2-本地磁盘获取上述创建的仓库" class="headerlink" title="3.2 本地磁盘获取上述创建的仓库"></a>3.2 本地磁盘获取上述创建的仓库</h3><p>git命令:<br>git clone git@github.com:JeremyKinge/springcloud-config-server.git</p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-20_10-01-44.png" alt=""></p>
<h3 id="3-3-在上述磁盘新建配置文件并上传到git仓库"><a href="#3-3-在上述磁盘新建配置文件并上传到git仓库" class="headerlink" title="3.3 在上述磁盘新建配置文件并上传到git仓库"></a>3.3 在上述磁盘新建配置文件并上传到git仓库</h3><p>（1）添加配置文件application.yml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">spring:</div><div class="line">  profiles:</div><div class="line">    active:</div><div class="line">    - dev</div><div class="line">---</div><div class="line">spring:</div><div class="line">  profiles: dev</div><div class="line">  application:    #开发环境</div><div class="line">    name: microservicecloud-config-kingge-dev</div><div class="line">---</div><div class="line">spring:</div><div class="line">  profiles: test   #测试环境</div><div class="line">  application:</div><div class="line">    name: microservicecloud-config-kingge-test</div><div class="line">#请保存为UTF-8格式</div></pre></td></tr></table></figure>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-20_10-06-13.png" alt=""></p>
<p>（2）git bash执行上传命令：</p>
<p>git add .<br>git commit -m “新建配置文件”<br>git push origin master</p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-20_10-08-51.png" alt=""></p>
<p>（3）查看github</p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-20_10-09-16.png" alt=""></p>
<h3 id="3-4-新建Module模块microservicecloud-config-10000它即为Cloud的配置中心模块"><a href="#3-4-新建Module模块microservicecloud-config-10000它即为Cloud的配置中心模块" class="headerlink" title="3.4 新建Module模块microservicecloud-config-10000它即为Cloud的配置中心模块"></a>3.4 新建Module模块microservicecloud-config-10000它即为Cloud的配置中心模块</h3><h3 id="3-5-修改10000模块pom文件和yml配置文件、启动类"><a href="#3-5-修改10000模块pom文件和yml配置文件、启动类" class="headerlink" title="3.5 修改10000模块pom文件和yml配置文件、启动类"></a>3.5 修改10000模块pom文件和yml配置文件、启动类</h3><p>（1）修改pom文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"></div><div class="line">&lt;dependencies&gt;</div><div class="line"> &lt;!-- springCloud Config 关键代码--&gt;</div><div class="line"> &lt;dependency&gt;</div><div class="line">   &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">   &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;</div><div class="line"> &lt;/dependency&gt;</div><div class="line"> &lt;!-- 避免Config的Git插件报错：org/eclipse/jgit/api/TransportConfigCallback  --&gt;</div><div class="line"> &lt;dependency&gt;</div><div class="line">     &lt;groupId&gt;org.eclipse.jgit&lt;/groupId&gt;</div><div class="line">     &lt;artifactId&gt;org.eclipse.jgit&lt;/artifactId&gt;</div><div class="line">     &lt;version&gt;4.10.0.201712302008-r&lt;/version&gt;</div><div class="line"> &lt;/dependency&gt;</div><div class="line"> &lt;!-- 图形化监控 --&gt;</div><div class="line"> &lt;dependency&gt;</div><div class="line">   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">   &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;</div><div class="line"> &lt;/dependency&gt;</div><div class="line"> &lt;!-- 熔断 --&gt;</div><div class="line"> &lt;dependency&gt;</div><div class="line">   &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">   &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;</div><div class="line"> &lt;/dependency&gt;</div><div class="line"> &lt;dependency&gt;</div><div class="line">   &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">   &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;</div><div class="line"> &lt;/dependency&gt;</div><div class="line"> &lt;dependency&gt;</div><div class="line">   &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">   &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;</div><div class="line"> &lt;/dependency&gt;</div><div class="line"> &lt;dependency&gt;</div><div class="line">   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">   &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt;</div><div class="line"> &lt;/dependency&gt;</div><div class="line"> &lt;dependency&gt;</div><div class="line">   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">   &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</div><div class="line"> &lt;/dependency&gt;</div><div class="line"> &lt;dependency&gt;</div><div class="line">   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">   &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</div><div class="line"> &lt;/dependency&gt;</div><div class="line"> &lt;!-- 热部署插件 --&gt;</div><div class="line"> &lt;dependency&gt;</div><div class="line">   &lt;groupId&gt;org.springframework&lt;/groupId&gt;</div><div class="line">   &lt;artifactId&gt;springloaded&lt;/artifactId&gt;</div><div class="line"> &lt;/dependency&gt;</div><div class="line"> &lt;dependency&gt;</div><div class="line">   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">   &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;</div><div class="line"> &lt;/dependency&gt;</div><div class="line">&lt;/dependencies&gt;</div></pre></td></tr></table></figure>
<p>关键代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!-- springCloud Config 关键代码--&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">  &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">  &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p>（2）修改yml文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">server: </div><div class="line">  port: 10000 </div><div class="line">  </div><div class="line">spring:</div><div class="line">  application:</div><div class="line">    name:  microservicecloud-config</div><div class="line">  cloud:</div><div class="line">    config:</div><div class="line">      server:</div><div class="line">        git:</div><div class="line">          uri: git@github.com:JeremyKinge/springcloud-config-server.git #GitHub上面的git仓库名字</div><div class="line">          #username: xxxxxx  #如果访问github需要密码那么填写下面三项</div><div class="line">          #password: xxxxxxx</div><div class="line">          #force-pull: true</div></pre></td></tr></table></figure>
<p>（3）启动类</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">@EnableConfigServer</div><div class="line">public class ApplicationBootStart10000config &#123;</div><div class="line">    public static void main(String[] args)</div><div class="line">    &#123;</div><div class="line">        SpringApplication.run(ApplicationBootStart10000config.class,args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="3-6-完整项目结构"><a href="#3-6-完整项目结构" class="headerlink" title="3.6 完整项目结构"></a>3.6 完整项目结构</h3><p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-20_10-18-53.png" alt=""></p>
<h3 id="3-7-测试通过Config微服务是否可以从GitHub上获取配置内容"><a href="#3-7-测试通过Config微服务是否可以从GitHub上获取配置内容" class="headerlink" title="3.7 测试通过Config微服务是否可以从GitHub上获取配置内容"></a>3.7 测试通过Config微服务是否可以从GitHub上获取配置内容</h3><p>启动微服务10000<br><a href="http://localhost:10000/application-dev.yml" target="_blank" rel="external">http://localhost:10000/application-dev.yml</a></p>
<p>输出：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-20_10-23-00.png" alt=""></p>
<p><a href="http://localhost:10000/application-test.yml" target="_blank" rel="external">http://localhost:10000/application-test.yml</a></p>
<p>输出：</p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-20_10-23-19.png" alt=""></p>
<p><a href="http://localhost:10000/application-xxx.yml(不存在的配置" target="_blank" rel="external">http://localhost:10000/application-xxx.yml(不存在的配置</a>)</p>
<p><strong>成功实现了用SpringCloud Config通过GitHub获取配置信息</strong></p>
<h3 id="3-8-配置文件读取规则"><a href="#3-8-配置文件读取规则" class="headerlink" title="3.8 配置文件读取规则"></a>3.8 配置文件读取规则</h3><p><img src="/2019/05/01/SpringCloud个人总结/Topic578NotesImage5.jpg" alt=""></p>
<p>上面3.8测试中，我们采用的是第二种方式，通过10000配置中心去github获取配置文件</p>
<p>请求例子：</p>
<p>/{application}-{profile}.yml<br>  <a href="http://localhost:10000/application-dev.yml" target="_blank" rel="external">http://localhost:10000/application-dev.yml</a><br>  <a href="http://localhost:10000/application-test.yml" target="_blank" rel="external">http://localhost:10000/application-test.yml</a><br>  <a href="http://localhost:10000/application-xxx.yml(不存在的配置" target="_blank" rel="external">http://localhost:10000/application-xxx.yml(不存在的配置</a>)<br>/{application}/{profile}[/{label}]<br>  <a href="http://localhost:10000/application/dev/master" target="_blank" rel="external">http://localhost:10000/application/dev/master</a><br>  <a href="http://localhost:10000/application/test/master" target="_blank" rel="external">http://localhost:10000/application/test/master</a><br>  <a href="http://localhost:10000/application/xxx/master" target="_blank" rel="external">http://localhost:10000/application/xxx/master</a><br>/{label}/{application}-{profile}.yml<br>  <a href="http://localhost:10000/master/application-dev.yml" target="_blank" rel="external">http://localhost:10000/master/application-dev.yml</a><br>  <a href="http://localhost:10000/master/application-test.yml" target="_blank" rel="external">http://localhost:10000/master/application-test.yml</a></p>
<h2 id="4-SpringCloud-Config客户端配置与测试"><a href="#4-SpringCloud-Config客户端配置与测试" class="headerlink" title="4.SpringCloud Config客户端配置与测试"></a>4.SpringCloud Config客户端配置与测试</h2><p>在上面中我们已经搭建好了，配置中心的服务端。那么接下来演示一下客户端怎么取获取服务端的配置信息。</p>
<p><strong>新建8004服务提供者，他的配置信息我们取自配置中心（而不是在application.yml中配置，动态获取）</strong></p>
<h3 id="4-1-新建8004-配置文件并上传到github"><a href="#4-1-新建8004-配置文件并上传到github" class="headerlink" title="4.1 新建8004 配置文件并上传到github"></a>4.1 新建8004 配置文件并上传到github</h3><p>新建microservicecloud-provider-person-config-client-8004.yml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">spring: </div><div class="line">  profiles:</div><div class="line">    active:</div><div class="line">    - dev</div><div class="line">--- </div><div class="line">server:</div><div class="line">  port: 8004</div><div class="line"></div><div class="line">mybatis:</div><div class="line">  config-location: classpath:mybatis/mybatis.cfg.xml        # mybatis配置文件所在路径</div><div class="line">  type-aliases-package: com.kingge.entity    # 所有Entity别名类所在包</div><div class="line">  mapper-locations:</div><div class="line">  - classpath:mybatis/mapper/**/*.xml                       # mapper映射文件</div><div class="line"></div><div class="line">spring:</div><div class="line">   profiles: dev</div><div class="line">   application:</div><div class="line">    name: microservicecloud-person                          #很重要，对外暴露的微服务的名称</div><div class="line">   datasource:</div><div class="line">    type: com.alibaba.druid.pool.DruidDataSource            # 当前数据源操作类型</div><div class="line">    driver-class-name: org.gjt.mm.mysql.Driver              # mysql驱动包</div><div class="line">    url: jdbc:mysql://127.0.0.1:3306/test              # 数据库名称</div><div class="line">    username: root</div><div class="line">    password: 123</div><div class="line">    dbcp2:</div><div class="line">      min-idle: 5                                           # 数据库连接池的最小维持连接数</div><div class="line">      initial-size: 5                                       # 初始化连接数</div><div class="line">      max-total: 5                                          # 最大连接数</div><div class="line">      max-wait-millis: 200                                  # 等待连接获取的最大超时时间</div><div class="line">#</div><div class="line">eureka:</div><div class="line">  client: #客户端注册进eureka服务列表内</div><div class="line">    service-url:</div><div class="line">      defaultZone: http://peer1:7001/eureka/,http://peer2:7002/eureka/,http://peer3:7003/eureka/</div><div class="line">#      http://localhost:7001/eureka #单机版本使用</div><div class="line">#      defaultZone: http://peer1:7001/eureka/,http://peer2:7002/eureka/,http://peer3:7003/eureka/</div><div class="line">  instance:</div><div class="line">    instance-id: microservicecloud-person8001 #自定义服务实例名</div><div class="line">    prefer-ip-address: true     #访问路径可以显示IP地址</div><div class="line">    lease-expiration-duration-in-seconds: 10 # 10秒即过期</div><div class="line">    lease-renewal-interval-in-seconds: 5 # 5秒一次心跳</div><div class="line">#</div><div class="line">info:</div><div class="line">  app.name: $&#123;spring.application.name&#125;</div><div class="line">  company.name: kingge.top</div><div class="line">  build.artifactId: $&#123;project.artifactId&#125;</div><div class="line">  build.version: $&#123;project.version&#125;</div><div class="line">  app.desc: 这是一个提供查询部门人员信息的服务</div><div class="line">---</div><div class="line">server:</div><div class="line">  port: 8005</div><div class="line"></div><div class="line">mybatis:</div><div class="line">  config-location: classpath:mybatis/mybatis.cfg.xml        # mybatis配置文件所在路径</div><div class="line">  type-aliases-package: com.kingge.entity    # 所有Entity别名类所在包</div><div class="line">  mapper-locations:</div><div class="line">  - classpath:mybatis/mapper/**/*.xml                       # mapper映射文件</div><div class="line"></div><div class="line">spring:</div><div class="line">   profiles: test</div><div class="line">   application:</div><div class="line">    name: microservicecloud-person                          #很重要，对外暴露的微服务的名称</div><div class="line">   datasource:</div><div class="line">    type: com.alibaba.druid.pool.DruidDataSource            # 当前数据源操作类型</div><div class="line">    driver-class-name: org.gjt.mm.mysql.Driver              # mysql驱动包</div><div class="line">    url: jdbc:mysql://127.0.0.1:3306/test2              # 数据库名称</div><div class="line">    username: root</div><div class="line">    password: 123</div><div class="line">    dbcp2:</div><div class="line">      min-idle: 5                                           # 数据库连接池的最小维持连接数</div><div class="line">      initial-size: 5                                       # 初始化连接数</div><div class="line">      max-total: 5                                          # 最大连接数</div><div class="line">      max-wait-millis: 200                                  # 等待连接获取的最大超时时间</div><div class="line">#</div><div class="line">eureka:</div><div class="line">  client: #客户端注册进eureka服务列表内</div><div class="line">    service-url:</div><div class="line">      defaultZone: http://peer1:7001/eureka/,http://peer2:7002/eureka/,http://peer3:7003/eureka/</div><div class="line">#      http://localhost:7001/eureka #单机版本使用</div><div class="line">#      defaultZone: http://peer1:7001/eureka/,http://peer2:7002/eureka/,http://peer3:7003/eureka/</div><div class="line">  instance:</div><div class="line">    instance-id: microservicecloud-person8001 #自定义服务实例名</div><div class="line">    prefer-ip-address: true     #访问路径可以显示IP地址</div><div class="line">    lease-expiration-duration-in-seconds: 10 # 10秒即过期</div><div class="line">    lease-renewal-interval-in-seconds: 5 # 5秒一次心跳</div><div class="line">#</div><div class="line">info:</div><div class="line">  app.name: $&#123;spring.application.name&#125;</div><div class="line">  company.name: kingge.top</div><div class="line">  build.artifactId: $&#123;project.artifactId&#125;</div><div class="line">  build.version: $&#123;project.version&#125;</div><div class="line">  app.desc: 这是一个提供查询部门人员信息的服务</div></pre></td></tr></table></figure>
<p><strong>dev和test环境的不同在于，他们的服务端口不同和访问的数据库不同</strong></p>
<h3 id="4-2-microservicecloud-provider-person-config-client-8004模块"><a href="#4-2-microservicecloud-provider-person-config-client-8004模块" class="headerlink" title="4.2 microservicecloud-provider-person-config-client-8004模块"></a>4.2 microservicecloud-provider-person-config-client-8004模块</h3><p>（1）修改pom文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;dependencies&gt;</div><div class="line">    &lt;!-- 引入自己定义的api通用包，可以使用Person用户Entity --&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;com.kingge.springcloud&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;microservicecloud-api&lt;/artifactId&gt;</div><div class="line">        &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;!-- SpringCloud Config客户端 --&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;!-- actuator监控信息完善 --&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;!-- 将微服务provider端注册进eureka --&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;junit&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;junit&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;mysql&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;com.alibaba&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;druid&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;logback-core&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;!-- 修改后立即生效，热部署 --&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;springloaded&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">&lt;/dependencies&gt;</div></pre></td></tr></table></figure>
<p>关键依赖</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!-- SpringCloud Config客户端 --&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<h3 id="4-3-新建bootstrap-yml-系统级别配置文件"><a href="#4-3-新建bootstrap-yml-系统级别配置文件" class="headerlink" title="4.3 新建bootstrap.yml 系统级别配置文件"></a>4.3 新建bootstrap.yml 系统级别配置文件</h3><p>applicaiton.yml是用户级的资源配置项<br>bootstrap.yml是系统级的，优先级更加高</p>
<p>Spring Cloud会创建一个<code>Bootstrap Context</code>，作为Spring应用的<code>Application Context</code>的父上下文。初始化的时候，<code>Bootstrap Context</code>负责从外部源加载配置属性并解析配置。这两个上下文共享一个从外部获取的<code>Environment</code>。<code>Bootstrap</code>属性有高优先级，默认情况下，它们不会被本地配置覆盖。 <code>Bootstrap context</code>和<code>Application Context</code>有着不同的约定，<br>所以新增了一个<code>bootstrap.yml</code>文件，保证<code>Bootstrap Context</code>和<code>Application Context</code>配置的分离。</p>
<p><strong>换句话说，如果将下面内容放到application.yml中，那么项目启动会报错，因为是找不到控制层ConfigClientRest导入的属性</strong></p>
<p><strong>@Value(“${spring.application.name}”)</strong></p>
<p>（1）增加内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">spring:</div><div class="line">  cloud:</div><div class="line">    config:</div><div class="line">      name: microservicecloud-provider-person-config-client-8004 #需要从github上读取的资源名称，注意没有yml后缀名</div><div class="line">      profile: dev   #本次访问的配置项-profile值是什么，决定从github上读取什么</div><div class="line">      label: master</div><div class="line">      uri: http://localhost:10000  #本微服务启动后先去找config配置中心地址，通过SpringCloudConfig获取GitHub的服务地址</div></pre></td></tr></table></figure>
<p>（2）为了配置文件的完整性我们新建一个空的application.yml</p>
<h3 id="4-4-新建一个控制层，获取配置文件的某些属性（测试）"><a href="#4-4-新建一个控制层，获取配置文件的某些属性（测试）" class="headerlink" title="4.4 新建一个控制层，获取配置文件的某些属性（测试）"></a>4.4 新建一个控制层，获取配置文件的某些属性（测试）</h3><p>实际上如果8004服务端能够正常启动和访问，也能够说明客户端获取config配置中心配置文件成功。不过为了证实一下，所以这里通过控制层输出某些属性</p>
<p>（1）新建ConfigClientRest </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@RestController</div><div class="line">public class ConfigClientRest &#123;</div><div class="line"></div><div class="line">    @Value(&quot;$&#123;spring.application.name&#125;&quot;)</div><div class="line">    private String applicationName;</div><div class="line"></div><div class="line">    @Value(&quot;$&#123;eureka.client.service-url.defaultZone&#125;&quot;)</div><div class="line">    private String eurekaServers;</div><div class="line"></div><div class="line">    @Value(&quot;$&#123;server.port&#125;&quot;)</div><div class="line">    private String port;</div><div class="line"></div><div class="line">    @Value(&quot;$&#123;spring.datasource.url&#125;&quot;)</div><div class="line">    private String datasourceurl;</div><div class="line"></div><div class="line">    @RequestMapping(&quot;/config&quot;)</div><div class="line">    public String getConfig()</div><div class="line">    &#123;</div><div class="line">        String str = &quot;applicationName: &quot;+applicationName+&quot;\t eurekaServers:&quot;+eurekaServers+&quot;\t port: &quot;+port;</div><div class="line">        System.out.println(&quot;******str: &quot;+ str);</div><div class="line">        return &quot;applicationName: &quot;+applicationName+&quot;\t eurekaServers:&quot;+eurekaServers+&quot;\t port: &quot;+port + &quot;\t datasourceurl：&quot;+datasourceurl;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>后面可以通过更改 bootstrap.yml的profile属性的值，访问/config,查看服务端口号和数据库url是否改变。</p>
<h3 id="4-5-新建启动类-1"><a href="#4-5-新建启动类-1" class="headerlink" title="4.5 新建启动类"></a>4.5 新建启动类</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">public class ApplicationBootStart8004client &#123;</div><div class="line">    public static void main(String[] args)</div><div class="line">    &#123;</div><div class="line">        SpringApplication.run(ApplicationBootStart8004client.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="4-5-1-完整目录机构"><a href="#4-5-1-完整目录机构" class="headerlink" title="4.5.1 完整目录机构"></a>4.5.1 完整目录机构</h3><p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-20_11-07-11.png" alt=""></p>
<h3 id="4-6-启动10000配置中心和8004服务"><a href="#4-6-启动10000配置中心和8004服务" class="headerlink" title="4.6 启动10000配置中心和8004服务"></a>4.6 启动10000配置中心和8004服务</h3><p> （1） 启动Config配置中心10000微服务并自测</p>
<p><img src="/2019/05/01/SpringCloud个人总结/Snipaste_2019-08-20_11-05-27.png" alt=""></p>
<p>（2）启动8004作为Client准备访问</p>
<pre><code>  bootstrap.yml里面的profile值是什么，决定从github上读取什么

2.1 启动成功，说明配置文件获取成功



   2.2 额外验证
</code></pre><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">假如目前是 profile: dev</div><div class="line">  dev默认在github上对应的端口就是8004</div><div class="line">  http://localhost:8004/config</div><div class="line">  输出：applicationName: microservicecloud-person	eurekaServers:http://peer1:7001/eureka/,http://peer2:7002/eureka/,http://peer3:7003/eureka/	port: 8004	datasourceurl：jdbc:mysql://127.0.0.1:3306/test</div></pre></td></tr></table></figure>
<p>​<br>​    假如目前是 profile: test<br>​      test默认在github上对应的端口就是8005<br>​      <a href="http://localhost:8005/config" target="_blank" rel="external">http://localhost:8005/config</a><br>​      输出：applicationName: microservicecloud-person    eurekaServers:<a href="http://peer1:7001/eureka/,http://peer2:7002/eureka/,http://peer3:7003/eureka/" target="_blank" rel="external">http://peer1:7001/eureka/,http://peer2:7002/eureka/,http://peer3:7003/eureka/</a>    port: 8005    datasourceurl：jdbc:mysql://127.0.0.1:3306/test2</p>
<h2 id="5-手动刷新配置"><a href="#5-手动刷新配置" class="headerlink" title="5.手动刷新配置"></a>5.手动刷新配置</h2><pre><code>上面的案例，有个缺点，那就是我们修改了github上面的配置文件（例如修改了连接数据库的地址），对应的8004模块没有刷新，也就是，他获取的连接数据库的地址还是未修改前的。

在真实的案例中，我们不可能手动关闭服务器，然后重启。所以就需要8004它能够自动刷新
</code></pre><p><img src="/2019/05/01/SpringCloud个人总结/1566377247710.png" alt="1566377247710"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/1566377271635.png" alt="1566377271635"></p>
<p> 需要依赖actuator组件和通过psot方式访问请求配置变动的服务器（也即是@RefreshScope注解所在的bean）</p>
<p>（1）8004模块引入actuator依赖</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p>（2）8004启动类添加@EnableDiscoveryClient服务发现注解</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">@EnableDiscoveryClient</div><div class="line">public class ApplicationBootStart8004client &#123;</div><div class="line">    public static void main(String[] args)</div><div class="line">    &#123;</div><div class="line"></div><div class="line">        SpringApplication.run(ApplicationBootStart8004client.class, args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（3）8004模块修改application.yml文件，暴露所有端点</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">management:</div><div class="line">  security:</div><div class="line">    enabled: false</div></pre></td></tr></table></figure>
<p>（4）8004添加controller</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@RestController</div><div class="line">@RefreshScope</div><div class="line">public class ConfigClientRest &#123;</div><div class="line"></div><div class="line">    @Value(&quot;$&#123;spring.application.name&#125;&quot;)</div><div class="line">    private String applicationName;</div><div class="line"></div><div class="line">    @Value(&quot;$&#123;eureka.client.service-url.defaultZone&#125;&quot;)</div><div class="line">    private String eurekaServers;</div><div class="line"></div><div class="line">    @Value(&quot;$&#123;server.port&#125;&quot;)</div><div class="line">    private String port;</div><div class="line"></div><div class="line">    @Value(&quot;$&#123;spring.datasource.url&#125;&quot;)</div><div class="line">    private String datasourceurl;</div><div class="line"></div><div class="line">    @RequestMapping(&quot;/config&quot;)</div><div class="line">    public String getConfig()</div><div class="line">    &#123;</div><div class="line">        String str = &quot;applicationName: &quot;+applicationName+&quot;\t eurekaServers:&quot;+eurekaServers+&quot;\t port: &quot;+port;</div><div class="line">        System.out.println(&quot;******str: &quot;+ str);</div><div class="line">        return &quot;applicationName: &quot;+applicationName+&quot;\t eurekaServers:&quot;+eurekaServers+&quot;\t port: &quot;+port + &quot;\t datasourceurl：&quot;+datasourceurl;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（5）启动configserver10000和8004模块</p>
<p> 打印通过configserver从github上面获取的配置信息</p>
<p><img src="/2019/05/01/SpringCloud个人总结/1566379397446.png" alt="1566379397446"></p>
<p>此时数据库的url是：jdbc:mysql://127.0.0.1:3306/test1</p>
<p>（5）这个时候我们修改8004模块在github中引入的配置文件-</p>
<p>也就是修改microservicecloud-provider-person-config-client-8004.yml 文件。</p>
<p>1.修改访问数据库的url为，原先是test1</p>
<blockquote>
<p>url: jdbc:mysql://127.0.0.1:3306/test2    </p>
</blockquote>
<p>2.修改8004的服务端口为8005，原先是8008 - <strong>这个修改我们预测不会成功，因为服务器没有重启</strong></p>
<p>server.port：8005</p>
<p>（6）请求：curl -X POST <a href="http://localhost:8008/refresh" target="_blank" rel="external">http://localhost:8008/refresh</a>  手动更新8004模块的配置</p>
<p>  我们只需要请求这个地址就可以实现配置文件的更新，而不用重启8004模块，他默认会帮我们刷新配置文件。</p>
<p><img src="/2019/05/01/SpringCloud个人总结/1566379561052.png" alt="1566379561052"></p>
<p><img src="/2019/05/01/SpringCloud个人总结/1566379675277.png" alt="1566379675277"></p>
<p>我们发现数据库访问地址修改成功，但是服务端口号没有成功（很明显这种做法是错误的，因为服务端口号不会轻易的变动）</p>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>如果执行curl -X POST <a href="http://localhost:8008/refresh" target="_blank" rel="external">http://localhost:8008/refresh</a> 包如下错误</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&#123;&quot;timestamp&quot;:1513070580796,&quot;status&quot;:401,&quot;error&quot;:&quot;Unauthorized&quot;,&quot;message&quot;:&quot;Full authentication is required to access this resource.&quot;,&quot;path&quot;:&quot;/refresh&quot;&#125;</div></pre></td></tr></table></figure>
<p>那就说明默认开启访问端口验证了。需要关闭</p>
<p>一、在Spring Boot1.5.x版本中通过management.security.enabled=false来暴露所有端点</p>
<p><img src="/2019/05/01/SpringCloud个人总结/asdfafd.png" alt="img"></p>
<p>二、切换SpringBoot版本为2.x 使用IDE的搜索功能，找到类ManagementServerProperties，发现Security内部类已经被删除，通过去官网查看2.0暴露端点的方式得知：</p>
<blockquote>
<p>方式1：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># 启用端点 env</div><div class="line">management.endpoint.env.enabled=true</div><div class="line"> </div><div class="line"># 暴露端点 env 配置多个,隔开</div><div class="line">management.endpoints.web.exposure.include=env</div></pre></td></tr></table></figure>
<blockquote>
<p>方式2：</p>
</blockquote>
<p>方式1中的暴露方式需要一个一个去开启需要暴露的端点，方式2直接开启和暴露所有端点</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">management.endpoints.web.exposure.include=*</div></pre></td></tr></table></figure>
<p>注意在使用Http访问端点时，需要加上默认/actuator 前缀</p>
<p>三、如果这三种还不行，可以尝试在8004添加security验证依赖，然后给8004模块设置访问账号和密码， 然后通过  curl -X POST <a href="http://账号:密码@localhost:8008/refresh" target="_blank" rel="external">http://账号:密码@localhost:8008/refresh</a>  这种方式访问</p>
<h2 id="6-自动刷新配置"><a href="#6-自动刷新配置" class="headerlink" title="6.自动刷新配置"></a>6.自动刷新配置</h2><p>上面是通过手动刷新方式，缺点就是，如果我们在github上面修改了20个服务器的配置，那么我们需要手动执行20次 curl -X POST  ——  ，那么我们想能够缩减执行命令的次数或者说自动刷新配置。</p>
<h1 id="额外知识补充"><a href="#额外知识补充" class="headerlink" title="额外知识补充"></a>额外知识补充</h1><h2 id="1-spring-cloud服务发现注解之-EnableDiscoveryClient与-EnableEurekaClient区别"><a href="#1-spring-cloud服务发现注解之-EnableDiscoveryClient与-EnableEurekaClient区别" class="headerlink" title="1.spring cloud服务发现注解之@EnableDiscoveryClient与@EnableEurekaClient区别"></a>1.spring cloud服务发现注解之@EnableDiscoveryClient与@EnableEurekaClient区别</h2><p>在使用服务发现的时候有两种注解，</p>
<p>一种为@EnableDiscoveryClient,</p>
<p>一种为@EnableEurekaClient,</p>
<p>用法上基本一致，下文是从stackoverflow上面找到的对这<a href="https://www.cnblogs.com/liaojie970/p/What%E2%80%99s%20the%20difference%20between%20EnableEurekaClient%20and%20EnableDiscoveryClient?" target="_blank" rel="external">两者的解释</a>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">There are multiple implementations of &quot;Discovery Service&quot; (eureka, consul, zookeeper). </div><div class="line">@EnableDiscoveryClient lives in spring-cloud-commons and picks the implementation on the classpath.  </div><div class="line">@EnableEurekaClient lives in spring-cloud-netflix and only works for eureka. If eureka is on your classpath, they are effectively the same.</div></pre></td></tr></table></figure>
<p>意思也就是spring cloud中discovery service有许多种实现（eureka、consul、zookeeper等等）</p>
<p>@EnableDiscoveryClient基于spring-cloud-commons；而 @EnableEurekaClient基于spring-cloud-netflix</p>
<p>对@EnableEurekaClient的源码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">/**</div><div class="line"> * Convenience annotation for clients to enable Eureka discovery configuration</div><div class="line"> * (specifically). Use this (optionally) in case you want discovery and know for sure that</div><div class="line"> * it is Eureka you want. All it does is turn on discovery and let the autoconfiguration</div><div class="line"> * find the eureka classes if they are available (i.e. you need Eureka on the classpath as</div><div class="line"> * well).</div><div class="line"> *</div><div class="line"> * @author Dave Syer</div><div class="line"> * @author Spencer Gibb</div><div class="line"> */</div><div class="line">@Target(ElementType.TYPE)</div><div class="line">@Retention(RetentionPolicy.RUNTIME)</div><div class="line">@Documented</div><div class="line">@Inherited</div><div class="line">@EnableDiscoveryClient</div><div class="line">public @interface EnableEurekaClient &#123;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>注解@EnableEurekaClient上有@EnableDiscoveryClient注解，可以说基本就是EnableEurekaClient有@EnableDiscoveryClient的功能，另外上面的注释中提到，其实@EnableEurekaClient注解就是一种方便使用eureka的注解而已，可以说使用其他的注册中心后，都可以使用@EnableDiscoveryClient注解，</p>
<p>但是使用@EnableEurekaClient的情景，就是在服务采用eureka作为注册中心的时候，使用场景较为单一。</p>
<p><strong>所以还是比较建议使用@EnableDiscoveryClient。</strong></p>
<p><strong>所以上面的还是建议使用@EnableDiscoveryClient替换@EnableEurekaClient</strong></p>
<h2 id="2-Ribbon和Feign"><a href="#2-Ribbon和Feign" class="headerlink" title="2.Ribbon和Feign"></a>2.Ribbon和Feign</h2><p>这两种都是SPringcloud提供的负载均衡技术，都是客户端的软负载均衡技术。feign优化的Ribbon的服务调用方式，实现了面向接口编程的封装。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一下内容就是个人学习sc微服务架构中的学习总结，整个架构的东西很多，大家可以在需要某个组件时再去学习。&lt;/p&gt;
&lt;p&gt;一、为什么需要微服务&lt;/p&gt;
&lt;p&gt;我么那首先思考下面这些问题，为什么需要微服务，微服务能够解决什么痛点，它有什么优缺点？微服务和微服务架构是什么关系？什么
    
    </summary>
    
      <category term="springcloud" scheme="http://kingge.top/categories/springcloud/"/>
    
    
      <category term="分布式" scheme="http://kingge.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="springcloud" scheme="http://kingge.top/tags/springcloud/"/>
    
      <category term="微服务架构" scheme="http://kingge.top/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>浅谈dubbo和springcloud</title>
    <link href="http://kingge.top/2019/04/27/%E6%B5%85%E8%B0%88dubbo%E5%92%8Cspringcloud/"/>
    <id>http://kingge.top/2019/04/27/浅谈dubbo和springcloud/</id>
    <published>2019-04-27T02:21:59.000Z</published>
    <updated>2019-08-25T02:08:25.860Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、Dubbo负责人的采访"><a href="#一、Dubbo负责人的采访" class="headerlink" title="一、Dubbo负责人的采访"></a>一、Dubbo负责人的采访</h1><p>刘军，阿里巴巴中间件高级研发工程师，主导了 Dubbo 重启维护以后的几个发版计划，所以让我们来看一下他关于Dubbo和Springcloud是否二选一，他们之间的区别的阐述。</p>
<blockquote>
<p><strong>7、目前 Dubbo 被拿来比较最多的就是 Spring Cloud ，您怎么看待二者的关系，业务上是否有所冲突？</strong></p>
</blockquote>
<p>关于 Dubbo 和 Spring Cloud 间的关系，我们在<a href="https://www.oschina.net/2017-beijing-ceremony" target="_blank" rel="external">开源中国年终盛典</a>的 Dubbo 分享中也作了简单阐述，首先要明确的一点是 Dubbo 和 Spring Cloud 并不是完全的竞争关系，两者所解决的问题域并不一样：<strong>Dubbo 的定位始终是一款 RPC 框架</strong>，<strong>而 Spring Cloud 的目标是微服务架构下的一站式解决方案</strong>。如果非要比较的话，<strong>我觉得 Dubbo 可以类比到 Netflix OSS 技术栈，而 Spring Cloud 集成了 Netflix OSS 作为分布式服务治理解决方案，但除此之外 Spring Cloud 还提供了包括 config、stream、security、sleuth 等等分布式问题解决方案</strong>。</p>
<p>当前由于 RPC 协议、注册中心元数据不匹配等问题，在面临微服务基础框架选型时 Dubbo 与 Spring Cloud 是只能二选一，这也是为什么大家总是拿 Dubbo 和 Spring Cloud 做对比的原因之一。Dubbo 之后会积极寻求适配到 Spring Cloud 生态，比如作为 Spring Cloud 的二进制通信方案来发挥 Dubbo 的性能优势，或者 Dubbo 通过模块化以及对 http 的支持适配到 Spring Cloud 。</p>
<blockquote>
<p>Netflix OSS 技术栈</p>
</blockquote>
<p>1.Netflix Eureka 服务注册中心，提供服务的注册和发现</p>
<p>2.Netflix Ribbon 客户端负载均衡</p>
<p>3.Netflix Feign   客户端负载均衡，包装Ribbon，提供了接口式的服务调用</p>
<p>4.Netflix Hystrix 熔断器，负责服务的熔断和降级</p>
<p>5.NetFlix Hystrix dashboard 提供服务监控</p>
<p>6.Netflix zuul 路由网管 提供代理+路由+过滤三大功能</p>
<h1 id="二、Dubbo和Springcloud比较"><a href="#二、Dubbo和Springcloud比较" class="headerlink" title="二、Dubbo和Springcloud比较"></a>二、Dubbo和Springcloud比较</h1><blockquote>
<p>1.社区活跃度</p>
</blockquote>
<p><a href="https://github.com/dubbo" target="_blank" rel="external">https://github.com/dubbo</a> dubbo社区<br><a href="https://github.com/springcloud" target="_blank" rel="external">https://github.com/springcloud</a> springcloud社区</p>
<p>可以进去看一下他们对于技术的活跃程度曲线</p>
<blockquote>
<p>2.解决问题的方向</p>
</blockquote>
<p>dubbo：定位始终是一款 RPC 框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。</p>
<p>springcloud：微服务架构，提供微服务架构的一站式服务。</p>
<blockquote>
<p>3.功能对比</p>
</blockquote>
<p>根据两者的解决问题的域，得到他们的功能</p>
<table>
<thead>
<tr>
<th></th>
<th>Dubbo</th>
<th>Spring</th>
</tr>
</thead>
<tbody>
<tr>
<td>服务注册中心</td>
<td>Zookeeper</td>
<td>Spring   Cloud Netfilx Eureka</td>
</tr>
<tr>
<td>服务调用方式</td>
<td>RPC</td>
<td>REST   API</td>
</tr>
<tr>
<td>服务监控</td>
<td>Dubbo-monitor</td>
<td>Spring   Boot Admin</td>
</tr>
<tr>
<td>断路器</td>
<td>不完善</td>
<td>Spring   Cloud Netflix Hystrix</td>
</tr>
<tr>
<td>服务网关</td>
<td>无</td>
<td>Spring   Cloud Netflix Zuul</td>
</tr>
<tr>
<td>分布式配置</td>
<td>无</td>
<td>Spring   Cloud Config</td>
</tr>
<tr>
<td>服务跟踪</td>
<td>无</td>
<td>Spring   Cloud Sleuth</td>
</tr>
<tr>
<td>消息总线</td>
<td>无</td>
<td>Spring   Cloud Bus</td>
</tr>
<tr>
<td>数据流</td>
<td>无</td>
<td>Spring   Cloud Stream</td>
</tr>
<tr>
<td>批量任务</td>
<td>无</td>
<td>Spring   Cloud Task</td>
</tr>
</tbody>
</table>
<p>Dubbo的某些功能都是，通过整合其他组件实现，springcloud是通过实现Netflix oss的技术栈和原有的技术，实现的架构。</p>
<p>Dubbo提供了各种Filter，对于上述中“无”的要素，可以通过扩展Filter来完善。</p>
<blockquote>
<p>例如</p>
<p>1．分布式配置：可以使用淘宝的diamond、百度的disconf来实现分布式配置管理</p>
<p>2．服务跟踪：可以使用京东开源的Hydra，或者扩展Filter用Zippin来做服务跟踪</p>
<p>3．批量任务：可以使用当当开源的Elastic-Job、tbschedule</p>
</blockquote>
<p>总结：从核心要素来看，Spring Cloud 更胜一筹，在开发过程中只要整合Spring Cloud的子项目就可以顺利的完成各种组件的融合，而Dubbo缺需要通过实现各种Filter来做定制，开发成本以及技术难度略高。Dubbo更像是一个组装机，springcloud是一体机。</p>
<blockquote>
<p>4.服务调用方式</p>
</blockquote>
<p>Spring Cloud抛弃了RPC通讯，采用基于HTTP的REST方式。Spring Cloud牺牲了服务调用的性能，但是同时也避免了原生RPC带来的问题。REST比RPC更为灵活，不存在代码级别的强依赖，在强调快速演化的微服务环境下，显然更合适。</p>
<blockquote>
<p>5.服务获取方式</p>
</blockquote>
<p>dubbo通过长连接推送服务提供者地址列表给消费端，即是：Dubbo订阅Zookeeper下相应的节点，当节点的状态发生改变时，Zookeeper会立即反馈订阅的Client，实时性很高。</p>
<p>springcloud的eureka是 消费者端主动去eurekaServer注册中心获取数据，消费者可以配置去EurekaServer拉去服务列表的周期</p>
<p><strong>dubbo支持各种通信协议，而且消费方和服务方使用长链接方式交互，通信速度上略胜Spring Cloud，如果对于系统的响应时间有严格要求，长链接更合适。</strong></p>
<blockquote>
<p>6.服务注册中心满足的CAP原则</p>
</blockquote>
<p>著名的CAP理论指出，一个分布式系统不可能同时满足C(一致性)、A(可用性)和P(分区容错性)。由于分区容错性P在是分布式系统中必须要保证的，因此我们只能在A和C之间进行权衡。</p>
<p>Dubbo推荐使用zookeeper作为服务注册中心，zookeeper满足CP原则，一致性和分区容错性。springcloud的服务注册中心是Eureka，他满足的是AP原则，可用性和分区容错性。</p>
<p>Zookeeper如何保证CP</p>
<p> 当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的注册信息，但不能接受服务直接down掉不可用。也就是说，服务注册功能对可用性的要求要高于一致性。但是zk会出现这样一种情况，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新进行leader选举。问题在于，选举leader的时间太长，30 ~ 120s, 且选举期间整个zk集群都是不可用的，这就导致在选举期间注册服务瘫痪。在云部署的环境下，因网络问题使得zk集群失去master节点是较大概率会发生的事，虽然服务能够最终恢复，但是漫长的选举时间导致的注册长期不可用是不能容忍的。</p>
<p>Eureka如何保证AP</p>
<p> Eureka看明白了这一点，因此在设计时就优先保证可用性。Eureka各个节点都是平等的 ，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而Eureka的客户端在向某个Eureka注册或时如果发现连接失败，则会自动切换至其它节点，只要有一台Eureka还在，就能保证注册服务可用(保证可用性)，只不过查到的信息可能不是最新的(不保证强一致性)。除此之外，Eureka还有一种自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，此时会出现以下几种情况： </p>
<p> Eureka不再从注册列表中移除因为长时间没收到心跳而应该过期的服务 </p>
<p> Eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其它节点上(即保证当前节点依然可用)</p>
<p> 当网络稳定时，当前实例新的注册信息会被同步到其它节点中</p>
<p>因此， Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使整个注册服务瘫痪。</p>
<p>总结：那么既然保证了保证了可用性，那么数据的一致性肯定是不能够保证了，所以这个就是自我保护的机制。所以到底是AP还是CP，又或者是AC（数据库），要看业务场景来定。</p>
<p>而且Eureka部署集群时非常简单的，相比于dubbo部署zookeeper集群。</p>
<blockquote>
<p>7.节点性质</p>
</blockquote>
<p>Dubbo只有Consumer订阅Provider节点，也就是Consumer发现Provider节点信息</p>
<p>Eureka不区分Consumer或者Provider，两者都统称为Client，一个Client内可能同时含有Provider，Consumer，通过服务发现组件获取的是其他所有的Client节点信息，在调用时根据应用名称来筛选节点</p>
<h1 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h1>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一、Dubbo负责人的采访&quot;&gt;&lt;a href=&quot;#一、Dubbo负责人的采访&quot; class=&quot;headerlink&quot; title=&quot;一、Dubbo负责人的采访&quot;&gt;&lt;/a&gt;一、Dubbo负责人的采访&lt;/h1&gt;&lt;p&gt;刘军，阿里巴巴中间件高级研发工程师，主导了 Dubb
    
    </summary>
    
      <category term="dubbo" scheme="http://kingge.top/categories/dubbo/"/>
    
    
      <category term="dubbo" scheme="http://kingge.top/tags/dubbo/"/>
    
      <category term="分布式" scheme="http://kingge.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="rpc" scheme="http://kingge.top/tags/rpc/"/>
    
  </entry>
  
  <entry>
    <title>spring注解-辅助学习springboot和springcloud</title>
    <link href="http://kingge.top/2019/03/14/spring%E6%B3%A8%E8%A7%A3-%E8%BE%85%E5%8A%A9%E5%AD%A6%E4%B9%A0springboot%E5%92%8Cspringcloud/"/>
    <id>http://kingge.top/2019/03/14/spring注解-辅助学习springboot和springcloud/</id>
    <published>2019-03-14T14:59:59.000Z</published>
    <updated>2019-09-03T12:48:30.441Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h1><p> 因为后面要学习sb（springboot）和sc（springcloud），所以需要学习一些相关的注解和了解他们底层代码实现，例如@import注解，Aware接口，生命周期。</p>
<p>​    通过前面几个章节的学习，你会发现无论springboot还是springcloud的很多知识都是来源于spring相关的知识，章节还有一些内容没有补充完整，后续如果有时间会逐步更新完成！！！</p>
<h1 id="2-组件注册"><a href="#2-组件注册" class="headerlink" title="2.组件注册"></a>2.组件注册</h1><p>我们知道spring得IOC容器中存储了很多类的实例化对象，那么下面介绍几种往IOC容器中注册实体类的方式</p>
<h2 id="2-1-xml配置文件实例化实体类（方式一）"><a href="#2-1-xml配置文件实例化实体类（方式一）" class="headerlink" title="2.1 xml配置文件实例化实体类（方式一）"></a>2.1 xml配置文件实例化实体类（方式一）</h2><ol>
<li><p>首先新建spring.xml 文件，通过bean 标签实例化实体类</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567414688035.png" alt="1567414688035"></p>
</li>
</ol>
<p>2.通过ClassPathXmlApplicationContext获取实体类</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567414725611.png" alt="1567414725611"></p>
<p>缺点：大型项目的实体类会非常多，那么配置文件会变得非常的臃肿，而且也不易于维护。</p>
<h2 id="2-2-使用-Configuration和-bean（方式二）"><a href="#2-2-使用-Configuration和-bean（方式二）" class="headerlink" title="2.2 使用@ Configuration和@bean（方式二）"></a>2.2 使用@ Configuration和@bean（方式二）</h2><p>Spring提供了配置实体类的第二种方式，就是不用通过书写xml文件，通过两个注解就可以达到2.1 的功能。</p>
<ol>
<li>编写配置类，配置bean</li>
</ol>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567414770812.png" alt="1567414770812"></p>
<ol>
<li><p>通过AnnotationConfigApplicationContext获取实体类</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567414786811.png" alt="1567414786811"></p>
</li>
</ol>
<p>这里是new了一个AnnotationConfigApplicationContext对象，以前new的ClassPathXmlApplicationContext对象，的构造函数里面传的是配置文件的位置，而现在AnnotationConfigApplicationContext对象的构造函数里面传的是配置类的类型</p>
<h2 id="2-3-ComponentScan-自动扫描组件-amp-指定扫描规则（方式三）"><a href="#2-3-ComponentScan-自动扫描组件-amp-指定扫描规则（方式三）" class="headerlink" title="2.3 @ComponentScan-自动扫描组件&amp;指定扫描规则（方式三）"></a>2.3 @ComponentScan-自动扫描组件&amp;指定扫描规则（方式三）</h2><pre><code>**实际上这个注解跟前面两种方式是配合使用的，避免书写ClassPathXmlApplicationContext或者AnnotationConfigApplicationContext** **获取IOC容器。**
</code></pre><p>我们知道，在实际开发中我们是不会通过ClassPathXmlApplicationContext这样的代码方式获取对象，而是通过包扫描的方式进行实例化对象并注入IOC容器中</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567414821714.png" alt="1567414821714"></p>
<p>他的扫描规则是：以下这几个注解都是继承自@Component</p>
<p>@controller(给web层的注解)</p>
<p>@service(给serivce层加的注解)</p>
<p>@repository(给dao层加的注解) </p>
<p>@component(给java类加注解,老版本spring只有这一个注解)</p>
<p>只要书写了上面四个注解的类，那么会自动装配到ioc容器中。<strong>Id默认是类名首字母小写</strong></p>
<h3 id="1-ComponentScan注解的结构"><a href="#1-ComponentScan注解的结构" class="headerlink" title="1. @ComponentScan注解的结构"></a>1. @ComponentScan注解的结构</h3><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567414886849.png" alt="1567414886849"></p>
<p>1.这个注解上，也是可以指定要排除哪些包或者是只包含哪些包来进行管理：里面传是一个Filter[]数组。</p>
<p>2.Value ：就相当于spring的xml配置文件-</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567414894134.png" alt="1567414894134"></p>
<h3 id="2-用例"><a href="#2-用例" class="headerlink" title="2.用例"></a>2.用例</h3><p>–那么我们使用配置类的方式实现component-sacn同样的功能</p>
<p>1.首先在配置文件类，添加扫描的范围</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567414906119.png" alt="1567414906119"></p>
<p>2.添加几个注解类-</p>
<p>@controller（UserController）</p>
<p>@service（UserService）</p>
<p>@repository （UserDao）</p>
<p>@component（ComponentTest）</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567414919145.png" alt="1567414919145"></p>
<p>3.书写IOC</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567414938745.png" alt="1567414938745"></p>
<p>输出：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567414956045.png" alt="1567414956045"></p>
<p><strong>发现-扫描进入IOC容器的bean的id默认是：类名首字母小写</strong></p>
<p>4.使用Filter去除某些注解类</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567414983170.png" alt="1567414983170"></p>
<p>根据注解的方式排除，排除使用@Controller注解注解的类</p>
<p>–注意在使用includeFilters 扫描只包含那些组件的时候，要禁用spring默认全局扫描（跟配置文件一样，也是需要禁用的）</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567414996062.png" alt="1567414996062"></p>
<p>例子4</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415050284.png" alt="1567415050284"></p>
<h3 id="3-扩展"><a href="#3-扩展" class="headerlink" title="3.    扩展"></a>3.    扩展</h3><p>我们打开Component注解的源码，发现他是：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415143194.png" alt="1567415143194"></p>
<p>多了Repeatable注解，也就是说明，这个Component注解是可以多次重复用的</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415194264.png" alt="1567415194264"></p>
<p>那么你可能会问，如果不是jdk1.8,那么怎么书写多个扫描策略呢？</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415212225.png" alt="1567415212225"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415217769.png" alt="1567415217769"></p>
<p>也就是说，我们可以在配置类，使用ComponentScans注解，配置多个扫描策略</p>
<p>例子：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415246906.png" alt="1567415246906"></p>
<p>跟 { 例子4 } 效果一样</p>
<h4 id="4-1-FilterType-过滤规则"><a href="#4-1-FilterType-过滤规则" class="headerlink" title="4.1 FilterType 过滤规则"></a>4.1 FilterType 过滤规则</h4><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415321043.png" alt="1567415321043"></p>
<p>下面我们注重讲解一下，CUSTOM 自定义实现类</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415342468.png" alt="1567415342468"></p>
<p>需要先实现 TypeFilter</p>
<p>1.首先定义一个扫描规则类</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415368545.png" alt="1567415368545"></p>
<ol>
<li>配置类，实现自定义过滤规则</li>
</ol>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415379844.png" alt="1567415379844"></p>
<p> 表示 – 扫描的类中如果包含er那么就会被过滤掉（注意：他是会取扫描com.kingge下面的所有类-<strong>包括哪些没有被注解，注解的类也会被扫描</strong>）</p>
<h2 id="2-4-Import注解"><a href="#2-4-Import注解" class="headerlink" title="2.4      @Import注解"></a>2.4      @Import注解</h2><p><strong>有三种使用方式</strong></p>
<p><strong>第一种写法</strong>：直接在import注解中配置需要导入的类</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415399146.png" alt="1567415399146"></p>
<p>他在IOC容器中的id是：（全类名）</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415407178.png" alt="1567415407178"></p>
<p>缺点：如果有多个类需要注入IOC，那么代码量就很长</p>
<p><strong>第二种实现方式</strong>：自定义导入逻辑，批量导入，只需要返回需要导入的全类名数组</p>
<p>  实现ImportSelector 类</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415418134.png" alt="1567415418134"></p>
<p>配置类上使用</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415430330.png" alt="1567415430330"></p>
<p>这样 pp就注入到了IOC 容器中</p>
<p><strong>第三种方式</strong>：ImportBeanDefinitionRegistrar 实现这个类。</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415449102.png" alt="1567415449102"></p>
<p>例子：</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415496868.png" alt="1567415496868"></p>
<p>配置类引用</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415510372.png" alt="1567415510372"></p>
<p>调用：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415521934.png" alt="1567415521934"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415535174.png" alt="1567415535174"></p>
<h3 id="2-4-1-总结"><a href="#2-4-1-总结" class="headerlink" title="2.4.1 总结"></a>2.4.1 总结</h3><p>@Import[快速的给容器中导入一个组件]</p>
<p>（1）、 @Import(要导入容器中的组件);容器中就会自动的注册这个组件，id默认是全类名</p>
<p>（2）、 ImportSelector ：返回需要的组件的全类名的数组；</p>
<p>（3）、 ImportBeanDefinitionRegistrar : 手动注册bean到容器中</p>
<p> <strong>前面学习的springboot中，用到了该注解的次数很多。</strong></p>
<h2 id="2-5-Factorybean-工厂bean"><a href="#2-5-Factorybean-工厂bean" class="headerlink" title="2.5 Factorybean 工厂bean"></a>2.5 Factorybean 工厂bean</h2><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415551953.png" alt="1567415551953"></p>
<p>例子：</p>
<p>1.实现这个工厂bean</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415565829.png" alt="1567415565829"></p>
<p>getObject 方法：当调用bean时候，调用这个方法获取bean实例。</p>
<p>getObjectType：返回对象类型</p>
<p>isSIngleton: 是否是单例。False-表示是多例。True-表示是单例。（如果配置类中配置<strong>@Scope注解，企图改变UserDao的单实例，无效，以isDingleto方法设置为准</strong>）</p>
<p>2.配置类配置</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415579392.png" alt="1567415579392"></p>
<p>输出：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415589497.png" alt="1567415589497"></p>
<blockquote>
<p>输出：</p>
<p>class com.kingge.dao.UserDao</p>
<p>false</p>
</blockquote>
<p>、</p>
<p>第二个输出肯定是false</p>
<p>不过为什么第一个输出的是 Userdao的全类名而不是UserDaoFactoryBean的全类名呢？因为在构造的时候spring默认返回的就是getObjectType的值。</p>
<p>那么怎么获取这个工厂bean呢？spring提供了一个方式：加上&amp;</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415621835.png" alt="1567415621835"></p>
<p>输出：class com.kingge.utils.UserDaoFactoryBean</p>
<h2 id="2-6-总结-组件注册"><a href="#2-6-总结-组件注册" class="headerlink" title="2.6 总结-组件注册"></a>2.6 总结-组件注册</h2><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415637061.png" alt="1567415637061"></p>
<pre><code>/**

 \* 给容器中注册组件：

 \* 1）、扫描+组件标注注解（@Controller/@Service/@Repository/@Component）

 \* 【局限于要求是自己写的类，如果导入的第三方没有添加这些注解，那么就注册不上了】

 *

 \* 2）、@Bean[导入的第三方包里面的组件]

 \* 3）、@Import[快速的给容器中导入一个组件]

 \*      （1）、 @Import(要导入容器中的组件);容器中就会自动的注册这个组件，id默认是全类名

 \*      （2）、 ImportSelector ：返回需要的组件的全类名的数组；

 \*      （3）、 ImportBeanDefinitionRegistrar : 手动注册bean到容器中

 *

 \* 4）、使用Spring提供的FactoryBean（工厂bean）

 \*      （1）、默认获取到的是工厂bean调用getObject创建的对象

 \*      （2）、要获取工厂bean本身，我们需要给id前面加上一个“&amp;”符号：&amp;userDaoFactoryBean
</code></pre><p>第一种方式：一般用于自己定义的类，但是如果我们是通过导入第三方jar的方式导入了很多组件（类），但是我想把这些类注册到IOC容器中怎么办呢？这个时候就需要使用bean注解的方式注册组件。</p>
<p>第二种方式：可以实现自定义类或者第三方类的注入到IOC容器。缺点，那就是每实例化一个bean就得写个方法。这样代码量太多。</p>
<p>第三种方式：import标签（作用在配置类）</p>
<h1 id="3-修饰Bean的相关注解"><a href="#3-修饰Bean的相关注解" class="headerlink" title="3.修饰Bean的相关注解"></a>3.修饰Bean的相关注解</h1><h2 id="3-1-Scope注解"><a href="#3-1-Scope注解" class="headerlink" title="3.1 @Scope注解"></a>3.1 @Scope注解</h2><p>他一般是<strong>和@Bean注解配套使用</strong>，标识实体类的作用范围。我们知道IOC容器中的实体类，默认是单实例的。</p>
<p>证明：</p>
<ol>
<li>自定义IOC容器-实现配置类</li>
</ol>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415657803.png" alt="1567415657803"></p>
<p>2.获取 Person实体类</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415670181.png" alt="1567415670181"></p>
<p>我们不难发现-这里输出的是true，所以spring扫描bean策略默认是单实例。</p>
<p>那么怎么修改这种作用域呢？</p>
<p>查看Scope注解源码，发现可以指定这四种类型的作用范围</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415683803.png" alt="1567415683803"></p>
<p>第一个是多实例，第二个是：单实例（<strong>默认值</strong>）</p>
<p>第三个是：web环境下，用一个请求创建一次实例</p>
<p>第四个是：web环境下，同一个session创建一次实例</p>
<p>那么上诉代码只需要修改为</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415696308.png" alt="1567415696308"></p>
<p>这样就是多实例。</p>
<p><strong>总结：</strong></p>
<p>   单实例：在IOC容器启动的时候就已经实例化好Person（调用getPerson实例化），那么每次获取的时候直接从IOC容器中拿。</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415714441.png" alt="1567415714441"></p>
<p>这段代码运行时候会去调用getPerson方法完成实例</p>
<p>多实例：IOC容器启动时，不会去实例化Person，而是每次获取的时候才会去调用getPerson获取对象。</p>
<h2 id="3-2-Lazy注解"><a href="#3-2-Lazy注解" class="headerlink" title="3.2 @Lazy注解"></a>3.2 @Lazy注解</h2><p><strong>和@Bean注解配套使用，解决单实例bean在IOC容器启动就马上创建实例的问题。</strong></p>
<p><strong>懒加载bean，这个只对于单实例的情况下才有用</strong></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415726984.png" alt="1567415726984"></p>
<p>也就是IOC容器初始化的时候，不会去调用getPerson，实例化Person。<strong>第一次获取的时候才会去创建，以后再使用该实例化，会使用以前获取的</strong></p>
<h2 id="3-3-Conditional"><a href="#3-3-Conditional" class="headerlink" title="3.3 @Conditional"></a>3.3 @Conditional</h2><p>根据满足某个特定的条件创建一个特定的Bean。</p>
<p>因为我们可能存在一个需求那就是，根据不同的业务场景我们会有选择性的实例化某些bean，那么就可以使用这个注解。</p>
<h3 id="1-例子"><a href="#1-例子" class="headerlink" title="1.例子"></a>1.例子</h3><p> 需求：根据不同的系统实例化不同的bean。</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415756903.png" alt="1567415756903"></p>
<p>输出：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415769824.png" alt="1567415769824"></p>
<p>l  <strong>增加需求</strong> <strong>–</strong> <strong>当使用windows系统时，在IOC容器中创建windows实体类，反之创建linux</strong> <strong>实体类</strong></p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415788706.png" alt="1567415788706"></p>
<p>\1.      实现两个 条件类</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415816993.png" alt="1567415816993"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415830634.png" alt="1567415830634"></p>
<p>2.配置类</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415842983.png" alt="1567415842983"></p>
<p>\2.      实例化IOC 容器</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415854254.png" alt="1567415854254"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415865773.png" alt="1567415865773"></p>
<p>你会发现仅仅只是实例化了windows，linux实体类已经不见了，那么说明是条件生效了。</p>
<p>备注：</p>
<p>   @Conditional注解是可以作用在配置类上面的，那么他的作用就是全局的条件，只有满足了这个条件，配置类里面的bean才能够实例化。（局部方法配置Conditional注解会失效）</p>
<h1 id="4-生命周期"><a href="#4-生命周期" class="headerlink" title="4.生命周期"></a>4.生命周期</h1><pre><code>我们知道，Bean的生命周期是由IOC容器来管理的，那么我们也是可以自定义初始化方法和销毁方法。
</code></pre><p>Bean生命周期：<strong>bean创建-初始化-销毁</strong>，那么下面我们将来介绍，能够控制Bean生命周期的几种方式。</p>
<h2 id="4-1-init-method、destory-method-管理bean生命周期"><a href="#4-1-init-method、destory-method-管理bean生命周期" class="headerlink" title="4.1. init-method、destory-method 管理bean生命周期"></a>4.1. init-method、destory-method 管理bean生命周期</h2><p>需要注意的是，单实例和多实例的情况下，bean生命周期是不一样的。<strong>单实例bean的生命周期全部托管给IOC容器，多实例部分托管</strong>。</p>
<h3 id="1-在配置文件XML中："><a href="#1-在配置文件XML中：" class="headerlink" title="1.在配置文件XML中："></a>1.在配置文件XML中：</h3><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415958501.png" alt="1567415958501"></p>
<p>这两个方法是来控制初始化和销毁的</p>
<h3 id="2-代码控制初始化和销毁"><a href="#2-代码控制初始化和销毁" class="headerlink" title="2.代码控制初始化和销毁"></a>2.代码控制初始化和销毁</h3><h4 id="单实例情况下"><a href="#单实例情况下" class="headerlink" title="单实例情况下"></a>单实例情况下</h4><p>其实也就是在Bean注解，上填充init-method和destory-method方法</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415979268.png" alt="1567415979268"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415990937.png" alt="1567415990937"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567415998217.png" alt="1567415998217"></p>
<p>输出：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416012675.png" alt="1567416012675"></p>
<p><strong>因为是单实例的原因</strong>-所以容器启动的时候就开始调用了无参构造器创建对象，然后调用init初始化方法，容器关闭时，调用销毁方法.</p>
<h4 id="多实例情况下"><a href="#多实例情况下" class="headerlink" title="多实例情况下"></a>多实例情况下</h4><p>我们把配置类获取Car对象的方法改为多实例的形式，观察输出。</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416024604.png" alt="1567416024604"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416034091.png" alt="1567416034091"></p>
<p>输出</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416054016.png" alt="1567416054016"></p>
<p>我们发现我们在关闭容器的时候，<strong>他并没有调用destory销毁实例</strong>，因为多实例的bean他是不归于容器管辖，需要我们自己手动销毁</p>
<h3 id="3-总结"><a href="#3-总结" class="headerlink" title="3.总结"></a>3.总结</h3><p>总的来说，bean在IOC容器的生命周期如下：</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416082833.png" alt="1567416082833"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">* 我们可以自定义初始化和销毁方法；容器在bean进行到当前生命周期的时候来调用我们自定义的初始化和销毁方法</div><div class="line">* </div><div class="line">* 构造（对象创建）</div><div class="line">* 		单实例：在容器启动的时候创建对象</div><div class="line">* 		多实例：在每次获取的时候创建对象</div><div class="line">* </div><div class="line">* BeanPostProcessor.postProcessBeforeInitialization</div><div class="line">* 初始化：</div><div class="line">* 		对象创建完成，并赋值好，调用初始化方法。。。</div><div class="line">* BeanPostProcessor.postProcessAfterInitialization</div><div class="line">* 销毁：</div><div class="line">* 		单实例：容器关闭的时候</div><div class="line">* 		多实例：容器不会管理这个bean；容器不会调用销毁方法；</div></pre></td></tr></table></figure>
<h2 id="4-2-InitializingBean和DisposableBean-控制bean生命周期"><a href="#4-2-InitializingBean和DisposableBean-控制bean生命周期" class="headerlink" title="4.2 InitializingBean和DisposableBean 控制bean生命周期"></a>4.2 InitializingBean和DisposableBean 控制bean生命周期</h2><h3 id="1单实例情况下"><a href="#1单实例情况下" class="headerlink" title="1单实例情况下"></a>1单实例情况下</h3><p>1.新建Food类实现这两个接口</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416100346.png" alt="1567416100346"></p>
<p>配置类扫描</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416118482.png" alt="1567416118482"></p>
<p>测试</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416129315.png" alt="1567416129315"></p>
<p>输出：</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416137640.png" alt="1567416137640"></p>
<p>很明显单实例情况下，bean的生命周期是全部托管到IOC容器中。</p>
<h3 id="2-多实例情况下"><a href="#2-多实例情况下" class="headerlink" title="2.多实例情况下"></a>2.多实例情况下</h3><p>如果Food注入IOC容器时，选择多实例的方式的话，那么上面的案例在启动IOC容器时，不会有任何输出，因为多实例的情况下只有获取对象才会去做相关的初始化工作。</p>
<p>验证1：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416163330.png" alt="1567416163330"></p>
<p>没有任何输出。</p>
<p>验证2：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416175448.png" alt="1567416175448"></p>
<p>输出：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416191108.png" alt="1567416191108"></p>
<h3 id="3-总结-1"><a href="#3-总结-1" class="headerlink" title="3.总结"></a>3.总结</h3><blockquote>
<p><strong>很明显没有调用DisposableBean接口的destory方法和自定义的destory方法。</strong></p>
<p><strong>也就是说在多实例的情况下IOC容器只帮我们做创建和初始化bean的工作，但是销毁bean的工作他没有帮我们做，需要自己去实现。</strong></p>
</blockquote>
<h2 id="4-3-PostConstruct和-PreDestroy注解"><a href="#4-3-PostConstruct和-PreDestroy注解" class="headerlink" title="4.3 @PostConstruct和@PreDestroy注解"></a>4.3 @PostConstruct和@PreDestroy注解</h2><p>这两个注解是作用在方法上面的。</p>
<p>可以使用JSR250规范里面定义的两个注解：</p>
<p>@PostConstruct :在bean创建完成并且属性赋值完成，来执行初始化方法</p>
<p>@PreDestroy ：在容器销毁bean之前通知我们来进行清理工作</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416209944.png" alt="1567416209944"></p>
<p>初始化容器</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416222017.png" alt="1567416222017"></p>
<p>输出：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416237939.png" alt="1567416237939"></p>
<p>很明显-这两个注解的作用比4.2章节的两个接口的重载方法的调用更早，注意看官方的 注释说明</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416255764.png" alt="1567416255764"></p>
<p><strong>注意：这两个注解注解的方法，无返回值（void）</strong></p>
<h2 id="4-4-BeanPostProcessor-后置处理接口（重要）"><a href="#4-4-BeanPostProcessor-后置处理接口（重要）" class="headerlink" title="4.4 BeanPostProcessor 后置处理接口（重要）"></a>4.4 BeanPostProcessor 后置处理接口（重要）</h2><p>我们发现上面三种管理bean生命周期的方式，他们的方法是没有入参和出参的。，下面这种方式提供了</p>
<p>BeanPostProcessor接口：bean的后置处理器，在bean初始化前后做一些处理工作，这个接口有两个方法：</p>
<p>postProcessBeforeInitialization：在初始化之前工作</p>
<p>postProcessAfterInitialization：在初始化之后工作</p>
<p>（1）. 实现Food实体类</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416280606.png" alt="1567416280606"></p>
<p>（2）.配置类</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416311128.png" alt="1567416311128"></p>
<p>（3）.  启动容器查看输出</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416341585.png" alt="1567416341585"></p>
<p>（4）输出</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416364626.png" alt="1567416364626"></p>
<p><strong>他没有销毁方法。</strong></p>
<h2 id="4-1-4-4总结"><a href="#4-1-4-4总结" class="headerlink" title="4.1-4.4总结"></a>4.1-4.4总结</h2><p>上面这四种方式调用顺序</p>
<p>对象构造器 –&gt;&gt; PostConstruct -&gt;&gt; afterPropertiesSet -&gt;&gt; init-method -&gt;&gt; <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416382230.png" alt="1567416382230"> -&gt;&gt;   <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416398530.png" alt="1567416398530">-&gt;&gt;PreDestroy注解 自定义实现的destory方法-&gt;&gt; DisposableBean的destroy方法 -&gt;&gt;Food 自定义实现的destoryMethod方法</p>
<p>销毁：</p>
<p>  @PreDestroy注解的 PreDestroy —》DisposableBean接口的destory —》 destroy-method</p>
<h2 id="4-5BeanPostProcessor-原理"><a href="#4-5BeanPostProcessor-原理" class="headerlink" title="4.5BeanPostProcessor 原理"></a>4.5BeanPostProcessor 原理</h2><h3 id="1-两个方法打上断点"><a href="#1-两个方法打上断点" class="headerlink" title="1.两个方法打上断点"></a>1.两个方法打上断点</h3><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416431574.png" alt="1567416431574"></p>
<p>Dubug方式启动IOC容器</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416442452.png" alt="1567416442452"></p>
<p>2.查看方法栈调用</p>
<p>创建容器构造器</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416469689.png" alt="1567416469689"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416483129.png" alt="1567416483129"></p>
<pre><code>前置处理器调用的方法：调用getBeanPostProcessors()方法找到容器里面的所有的BeanPostProcessor，挨个遍历，调用BeanPostProcessor的postProcessBeforeInitialization方法，一旦调用postProcessBeforeInitialization方法的返回值为null的时候，就直接跳出遍历 ，后面的BeanPostProcessor 的postProcessBeforeInitialization也就不会执行了：
</code></pre><p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416501945.png" alt="1567416501945"></p>
<p>后置处理器调用的方法：调用getBeanPostProcessors()方法找到容器里面的所有的BeanPostProcessor，挨个遍历，调用BeanPostProcessor的postProcessAfterInitialization方法，一旦调用postProcessAfterInitialization方法的返回值为null的时候，就直接跳出遍历 ，后面的BeanPostProcessor 的postProcessAfterInitialization也就不会执行了：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416524867.png" alt="1567416524867"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416538029.png" alt="1567416538029"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416547870.png" alt="1567416547870"></p>
<h3 id="2-BeanPostProcessor在springboot中的使用"><a href="#2-BeanPostProcessor在springboot中的使用" class="headerlink" title="2.BeanPostProcessor在springboot中的使用"></a>2.BeanPostProcessor在springboot中的使用</h3><p>查看该接口的实现类</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416562220.png" alt="1567416562220"></p>
<p>这个接口，其实在spring的IOC容器中使用的频率是很多的，而且spring提供了很多实现类，例如如果我们想在bean中使用IOC容器的话，那么就可以使用</p>
<h3 id="1-ApplicationContextAwareProcessor"><a href="#1-ApplicationContextAwareProcessor" class="headerlink" title="1.ApplicationContextAwareProcessor"></a>1.ApplicationContextAwareProcessor</h3><p>给实体类，注入IOC容器。</p>
<p>ApplicationContextAware 接口，注入IOC容器</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416620035.png" alt="1567416620035"></p>
<p>例如：Dog实体类需要使用到IOC容器，那么就可以实现这个接口</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416633367.png" alt="1567416633367"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416638886.png" alt="1567416638886"></p>
<p>然后 他实际上是去 调用这个ApplicationContextAwareProcessor，方法，在创建Dog 对象他会去调用 postProcessBeforeInitialization 方法，判断实例化</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416668422.png" alt="1567416668422"></p>
<p>然后判断当前Dog实体类是否实现了ApplicationContextAware，如果是，那么调用invokeAwareInterface注入，IOC容器。</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416682517.png" alt="1567416682517"></p>
<p>最终去调用 Dog的 setApplicationContext 方法，赋值。</p>
<h3 id="1-BeanValidationPostProcessor"><a href="#1-BeanValidationPostProcessor" class="headerlink" title="1.    BeanValidationPostProcessor"></a>1.    BeanValidationPostProcessor</h3><p>实体类校验，后置处理器</p>
<h3 id="2-InitDestroyAnnotationBeanPostProcessor"><a href="#2-InitDestroyAnnotationBeanPostProcessor" class="headerlink" title="2.InitDestroyAnnotationBeanPostProcessor"></a>2.InitDestroyAnnotationBeanPostProcessor</h3><p>这个处理类，就是处理，我们3.3章节的两个注解。</p>
<h3 id="3-AutowiredAnnotationBeanPostProcessor"><a href="#3-AutowiredAnnotationBeanPostProcessor" class="headerlink" title="3.AutowiredAnnotationBeanPostProcessor"></a>3.AutowiredAnnotationBeanPostProcessor</h3><p>这个类就是处理我们的Autoware注解的</p>
<h3 id="4-BeanFactoryPostProcessor"><a href="#4-BeanFactoryPostProcessor" class="headerlink" title="4. BeanFactoryPostProcessor"></a>4. BeanFactoryPostProcessor</h3><p>BeanFactory的后置处理器，在BeanFactory的标准初始化之后调用</p>
<p>所有bean的定义已经保存加载到BeanFactory，但是bean的实例还未创建</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416709158.png" alt="1567416709158"></p>
<p>运行IOC容器</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416721160.png" alt="1567416721160"></p>
<p>查看输出：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416731721.png" alt="1567416731721"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416742609.png" alt="1567416742609"></p>
<p><strong>很明显他是在bean实例创建之前执行的。</strong></p>
<p>  BeanFactoryPostProcessor原理:</p>
<p>  1)、ioc容器创建对象</p>
<p>  2)、invokeBeanFactoryPostProcessors(beanFactory);</p>
<pre><code>如何找到所有的BeanFactoryPostProcessor并执行他们的方法；

          1）、直接在BeanFactory中找到所有类型是BeanFactoryPostProcessor的组件，并执行他们的方法

          2）、在初始化创建其他组件前面执行
</code></pre><h3 id="5-BeanDefinitionRegistryPostProcessor"><a href="#5-BeanDefinitionRegistryPostProcessor" class="headerlink" title="5.BeanDefinitionRegistryPostProcessor"></a>5.BeanDefinitionRegistryPostProcessor</h3><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416769528.png" alt="1567416769528"></p>
<p>启动ioc容器查看输出</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416783886.png" alt="1567416783886"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416793969.png" alt="1567416793969"></p>
<h3 id="6-ApplicationListener"><a href="#6-ApplicationListener" class="headerlink" title="6. ApplicationListener"></a>6. ApplicationListener</h3><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416807398.png" alt="1567416807398"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416820306.png" alt="1567416820306"></p>
<h1 id="5-属性赋值"><a href="#5-属性赋值" class="headerlink" title="5.属性赋值"></a>5.属性赋值</h1><h2 id="5-1-Value注解"><a href="#5-1-Value注解" class="headerlink" title="5.1 @Value注解"></a>5.1 @Value注解</h2><p>这个注解一般是作用在类的属性上面，他的作用等同于</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417097750.png" alt="1567417097750"></p>
<p>那么他可以书写那些值呢？</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416934645.png" alt="1567416934645"></p>
<p>第三种是取配置文件的数据</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416950884.png" alt="1567416950884"></p>
<p>那么怎么使用 第三种方式赋值呢？下面讲解</p>
<h2 id="5-2-PropertySource-注解"><a href="#5-2-PropertySource-注解" class="headerlink" title="5.2 @ PropertySource 注解"></a>5.2 @ PropertySource 注解</h2><p>他的作用相当于XML的：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567416959675.png" alt="1567416959675"></p>
<p>1.配置类添加配置注解</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417123219.png" alt="1567417123219"></p>
<p>2.Person实体类</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417130983.png" alt="1567417130983"></p>
<p>输出：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417138775.png" alt="1567417138775"></p>
<p>我们也可以通过IOC容器手动的去获取配置的信息</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417160484.png" alt="1567417160484"></p>
<h2 id="3-3-通过实现-EmbeddedValueResolverAware-获取属性值"><a href="#3-3-通过实现-EmbeddedValueResolverAware-获取属性值" class="headerlink" title="3.3   通过实现 EmbeddedValueResolverAware 获取属性值"></a>3.3   通过实现 EmbeddedValueResolverAware 获取属性值</h2><p>l  <strong>见6.5</strong> <strong>章节</strong></p>
<h1 id="6-自动装配"><a href="#6-自动装配" class="headerlink" title="6.自动装配"></a>6.自动装配</h1><h2 id="6-1-Autowire、-Qualifier、-Primary（spring规范的注解）"><a href="#6-1-Autowire、-Qualifier、-Primary（spring规范的注解）" class="headerlink" title="6.1 @Autowire、@Qualifier、@Primary（spring规范的注解）"></a>6.1 @Autowire、@Qualifier、@Primary（spring规范的注解）</h2><p>在spring的项目中我们是经常这个Autowire来进行实体类之间的依赖注入，他的注入规则是：</p>
<p>\1.      默认按照类型去IOC容器中查找需要的实体类（例如UserDao.class）</p>
<p>\2.      如果找到多个同类型的实体类，那么他会根据属性名作为组件ID去进一步匹配。</p>
<p>例如：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417175481.png" alt="1567417175481"></p>
<p>然后IOC容器中有两个UserDao实例，一个是ID为userDao，一个ID为userDao1.</p>
<p>那么上面service注入的是哪一个呢？</p>
<p>  答案：注入的是ID为userDao的实体类。如果想要注入userDao1，那么应该把属性名改为userDao1</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417185951.png" alt="1567417185951"></p>
<p>@Qualifier，指定需要装配的ID，取消默认根据属性名去匹配。</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417197152.png" alt="1567417197152"> 默认是必须找到需要的依赖实体类，然后注入Service，否则就会报错，我们可以使用required属性来控制</p>
<p>@Primary ： <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417205766.png" alt="1567417205766"></p>
<p>这个注解是作用在被依赖的实体类（UserDao）上面，明确指定，当某个类（UserService）依赖这个实体类的时候，假设IOC容器中存在多个相同类型的被依赖类（UserDao）那么首选呗Primary注解的被依赖类。（</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417215346.png" alt="1567417215346"></p>
<p>如果UserService同时使用了@Qualifier<strong>注解</strong> ，那么@Primary的效果将会失效，以Qualifier注解需要的ID为主</p>
<h3 id="Autowire注解扩展"><a href="#Autowire注解扩展" class="headerlink" title="@Autowire注解扩展"></a>@Autowire注解扩展</h3><p>他可以标在构造器上，方法上</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417225715.png" alt="1567417225715"></p>
<h2 id="6-2-Resource、-Inject（java规范的注解）"><a href="#6-2-Resource、-Inject（java规范的注解）" class="headerlink" title="6.2 @Resource、@Inject（java规范的注解）"></a>6.2 @Resource、@Inject（java规范的注解）</h2><pre><code>![1567417242591](spring注解-辅助学习springboot和springcloud\1567417242591.png)
</code></pre><p><strong>@Resource注解</strong></p>
<p>他的作用跟@Autowire注解的作用是一样的，默认根据属性名进行装配。Name属性可以更改装配的id</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417260280.png" alt="1567417260280"></p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417265681.png" alt="1567417265681"></p>
<p><strong>@Inject</strong> <strong>的使用，需要添加依赖</strong></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417277299.png" alt="1567417277299"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417283634.png" alt="1567417283634"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417290770.png" alt="1567417290770"></p>
<p>支持@Primary功能，但是他没有属性</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417301282.png" alt="1567417301282"></p>
<h2 id="6-3-Aware接口-（重要）"><a href="#6-3-Aware接口-（重要）" class="headerlink" title="6.3 Aware接口 （重要）"></a>6.3 Aware接口 （重要）</h2><p>自定义组件想要使用Spring容器底层的一些组件（ApplicationContext、BeanFactory…）</p>
<p>自定义组件实现xxxAware接口就可以实现，在创建对象的时候，会调用接口规定的方法注入相关的组件，把Spring底层的一些组件注入到自定义的bean中。 xxxAware等这些都是</p>
<p>利用<strong>后置处理器的机制</strong>，比如ApplicationContextAware 是通过ApplicationContextAwareProcessor来进行处理的。</p>
<p>如果我们想在自定义实体类中，使用IOC容器的context怎么办呢？</p>
<p>例子：我有在第四章节中 BeanPostProcessor中讲过。</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417315217.png" alt="1567417315217"></p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417323109.png" alt="1567417323109"></p>
<p>例子：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417358798.png" alt="1567417358798"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417366098.png" alt="1567417366098"></p>
<h3 id="1-下面我们就是用一个例子来详细讲解一下Aware接口的工作流程。"><a href="#1-下面我们就是用一个例子来详细讲解一下Aware接口的工作流程。" class="headerlink" title="1.下面我们就是用一个例子来详细讲解一下Aware接口的工作流程。"></a>1.下面我们就是用一个例子来详细讲解一下Aware接口的工作流程。</h3><p>（1）.实现一个entity，实现<strong>ApplicationContextAware</strong> 接口</p>
<p>实现该接口的setApplicationContext方法。</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417382674.png" alt="1567417382674"></p>
<p>（2）. 配置类，配置Blue实体类，实例化到IOC容器中</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417392347.png" alt="1567417392347"></p>
<p>（3）.获取IOC容器</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417433281.png" alt="1567417433281"></p>
<p>（4）输出</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417443301.png" alt="1567417443301"></p>
<h3 id="2-源码分析"><a href="#2-源码分析" class="headerlink" title="2.源码分析"></a>2.源码分析</h3><p>在setApplicationContext 打个断点。</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417460772.png" alt="1567417460772"></p>
<p>发现他是去调用 ApplicationContextAwareProcessor 实体类，这个实体类实现了BeanPostProcessor 后置处理器。</p>
<p>2.执行postProcessBeforeInitialization 前置方法，判断当前的实体类是否继承了某些接口。做一些权限判断</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417474653.png" alt="1567417474653"></p>
<p>3.然后调用 invokeAwareInterfaces ，紧接着调用实体类实现的 <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417484555.png" alt="1567417484555"> 方法，注入IOC容器</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417501646.png" alt="1567417501646"></p>
<h2 id="6-4-Profile注解"><a href="#6-4-Profile注解" class="headerlink" title="6.4 @Profile注解"></a>6.4 @Profile注解</h2><pre><code>和Springboot的profile是一致的。
</code></pre><p>@profile注解是spring提供的一个用来标明当前运行环境的注解。我们正常开发的过程中经常遇到的问题是，开发环境是一套环境，qa测试是一套环境，线上部署又是一套环境。这样从开发到测试再到部署，会对程序中的配置修改多次，尤其是从qa到上线这个环节，让qa的也不敢保证改了哪个配置之后能不能在线上运行。</p>
<p>为了解决上面的问题，我们一般会使用一种方法，就是配置文件，然后通过不同的环境读取不同的配置文件，从而在不同的场景中跑我们的程序。</p>
<p>那么，spring中的@profile注解的作用就体现在这里。在spring使用DI来依赖注入的时候，能够根据当前制定的运行环境来注入相应的bean。最常见的就是使用不同的DataSource了。</p>
<p><strong>下面-结合</strong> <strong>properties配置文件的三种注入方式来讲解一下@Profile注解的用法</strong></p>
<p>—-以作用在方法上，表示只要在当前设置的环境下才会往IOC容器中注册当前bean。</p>
<p>—-作用在类上面 </p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417520813.png" alt="1567417520813"></p>
<p>类里面的所有bean，能够被注册到IOC容器中的条件是：只要开发环境满足了当前配置类上面的Prifile注解标识的环境。 </p>
<p>例如：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417527878.png" alt="1567417527878"></p>
<p>主要开发环境是test 里面的bean才能够被注册。</p>
<p>-</p>
<h2 id="6-5-profile的使用"><a href="#6-5-profile的使用" class="headerlink" title="6.5 @profile的使用"></a>6.5 @profile的使用</h2><p>我们知道，如果在组件上标识了这个注解，那么如果没有激活，那么就不会被注册到IOC容器中。通过这个特性来过滤一些组件的注册。</p>
<p>@Profile(“default”) 是默认注册某个bean</p>
<p>1.配置类</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417566591.png" alt="1567417566591"></p>
<p>2.测试</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417580291.png" alt="1567417580291"></p>
<p>输出：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417588458.png" alt="1567417588458"></p>
<p>很明显，三个配置都没有被注册在IOC容器中，因为没有指定运行环境。</p>
<p>\3.      制定运行环境（第一种方式：虚拟机参数位置添加-Dspring.profiles.active=test）</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417616396.png" alt="1567417616396"></p>
<p>这样</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417625690.png" alt="1567417625690"> 就会输出了。</p>
<p>\4.      制定运行环境（第二种方式-代码方式）</p>
<p> <img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417638837.png" alt="1567417638837"></p>
<p>可以指定多个配置环境</p>
<p>输出：</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417653302.png" alt="1567417653302"></p>
<h1 id="7-AOP"><a href="#7-AOP" class="headerlink" title="7.AOP"></a>7.AOP</h1><blockquote>
<p> 什么叫AOP和他的作用</p>
</blockquote>
<p>在程序运行期间，动态的将某段代码切入到指定方法运行时的指定时机运行，其实就是动态代理。</p>
<blockquote>
<p>作用场景</p>
</blockquote>
<pre><code>可以在某个业务实现的过程前后，或者出现异常，进行一些额外业务的操作。例如当你调用add()方法进行加法运算的时候，我们可以在调用方法前，得到结果后，或者出现异常时，记录一些日志。以前我们传统的做法是，在方法里面打印日志（System.out.println）,但是这样会造成耦合，而且我们也想把打印日志抽离成一个统一的模块。
</code></pre><h2 id="1-例子-1"><a href="#1-例子-1" class="headerlink" title="1.  例子"></a>1.  例子</h2><p> Maven依赖：spring提供了对AOP的支持</p>
<h3 id="（1）导入aop依赖"><a href="#（1）导入aop依赖" class="headerlink" title="（1）导入aop依赖"></a>（1）导入aop依赖</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-aspects --&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.springframework&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;4.3.14.RELEASE&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<h3 id="（2）MathCalculator-java"><a href="#（2）MathCalculator-java" class="headerlink" title="（2）MathCalculator.java"></a>（2）MathCalculator.java</h3><pre><code>业务逻辑类：要求在业务方法运行时打印日志
</code></pre><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417713757.png" alt="1567417713757"></p>
<h3 id="（3）：日志切面类：LogAspects-java"><a href="#（3）：日志切面类：LogAspects-java" class="headerlink" title="（3）：日志切面类：LogAspects.java"></a>（3）：日志切面类：LogAspects.java</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.aop;</div><div class="line"></div><div class="line">import java.util.Arrays;</div><div class="line"></div><div class="line">import org.aspectj.lang.JoinPoint;</div><div class="line">import org.aspectj.lang.annotation.After;</div><div class="line">import org.aspectj.lang.annotation.AfterReturning;</div><div class="line">import org.aspectj.lang.annotation.AfterThrowing;</div><div class="line">import org.aspectj.lang.annotation.Aspect;</div><div class="line">import org.aspectj.lang.annotation.Before;</div><div class="line">import org.aspectj.lang.annotation.Pointcut;</div><div class="line"></div><div class="line">/**</div><div class="line"> * 切面类</div><div class="line"> * @Aspect： 告诉Spring当前类是一个切面类</div><div class="line"> *</div><div class="line"> */</div><div class="line">@Aspect</div><div class="line">public class LogAspects &#123;</div><div class="line"></div><div class="line">	//抽取公共的切入点表达式</div><div class="line">	//1、本类引用</div><div class="line">	//2、其他的切面引用</div><div class="line">	@Pointcut(&quot;execution(public int com.kingge.aop.MathCalculator.*(..))&quot;)</div><div class="line">	public void pointCut()&#123;&#125;;</div><div class="line"></div><div class="line">	//@Before在目标方法之前切入；切入点表达式（指定在哪个方法切入）</div><div class="line">	@Before(&quot;pointCut()&quot;)</div><div class="line">	public void logStart(JoinPoint joinPoint)&#123;</div><div class="line">		Object[] args = joinPoint.getArgs();</div><div class="line">		System.out.println(&quot;&quot;+joinPoint.getSignature().getName()+&quot;运行。。。@Before:参数列表是：&#123;&quot;+Arrays.asList(args)+&quot;&#125;&quot;);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@After(&quot;com.kingge.aop.LogAspects.pointCut()&quot;)</div><div class="line">	public void logEnd(JoinPoint joinPoint)&#123;</div><div class="line">		System.out.println(&quot;&quot;+joinPoint.getSignature().getName()+&quot;结束。。。@After&quot;);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	//JoinPoint一定要出现在参数表的第一位</div><div class="line">	@AfterReturning(value=&quot;pointCut()&quot;,returning=&quot;result&quot;)</div><div class="line">	public void logReturn(JoinPoint joinPoint,Object result)&#123;</div><div class="line">		System.out.println(&quot;&quot;+joinPoint.getSignature().getName()+&quot;正常返回。。。@AfterReturning:运行结果：&#123;&quot;+result+&quot;&#125;&quot;);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@AfterThrowing(value=&quot;pointCut()&quot;,throwing=&quot;exception&quot;)</div><div class="line">	public void logException(JoinPoint joinPoint,Exception exception)&#123;</div><div class="line">		System.out.println(&quot;&quot;+joinPoint.getSignature().getName()+&quot;异常。。。异常信息：&#123;&quot;+exception+&quot;&#125;&quot;);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<pre><code>这四个方法，都是作用在MathCalculator的add方法，那么他们的切入点表达式都是一样的，为了避免重复书写，我们一般采用抽取公共切入点的方式，抽取出来，复用。---- 使用@PoinCut注解
</code></pre><blockquote>
<p> 切面类中的方法也称为通知方法：</p>
<p>  前置通知(@Before)：在目标方法运行之前运行</p>
<p>  后置通知(@After)：在目标方法运行之后运行，即使出现异常也会运行</p>
<p>  返回通知(@AfterReturning)：在目标方法正常返回之后运行</p>
<p>  异常通知(@AfterThrowing)：在目标方法运行出现异常之后运行</p>
<p>  环绕通知(@Around)：动态代理，手动推进目标方法的运行</p>
</blockquote>
<h3 id="（4）开启spring切面自动代理"><a href="#（4）开启spring切面自动代理" class="headerlink" title="（4）开启spring切面自动代理"></a>（4）开启spring切面自动代理</h3><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417746703.png" alt="1567417746703"></p>
<pre><code>**使用Spring的切面需要开启Spring的切面自动代理，只需要在配置类中加注解@EnableAspectJAutoProxy，Spring中有很多@EnableXxx（关于这点我们在springcloud中使用的最多，自动配置）注解，用来开启一些功能**
</code></pre><blockquote>
<pre><code>配置bean怎么区分哪个bean是切面类呢，它会看哪个类上有@Aspect注解，另外切面方法的执行仅对Spring容器中的bean起作用，对于我们自己new出来的对象是不起作用的，原因也很简单，我们自己创建的bean并没有被spring管理，也就没有为其设置切面方法等。

    通过JoinPoint对象获取调用目标方法时的信息，比如方法名、参数等，使用returning指定用通知方法的哪个入参接收返回值，使用throwing指定用哪个入参接收异常，另外如果使用JoinPoint，则必须将其放在切面方法入参的第一个位置，否则会报错
</code></pre></blockquote>
<h3 id="（5）测试"><a href="#（5）测试" class="headerlink" title="（5）测试"></a>（5）测试</h3><blockquote>
<p> 正常计算</p>
</blockquote>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417764521.png" alt="1567417764521"></p>
<blockquote>
<p>错误计算</p>
</blockquote>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567472449448.png" alt="1567472449448"></p>
<p>给一个出现异常的 1 /0 运算处理，查看日志。</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417773670.png" alt="1567417773670"></p>
<p>你会发现，无论是否出现异常 logStart 和 logEnd 都会正常输出，如果正常返回那么<code>@AfterReturning标识的方法</code>会被调用，如果运算发生异常那么<code>@AfterReturning标识的方法</code>不会被调用，而<code>@AfterThrowing标识的异常处理方法会被调用</code></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417705277.png" alt="1567417705277"></p>
<h2 id="2-AOP原理"><a href="#2-AOP原理" class="headerlink" title="2.  AOP原理"></a>2.  AOP原理</h2><p>通过上面的例子我们知道，实现AOP的关键点在于我么能使用@EnableAspectJAutoProxy注解，那么接下来我们查看一下这个注解到底做了什么工作</p>
<h3 id="1-查看-EnableAspectJAutoProxy注解"><a href="#1-查看-EnableAspectJAutoProxy注解" class="headerlink" title="1.查看@EnableAspectJAutoProxy注解"></a>1.查看@EnableAspectJAutoProxy注解</h3><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417786810.png" alt="1567417786810"></p>
<p>两个属性的含义：</p>
<blockquote>
<pre><code>英文注解已经很详细了,这里简单介绍一下两个参数,一个是控制aop的具体实现方式,为true 的话使用cglib,为false的话使用java的Proxy,默认为false,第二个参数控制代理的暴露方式,解决内部调用不能使用代理的场景，默认为false
</code></pre></blockquote>
<h3 id="2-查看一下-AspectJAutoProxyRegistrar-java-到底导入了哪些类"><a href="#2-查看一下-AspectJAutoProxyRegistrar-java-到底导入了哪些类" class="headerlink" title="2.查看一下 AspectJAutoProxyRegistrar.java 到底导入了哪些类"></a>2.查看一下 AspectJAutoProxyRegistrar.java 到底导入了哪些类</h3><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417799676.png" alt="1567417799676"></p>
<p>很明显这个类是采用了ImportBeanDefinitionRegistrar的方式注册了某些类大oIOC容器中，那么我们看一下他到底注入了什么类。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">核心是这里： AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry);</div></pre></td></tr></table></figure>
<pre><code>一个AOP的工具类,这个工具类的主要作用是把AnnotationAwareAspectJAutoProxyCreator这个类定义为BeanDefinition放到spring容器中,这是通过实现ImportBeanDefinitionRegistrar接口来装载的,具体装载过程不是本篇的重点,这里就不赘述,我们重点看AnnotationAwareAspectJAutoProxyCreator这个类.
</code></pre><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/5C1567438805334.png" alt="1567438805334"></p>
<pre><code>从类图是可以大致了解AnnotationAwareAspectJAutoProxyCreator这个类的功能.它实现了一系列Aware的接口,在Bean装载的时候获取BeanFactory(Bean容器),Bean的ClassLoader,还实现了order接口,继承了PorxyConfig,ProxyConfig中主要封装了代理的通用处理逻辑,比如设置目标类,设置使用cglib还是java proxy等一些基础配置.

而能够让这个类参与到bean初始化功能,并为bean添加代理功能的还是因为它实现了BeanPostProcessor这个接口.这个接口的postProcessAfterInitialization方法会在bean初始化结束后(赋值完成)被调用。
</code></pre><h3 id="3-最顶部的抽象类-AbstractAutoProxyCreator"><a href="#3-最顶部的抽象类-AbstractAutoProxyCreator" class="headerlink" title="3.最顶部的抽象类:AbstractAutoProxyCreator"></a>3.最顶部的抽象类:AbstractAutoProxyCreator</h3><p>注意看bean初始化的方法</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/5C1567439298675.png" alt="1567439298675"></p>
<pre><code>当我们开启了EbableAspectJAutoProxy后,每次Bean的装配时,都会执行这段逻辑.前面主要是校验是否需要对bean进行代理(特殊的类,和已经被代理),核心逻辑在后面几行.getAdvicesAndAdvisorsForBean方法来获取所有符合条件的切面,具体的实现在子类,这里是抽象方法,获取切面后就是创建代理:
</code></pre><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/5C1567439441240.png" alt="1567439441240"></p>
<p>TargetSource中存放被代理的对象,这段代码主要是为了构建ProxyFactory,将配置信息(是否使用java proxy,是否threadlocal等),目标类,切面,传入ProxyFactory中,而在ProxyFactory中,会通过createAopProxy()方法创建代理工厂DefaultAopProxyFactory,由代理厂生成具体的代理对目标类进行代理:</p>
<p>进入<code>proxyFactory.getProxy(getProxyClassLoader());</code> 的<code>getProxy()</code>方法 </p>
<p>跳到</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/5C1567439674687.png" alt="1567439674687"></p>
<p>进入<code>createAopProxy()</code>，跳转到</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/5C1567439733523.png" alt="1567439733523"></p>
<p>我们可以查看AopProxy的都有哪些 ，在AOpProxy上按键：ctrl t，</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/5C1567439796941.png" alt="1567439796941"></p>
<p>很明显有我们熟悉的cglib和jdk、默认的实现</p>
<p>紧接着进入<code>createAopProxy(this)</code></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/5C1567439888919.png" alt="1567439888919"></p>
<p>是个接口，查看他的默认实现类。</p>
<h3 id="4-DefaultAopProxyFactory-aop代理获取类"><a href="#4-DefaultAopProxyFactory-aop代理获取类" class="headerlink" title="4. DefaultAopProxyFactory aop代理获取类"></a>4. DefaultAopProxyFactory aop代理获取类</h3><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/C1567439971239.png" alt="1567439971239"></p>
<p>可以看到,在这里有我们在注解中设置的参数的判断逻辑,是创建java代理,还是cglib代理，有关cglib的讲解请看<a href="http://www.cnblogs.com/foreveravalon/p/8489907.html" target="_blank" rel="external">cglib的使用</a>.</p>
<p>我们主要看一下JdkDynamicAopProxy的实现，因为我们没有设置<code>@EnableAspectJAutoProxy(proxyTargetClass=true)</code> 所以我们默认使用jdk自带实现。cglib其实差不多。</p>
<h3 id="5-JdkDynamicAopProxy-默认切面代理类"><a href="#5-JdkDynamicAopProxy-默认切面代理类" class="headerlink" title="5. JdkDynamicAopProxy 默认切面代理类"></a>5. JdkDynamicAopProxy 默认切面代理类</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Override</div><div class="line">    public Object getProxy() &#123;</div><div class="line">        return getProxy(ClassUtils.getDefaultClassLoader());</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    @Override</div><div class="line">    public Object getProxy(@Nullable ClassLoader classLoader) &#123;</div><div class="line">        if (logger.isDebugEnabled()) &#123;</div><div class="line">            logger.debug(&quot;Creating JDK dynamic proxy: target source is &quot; + this.advised.getTargetSource());</div><div class="line">        &#125;</div><div class="line">        Class&lt;?&gt;[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true);</div><div class="line">        findDefinedEqualsAndHashCodeMethods(proxiedInterfaces);</div><div class="line">        return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this);</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>findDefinedEqualsAndHashCodeMethods方法是为了查询被代理的接口是否包括equals和hashcode方法，这会影响到下面的调用。</p>
<p>可以看到InvocationHandler的实现就是this。我们看一下invoke方法的实现：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Override</div><div class="line">  @Nullable</div><div class="line">  public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;</div></pre></td></tr></table></figure>
<p>关键代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">// Get the interception chain for this method.</div><div class="line">            List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);</div></pre></td></tr></table></figure>
<p>构建代理链，因为一个方法可能有多个切点匹配上，这个时候就需要构建一个链式的执行结构。</p>
<p>进入<code>getInterceptorsAndDynamicInterceptionAdvice（）</code>方法</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/C1567440444983.png" alt="1567440444983"></p>
<p>这里做了一个缓存，虽然new了一个对象作为key，但是对象的equals和hashcode方法都被重写了，所以没有问题，我们主要来看一下它是如何组装这个链式处理结构的：</p>
<p>进入<code>getInterceptorsAndDynamicInterceptionAdvice（）</code>方法，紧接着发现是一个接口，那么查看他的实现类</p>
<h3 id="6-DefaultAdvisorChainFactory-处理链式切点"><a href="#6-DefaultAdvisorChainFactory-处理链式切点" class="headerlink" title="6.DefaultAdvisorChainFactory 处理链式切点"></a>6.DefaultAdvisorChainFactory 处理链式切点</h3><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/5C1567440624426.png" alt="1567440624426"></p>
<p>可以看到，它会遍历自己的所有切点，那这些advisor是从哪里来的呢：</p>
<p> 还记得最开始,我们说过,AbstractAutoProxyCreator中通过getAdvicesAndAdvisorsForBean方法来装载切面,而这个是一个抽象方法,现在来看它的实现,在AbstractAdvisorAutoProxyCreator中:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Override</div><div class="line">    @Nullable</div><div class="line">    protected Object[] getAdvicesAndAdvisorsForBean(Class&lt;?&gt; beanClass, String beanName, @Nullable TargetSource targetSource) &#123;</div><div class="line">        List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName);</div><div class="line">        if (advisors.isEmpty()) &#123;</div><div class="line">            return DO_NOT_PROXY;</div><div class="line">        &#125;</div><div class="line">        return advisors.toArray();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) &#123;</div><div class="line">        List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors();</div><div class="line">        List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName);</div><div class="line">        extendAdvisors(eligibleAdvisors);</div><div class="line">        if (!eligibleAdvisors.isEmpty()) &#123;</div><div class="line">            eligibleAdvisors = sortAdvisors(eligibleAdvisors);</div><div class="line">        &#125;</div><div class="line">        return eligibleAdvisors;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">findCandidateAdvisors又是一个抽象方法,主要功能就是找到候选的切面,为什么是候选的,因为它是加载了所有的切面,有些切面并不需要,在最底层AnnotationAwareAspectJAutoProxyCreator的实现类中也有:</div><div class="line"></div><div class="line">protected List&lt;Advisor&gt; findCandidateAdvisors() &#123;</div><div class="line">        // Add all the Spring advisors found according to superclass rules.</div><div class="line">        List&lt;Advisor&gt; advisors = super.findCandidateAdvisors();</div><div class="line">        // Build Advisors for all AspectJ aspects in the bean factory.</div><div class="line">        if (this.aspectJAdvisorsBuilder != null) &#123;</div><div class="line">            advisors.addAll(this.aspectJAdvisorsBuilder.buildAspectJAdvisors());</div><div class="line">        &#125;</div><div class="line">        return advisors;</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>可以看到,通过aspectJAdvisorsBuilder来将该类关心的所有的切面装载进来,并添加到父类的集合里面.aspectJAdvisorsBuilder里缓存了advisor的信息,拿到切面后,通过findAdvisorsThatCanApply方法来筛选合适的切面,之后对切面进行排序(如果实现了Order接口),然后返回切面的链表.</p>
<h1 id="8-声明式事务-Transactional注解"><a href="#8-声明式事务-Transactional注解" class="headerlink" title="8.声明式事务@Transactional注解"></a>8.声明式事务@Transactional注解</h1><h2 id="1-前言-1"><a href="#1-前言-1" class="headerlink" title="1.前言"></a>1.前言</h2><pre><code>我们知道spring的事务管理分为两大部分：声明式和编程式，两种方式均为我们提供便捷的事务管理方法，各自优劣。
</code></pre><blockquote>
<p>声明式事务</p>
</blockquote>
<pre><code>声明式的事务管理对业务代码基本0入侵，能够很好的把事务管理和业务代码剥离开来，提高代码扩展性和可读性但是控制的粒度只能是方法级别而且必须是public，同时还不能在一个类中调用等。
</code></pre><blockquote>
<p>编程式事务</p>
</blockquote>
<pre><code>编程式事务则需要通过编写具体的事务代码来获得事务的管理能力，TransactionTemplate，或者直接使用PlatformTransactionManager，好处是控制粒度小，没有太多限制，坏处就是对业务代码有入侵，如果事务需要嵌套或者事务本身很繁琐，使用编程式则会十分麻烦。
</code></pre><p>这里讲述的是声明式事务，因为他比较常用。而且两种方式的源码其实是一样的。</p>
<h2 id="2-环境搭建"><a href="#2-环境搭建" class="headerlink" title="2. 环境搭建"></a>2. 环境搭建</h2><h3 id="1-1导入相关依赖：数据源、数据库驱动、Spring-jdbc模块"><a href="#1-1导入相关依赖：数据源、数据库驱动、Spring-jdbc模块" class="headerlink" title="1.1导入相关依赖：数据源、数据库驱动、Spring-jdbc模块"></a>1.1导入相关依赖：数据源、数据库驱动、Spring-jdbc模块</h3><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417823342.png" alt="1567417823342"></p>
<h3 id="1-2配置数据源、JdbcTemplate（Spring提供简化数据库操作的工具）操作数据"><a href="#1-2配置数据源、JdbcTemplate（Spring提供简化数据库操作的工具）操作数据" class="headerlink" title="1.2配置数据源、JdbcTemplate（Spring提供简化数据库操作的工具）操作数据"></a>1.2配置数据源、JdbcTemplate（Spring提供简化数据库操作的工具）操作数据</h3><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417832614.png" alt="1567417832614"></p>
<h3 id="1-3新建PersonDao、PersonService"><a href="#1-3新建PersonDao、PersonService" class="headerlink" title="1.3新建PersonDao、PersonService"></a>1.3新建PersonDao、PersonService</h3><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417847101.png" alt="1567417847101"></p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417852548.png" alt="1567417852548"></p>
<h3 id="1-4-测试"><a href="#1-4-测试" class="headerlink" title="1.4 测试"></a>1.4 测试</h3><p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417897324.png" alt="1567417897324"></p>
<p>插入成功</p>
<h3 id="1-5-测试事务"><a href="#1-5-测试事务" class="headerlink" title="1.5 测试事务"></a>1.5 测试事务</h3><p>修改Service方法，故意暴露一个异常</p>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417910208.png" alt="1567417910208"></p>
<p>我们运行测试，发现还是插入成功，那么怎么阻止这种行为呢？添加事务</p>
<h3 id="1-6-添加事务"><a href="#1-6-添加事务" class="headerlink" title="1.6 添加事务"></a>1.6 添加事务</h3><ol>
<li>给insertUser方法添加注解- @Transactional</li>
</ol>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417923873.png" alt="1567417923873"></p>
<ol>
<li><p>@EnableTransactionManagement 开启基于注解的事务管理功能</p>
</li>
<li><p>配置事务管理器来控制事务</p>
</li>
</ol>
<p><img src="/2019/03/14/spring注解-辅助学习springboot和springcloud/1567417943208.png" alt="1567417943208"></p>
<p>事务添加成功</p>
<h3 id="1-8-再次运行测试"><a href="#1-8-再次运行测试" class="headerlink" title="1.8 再次运行测试"></a>1.8 再次运行测试</h3><p>发现插入失败，满足事务的原子性。</p>
<h3 id="1-7-源码分析"><a href="#1-7-源码分析" class="headerlink" title="1.7 源码分析"></a>1.7 源码分析</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">声明式事务：</div><div class="line"> </div><div class="line">环境搭建：</div><div class="line">1、导入相关依赖</div><div class="line">		数据源、数据库驱动、Spring-jdbc模块</div><div class="line">2、配置数据源、JdbcTemplate（Spring提供的简化数据库操作的工具）操作数据</div><div class="line">3、给方法上标注 @Transactional 表示当前方法是一个事务方法；</div><div class="line">4、 @EnableTransactionManagement 开启基于注解的事务管理功能；</div><div class="line">		@EnableXXX</div><div class="line">5、配置事务管理器来控制事务;</div><div class="line">		@Bean</div><div class="line">		public PlatformTransactionManager transactionManager()</div><div class="line"> </div><div class="line"> </div><div class="line">原理：</div><div class="line">1）、@EnableTransactionManagement</div><div class="line">			利用TransactionManagementConfigurationSelector给容器中会导入组件</div><div class="line">			导入两个组件</div><div class="line">			AutoProxyRegistrar</div><div class="line">			ProxyTransactionManagementConfiguration</div><div class="line">2）、AutoProxyRegistrar：</div><div class="line">			给容器中注册一个 InfrastructureAdvisorAutoProxyCreator 组件；</div><div class="line">			InfrastructureAdvisorAutoProxyCreator：？</div><div class="line">			利用后置处理器机制在对象创建以后，包装对象，返回一个代理对象（增强器），代理对象执行方法利用拦截器链进行调用；</div><div class="line"> </div><div class="line">3）、ProxyTransactionManagementConfiguration 做了什么？</div><div class="line">			1、给容器中注册事务增强器；</div><div class="line">				1）、事务增强器要用事务注解的信息，AnnotationTransactionAttributeSource解析事务注解</div><div class="line">				2）、事务拦截器：</div><div class="line">					TransactionInterceptor；保存了事务属性信息，事务管理器；</div><div class="line">					他是一个 MethodInterceptor；</div><div class="line">					在目标方法执行的时候；</div><div class="line">						执行拦截器链；</div><div class="line">						事务拦截器：</div><div class="line">							1）、先获取事务相关的属性</div><div class="line">							2）、再获取PlatformTransactionManager，如果事先没有添加指定任何transactionmanger</div><div class="line">								最终会从容器中按照类型获取一个PlatformTransactionManager；</div><div class="line">							3）、执行目标方法</div><div class="line">								如果异常，获取到事务管理器，利用事务管理回滚操作；</div><div class="line">								如果正常，利用事务管理器，提交事务</div></pre></td></tr></table></figure>
<h2 id="3-源码深入分析"><a href="#3-源码深入分析" class="headerlink" title="3.源码深入分析"></a>3.源码深入分析</h2><p>未完待续</p>
<h1 id="9-总结"><a href="#9-总结" class="headerlink" title="9 总结"></a>9 总结</h1><p>通过使用AOP和声明式事务，我们知道了一个套路，如果我们想使用某项功能，例如上面的aop和声明式事务、或者以后的springcloud的eureka、zull、feign等等功能，都遵循一下三点：</p>
<blockquote>
<p>1.导入功能组件相关的依赖</p>
<p>2.在配置类开启组件（@EnableXXXX）</p>
<p>3.在关键位置标示使用的地方（例如@Aspect、@Transactional）</p>
</blockquote>
<p>所以以后需要在spring中使用某个组件，一般都是遵循这样的思路</p>
<p># </p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-前言&quot;&gt;&lt;a href=&quot;#1-前言&quot; class=&quot;headerlink&quot; title=&quot;1. 前言&quot;&gt;&lt;/a&gt;1. 前言&lt;/h1&gt;&lt;p&gt; 因为后面要学习sb（springboot）和sc（springcloud），所以需要学习一些相关的注解和了解他们底层代
    
    </summary>
    
      <category term="spring注解和生命周期" scheme="http://kingge.top/categories/spring%E6%B3%A8%E8%A7%A3%E5%92%8C%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"/>
    
    
      <category term="spring注解" scheme="http://kingge.top/tags/spring%E6%B3%A8%E8%A7%A3/"/>
    
      <category term="aop" scheme="http://kingge.top/tags/aop/"/>
    
      <category term="spring生命周期" scheme="http://kingge.top/tags/spring%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"/>
    
  </entry>
  
  <entry>
    <title>持续集成技术总结</title>
    <link href="http://kingge.top/2019/03/08/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/"/>
    <id>http://kingge.top/2019/03/08/持续集成技术总结/</id>
    <published>2019-03-08T15:59:59.000Z</published>
    <updated>2019-08-25T04:37:53.613Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、DockerMaven插件的使用"><a href="#一、DockerMaven插件的使用" class="headerlink" title="一、DockerMaven插件的使用"></a>一、DockerMaven插件的使用</h1><p>这个插件的目的就是，能够把本地项目远程打包到docker，并生成相应的镜像。</p>
<p>微服务部署有两种方法：</p>
<p>（1）手动部署：首先基于源码打包生成jar包（或war包）,将jar包（或war包）上传至虚 拟机并拷贝至JDK容器。</p>
<p>（2）通过Maven插件自动部署。</p>
<p>对于数量众多的微服务，手动部署无疑是非常麻烦的做法，并且容易出错。所以我们这 里学习如何自动部署，这也是企业实际开发中经常使用的方法</p>
<p> 而且使用dockermaven插件自动部署项目，有两种方式，一种是编写Dockerfile方式，一种是纯xml方式。第一种方式在本人的总结的《Docker总结》第十二章有写到。下面的案例主要是讲解通过xml的方式部署项目。</p>
<p>  <strong>其实他们本质上是一样的</strong></p>
<h2 id="Maven插件自动部署步骤："><a href="#Maven插件自动部署步骤：" class="headerlink" title="Maven插件自动部署步骤："></a>Maven插件自动部署步骤：</h2><p>（1）修改宿主机的docker配置，让其可以远程访问</p>
<p>Vi  /lib/systemd/system/docker.service</p>
<p>其中ExecStart=后添加配置</p>
<p> ‐H tcp://0.0.0.0:2375 ‐H unix:///var/run/docker.sock</p>
<p>修改后如下：</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image002.jpg" alt="img"></p>
<p>（2）刷新配置，重启服务</p>
<p>systemctl daemon‐reload </p>
<p> systemctl restart docker </p>
<p> docker start registry</p>
<p>   注意：这里的registry是本人新建的本地仓库（怎么新建本地仓库以及怎么使用，参见docker的文章）-当然你也可以把镜像提交到阿里云镜像仓库中。</p>
<p><strong>使用SpringBoot2.0+DockerFile+Maven插件构建镜像并推送到阿里云仓库</strong></p>
<p><strong><a href="https://blog.csdn.net/haogexiang9700/article/details/88318867" target="_blank" rel="external">https://blog.csdn.net/haogexiang9700/article/details/88318867</a></strong></p>
<p>（3）在工程pom.xml 增加配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;build&gt;         </div><div class="line">&lt;finalName&gt;app&lt;/finalName&gt;         </div><div class="line">&lt;plugins&gt;            </div><div class="line"> &lt;plugin&gt;</div><div class="line">&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                 </div><div class="line">&lt;artifactId&gt;spring‐boot‐maven‐plugin&lt;/artifactId&gt;             </div><div class="line">&lt;/plugin&gt;</div><div class="line"> &lt;plugin&gt;                 </div><div class="line">&lt;groupId&gt;com.spotify&lt;/groupId&gt;                 </div><div class="line">&lt;artifactId&gt;docker‐maven‐plugin&lt;/artifactId&gt;                 </div><div class="line">&lt;version&gt;0.4.13&lt;/version&gt;                 </div><div class="line">&lt;configuration&gt;</div><div class="line">&lt;imageName&gt;192.168.1.105:5000/$&#123;project.artifactId&#125;:$&#123;project.version&#125; &lt;/imageName&gt;</div><div class="line">&lt;baseImage&gt;jdk1.8&lt;/baseImage&gt;                     </div><div class="line">&lt;entryPoint&gt;[&quot;java&quot;, &quot;‐jar&quot;,  &quot;/$&#123;project.build.finalName&#125;.jar&quot;]</div><div class="line">&lt;/entryPoint&gt;                     </div><div class="line">&lt;resources&gt;</div><div class="line"> &lt;resource&gt;</div><div class="line"> &lt;targetPath&gt;/&lt;/targetPath&gt;                             </div><div class="line">&lt;directory&gt;$&#123;project.build.directory&#125; &lt;/directory&gt;</div><div class="line">&lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt;                         </div><div class="line">&lt;/resource&gt;                     </div><div class="line">&lt;/resources&gt;                     </div><div class="line">&lt;dockerHost&gt;http://192.168.1.105:2375&lt;/dockerHost&gt;                 </div><div class="line">&lt;/configuration&gt;            </div><div class="line"> &lt;/plugin&gt;         </div><div class="line">&lt;/plugins&gt;     </div><div class="line">&lt;/build&gt;</div></pre></td></tr></table></figure>
   <build>            <finalname>app</finalname>              <plugins>                  <plugin>   <groupid>org.springframework.boot</groupid>                      <artifactid>spring‐boot‐maven‐plugin</artifactid>                  </plugin>    <plugin>                      <groupid>com.spotify</groupid>                      <artifactid>docker‐maven‐plugin</artifactid>                      <version>0.4.13</version>                      <configuration>   <imagename>192.168.1.105:5000/${project.artifactId}:${project.version}   </imagename>   <baseimage>jdk1.8</baseimage>                          <entrypoint>[“java”, “‐jar”,    “/${project.build.finalName}.jar”]   </entrypoint>                          <resources>    <resource>    <targetpath>/</targetpath>                                  <directory>${project.build.directory}   </directory>   <include>${project.build.finalName}.jar</include>                              </resource>                          </resources>                          <dockerhost><a href="http://192.168.1.105:2375" target="_blank" rel="external">http://192.168.1.105:2375</a></dockerhost>                      </configuration>                  </plugin>              </plugins>          </build>   

<p>以上配置会自动生成Dockerfile</p>
<p>   FROM jdk1.8     ADD app.jar /     ENTRYPOINT [“java”,”‐jar”,”/app.jar”]   </p>
<p>创建一个镜像，继承自jdk1.8，同时拷贝本地的app.jar到镜像的根目录。在容器启动时，执行java –jar /app.jar(也就是启动项目)</p>
<p>（4）在windows的命令提示符下，进入工程app所在的目录，进行打包和上传镜像</p>
<p>mvn install</p>
<p>mvn docker:build  ‐DpushImage</p>
<p>执行后，会有如下输出，代码正在上传</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image004.jpg" alt="img"></p>
<p>（6）进入宿主机 , 查看镜像</p>
<pre><code>Docker images
</code></pre><p><img src="/2019/03/08/持续集成技术总结/clip_image006.jpg" alt="img"></p>
<p>（7）启动容器</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image008.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image009.png" alt="img"></p>
<p>访问成功！！！</p>
<h1 id="二、持续集成工具Jenkins"><a href="#二、持续集成工具Jenkins" class="headerlink" title="二、持续集成工具Jenkins"></a>二、持续集成工具Jenkins</h1><p>官网：<a href="https://jenkins.io/zh/doc/tutorials/build-a-java-app-with-maven/" target="_blank" rel="external">https://jenkins.io/zh/doc/tutorials/build-a-java-app-with-maven/</a></p>
<p>主要是解决自动化构建项目，发布项目等等问题。</p>
<p>微服务架构下，带来了运维上的额外复杂性，尤其是在服务部署和服务监控上。单体应用是集中式的，就一个单体跑在一起，部署和管理的时候非常简单。而微服务是一个网状分布的，有很多服务需要维护和管理，对它进行部署和维护的时候则比较复杂，所以就需要一个工具能够自动化的完成自动编译、发布和测试，从而尽快地发现集成错误，让团队能够更快的开发内聚的软件。</p>
<pre><code>**持续集成具有的特点：**
</code></pre><p>它是一个自动化的周期性的集成测试过程，从检出代码、编译构建、运行测试、结果 记录、测试统计等都是自动完成的，无需人工干预； </p>
<p>需要有专门的集成服务器来执行集成构建； </p>
<p>需要有代码托管工具支持，我们下一小节将介绍Git以及可视化界面Gogs的使用</p>
<p><strong>持续集成的作用：</strong></p>
<p>保证团队开发人员提交代码的质量，减轻了软件发布时的压力； </p>
<p>持续集成中的任何一个环节都是自动完成的，无需太多的人工干预，有利于减少重复 过程以节省时间、费用和工作量；</p>
<p><strong>基本思路：</strong></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image011.jpg" alt="https://www.centos.bz/wp-content/uploads/2017/11/1-17.jpg"></p>
<h2 id="1-Jenkins简介"><a href="#1-Jenkins简介" class="headerlink" title="1.Jenkins简介"></a>1.Jenkins简介</h2><p> Jenkins，原名Hudson，2011年改为现在的名字，它 是一个开源的实现持续集成的 软件工具。官方网站：<a href="http://jenkins-ci.org/。" target="_blank" rel="external">http://jenkins-ci.org/。</a></p>
<p> Jenkins 能实施监控集成中存在的错误，提供详细的日志文件和提醒功能，还能用图 表的形式形象地展示项目构建的趋势和稳定性。</p>
<p> <strong>特点：</strong> </p>
<p><strong>易安装：</strong>仅仅一个 java -jar jenkins.war，从官网下载该文件后，直接运行，无需额 外的安装，更无需安装数据库； </p>
<p><strong>易配置：</strong>提供友好的GUI配置界面； </p>
<p><strong>变更支持：</strong>Jenkins能从代码仓库（Subversion/CVS）中获取并产生代码更新列表并 输出到编译输出信息中； </p>
<p><strong>支持永久链接：</strong>用户是通过web来访问Jenkins的，而这些web页面的链接地址都是 永久链接地址，因此，你可以在各种文档中直接使用该链接； </p>
<p><strong>集成E-Mail/RSS/IM：</strong>当完成一次集成时，可通过这些工具实时告诉你集成结果（据 我所知，构建一次集成需要花费一定时间，有了这个功能，你就可以在等待结果过程 中，干别的事情）；</p>
<p> <strong>JUnit/TestNG**</strong>测试报告：**也就是用以图表等形式提供详细的测试报表功能； </p>
<p><strong>支持分布式构建：</strong>Jenkins可以把集成构建等工作分发到多台计算机中完成； </p>
<p><strong>文件指纹信息：</strong>Jenkins会保存哪次集成构建产生了哪些jars文件，哪一次集成构建使 用了哪个版本的jars文件等构建记录； </p>
<p><strong>支持第三方插件：</strong>使得 Jenkins 变得越来越强大</p>
<h2 id="2-Jenkins安装"><a href="#2-Jenkins安装" class="headerlink" title="2. Jenkins安装"></a>2. Jenkins安装</h2><p>资源准备</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image013.jpg" alt="img"></p>
<p>当然你可以通过wget命令进行下载相应的rpm包</p>
<h3 id="2-1-JDK安装"><a href="#2-1-JDK安装" class="headerlink" title="2.1 JDK安装"></a>2.1 JDK安装</h3><p>（1）将jdk-8u171-linux-x64.rpm上传至服务器（虚拟机）</p>
<p>（2）执行安装命令</p>
<p>rpm ‐ivh jdk‐8u171‐linux‐x64.rpm</p>
<p>（3）查看是否安装成功</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image014.png" alt="img"></p>
<pre><code>因为rpm包已经自动为我们做了相关的环境变量配置，所以不需要额外配置（相关的命令在 /usr/bin）
</code></pre><h3 id="2-2-maven安装"><a href="#2-2-maven安装" class="headerlink" title="2.2 maven安装"></a>2.2 maven安装</h3><p>（1）将 apache‐maven‐3.5.4‐bin.tar.gz上传至服务器（虚拟机）</p>
<p>（2）解压</p>
<p>tar zxvf apache‐maven‐3.5.4‐bin.tar.gz</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image016.jpg" alt="img"></p>
<p>（3））编辑setting.xml配置文件</p>
<p>vi /opt/software/apache-maven-3.5.4/conf/settings.xml</p>
<p>   增加如下配置</p>
<localrepository>/opt/software/mavenRepostory</localrepository>



<p>（4）将开发环境（win10）的本地仓库上传至服务器（虚拟机）并移动到/opt/software/mavenRepostory</p>
<p>执行此步是为了以后在打包的时候不必重新下载，缩短打包的时间  </p>
<h3 id="2-3-Jenkins安装与启动"><a href="#2-3-Jenkins安装与启动" class="headerlink" title="2.3 Jenkins安装与启动"></a>2.3 Jenkins安装与启动</h3><p><strong>在安装jenkins之前必须要安装jdk。</strong></p>
<p>（1）下载jenkins</p>
<p>wget <a href="https://pkg.jenkins.io/redhat/jenkins‐2.83‐1.1.noarch.rpm" target="_blank" rel="external">https://pkg.jenkins.io/redhat/jenkins‐2.83‐1.1.noarch.rpm</a></p>
<p>或将应下载好的jenkins-2.83-1.1.noarch.rpm上传至服务器</p>
<p><a href="https://pkg.jenkins.io/redhat-stable/" target="_blank" rel="external">https://pkg.jenkins.io/redhat-stable/</a> 官网下载（建议下载最新版本，避免安装插件时报错 jenkins-2.187-1.1.noarch.rpm）</p>
<p>（2）安装jenkins</p>
<p>rpm ‐ivh jenkins‐2.83‐1.1.noarch.rpm</p>
<p><strong>自动安装完成之后：</strong> </p>
<p><strong>/usr/lib/jenkins/jenkins.war    WAR**</strong>包** </p>
<p><strong>/etc/sysconfig/jenkins</strong>       <strong>配置文件</strong></p>
<p><strong>/var/lib/jenkins/</strong>       <strong>默认的JENKINS_HOME目录</strong></p>
<p><strong>/var/log/jenkins/jenkins.log    Jenkins**</strong>日志文件**</p>
<p>（3）配置jenkins</p>
<p>vi /etc/sysconfig/jenkins</p>
<p>修改用户和端口</p>
<p>JENKINS_USER=”root”  JENKINS_PORT=”8888”</p>
<p>（4）启动服务</p>
<p>systemctl start Jenkins</p>
<p>（5）访问链接 <a href="http://49.234.188.74:8888" target="_blank" rel="external">http://49.234.188.74:8888</a></p>
<p>从/var/lib/jenkins/secrets/initialAdminPassword中获取初始密码串</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image018.jpg" alt="img"></p>
<p>（6）安装插件</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image020.jpg" alt="img"></p>
<p>选择推荐安装，避免漏掉一些jenkins必须依赖的插件，后面有额外需要的插件我们还可以手动安装</p>
<p>安装插件中</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image022.jpg" alt="img"></p>
<p><strong>需要注意的是，在安装插件的可能会失败，一般是因为当前jenkins版本太低的原因，可以先忽略错误，进去后更新jenkins为新的版本，插件自己会自动安装成功。</strong></p>
<p>（7）新建用户</p>
<p>完成安装进入主界面</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image024.jpg" alt="img"></p>
<h2 id="3-Jenkins插件安装"><a href="#3-Jenkins插件安装" class="headerlink" title="3. Jenkins插件安装"></a>3. Jenkins插件安装</h2><p>我们以安装maven插件为例，演示插件的安装</p>
<p>（1）点击左侧的“系统管理”菜单 ,然后点点击</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image026.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image028.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image030.jpg" alt="img"></p>
<h2 id="4-全局工具配置"><a href="#4-全局工具配置" class="headerlink" title="4.全局工具配置"></a>4.全局工具配置</h2><p>选择系统管理，全局工具配置</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image032.jpg" alt="img"></p>
<p>（1）JDK配置</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image034.jpg" alt="img"></p>
<p>设置javahome为 /usr/java/jdk1.8.0_171-amd64</p>
<p>（2）Git配置   （本地已经安装了Git软件）</p>
<p>   如果linux 没有安装过git。那么可以参考 《额外补充》第三章节进行安装。</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image036.jpg" alt="img"></p>
<p>如果不知道本地git的地址可以使用命令：whereis git 获取地址。</p>
<p>  默认在启动jenkins时，应安装好了git插件</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image038.jpg" alt="img"></p>
<p>（3）Maven配置</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image040.jpg" alt="img"></p>
<p>然后保存即可，接下来上传代码到git，然后创建任务。</p>
<h2 id="5-代码上传至Git服务器"><a href="#5-代码上传至Git服务器" class="headerlink" title="5 代码上传至Git服务器"></a>5 代码上传至Git服务器</h2><h3 id="5-1-Gogs搭建与配置"><a href="#5-1-Gogs搭建与配置" class="headerlink" title="5.1 Gogs搭建与配置"></a>5.1 Gogs搭建与配置</h3><p>Gogs 是一款极易搭建的自助 Git 服务。</p>
<p>Gogs 的目标是打造一个最简单、最快速和最轻松的方式搭建自助 Git 服务。使用 Go 语 言开发使得 Gogs 能够通过独立的二进制分发，并且支持 Go 语言支持的 所有平台，包 括 Linux、Mac OS X、Windows 以及 ARM 平台</p>
<p>地址：<a href="https://gitee.com/Unknown/gogs" target="_blank" rel="external">https://gitee.com/Unknown/gogs</a></p>
<p>（1）下载镜像</p>
<p>docker pull gogs/gogs</p>
<p>（2）创建容器</p>
<p>  docker run -d -p 10022:22 -p 10080:3000 \ </p>
<p>–name=gogs \</p>
<p>-v /opt/docker/gogs/:/data \ </p>
<p>gogs/gogs</p>
<p>（3）安装gogs</p>
<p>在地址栏输入 <a href="http://49.234.188.74:3000/" target="_blank" rel="external">http://49.234.188.74: 10080/</a>，会进入首次运行安装程序页面，我们可以选择一种数据 库作为gogs数据的存储，最简单的是选择SQLite3。如果对于规模较大的公司，可以选择 MySQL  </p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image042.jpg" alt="img"></p>
<p>点击“立即安装”</p>
<p>这里的域名要设置为centos的IP地址,安装后显示主界面</p>
<p>（4）注册</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image044.jpg" alt="img"></p>
<p>（5）登录</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image046.jpg" alt="img"></p>
<p>登陆后</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image048.jpg" alt="img"></p>
<p>（6）创建仓库 </p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image050.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image052.jpg" alt="img"></p>
<h3 id="5-2-提交代码到git"><a href="#5-2-提交代码到git" class="headerlink" title="5.2 提交代码到git"></a>5.2 提交代码到git</h3><p>步骤：</p>
<p>（1）在本地安装git(Windows版本)</p>
<p>（2）在IDEA中选择菜单 :  File – settings ,  在窗口中选择Version Control –  Gi</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image054.jpg" alt="img"></p>
<p>（3）选择菜单VCS  –&gt; Enable Version Control Integration</p>
<p>（4）设置远程地址:  右键点击工程选择菜单    Git –&gt; Repository   –&gt;Remotes…</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image056.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image057.png" alt="img"></p>
<p>url填写我们之前用gogs创建的git仓库：<a href="http://49.234.188.74:10080/root/kingge.git" target="_blank" rel="external">http://49.234.188.74:10080/root/kingge.git</a></p>
<p>（5）右键点击工程选择菜单    Git –&gt; Add </p>
<p>（6）右键点击工程选择菜单    Git –&gt; Commit Directory…</p>
<p>（7）右键点击工程选择菜单    Git –&gt; Repository   –&gt; Push …</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image059.jpg" alt="img"></p>
<h2 id="6-jenkins任务的创建与执行"><a href="#6-jenkins任务的创建与执行" class="headerlink" title="6 jenkins任务的创建与执行"></a>6 jenkins任务的创建与执行</h2><p>（1）回到首页，点击新建按钮 .如下图，输入名称，选择创建一个Maven项目，点击OK</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image061.jpg" alt="img"></p>
<p>（2）源码管理，选择Git</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image063.jpg" alt="img"></p>
<p>（3）填写构建语句</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image065.jpg" alt="img"></p>
<p>clean package docker:build ‐DpushImage</p>
<p>（4）查看项目</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image067.jpg" alt="img"></p>
<p>我们点击执行后，可以看到左下角出现这个任务进度</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image068.png" alt="img"></p>
<p>这样就能够上传成功了</p>
<h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7.总结"></a>7.总结</h2><p>通过jenkins，我们可以很好的集成、部署了我们开发的项目，自动构建项目的镜像，这样为我们节省了很多的时间。</p>
<h1 id="三、容器管理工具Rancher"><a href="#三、容器管理工具Rancher" class="headerlink" title="三、容器管理工具Rancher"></a>三、容器管理工具Rancher</h1><p>管理docker和Kubernetes容器，通过可视化界面的方式，管理，部署，启动docker容器，同时支持分布式集群部署docekr容器。</p>
<h2 id="1-安装Rancher"><a href="#1-安装Rancher" class="headerlink" title="1.安装Rancher"></a>1.安装Rancher</h2><p>Rancher是一个开源的企业级全栈化容器部署及管理平台。Rancher为容器提供一揽 子基础架构服务：CNI兼容的网络服务、存储服务、主机管理、负载均衡、防护墙…… Rancher让上述服务跨越公有云、私有云、虚拟机、物理机环境运行，真正实现一键式应 用部署和管理</p>
<p><a href="https://www.cnrancher.com/" target="_blank" rel="external">https://www.cnrancher.com/</a> </p>
<p>（1）下载Rancher 镜像</p>
<p>docker pull rancher/server</p>
<p>（2）创建Rancher容器</p>
<p>docker run ‐di ‐‐name=rancher ‐p 9090:8080 rancher/server</p>
<p>（3）在浏览器输入地址： <a href="http://192.168.184.136:9090" target="_blank" rel="external">http://192.168.184.136:9090</a>  </p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image070.jpg" alt="img"></p>
<h2 id="2-初始化Rancher"><a href="#2-初始化Rancher" class="headerlink" title="2.初始化Rancher"></a>2.初始化Rancher</h2><h3 id="2-1-添加环境"><a href="#2-1-添加环境" class="headerlink" title="2.1 添加环境"></a>2.1 添加环境</h3><p>Rancher 支持将资源分组归属到多个环境。 每个环境具有自己独立的基础架构资源及服 务，并由一个或多个用户、团队或组织所管理。</p>
<p>例如，您可以创建独立的“开发”、“测试”及“生产”环境以确保环境之间的安全隔离，将“开 发”环境的访问权限赋予全部人员，但限制“生产”环境的访问权限给一个小的团队。</p>
<p>（1）     选择“Default –&gt;环境管理” 菜单</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image071.png" alt="img"></p>
<p>（2）填写名称，点击“创建”按钮</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image073.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image075.jpg" alt="img"></p>
<p>可以添加多个环境，分别给区分不同用户使用场景</p>
<p>（4））你可以通过点击logo右侧的菜单在各种环境下切换</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image076.png" alt="img"></p>
<h3 id="2-2-添加主机"><a href="#2-2-添加主机" class="headerlink" title="2.2 添加主机"></a>2.2 添加主机</h3><p>（1）选择基础架构–&gt;主机 菜单，点击添加主机</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image078.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image080.jpg" alt="img"></p>
<p>直接保存，当然你也可以选择其他主机（管理非当前服务器）</p>
<p>（2）拷贝脚本，主机和rancher服务建立连接</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image082.jpg" alt="img"></p>
<p>（3）在主机上运行脚本</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image084.jpg" alt="img"></p>
<p>（4）点击关闭按钮后，会看到界面中显示此主机。我们可以很方便地管理主机的每个容 器的开启和关闭</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image085.png" alt="img"></p>
<p>在这里可以看到当前主机下，已经创建好的容器</p>
<h3 id="2-3-添加应用"><a href="#2-3-添加应用" class="headerlink" title="2.3 添加应用"></a>2.3 添加应用</h3><p>（1）点击应用–&gt;全部(或用户)  ，点击“添加应用”按钮</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image086.png" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image088.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image090.jpg" alt="img"></p>
<p>应用是多个服务的载体。例如一个mysql容器就是一个服务，它提供数据库服务。例如redis也是一个服务等等。</p>
<h3 id="2-4-添加服务"><a href="#2-4-添加服务" class="headerlink" title="2.4 添加服务"></a>2.4 添加服务</h3><p><strong>相对于docker而言，添加一个服务就等同于创建一个容器</strong></p>
<h4 id="2-4-1-添加mysql服务"><a href="#2-4-1-添加mysql服务" class="headerlink" title="2.4.1 添加mysql服务"></a>2.4.1 添加mysql服务</h4><p>镜像：mysql:latest   增加mysql数据库服务</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image092.jpg" alt="img"></p>
<p>打开我们在2.3节创建的应用，然后点击创建服务</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image094.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image096.jpg" alt="img"></p>
<p>点击创建按钮，完成创建。上述操作相当于以下docker命令</p>
<p>docker run ‐di ‐‐name mysql ‐p 3306:3306 ‐e MYSQL_ROOT_PASSWORD=123456  mysql:latest</p>
<p>创建中</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image098.jpg" alt="img"></p>
<p>创建完毕</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image100.jpg" alt="img"></p>
<h4 id="2-4-2-添加RabbitMQ服务"><a href="#2-4-2-添加RabbitMQ服务" class="headerlink" title="2.4.2 添加RabbitMQ服务"></a>2.4.2 添加RabbitMQ服务</h4><p>镜像：rabbitmq:management     端口映射5671   5672  4369    15671  15672  25672</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image102.jpg" alt="img"></p>
<h4 id="2-4-3-Redis服务"><a href="#2-4-3-Redis服务" class="headerlink" title="2.4.3 Redis服务"></a>2.4.3 Redis服务</h4><p><img src="/2019/03/08/持续集成技术总结/clip_image104.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image106.jpg" alt="img"></p>
<h4 id="2-5-部署我们在第一章节dockermaven构建的app容器"><a href="#2-5-部署我们在第一章节dockermaven构建的app容器" class="headerlink" title="2.5 部署我们在第一章节dockermaven构建的app容器"></a>2.5 部署我们在第一章节dockermaven构建的app容器</h4><p><img src="/2019/03/08/持续集成技术总结/clip_image108.jpg" alt="img"></p>
<p>开始部署服务</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image110.jpg" alt="img"></p>
<p>点击创建部署中</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image112.jpg" alt="img"></p>
<p>创建成功</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image114.jpg" alt="img"></p>
<p>访问</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image115.png" alt="img"></p>
<h2 id="3-rancher的扩容与缩容"><a href="#3-rancher的扩容与缩容" class="headerlink" title="3. rancher的扩容与缩容"></a>3. rancher的扩容与缩容</h2><p>就是对某个服务（容器）进行数量的增加或者减少，因为我们知道大型的项目一个服务是部署到多台服务器的，构建成一个服务集群，是为了应变访问量的高低。所以rancher也是提供了这种功能。</p>
<p> 一下例子，以我们在上面构建的app服务为例子。</p>
<p>（1）部署app服务，不指定端口</p>
<p>  这里为什么不指定端口，因为假设我们把服务扩容到两台，那么端口号就会冲突，所以这里让docker为我们默认分配端口。</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image117.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image119.jpg" alt="img"></p>
<p>（2）在选择菜单API  –&gt;WebHooks  ，点击“添加接收器”按钮</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image121.jpg" alt="img"></p>
<p>（3）填写名称等信息，选择要扩容的服务，点击创建按钮</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image123.jpg" alt="img"></p>
<p>创建成功</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image125.jpg" alt="img"></p>
<p>提供了一个触发扩容操作的url</p>
<p><a href="http://192.168.1.105:9090/v1-webhooks/endpoint?key=ctm3rFpH6oAsbOA5mXMHvZyW7BoCkz1QQgpw00ay&amp;projectId=1a5" target="_blank" rel="external">http://192.168.1.105:9090/v1-webhooks/endpoint?key=ctm3rFpH6oAsbOA5mXMHvZyW7BoCkz1QQgpw00ay&amp;projectId=1a5</a></p>
<p>（4）测试扩容服务</p>
<p>必须使用post的方式，触发上面提供的url</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image127.jpg" alt="img"></p>
<p>在触发之前，我们先查看一下app服务的数量</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image129.jpg" alt="img"></p>
<p>是一个</p>
<p>开始触发</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image131.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image133.jpg" alt="img"></p>
<p>扩容成功，数量变成了3</p>
<p>那么这个时候，我么你会有个疑问，我们怎么访问这些服务呢？这些服务并没有提供对外暴露的端口？</p>
<p> 答案是：采用创建负载均衡服务的方式访问</p>
<h2 id="4-负载均衡"><a href="#4-负载均衡" class="headerlink" title="4.负载均衡"></a>4.负载均衡</h2><p>（1）创建负载均衡服务  </p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image135.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image137.jpg" alt="img"></p>
<p>创建负载均衡服务中</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image139.jpg" alt="img"></p>
<p>创建成功</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image141.jpg" alt="img"></p>
<p>尝试访问</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image143.jpg" alt="img"></p>
<p>访问成功，他会通过轮询的方式访问这三台容器。</p>
<h1 id="四、时间序列数据库influxDB"><a href="#四、时间序列数据库influxDB" class="headerlink" title="四、时间序列数据库influxDB"></a>四、时间序列数据库influxDB</h1><p>他主要是用来存储一些实时的数据，例如下面我们将会学习的cAdvisor，监控容器的内存相关的信息，就是存储在influDB中。记住他并不是用来存储大量数据的，不是mysql这样类型的数据库。</p>
<h2 id="1-什么是influxDB"><a href="#1-什么是influxDB" class="headerlink" title="1. 什么是influxDB"></a>1. 什么是influxDB</h2><p> influxDB是一个分布式时间序列数据库。cAdvisor仅仅显示实时信息，但是不存储 监视数据。因此，我们需要提供时序数据库用于存储cAdvisor组件所提供的监控信息， 以便显示除实时信息之外的时序数据。 </p>
<h2 id="2-influxDB安装"><a href="#2-influxDB安装" class="headerlink" title="2 influxDB安装"></a>2 influxDB安装</h2><p>（1）下载镜像</p>
<p>docker pull tutum/influxdb</p>
<p>（2）创建容器</p>
<p>docker run ‐di \     </p>
<p>‐p 8083:8083 \     </p>
<p>‐p 8086:8086 \     </p>
<p>‐‐expose 8090 \     </p>
<p>‐‐expose 8099 \     </p>
<p>‐‐name influxsrv \     </p>
<p>tutum/influxdb</p>
<p>端口概述：  8083端口:web访问端口     8086:数据写入端口 （<strong>后面启动adviosr的时候会用到</strong>）</p>
<p>docker run -di -p 8083:8083 -p 8086:8086 –expose 8090 –expose 8099 –name influxsrv tutum/influxdb</p>
<p>打开浏览器   <a href="http://192.168.1.105:8083/" target="_blank" rel="external">http://192.168.1.105:8083/</a></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image145.jpg" alt="img"></p>
<h2 id="3-influxDB常用操作"><a href="#3-influxDB常用操作" class="headerlink" title="3 influxDB常用操作"></a>3 influxDB常用操作</h2><p>3.1 创建数据库 </p>
<p>CREATE DATABASE “cadvisor”</p>
<p>回车创建数据库</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image147.jpg" alt="img"></p>
<p>查看数据库 </p>
<p>SHOW DATABASES</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image149.jpg" alt="img"></p>
<p>3.2 创建用户并授权 </p>
<p>创建用户</p>
<p>CREATE USER “cadvisor” WITH PASSWORD ‘cadvisor’ WITH ALL PRIVILEGES</p>
<p>查看用户</p>
<p>SHOW USRES</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image151.jpg" alt="img"></p>
<p>用户授权</p>
<p>grant all privileges on cadvisor to cadvisor  （on后面跟的是数据库名，to后面跟的是 用户名）</p>
<p>grant WRITE on cadvisor to cadvisor  </p>
<p>grant READ on cadvisor to cadvisor</p>
<p>3.3 查看采集的数据 </p>
<p>切换到cadvisor数据库，使用以下命令查看采集的数据</p>
<p>SHOW MEASUREMENTS</p>
<p>现在我们还没有数据，如果想采集系统的数据，我们需要使用Cadvisor软件来实现</p>
<h1 id="五、容器监控工具cAdvisor"><a href="#五、容器监控工具cAdvisor" class="headerlink" title="五、容器监控工具cAdvisor"></a>五、容器监控工具cAdvisor</h1><h2 id="1-什么是cAdvisor"><a href="#1-什么是cAdvisor" class="headerlink" title="1 什么是cAdvisor"></a>1 什么是cAdvisor</h2><p> Google开源的用于监控基础设施应用的工具，它是一个强大的监控工具，不需要任何配置就可以通过运行在Docker主机上的容器来监控Docker容器，而且可以监控Docker 主机。更多详细操作和配置选项可以查看Github上的cAdvisor项目文档。 </p>
<h2 id="2-cAdvisor安装"><a href="#2-cAdvisor安装" class="headerlink" title="2 cAdvisor安装"></a>2 cAdvisor安装</h2><h3 id="（1）下载镜像"><a href="#（1）下载镜像" class="headerlink" title="（1）下载镜像"></a>（1）下载镜像</h3><p>docker pull google/cadvisor</p>
<h3 id="（2）创建容器"><a href="#（2）创建容器" class="headerlink" title="（2）创建容器"></a>（2）创建容器</h3><p>   docker run –volume=/:/rootfs:ro –volume=/var/run:/var/run:rw    –volume=/sys:/sys:ro –volume=/var/lib/docker/:/var/lib/docker:ro    –publish=8080:8080 –detach=true –link influxsrv:influxsrv    –name=cadvisor google/cadvisor    -storage_driver=influxdb    -storage_driver_db=cadvisor    -storage_driver_host=influxsrv:8086   </p>
<p>我们可以看到启动cadvisor容器时，可以看到storage_driver 指定了存储的用的数据库，storage_driver_db指定了用的数据库名称，storage_driver_host指定写入数据库地址，–link 表示连接到我们在上面创建的influxsrv容器</p>
<h3 id="（3）查看容器"><a href="#（3）查看容器" class="headerlink" title="（3）查看容器"></a>（3）查看容器</h3><p>WEB前端访问地址 <a href="http://192.168.1.105:8080/containers/" target="_blank" rel="external">http://192.168.1.105:8080/containers/</a></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image153.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image155.jpg" alt="img"></p>
<p>性能指标含义参照如下地址</p>
<p><a href="https://blog.csdn.net/ZHANG_H_A/article/details/53097084" target="_blank" rel="external">https://blog.csdn.net/ZHANG_H_A/article/details/53097084</a></p>
<h3 id="（4）查看influxsrv容器"><a href="#（4）查看influxsrv容器" class="headerlink" title="（4）查看influxsrv容器"></a>（4）查看influxsrv容器</h3><p>再次查看influxDB，发现已经有很多数据被采集进去了</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image157.jpg" alt="img"></p>
<p>可以使用select语句查询某张表的数据</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image159.jpg" alt="img"></p>
<h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3.总结"></a>3.总结</h2><p>经过上面的学习，cadvisor和influxsrv 的使用我们可以检测采集，以及采集数据保存到influxdb中，但是有个缺点，那就是采集到infludb的数据，通过select语句查询，不是那么直观，那么下面我们将使用grafana图表工具展示influx的数据。</p>
<h1 id="六、图表工具Grafana"><a href="#六、图表工具Grafana" class="headerlink" title="六、图表工具Grafana"></a>六、图表工具Grafana</h1><h2 id="1-什么是Grafana"><a href="#1-什么是Grafana" class="headerlink" title="1 什么是Grafana"></a>1 什么是Grafana</h2><p> Grafana是一个可视化面板（Dashboard），有着非常漂亮的图表和布局展示，功能齐全的度量仪表盘和图形编辑器。支持Graphite、zabbix、InfluxDB、Prometheus和 OpenTSDB作为数据源。 Grafana主要特性：灵活丰富的图形化选项；可以混合多种风格；支持白天和夜间模式，多个数据源。 </p>
<h2 id="2-Grafana安装"><a href="#2-Grafana安装" class="headerlink" title="2 Grafana安装"></a>2 Grafana安装</h2><h3 id="（1）下载镜像-1"><a href="#（1）下载镜像-1" class="headerlink" title="（1）下载镜像"></a>（1）下载镜像</h3><p>docker pull grafana/grafana</p>
<h3 id="（2）创建容器-1"><a href="#（2）创建容器-1" class="headerlink" title="（2）创建容器"></a>（2）创建容器</h3><p>​       </p>
<p>   docker run -d -p 3001:3000 -e INFLUXDB_HOST=influxsrv -e   INFLUXDB_PORT=8086 -e INFLUXDB_NAME=cadvisor -e INFLUXDB_USER=root -e   INFLUXDB_PASS=itcast –link influxsrv:influxsrv –name=grafana   grafana/grafana   </p>
<h3 id="（3）访问"><a href="#（3）访问" class="headerlink" title="（3）访问"></a>（3）访问</h3><p><a href="http://192.168.1.105:3001" target="_blank" rel="external">http://192.168.1.105:3001</a></p>
<p>用户名密码均为admin</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image161.jpg" alt="img"></p>
<p>登录后需要修改密码，密码修改为：123456</p>
<h3 id="（4）之后进入主页面"><a href="#（4）之后进入主页面" class="headerlink" title="（4）之后进入主页面"></a>（4）之后进入主页面</h3><p><img src="/2019/03/08/持续集成技术总结/clip_image163.jpg" alt="img"></p>
<p>（5）添加数据源</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image165.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image167.jpg" alt="img"></p>
<p>选择InfluxDB</p>
<p>（5）填写数据源信息</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image169.jpg" alt="img"></p>
<p>点击save</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image171.jpg" alt="img"></p>
<p>连接成功</p>
<h3 id="（5）添加仪表盘"><a href="#（5）添加仪表盘" class="headerlink" title="（5）添加仪表盘"></a>（5）添加仪表盘</h3><p>选择Dashboards –Manager</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image173.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image175.jpg" alt="img"></p>
<p>然后选择展示数据的图表样式</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image177.jpg" alt="img"></p>
<p>这里我们选择第一个，柱状图</p>
<p>（6）设置图表数据源</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image179.jpg" alt="img"></p>
<p>进入下个界面</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image181.jpg" alt="img"></p>
<p>点击edit</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image183.jpg" alt="img"></p>
<p>然后点击右上角保存即可</p>
<p>（6）预警通知设置</p>
<p>（1）选择菜单  alerting–&gt; Notification channels</p>
<p>（2）点击Add channel 按钮</p>
<p>（3）填写名称，选择类型为webhook  ,填写钩子地址</p>
<p>这个钩子地址是之前对base微服务扩容的地址</p>
<p>（4）点击SendTest  测试  观察基础微服务是否增加容器</p>
<p>（5）点击save保存</p>
<p>（6）按照同样的方法添加缩容地址 6.4.4 仪表盘预警设置 </p>
<p>（7）再次打开刚刚编辑的仪表盘</p>
<p>（8）点击 Create Alert </p>
<p>设置预警线</p>
<p>（9）选择通知</p>
<p>保存更改</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Influxdb和cadvisor、grafana，这三者一般都是一起使用，cadvisor负责往influxdb里面写入监控的数据，grafana负责从infuxdb中读取数据，并做可视化显示。</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image185.jpg" alt="img"></p>
<h1 id="额外补充"><a href="#额外补充" class="headerlink" title="额外补充"></a>额外补充</h1><h2 id="1-使用docker安装jenkins"><a href="#1-使用docker安装jenkins" class="headerlink" title="1 使用docker安装jenkins"></a>1 使用docker安装jenkins</h2><p>在第二章节中我们是使用rpm的方式安装jenkins，其实我们也是可以使用docker镜像的方式安装jenkins。<strong>但是这种方式创建数据卷会存在权限问题，所以一般也不常用</strong></p>
<p><a href="https://hub.docker.com/_/jenkins/" target="_blank" rel="external">https://hub.docker.com/_/jenkins/</a> 官网。注意查看jenkins容器启动后配置文件在容器中的位置，方便我们设置容器卷链接到本地虚拟机</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image187.jpg" alt="img"></p>
<h3 id="1-1-下载jenkins镜像"><a href="#1-1-下载jenkins镜像" class="headerlink" title="1.1 下载jenkins镜像"></a>1.1 下载jenkins镜像</h3><p>docker pull jenkins</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image189.jpg" alt="img"></p>
<h3 id="1-2-启动jenkins容器"><a href="#1-2-启动jenkins容器" class="headerlink" title="1.2 启动jenkins容器"></a>1.2 启动jenkins容器</h3><p>在镜像文档里，我们知道Jenkins访问的端口号是8080，另外还需要暴露一个tcp的端口号50000。我们使用如下命令启动Jenkins镜像</p>
<p>1.首先创建本地挂载目录并修改权限</p>
<p>创建目录赋权限</p>
<p>mkdir /home/jenkins</p>
<p>ls -nd jenkins</p>
<p>chown -R 1000:1000 jenkins/ （设置权限）</p>
<p>为什么需要修改本地数据卷文件的权限呢？</p>
<p>我们首先查看一下jenkins容器数据卷的权限信息</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image191.jpg" alt="img"></p>
<p>如果不把全权限修改一致，那么当本地数据卷信息同步到容器数据卷目录的时候，就会出现没有权限的问题。</p>
<p><a href="https://www.cnblogs.com/jackluo/p/5783116.html" target="_blank" rel="external">https://www.cnblogs.com/jackluo/p/5783116.html</a> 可以查看这篇文章。</p>
<p>\2. docker run -itd -p 6666:8080 -p 6660:50000 –name jenkins –privileged=true -v /home/jenkins:/var/jenkins_home jenkins</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image193.jpg" alt="img"></p>
<h3 id="1-3-开始安装"><a href="#1-3-开始安装" class="headerlink" title="1.3 开始安装"></a>1.3 开始安装</h3><p>访问</p>
<p><a href="http://192.168.1.105:6666" target="_blank" rel="external">http://192.168.1.105:6666</a></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image195.jpg" alt="img"></p>
<p>查看初始化密码</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image197.jpg" alt="img"></p>
<p>位置在我们关联的本地数据卷目录中</p>
<p>如果安装过程中出现下面这个错误</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image199.jpg" alt="img"></p>
<p>说明需要更换jenkin安装插件地址</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image201.jpg" alt="img"></p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image203.jpg" alt="img"></p>
<h2 id="2-Docker-Volume-之权限管理"><a href="#2-Docker-Volume-之权限管理" class="headerlink" title="2. Docker Volume 之权限管理"></a>2. Docker Volume 之权限管理</h2><p><a href="https://www.cnblogs.com/jackluo/p/5783116.html" target="_blank" rel="external">https://www.cnblogs.com/jackluo/p/5783116.html</a></p>
<p>1.启动Jenkins官方镜像，并检查日志</p>
<p>docker run -d -p 8080:8080 -p 50000:50000 –name jenkins jenkin</p>
<p>docker logs jenkins</p>
<p>我们可以发现”jenkins”容器日志显示结果一切正常</p>
<p>2.然而为了持久化Jenkins配置数据，当我们把宿主机当前目录下的data文件夹挂载到容器中的目录”/var/jenkins_home”的时候，问题出现了：</p>
<p>docker rm -f jenkins</p>
<p>docker run -d -p 8080:8080 -p 50000:50000 -v $(pwd)/data:/var/jenkins_home –name jenkins jenkins</p>
<p>docker logs jenkins</p>
<p>错误日志如下</p>
<p>touch: cannot touch ‘/var/jenkins_home/copy_reference_file.log’: Permission denied</p>
<p>Can not write to /var/jenkins_home/copy_reference_file.log. Wrong volume permissions?</p>
<p>\3. 我们检查一下之前启动方式的”/var/jenkins_home”目录权限，查看Jenkins容器的当前用户: 当前用户是”jenkins”而且”/var/jenkins_home”目录是属于jenkins用户拥有的</p>
<p>   docker@default:~$ docker run -ti –rm   –entrypoint=”/bin/bash” jenkins -c “whoami &amp;&amp;   id”   jenkins   uid=1000(jenkins) gid=1000(jenkins) groups=1000(jenkins)       docker@default:~$ docker run -ti –rm   –entrypoint=”/bin/bash” jenkins -c “ls -la   /var/jenkins_home”   total 20   drwxr-xr-x  2 jenkins jenkins   4096 Jun  5 08:39 .   drwxr-xr-x 28 root    root    4096 May 24 16:43 ..   -rw-r–r–  1 jenkins   jenkins  220 Nov 12  2014 .bash_logout   -rw-r–r–  1 jenkins jenkins   3515 Nov 12  2014 .bashrc   -rw-r–r–  1 jenkins   jenkins  675 Nov 12  2014 .profile   </p>
<p>而当映射本地数据卷时，/var/jenkins_home目录的拥有者变成了root用户</p>
<p>docker run -ti –rm -v $(pwd)/data:/var/jenkins_home –entrypoint=”/bin/bash” jenkins -c “ls -la /var/jenkins_home”</p>
<p>total 4</p>
<p>drwxr-sr-x  2 root staff   40 Jun  5 08:32 .</p>
<p>drwxr-xr-x 28 root root  4096 May 24 16:43 ..</p>
<p>这就解释了为什么当”jenkins”用户的进程访问”/var/jenkins_home”目录时，会出现 Permission denied 的问题</p>
<p>我们再检查一下宿主机上的数据卷目录，当前路径下”data”目录的拥有者是”root”，这是因为这个目录是Docker进程缺省创建出来的。</p>
<p>docker@default:~$ ls -la data</p>
<p>total 0</p>
<p>drwxr-sr-x    2 root     staff           40 Jun  5 08:32 ./</p>
<p>drwxr-sr-x    5 docker   staff          160 Jun  5 08:32 ../</p>
<p>发现问题之后，相应的解决方法也很简单：把当前目录的拥有者赋值给uid 1000，再启动”jenkins”容器就一切正常了。</p>
<p>sudo chown -R 1000 data</p>
<p>docker start jenkins</p>
<p>这时利用浏览器访问 “<a href="http://192.168.99.100:8080/" target="_blank" rel="external">http://192.168.99.100:8080/</a>“ 就可以看到Jenkins的Web界面了。注：如无法访问，可能需要通过docker-machine ip命令获得当前Docker宿主机的IP地址。</p>
<p>当我们再进入容器内部查看”/var/jenkins_home”目录的权限，其拥有者已经变成 “jenkins”</p>
<p>复制代码</p>
<p>docker@default:~$ docker exec jenkins ls -la /var/jenkins_home</p>
<p>total 24</p>
<p>drwxr-sr-x 11 jenkins staff  340 Jun  5 09:00 .</p>
<p>drwxr-xr-x 28 root    root  4096 May 24 16:43 ..</p>
<p>drwxr-sr-x  3 jenkins staff   60 Jun  5 08:59 .java</p>
<p>-rw-r–r–  1 jenkins staff  289 Jun  5 08:59 copy_reference_file.log</p>
<p>…</p>
<p>复制代码</p>
<p>而有趣的是在宿主机上我们看到的 “data”目录的拥有者是”docker”，这是因为”docker”用户在”boot2docker”宿主机上的uid也是”1000”。</p>
<p>docker@default:~$ ls -la data</p>
<p>total 20</p>
<p>drwxr-sr-x    2 docker   staff           40 Jun  5 11:55 ./</p>
<p>drwxr-sr-x    6 docker   staff          180 Jun  5 11:55 ../</p>
<p>…</p>
<p>这时我们已经可以知道：容器的本地数据卷中文件/目录的权限是和宿主机上一致的，只是uid/gid在Docker容器和宿主机中可能映射为不同的用户/组名称。</p>
<p>在上文，我们使用了一个常见的技巧，即在宿主机上执行chown命令时采用了uid而不是具体的用户名，这样就可以保证设置正确的拥有者。</p>
<p>问题虽然解决了，但思考并没有结束。因为当使用本地数据卷时，Jenkins容器会依赖宿主机目录权限的正确性，这会给自动化部署带来额外的工作。有没有方法让Jenkins容器为数据卷自动地设置正确的权限呢？这个问题对很多以non-root方式运行的应用也都有借鉴意义。</p>
<p>为non-root应用正确地挂载本地数据卷</p>
<p>我们可以从万能的stackoverflow.com找到很多相关的讨论，其中一个非常有借鉴意义问答如下</p>
<p><a href="http://stackoverflow.com/questions/23544282/what-is-the-best-way-to-manage-permissions-for-docker-shared-volumes" target="_blank" rel="external">http://stackoverflow.com/questions/23544282/what-is-the-best-way-to-manage-permissions-for-docker-shared-volumes</a></p>
<p>其中的基本思路有两个：</p>
<p>一个是利用Data Container的方法在容器间共享数据卷。这样就规避了解决宿主机上数据卷的权限问题。由于在1.9版本之后，Docker提供了named volume来取代纯数据容器，我们还需要真正地解决这个问题。</p>
<p>另外一个思路就是让容器中以root用户启动，在容器启动脚本中利用”chown”命令来修正数据卷文件权限，之后切换到non-root用户来执行程序</p>
<p>我们来参照第二个思路来解决这个问题</p>
<p>下面是一个基于Jenkins镜像的Dockerfile：它会切换到”root”用户并在镜像中添加”gosu”命令，和新的入口点”/entrypoint.sh”</p>
<p>   FROM jenkins:latest   USER root   RUN   GOSU_SHA=5ec5d23079e94aea5f7ed92ee8a1a34bbf64c2d4053dadf383992908a2f9dc8a \     &amp;&amp; curl -sSL -o   /usr/local/bin/gosu   “<a href="https://github.com/tianon/gosu/releases/download/1.9/gosu-$(dpkg" target="_blank" rel="external">https://github.com/tianon/gosu/releases/download/1.9/gosu-$(dpkg</a>   –print-architecture)” \     &amp;&amp; chmod +x   /usr/local/bin/gosu \     &amp;&amp; echo   “$GOSU_SHA    /usr/local/bin/gosu” | sha256sum -c -    COPY entrypoint.sh /entrypoint.sh   ENTRYPOINT [“/entrypoint.sh”]   </p>
<p>注释：gosu 是经常出现在官方Docker镜像中的一个小工具。它是”su”和”sudo”命令的轻量级替代品，并解决了它们在tty和信号传递中的一些问题。</p>
<p>新入口点的”entrypoint.sh”的内容如下：它会为”JENKINS_HOME”目录设置”jenkins”的拥有权限，并且再利用”gosu”命令切换到”jenkins”用户来执行”jenkins”应用。</p>
<p>#! /bin/bash</p>
<p>set -e</p>
<p>chown -R 1000 “$JENKINS_HOME”</p>
<p>exec gosu jenkins /bin/tini – /usr/local/bin/jenkins.sh</p>
<p>您可以直接从 <a href="https://github.com/denverdino/docker-jenkins" target="_blank" rel="external">https://github.com/denverdino/docker-jenkins</a> 获得相关代码，并构建自己的Jenkins镜像。执行命令如下：</p>
<p>git clone <a href="https://github.com/AliyunContainerService/docker-jenkins" target="_blank" rel="external">https://github.com/AliyunContainerService/docker-jenkins</a></p>
<p>cd docker-jenkins/jenkins</p>
<p>docker build -t denverdino/jenkins .</p>
<p>然后基于新镜像启动Jenkins容器</p>
<p>docker rm -f jenkins</p>
<p>docker run -d -p 8080:8080 -p 50000:50000 -v $(pwd)/data:/var/jenkins_home –name jenkins denverdino/jenkins</p>
<h2 id="3-linux安装git"><a href="#3-linux安装git" class="headerlink" title="3.linux安装git"></a>3.linux安装git</h2><h3 id="3-1-使用yum命令进行安装"><a href="#3-1-使用yum命令进行安装" class="headerlink" title="3.1 使用yum命令进行安装"></a>3.1 使用yum命令进行安装</h3><p>yum install git</p>
<p>安装简单，但是安装的git版本太老，而且版本不好控制，推荐使用下面的方式进行安装</p>
<h3 id="3-2-源码编译安装Git"><a href="#3-2-源码编译安装Git" class="headerlink" title="3.2 源码编译安装Git"></a>3.2 源码编译安装Git</h3><p>①、获取github最新的Git安装包下载链接，进入Linux服务器，执行下载，命令为： wget <a href="https://github.com/git/git/archive/v2.22.0.tar.gz" target="_blank" rel="external">https://github.com/git/git/archive/v2.22.0.tar.gz</a> ；</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image205.jpg" alt="img"></p>
<p>②、压缩包解压，命令为： tar -zxvf v2.22.0.tar.gz ；</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image206.png" alt="img"></p>
<p>③、安装编译源码所需依赖，命令为： yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel gcc perl-ExtUtils-MakeMaker </p>
<p>耐心等待安装，出现提示输入y即可；</p>
<p>④、安装依赖时，yum自动安装了Git，需要卸载旧版本Git，命令为： yum remove git 出现提示输入y即可；</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image207.png" alt="img">很明显自己安装了一个1.8.3.1版本的git，卸载。</p>
<p>⑤、进入解压后的文件夹，命令 cd git-2.22.0 ，然后执行编译，命令为 make prefix=/usr/local/git all 耐心等待编译即可；</p>
<p>⑥、安装Git至/usr/local/git路径，命令为 make prefix=/usr/local/git install ；</p>
<p>⑦、打开环境变量配置文件，命令 vim /etc/profile ，在底部加上Git相关配置信息：</p>
<p>PATH=$PATH:/usr/local/git/bin </p>
<p>export PATH </p>
<p>然后保存，退出！</p>
<p>⑧、输入命令 git –version ，查看安装的git版本，校验通过，安装成功。</p>
<p>source /etc/profile</p>
<p><img src="/2019/03/08/持续集成技术总结/clip_image208.png" alt="img"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一、DockerMaven插件的使用&quot;&gt;&lt;a href=&quot;#一、DockerMaven插件的使用&quot; class=&quot;headerlink&quot; title=&quot;一、DockerMaven插件的使用&quot;&gt;&lt;/a&gt;一、DockerMaven插件的使用&lt;/h1&gt;&lt;p&gt;这个插件的目
    
    </summary>
    
      <category term="持续集成技术" scheme="http://kingge.top/categories/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="持续集成技术" scheme="http://kingge.top/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E6%8A%80%E6%9C%AF/"/>
    
      <category term="容器管理" scheme="http://kingge.top/tags/%E5%AE%B9%E5%99%A8%E7%AE%A1%E7%90%86/"/>
    
      <category term="自动部署" scheme="http://kingge.top/tags/%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/"/>
    
  </entry>
  
  <entry>
    <title>docker个人总结</title>
    <link href="http://kingge.top/2019/02/28/docker%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/"/>
    <id>http://kingge.top/2019/02/28/docker个人总结/</id>
    <published>2019-02-28T13:59:59.000Z</published>
    <updated>2019-08-25T04:35:01.597Z</updated>
    
    <content type="html"><![CDATA[<p>之前学习过docker，但是很浅显的使用，概念和流程各个方面总结的不够到位，下面根据旧版本的文档，重新的梳理。</p>
<h1 id="一、docker出现的契机"><a href="#一、docker出现的契机" class="headerlink" title="一、docker出现的契机"></a>一、docker出现的契机</h1><p>作为开发人员，我们经常会遇到一个问题，那就是环境不统一的问题。什么意思呢？自己在本地测试的项目是运行正常的，但是打包给测试或者运维人员部署使用时，经常会出现，部署报错，运行不起来，等等问题。就算是再详细的部署文档也还是会出错。</p>
<p>这个时候就产生了大量沟通的成本，通常产生这些问题的原因是部署的环境并不是开发人员的那一份环境，可能是jdk版本或者tomcat版本，数据库等等环境产生的问题。所以就需要我们开发人员打包一份连同环境和配置以及项目，交付给测试或者运维。这样就能够保证项目运行环境的一致性，也容易排查问题。<strong>这个就是docker的雏形</strong></p>
<pre><code>就好比我们在迁移一棵树的时候，尾部，总是会保留着一些原先的土，就是为了解决生长环境的不同额度适配问题。
</code></pre><p><strong>Docker之所以发展如此迅速，也是因为它对此给出了一个标准化的解决方案。</strong></p>
<p>环境配置如此麻烦，换一台机器，就要重来一次，费力费时。很多人想到，能不能从根本上解决问题，软件可以带环境安装？也就是说，安装的时候，把原始环境一模一样地复制过来。开发人员利用 Docker 可以消除协作编码时“在我的机器上可正常工作”的问题。</p>
<pre><code>*总的来说，以前我们是通过提交**war**包的方式，那么现在是连同**war***运行的环境***一起打包给测试或者运维。*
</code></pre><p><img src="/2019/02/28/docker个人总结/clip_image002.jpg" alt="graphic"></p>
<p>传统上认为，软件编码开发/测试结束后，所产出的成果即是程序或是能够编译执行的二进制字节码等(java为例)。而为了让这些程序可以顺利执行，开发团队也得准备完整的部署文件，让维运团队得以部署应用程式，开发需要清楚的告诉运维部署团队，用的全部配置文件+所有软件环境。不过，即便如此，仍然常常发生部署失败的状况。Docker镜像的设计，使得Docker得以打破过去「程序即应用」的观念。<strong>透过镜像(images)将作业系统核心除外，运作应用程式所需要的系统环境，由下而上打包，达到应用程式跨平台间（类似于jvm的理念）的无缝接轨运作</strong>。</p>
<h2 id="1-1-理念"><a href="#1-1-理念" class="headerlink" title="1.1 理念"></a>1.1 理念</h2><p>Docker是基于Go语言实现的云开源项目。</p>
<p>Docker的主要目标是“Build，Ship and Run Any App,Anywhere”，也就是通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的APP（可以是一个WEB应用或数据库应用等等）及其运行环境能够做到“<strong>一次封装，到处运行</strong>”。</p>
<p><strong>Linux</strong> <strong>容器技术</strong>的出现就解决了这样一个问题，而 Docker 就是在它的基础上发展过来的。将应用运行在 Docker 容器上面，而 Docker 容器在任何操作系统上都是一致的，这就实现了跨平台、跨服务器。<strong>只需要一次配置好环境，换到别的机子上就可以一键部署好，大大简化了操作</strong></p>
<p><img src="/2019/02/28/docker个人总结/clip_image004.jpg" alt="graphic"></p>
<p><strong>也就是说，我们可以把项目运行成功所需要的环境（redis，nginx，mysql）等等组件，通过编译打包的形式，打包成一个个的货仓。</strong></p>
<p><strong>项目部署到其他环境时（windowsàlinux）只需要运行这些货仓就可以安装这些环境，做到一次封装到处运行，解决了因为环境不同导致app部署或运行失败的问题</strong></p>
<p><img src="/2019/02/28/docker个人总结/clip_image006.jpg" alt="img">docker的logo就阐述了这一理念，部署项目的时候直接搬运已经测试成功的app运行环境。</p>
<pre><code>**特别是在多集群的环境下，docker的作用更显而易见（避免多次安装环境）**
</code></pre><p>总的来说：<strong>解决了运行环境和配置问题软件容器（每个容器对应着一个集装箱，每个集装箱对应着项目运行所需的软件或者配置），方便做持续集成并有助于整体发布的容器虚拟化技术</strong>。</p>
<h1 id="二、docker的演化"><a href="#二、docker的演化" class="headerlink" title="二、docker的演化"></a>二、docker的演化</h1><h2 id="2-1-虚拟机技术"><a href="#2-1-虚拟机技术" class="headerlink" title="2.1 虚拟机技术"></a>2.1 虚拟机技术</h2><p><img src="/2019/02/28/docker个人总结/clip_image007.png" alt="img">一个虚拟机的结构图</p>
<p>虚拟机（virtual machine）就是<strong>带环境安装</strong>的一种解决方案。</p>
<p>带环境安装的意思是：它里面模拟了一个正常的操作系统所具备的各种环境和配置（内存、处理器、硬盘。。。。）</p>
<p><img src="/2019/02/28/docker个人总结/clip_image008.png" alt="img"></p>
<p>它可以在一种操作系统里面运行另一种操作系统，比如在Windows 系统里面运行Linux 系统。应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件，不需要了就删掉，对其他部分毫无影响。这类虚拟机完美的运行了另一套系统，能够使应用程序，操作系统和硬件三者之间的逻辑不变。  </p>
<p>​       </p>
<p>缺点：</p>
<p>\1.     启动很慢</p>
<p>\2.     资源占用多</p>
<p>\3.     冗余步骤多</p>
<p>所以docker在这之上就演化出了 <strong>容器虚拟化技术</strong></p>
<h2 id="2-2-容器虚拟化技术"><a href="#2-2-容器虚拟化技术" class="headerlink" title="2.2 容器虚拟化技术"></a>2.2 容器虚拟化技术</h2><p>由于前面虚拟机存在这些缺点，Linux 发展出了另一种虚拟化技术：L<strong>inux</strong> <strong>容器（Linux Containers，缩写为</strong> <strong>LXC）</strong>。</p>
<p><strong>Linux</strong> <strong>容器不是模拟一个完整的操作系统</strong>，而是对进程进行隔离。有了容器，就可以将软件运行所需的所有资源打包到一个隔离的容器中。容器与虚拟机不同，不需要捆绑一整套操作系统，只需要软件工作所需的库资源和设置。系统因此而变得高效轻量并保证部署在任何环境中的软件都能始终如一地运行。</p>
<p><img src="/2019/02/28/docker个人总结/clip_image009.png" alt="img"></p>
<p>相比虚拟机技术的系统结构图，很明显发现，公用库api模块被移除。各个app维护自己的所依赖的api模块。好处就是，节省了资源的占用。</p>
<h2 id="2-3-总结不同"><a href="#2-3-总结不同" class="headerlink" title="2.3 总结不同"></a>2.3 总结不同</h2><p>比较了 Docker 和传统虚拟化方式的不同之处：</p>
<p>\1.     传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程</p>
<p>\2.     而容器内的应用进程<strong>直接运行于宿主的内核</strong>，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。</p>
<p>\3.      每个容器之间互相隔离，每个容器有自己的文件系统 ，容器之间进程不会相互影响，能区分计算资源。</p>
<p><strong>4.</strong>     <strong>Linux虚拟机安装包可能需要4G，但是docker只需要170M。很明显这是一个很大的提升，换句话说，docker就是一个精细版的linux虚拟机</strong></p>
<h1 id="三、docker的好处"><a href="#三、docker的好处" class="headerlink" title="三、docker的好处"></a>三、docker的好处</h1><p>一次构建、随处运行</p>
<h2 id="更快速的应用交付和部署"><a href="#更快速的应用交付和部署" class="headerlink" title="更快速的应用交付和部署"></a>更快速的应用交付和部署</h2><p><img src="/2019/02/28/docker个人总结/clip_image011.jpg" alt="img"></p>
<h2 id="更便捷的升级和扩缩容"><a href="#更便捷的升级和扩缩容" class="headerlink" title="更便捷的升级和扩缩容"></a>更便捷的升级和扩缩容</h2><p><img src="/2019/02/28/docker个人总结/clip_image013.jpg" alt="img"></p>
<h2 id="更简单的系统运维"><a href="#更简单的系统运维" class="headerlink" title="更简单的系统运维"></a>更简单的系统运维</h2><p><img src="/2019/02/28/docker个人总结/clip_image015.jpg" alt="img"></p>
<h2 id="更高效的计算资源利用"><a href="#更高效的计算资源利用" class="headerlink" title="更高效的计算资源利用"></a>更高效的计算资源利用</h2><p><img src="/2019/02/28/docker个人总结/clip_image017.jpg" alt="img"></p>
<h1 id="四、安装和下载"><a href="#四、安装和下载" class="headerlink" title="四、安装和下载"></a>四、安装和下载</h1><p>docker官网：<a href="http://www.docker.com" target="_blank" rel="external">http://www.docker.com</a></p>
<p>docker中文网站： <a href="https://www.docker-cn.com/" target="_blank" rel="external">https://www.docker-cn.com/</a></p>
<p>Docker Hub官网: <a href="https://hub.docker.com/" target="_blank" rel="external">https://hub.docker.com/</a></p>
<p><code>Docker</code> 分为 <code>CE</code> 和 <code>EE</code> 两大版本。 <code>CE</code> 即社区版（免费，支持周期 <code>7</code> 个月）， <code>EE</code> 即企业版，强调安全，付费使用，支持周期 <code>24</code> 个月。下面安装的是CE版本。</p>
<h2 id="4-1-docker安装前提条件"><a href="#4-1-docker安装前提条件" class="headerlink" title="4.1 docker安装前提条件"></a>4.1 docker安装前提条件</h2><p>Docker支持以下的CentOS版本：CentOS 7 (64-bit)</p>
<p>CentOS 6.5 (64-bit) 或更高的版本</p>
<p>目前，CentOS 仅发行版本中的内核支持 Docker。</p>
<p>Docker 运行在 CentOS 7 上，要求系统为64位、系统内核版本为 3.10 以上。</p>
<p>Docker 运行在 CentOS-6.5 或更高的版本的 CentOS 上，要求系统为64位、系统内核版本为 2.6.32-431 或者更高版本。</p>
<p>为了避免我们后面启动tomcat 容器做测试的时候，外部浏览器访问tomcat容器时，端口被拦截。这里先关闭虚拟机的防火墙</p>
<p>service firewalld status ；查看防火墙状态</p>
<p><img src="/2019/02/28/docker个人总结/clip_image019.jpg" alt="img"></p>
<p>service firewalld stop：关闭防火墙</p>
<h3 id="查看自己linux-内核"><a href="#查看自己linux-内核" class="headerlink" title="查看自己linux 内核"></a>查看自己linux 内核</h3><p>uname命令用于打印当前系统相关信息（内核版本号、硬件架构、主机名称和操作系统类型等）。</p>
<p><img src="/2019/02/28/docker个人总结/clip_image020.png" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image022.jpg" alt="img"></p>
<h3 id="查看已安装的CentOS版本信息（CentOS6-8有，CentOS7无该命令）"><a href="#查看已安装的CentOS版本信息（CentOS6-8有，CentOS7无该命令）" class="headerlink" title="查看已安装的CentOS版本信息（CentOS6.8有，CentOS7无该命令）"></a>查看已安装的CentOS版本信息（CentOS6.8有，CentOS7无该命令）</h3><p><img src="/2019/02/28/docker个人总结/clip_image024.jpg" alt="img"></p>
<p>另一种方式查询</p>
<p><img src="/2019/02/28/docker个人总结/clip_image025.png" alt="img"></p>
<h2 id="4-2-docker安装"><a href="#4-2-docker安装" class="headerlink" title="4.2 docker安装"></a>4.2 docker安装</h2><p><strong>一下安装是使用yum命令进行安装，所以linux虚拟机需要能够连接互联网</strong></p>
<p><strong>官方手册：</strong></p>
<p><a href="https://docs.docker-cn.com/engine/installation/linux/docker-ce/centos/#prerequisites" target="_blank" rel="external">https://docs.docker-cn.com/engine/installation/linux/docker-ce/centos/#prerequisites</a></p>
<h3 id="CentOS6-8安装Docker"><a href="#CentOS6-8安装Docker" class="headerlink" title="CentOS6.8安装Docker"></a>CentOS6.8安装Docker</h3><p>\1.      yum install -y epel-release</p>
<p>  使用root用户执行改命令。</p>
<p>Docker使用EPEL发布，RHEL系的OS首先要确保已经持有EPEL仓库，否则先检查OS的版本，然后安装相应的EPEL包</p>
<p><img src="/2019/02/28/docker个人总结/clip_image027.jpg" alt="img"></p>
<p>\2.      yum install -y docker-io</p>
<p>发现这个命令在centos6.10 版本时，提示docker包找不到，于是花了另一命令：yum –y  install  docker  安装成功</p>
<p>\3.      安装后的配置文件：/etc/sysconfig/docker</p>
<p>\4.      启动Docker后台服务：service docker start</p>
<p>5.docker version验证</p>
<h3 id="CentOS7以上安装Docker（本人使用的版本）-推荐"><a href="#CentOS7以上安装Docker（本人使用的版本）-推荐" class="headerlink" title="CentOS7以上安装Docker（本人使用的版本）-推荐"></a>CentOS7以上安装Docker（本人使用的版本）-推荐</h3><p><img src="/2019/02/28/docker个人总结/clip_image029.jpg" alt="img"></p>
<p>  下面使用仓库的方式进行安装docker-ce</p>
<p>\1. cat /etc/redhat-release</p>
<p>命令查看centos版本</p>
<p><img src="/2019/02/28/docker个人总结/clip_image030.png" alt="img"></p>
<p>\2. yum安装gcc相关</p>
<p>  执行以下两条命令</p>
<p>  yum -y install gcc</p>
<p>yum -y install gcc-c++</p>
<p>3.卸载老版本（如果之前没有装过，可以忽略这一步）</p>
<p>   注意看官网的操作手册，里面有着一段命令。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ sudo yum remove docker \</div><div class="line">                  docker-client \</div><div class="line">                  docker-client-latest \</div><div class="line">                  docker-common \</div><div class="line">                  docker-latest \</div><div class="line">                  docker-latest-logrotate \</div><div class="line">                  docker-logrotate \</div><div class="line">                  docker-engine</div></pre></td></tr></table></figure>
<p>   $ sudo yum remove docker \                     docker-client   \                       docker-client-latest \                     docker-common   \                     docker-latest   \                       docker-latest-logrotate \                       docker-logrotate \                     docker-engine   </p>
<p>\4. 安装需要的软件包</p>
<pre><code>yum install -y yum-utils device-mapper-persistent-data lvm2
</code></pre><p>\5. 设置stable镜像仓库</p>
<p>执行命令：</p>
<pre><code>yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo

       注意这里使用的是阿里的镜像仓库，不要使用官网推荐的仓库
</code></pre><p>​          </p>
<p>   yum-config-manager –add-repo   <a href="https://download.docker.com/linux/centos/docker-ce.repo" target="_blank" rel="external">https://download.docker.com/linux/centos/docker-ce.repo</a>               不能使用这条命令   </p>
<p>\6. 更新yum软件包索引</p>
<pre><code>yum makecache fast
</code></pre><p>\7. 安装DOCKER CE</p>
<pre><code>yum -y install docker-ce
</code></pre><p>\8. 启动docker</p>
<pre><code>systemctl start docker
</code></pre><p>\9. 测试</p>
<p>docker version  :查看docker版本</p>
<p>docker pull hello-world（从阿里云仓库中获取hello-world镜像）</p>
<pre><code>docker run hello-world （要先下载hello-world镜像后才能够运行）
</code></pre><p><img src="/2019/02/28/docker个人总结/clip_image032.jpg" alt="img"></p>
<p>10.卸载</p>
<pre><code>执行以下三条命令：

systemctl stop docker 

yum -y remove docker-ce

rm -rf /var/lib/docker
</code></pre><h2 id="4-3阿里云镜像加速"><a href="#4-3阿里云镜像加速" class="headerlink" title="4.3阿里云镜像加速"></a>4.3阿里云镜像加速</h2><p>因为docker官网提供的获取镜像地址（hub.docker），访问速度太过缓慢，这里改换成阿里云的镜像服务。</p>
<p>\1.     登录阿里云</p>
<p><a href="https://www.aliyun.com/" target="_blank" rel="external">https://www.aliyun.com/</a> 进入管理中心</p>
<p>\2.     搜索容器镜像服务</p>
<p><img src="/2019/02/28/docker个人总结/clip_image034.jpg" alt="img"></p>
<p>可以看到镜像加速器</p>
<p><img src="/2019/02/28/docker个人总结/clip_image036.jpg" alt="img"></p>
<p>获得加速器地址连接</p>
<p>\3. 配置本机Docker运行镜像加速器</p>
<p><strong>Centos6.8版本设置：</strong></p>
<ul>
<li>vim   /etc/sysconfig/docker      将获得的自己账户下的阿里云加速地址配置进   other_args=”–registry-mirror=<a href="https://你自己的账号加速信息.mirror.aliyuncs.com" target="_blank" rel="external">https://你自己的账号加速信息.mirror.aliyuncs.com</a>“   </li>
</ul>
<p><img src="/2019/02/28/docker个人总结/clip_image038.jpg" alt="img"></p>
<p><strong>Centos7.6版本设置：</strong></p>
<p>   sudo mkdir -p /etc/docker   sudo tee /etc/docker/daemon.json &lt;&lt;-‘EOF’   {     “registry-mirrors”:   [“<a href="https://sk6o0yc78m.mirror.aliyuncs.com" target="_blank" rel="external">https://sk6o0yc78m.mirror.aliyuncs.com</a>“]   }   EOF   sudo systemctl daemon-reload   sudo systemctl restart docker   </p>
<p><img src="/2019/02/28/docker个人总结/clip_image039.png" alt="img"></p>
<p>Centos7以上的配置文件时：/etc/docker/daemon.json</p>
<p>4．检查配置是否生效</p>
<p>  Centos6.8 检查命令：</p>
<pre><code>启动docker，执行命令 ps –ef| grep docker
</code></pre><p>Centos7.6检查命令：</p>
<p><img src="/2019/02/28/docker个人总结/clip_image041.jpg" alt="img"></p>
<h2 id="4-4-设置docker开机启动"><a href="#4-4-设置docker开机启动" class="headerlink" title="4.4    设置docker开机启动"></a>4.4    设置docker开机启动</h2><p>systemctl enable docker</p>
<h1 id="五、docker组成和分析"><a href="#五、docker组成和分析" class="headerlink" title="五、docker组成和分析"></a>五、docker组成和分析</h1><h2 id="5-1-Docker组成"><a href="#5-1-Docker组成" class="headerlink" title="5.1 Docker组成"></a>5.1 Docker组成</h2><h3 id="镜像（image）"><a href="#镜像（image）" class="headerlink" title="镜像（image）"></a>镜像（image）</h3><p>Docker 镜像（Image）就是一个<strong>只读</strong>的模板。镜像可以用来创建 Docker 容器，一个镜像可以创建很多容器。</p>
<p><img src="/2019/02/28/docker个人总结/clip_image042.png" alt="graphic"></p>
<p> 一个类可以new多个对象。</p>
<p>镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件。</p>
<h4 id="UnionFS（联合文件系统）"><a href="#UnionFS（联合文件系统）" class="headerlink" title="UnionFS（联合文件系统）"></a>UnionFS（联合文件系统）</h4><p>UnionFS（联合文件系统）：Union文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。Union 文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。</p>
<p> <img src="/2019/02/28/docker个人总结/clip_image044.jpg" alt="graphic">跟花卷一样，一层一层的</p>
<p>特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录</p>
<h4 id="Docker镜像加载原理"><a href="#Docker镜像加载原理" class="headerlink" title="Docker镜像加载原理"></a>Docker镜像加载原理</h4><p> Docker镜像加载原理：</p>
<p>   docker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统UnionFS。</p>
<p>bootfs(boot file system)主要包含bootloader和kernel, bootloader主要是引导加载kernel, Linux刚启动时会加载bootfs文件系统，在Docker镜像的最底层是bootfs。这一层与我们典型的Linux/Unix系统是一样的，包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs。</p>
<p>rootfs (root file system) ，在bootfs之上。包含的就是典型 Linux 系统中的 /dev, /proc, /bin, /etc 等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等等。 </p>
<p><img src="/2019/02/28/docker个人总结/clip_image046.jpg" alt="graphic"></p>
<p> <strong>平时我们安装进虚拟机的CentOS都是好几个G，为什么docker这里才200M？？</strong></p>
<p><img src="/2019/02/28/docker个人总结/clip_image048.jpg" alt="graphic"></p>
<p>对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令、工具和程序库就可以了，因为底层直接用Host（宿主机）的kernel，自己只需要提供 rootfs 就行了。由此可见对于不同的linux发行版, bootfs基本是一致的, rootfs会有差别, 因此不同的发行版可以公用bootfs。</p>
<h4 id="分层的镜像"><a href="#分层的镜像" class="headerlink" title="分层的镜像"></a>分层的镜像</h4><p>以我们的pull为例，在下载的过程中我们可以看到docker的镜像好像是在一层一层的在下载</p>
<p><img src="/2019/02/28/docker个人总结/clip_image050.jpg" alt="img"></p>
<p>有多个complete，说明有多个层次</p>
<h4 id="为什么-Docker-镜像要采用这种分层结构呢"><a href="#为什么-Docker-镜像要采用这种分层结构呢" class="headerlink" title="为什么 Docker 镜像要采用这种分层结构呢"></a>为什么 Docker 镜像要采用这种分层结构呢</h4><p>最大的一个好处就是 - 共享资源</p>
<p>比如：有多个镜像都从相同的 base 镜像构建而来，那么宿主机只需在磁盘上保存一份base镜像，</p>
<p>同时内存中也只需加载一份 base 镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。</p>
<h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><p>Docker镜像都是只读的</p>
<p>当容器启动时，一个新的可写层被加载到镜像的顶部。</p>
<p>这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层”。</p>
<h3 id="容器（container）鲸鱼背上的集装箱"><a href="#容器（container）鲸鱼背上的集装箱" class="headerlink" title="容器（container）鲸鱼背上的集装箱"></a>容器（container）鲸鱼背上的集装箱</h3><p><strong>Docker</strong> <strong>利用容器（Container）独立运行的一个或一组应用。容器是用镜像创建的运行实例。</strong></p>
<p>它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。</p>
<p><strong>可以把容器看做是一个简易版的</strong> <strong>Linux</strong> <strong>环境</strong>（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。</p>
<p>容器的定义和镜像几乎一模一样，也是一堆层的统一视角，<strong>唯一区别在于容器的最上面那一层是可读可写的</strong>。</p>
<p><strong>即是：容器=镜像+可读写层</strong></p>
<h3 id="仓库（repository）"><a href="#仓库（repository）" class="headerlink" title="仓库（repository）"></a>仓库（repository）</h3><p>仓库（Repository）是集中存放镜像文件的场所。</p>
<p>仓库(Repository)和仓库注册服务器（Registry）是有区别的。仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。</p>
<p>仓库分为公开仓库（Public）和私有仓库（Private）两种形式。</p>
<p>最大的公开仓库是 Docker Hub(<a href="https://hub.docker.com/)，" target="_blank" rel="external">https://hub.docker.com/)，</a></p>
<p>存放了数量庞大的镜像供用户下载。国内的公开仓库包括阿里云 、网易云 等</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>需要正确的理解仓储/镜像/容器这几个概念:</p>
<p> Docker 本身是一个容器运行载体或称之为管理引擎。我们把应用程序和配置依赖打包好形成一个可交付的运行环境，这个打包好的运行环境就似乎 image镜像文件。只有通过这个镜像文件才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。</p>
<p>\1.     image 文件生成的容器实例，本身也是一个文件，称为镜像文件。</p>
<p>\2.     一个容器运行一种服务，当我们需要的时候，就可以通过docker客户端创建一个对应的运行实例，也就是我们的容器</p>
<p>\3.     至于仓储，就是放了一堆镜像的地方，我们可以把镜像发布到仓储中，需要的时候从仓储中拉下来就可以了。</p>
<p>总结：仓库存放着很多镜像，通过使用镜像可以生成多个容器</p>
<h2 id="5-2-Docker运行流程"><a href="#5-2-Docker运行流程" class="headerlink" title="5.2 Docker运行流程"></a>5.2 Docker运行流程</h2><p><img src="/2019/02/28/docker个人总结/clip_image052.png" alt="docker-framework"></p>
<p>Docker 使用 C/S 结构，即客户端/服务器体系结构。 Docker 客户端与 Docker 服务器进行交互，Docker服务端负责构建、运行和分发 Docker 镜像。 Docker 客户端和服务端可以运行在一台机器上，也可以通过 RESTful 、 stock 或网络接口与远程 Docker 服务端进行通信。</p>
<h3 id="执行docker-run-hello-world"><a href="#执行docker-run-hello-world" class="headerlink" title="执行docker run hello-world"></a>执行docker run hello-world</h3><p>这个例子在上面我们已经使用过了，对照docker结构图我们来分析</p>
<p>Client：客户端就是我们的linux的命令窗口，也就是执行docker run hello-world的地方</p>
<p>Docker-host： docker主机，也就是执行客户端发出请求的地方，也就是我们启动的docker进程。收到一个执行hello-world容器的命令，现在本地种查找是否存在这个容器（镜像），存在则直接运行。不存在，则在Repository中取（上面我们配置了阿里云镜像仓库），pull镜像后放到本地，然后新建一个容器执行这个hello-world镜像。</p>
<p>Repository:：仓库，存放镜像的地方</p>
<p>下次执行docker run hello-world，则会从本地中拿hello-world镜像，然后新建容器执行。</p>
<p>完整流程如图：</p>
<p><img src="/2019/02/28/docker个人总结/clip_image054.jpg" alt="img"></p>
<h1 id="六、docker常用操作命令"><a href="#六、docker常用操作命令" class="headerlink" title="六、docker常用操作命令"></a>六、docker常用操作命令</h1><h2 id="6-1-帮助命令"><a href="#6-1-帮助命令" class="headerlink" title="6.1 帮助命令"></a>6.1 帮助命令</h2><h3 id="docker-version"><a href="#docker-version" class="headerlink" title="docker version"></a>docker version</h3><h3 id="docker-info"><a href="#docker-info" class="headerlink" title="docker info"></a>docker info</h3><p>能够查看更详细的docker信息，比docker version命令更加详细</p>
<h3 id="docker-–help"><a href="#docker-–help" class="headerlink" title="docker –help"></a>docker –help</h3><h2 id="6-2-镜像命令"><a href="#6-2-镜像命令" class="headerlink" title="6.2       镜像命令"></a>6.2       镜像命令</h2><h3 id="6-2-1-docker-images"><a href="#6-2-1-docker-images" class="headerlink" title="6.2.1 docker images"></a>6.2.1 docker images</h3><p>列出本地主机上的镜像</p>
<p><img src="/2019/02/28/docker个人总结/clip_image056.jpg" alt="img"></p>
<p>各个选项说明:</p>
<p>   REPOSITORY：表示镜像的仓库源   TAG：<strong>镜像 标签</strong>   IMAGE ID：镜像ID   CREATED：镜像创建时间   SIZE：镜像大小   </p>
<p> 同一仓库源可以有多个 TAG，代表这个仓库源的不同个版本，我们使用 REPOSITORY:TAG 来定义不同的镜像。</p>
<p><strong>如果你不指定一个镜像的版本标签，例如你只使用</strong> <strong>redis，docker</strong> <strong>将默认使用</strong> <strong>redis:latest镜像</strong></p>
<p>   OPTIONS说明：   -a :列出本地所有的镜像（含中间映像层）   -q :只显示镜像ID。   –digests :显示镜像的摘要信息   –no-trunc :显示完整的镜像信息   </p>
<h3 id="6-2-2-docker-search-某个XXX镜像名字"><a href="#6-2-2-docker-search-某个XXX镜像名字" class="headerlink" title="6.2.2 docker search 某个XXX镜像名字"></a>6.2.2 docker search 某个XXX镜像名字</h3><p><strong>需要注意，查询是从网站</strong> <a href="https://hub.docker.com" target="_blank" rel="external">https://hub.docker.com</a><strong>上进行查询，拉取镜像的时候是从阿里云上拉取</strong></p>
<p>命令： docker search [OPTIONS] 镜像名字</p>
<p>OPTIONS说明：</p>
<p>–no-trunc : 显示完整的镜像描述</p>
<p>-s : 列出收藏数不小于指定值的镜像。（<strong>就是下面的STARS数</strong>）</p>
<p>–automated : 只列出 automated build类型的镜像；</p>
<p><img src="/2019/02/28/docker个人总结/clip_image058.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image060.jpg" alt="img"></p>
<h3 id="6-2-3-docker-pull-某个XXX镜像名字"><a href="#6-2-3-docker-pull-某个XXX镜像名字" class="headerlink" title="6.2.3 docker pull 某个XXX镜像名字"></a>6.2.3 docker pull 某个XXX镜像名字</h3><p>下载镜像</p>
<p>命令：ker pull 镜像名字[:TAG]  （如果不指明标签默认下载最新版本）</p>
<h3 id="6-2-4-docker-rmi-某个XXX镜像名字ID"><a href="#6-2-4-docker-rmi-某个XXX镜像名字ID" class="headerlink" title="6.2.4 docker rmi 某个XXX镜像名字ID"></a>6.2.4 docker rmi 某个XXX镜像名字ID</h3><p>删除镜像</p>
<p>删除单个：</p>
<p>docker rmi  -f 镜像ID （不指明标签默认删除latest）</p>
<p>docker rmi  -f 镜像名称 （不指明标签默认删除latest）</p>
<p>删除多个：docker rmi -f 镜像名1:TAG 镜像名2:TAG </p>
<p>删除全部：ocker rmi -f $(docker images -qa) （<strong>docker images –qa</strong> <strong>查询当前docker中所有镜像id</strong>）</p>
<h2 id="6-3容器命令"><a href="#6-3容器命令" class="headerlink" title="6.3容器命令"></a>6.3容器命令</h2><h3 id="6-3-1有镜像才能创建容器，这是根本前提-下载一个CentOS镜像演示"><a href="#6-3-1有镜像才能创建容器，这是根本前提-下载一个CentOS镜像演示" class="headerlink" title="6.3.1有镜像才能创建容器，这是根本前提(下载一个CentOS镜像演示)"></a>6.3.1有镜像才能创建容器，这是根本前提(下载一个CentOS镜像演示)</h3><p>docker pull centos</p>
<p><img src="/2019/02/28/docker个人总结/clip_image062.jpg" alt="img"></p>
<p>所以说<strong>可以把容器看做是一个简易版的</strong> <strong>Linux</strong> <strong>环境</strong></p>
<h3 id="6-3-2新建并启动容器"><a href="#6-3-2新建并启动容器" class="headerlink" title="6.3.2新建并启动容器"></a>6.3.2新建并启动容器</h3><p>docker run [OPTIONS] IMAGE [COMMAND] [ARG…]</p>
<p> OPTIONS说明</p>
<p>OPTIONS说明（常用）：有些是一个减号，有些是两个减号</p>
<p>–name=”容器新名字”: 为容器指定一个名称；</p>
<p>-d: 后台运行容器，并返回容器ID，也即启动守护式容器；</p>
<p>-i：以交互模式运行容器，通常与 -t 同时使用；</p>
<p>-t：为容器重新分配一个伪输入终端，通常与 -i 同时使用；</p>
<p>-P: 随机端口映射；</p>
<p>-p: 指定端口映射，有以下四种格式</p>
<pre><code>ip:hostPort:containerPort

ip::containerPort

hostPort:containerPort

containerPort
</code></pre><p>下面运行6.3.1中下载的centos</p>
<p><img src="/2019/02/28/docker个人总结/clip_image064.jpg" alt="img"></p>
<p><strong>启动交互式容器（跟下面我们所说的启动守护式容器有区别）</strong></p>
<p><img src="/2019/02/28/docker个人总结/clip_image066.jpg" alt="graphic"></p>
<p>#使用镜像centos:latest以交互模式启动一个容器,在容器内执行/bin/bash命令。</p>
<p><strong>docker run -it centos /bin/bash</strong> <strong>等同于</strong> <strong>docker run -it centos</strong></p>
<h4 id="案例演示"><a href="#案例演示" class="headerlink" title="案例演示"></a>案例演示</h4><p>1.从Hub上下载tomcat镜像到本地并成功运行</p>
<p>  （1）docker pull tomcat </p>
<p>  （2）docker run -it -p 8088:8080 tomcat </p>
<p>  运行tomcat，第一个端口8088表示docker对外暴露访问内部tomcat的端口，映射内部tomcat 的8080端口，什么意思呢？</p>
<p><img src="/2019/02/28/docker个人总结/clip_image068.jpg" alt="img"></p>
<p>查看运行的容器</p>
<p><img src="/2019/02/28/docker个人总结/clip_image070.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image072.jpg" alt="img"></p>
<p>访问tomcat成功，直接访问<a href="http://192.168.1.105:8080/" target="_blank" rel="external">http://49.234.188.74:8080/</a> 失败，因为我们知道，tomcat 是docker运行的一个容器，所以需要docker对外暴露后才能够访问。</p>
<p>（3）使用-P 不指名端口的方式运行tomcat</p>
<p><img src="/2019/02/28/docker个人总结/clip_image074.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image076.jpg" alt="img"></p>
<p>很明显使用大P的方式启动tomcat，docker会随机分配一个对外暴露的端口</p>
<p><img src="/2019/02/28/docker个人总结/clip_image078.jpg" alt="img"></p>
<h3 id="6-3-3列出当前所有正在运行的容器"><a href="#6-3-3列出当前所有正在运行的容器" class="headerlink" title="6.3.3列出当前所有正在运行的容器"></a>6.3.3列出当前所有正在运行的容器</h3><p>docker ps [OPTIONS]</p>
<p>OPTIONS说明（常用）：</p>
<p>-a :列出当前所有正在运行的容器+历史上运行过的</p>
<p>-l :显示最近创建的容器。</p>
<p>-n：显示最近n个创建的容器。</p>
<p>-q :静默模式，只显示容器编号。</p>
<p>–no-trunc :不截断输出。</p>
<p><strong>查看6.3.2</strong> <strong>运行的centos</strong></p>
<p><img src="/2019/02/28/docker个人总结/clip_image080.jpg" alt="img"></p>
<h3 id="6-3-4退出容器"><a href="#6-3-4退出容器" class="headerlink" title="6.3.4退出容器"></a>6.3.4退出容器</h3><h4 id="exit"><a href="#exit" class="headerlink" title="exit"></a>exit</h4><p>容器停止退出，销毁容器。<strong>注意，容器内的数据也会一并消失，类似java的对象，close销毁后就不会存在了。</strong></p>
<h4 id="ctrl-P-Q"><a href="#ctrl-P-Q" class="headerlink" title="ctrl+P+Q"></a>ctrl+P+Q</h4><p>容器不停止退出,回到宿主机。（<strong>那么怎么回到容器呢？-请看下面补充章节的第五小点</strong>）</p>
<h3 id="6-3-5启动容器"><a href="#6-3-5启动容器" class="headerlink" title="6.3.5启动容器"></a>6.3.5启动容器</h3><p>docker start 容器ID或者容器名 （可以启动已经关闭的容器）（docker ps –l 查看最近运行过得容器）</p>
<h3 id="6-3-6重启容器"><a href="#6-3-6重启容器" class="headerlink" title="6.3.6重启容器"></a>6.3.6重启容器</h3><p>docker restart 容器ID或者容器名</p>
<h3 id="6-3-7停止容器"><a href="#6-3-7停止容器" class="headerlink" title="6.3.7停止容器"></a>6.3.7停止容器</h3><p>docker stop 容器ID或者容器名</p>
<h3 id="6-3-8强制停止容器"><a href="#6-3-8强制停止容器" class="headerlink" title="6.3.8强制停止容器"></a>6.3.8强制停止容器</h3><p>docker kill 容器ID或者容器名</p>
<h3 id="6-3-9删除已停止的容器"><a href="#6-3-9删除已停止的容器" class="headerlink" title="6.3.9删除已停止的容器"></a>6.3.9删除已停止的容器</h3><p>docker rm 容器ID</p>
<p>一次性删除多个容器（下面两种方式）</p>
<p>docker rm -f $(docker ps -a -q)</p>
<p>docker ps -a -q | xargs docker rm</p>
<h3 id="6-3-10-迁移与备份"><a href="#6-3-10-迁移与备份" class="headerlink" title="6.3.10 迁移与备份"></a>6.3.10 迁移与备份</h3><p><img src="/2019/02/28/docker个人总结/clip_image082.jpg" alt="img"></p>
<h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><h4 id="启动守护式容器"><a href="#启动守护式容器" class="headerlink" title="启动守护式容器"></a>启动守护式容器</h4><p> 命令：docker run -d 容器名</p>
<p>   docker run -d centos       问题：然后docker ps -a 进行查看, <strong>会发现容器已经退出，也就是说没有刚才我们启动的容器</strong>       很重要的要说明的一点: <strong>Docker**</strong>容器后台运行<strong><strong>,</strong></strong>就必须有一个前台进程<strong>**.</strong>   <strong>容器运行的命令如果不是那些一直挂起的命令（比如运行**</strong>top<strong><strong>，</strong></strong>tail<strong>**），就是会自动退出的</strong>。       这个是docker的机制问题,比如你的web容器,我们以nginx为例，正常情况下,我们配置启动服务只需要启动响应的service即可。例如   service nginx start   但是,这样做,nginx为后台进程模式运行,就导致docker前台没有运行的应用,   这样的容器后台启动后,会立即自杀因为他觉得他没事可做了.   所以，最佳的解决方案是,将你要运行的程序以前台进程的形式运行   </p>
<h4 id="查看容器日志"><a href="#查看容器日志" class="headerlink" title="查看容器日志"></a>查看容器日志</h4><p>命令：docker logs -f -t –tail 容器ID</p>
<p> 参数解析：</p>
<p>*   -t 是加入时间戳</p>
<p>*   -f 跟随最新的日志打印</p>
<p>*   –tail 数字 显示最后多少条</p>
<p>例子：</p>
<p>  启动守护式容器（因为存在前台程序一直循环输出,那么他就不会退出）</p>
<p>docker run -d centos /bin/sh -c “while true;do echo hello kingge;sleep 2;done”</p>
<p><img src="/2019/02/28/docker个人总结/clip_image084.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image085.png" alt="img"></p>
<h4 id="查看容器内运行的进程"><a href="#查看容器内运行的进程" class="headerlink" title="查看容器内运行的进程"></a>查看容器内运行的进程</h4><p>docker top 容器ID</p>
<p><img src="/2019/02/28/docker个人总结/clip_image087.jpg" alt="img"></p>
<p>返回的信息时，上个例子中启动的守护式容器</p>
<h4 id="查看容器内部细节"><a href="#查看容器内部细节" class="headerlink" title="查看容器内部细节"></a>查看容器内部细节</h4><p>docker inspect 容器ID</p>
<p>返回一个json串的描述格式</p>
<p><img src="/2019/02/28/docker个人总结/clip_image089.jpg" alt="img"></p>
<h4 id="进入正在运行的容器并以命令行交互"><a href="#进入正在运行的容器并以命令行交互" class="headerlink" title="进入正在运行的容器并以命令行交互"></a>进入正在运行的容器并以命令行交互</h4><p><strong>回到以ctrl+p+q的方式退出的容器中</strong></p>
<p>第一种方式：</p>
<p>   使用命令：docker exec -it 容器ID bashShell （后面必须携带bash指令）</p>
<p><img src="/2019/02/28/docker个人总结/clip_image090.png" alt="img">登录操作</p>
<p>效果等同</p>
<p><img src="/2019/02/28/docker个人总结/clip_image091.png" alt="img"></p>
<p>例子2：</p>
<p><img src="/2019/02/28/docker个人总结/clip_image093.jpg" alt="img"></p>
<p><strong>打印后台启动的centos容器的根目录的消息，我们发现，他并没有进入后台的容器，只是把容器执行的指令的结果输出到宿主。所以他的功能是比docker attach指令还要强大的</strong></p>
<p>第二种方式：</p>
<pre><code>docker attach 容器ID
</code></pre><p>两种方式的区别：</p>
<p>attach 直接进入容器启动命令的终端，不会启动新的进程</p>
<p>exec 是在容器中打开新的终端，并且可以启动新的进程</p>
<h4 id="从容器内拷贝文件到主机上"><a href="#从容器内拷贝文件到主机上" class="headerlink" title="从容器内拷贝文件到主机上"></a>从容器内拷贝文件到主机上</h4><p><strong>宿主机上执行</strong></p>
<p>docker cp  容器ID:容器内路径 目的主机路径</p>
<h4 id="Docker镜像commit"><a href="#Docker镜像commit" class="headerlink" title="Docker镜像commit"></a>Docker镜像commit</h4><p>\1. commit提交容器副本使之成为一个新的镜像</p>
<p>docker commit -m=“提交的描述信息” -a=“作者” 容器ID 要创建的目标镜像名:[标签名]</p>
<h5 id="案例演示-1"><a href="#案例演示-1" class="headerlink" title="案例演示"></a>案例演示</h5><p>1.删除运行的tomcat 的文档模块，然后提交为新的镜像</p>
<p><img src="/2019/02/28/docker个人总结/clip_image095.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image097.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image099.jpg" alt="img"></p>
<p>这个时候再来访问tomcat容器的docs文档模块，肯定是404.</p>
<p><img src="/2019/02/28/docker个人总结/clip_image101.jpg" alt="img"></p>
<p>\2. 也即当前的tomcat运行实例是一个没有文档内容的容器，以它为模板commit一个没有doc的tomcat新镜像kingge/tomcatnodoc</p>
<p><img src="/2019/02/28/docker个人总结/clip_image103.jpg" alt="img"></p>
<p><strong>注意这个标红框的镜像id必须是某一个正在运行的容器id</strong></p>
<p><img src="/2019/02/28/docker个人总结/clip_image105.jpg" alt="img"></p>
<p>3.启动重新上传的tomcat</p>
<p><img src="/2019/02/28/docker个人总结/clip_image107.jpg" alt="img"></p>
<p>查看是否存在doc目录</p>
<p><img src="/2019/02/28/docker个人总结/clip_image108.png" alt="img"></p>
<p>不存在，说明这个版本就是我们亲自提交的删除文档的tomcat版本。</p>
<p><strong>这个时候可以同时启动原先的tomcat版本，查看区别。</strong></p>
<h2 id="命令图例"><a href="#命令图例" class="headerlink" title="命令图例"></a>命令图例</h2><p><img src="/2019/02/28/docker个人总结/clip_image110.jpg" alt="graphic"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image112.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image114.jpg" alt="img"></p>
<h1 id="七、Docker容器数据卷"><a href="#七、Docker容器数据卷" class="headerlink" title="七、Docker容器数据卷"></a>七、Docker容器数据卷</h1><p>生产环境中使用Docker的过程中，往往需要对数据进行持久化，或者需要在多个容器之间进行数据共享，这必然涉及容器的数据管理操作。</p>
<p> 卷就是目录或文件，存在于一个或多个容器中，由docker挂载到容器，但不属于联合文件系统，因此能够绕过Union File System提供一些用于持续存储或共享数据的特性.</p>
<p> 卷的设计目的就是数据的持久化，完全独立于容器的生存周期，因此Docker不会在容器删除时删除其挂载的数据卷.( 数据卷是一个可供容器使用的特殊目录，它将主机操作系统目录直接映射进容器，类似于Linux中的mount操作)</p>
<p>​       </p>
<p>特点：</p>
<p>1：数据卷可在容器之间共享或重用数据</p>
<p>2：卷中的更改可以直接生效</p>
<p>3：数据卷中的更改不会包含在镜像的更新中</p>
<p>4：数据卷的生命周期一直持续到没有容器使用它为止</p>
<p>容器中管理数据主要有两种方式：</p>
<p>\1.     <strong>数据卷（Data Volumes）</strong>：容器内数据<strong>直接映射</strong>到本地主机环境，如何在容器内创建数据卷，并且把本地的目录或文件挂载到容器内的数据卷中。</p>
<p>\2.     <strong>数据卷容器（Data Volume Containers）</strong>：使用特定容器维护数据卷。如何使用数据卷容器在容器和主机、容器和容器之间共享数据，并实现数据的备份和恢复。</p>
<h2 id="7-1-创建数据卷"><a href="#7-1-创建数据卷" class="headerlink" title="7.1 创建数据卷"></a>7.1 创建数据卷</h2><h3 id="7-1-1-第一种方式：使用命令直接添加"><a href="#7-1-1-第一种方式：使用命令直接添加" class="headerlink" title="7.1.1 第一种方式：使用命令直接添加"></a>7.1.1 第一种方式：使用命令直接添加</h3><p>命令： docker run -it -v /宿主机绝对路径目录:/容器内目录 镜像名</p>
<pre><code>就是把宿主机的某个目录关联到容器中，两者数据共通（文件夹不存在时，自动创建）
</code></pre><p>1.使用命令创建数据卷</p>
<p><img src="/2019/02/28/docker个人总结/clip_image115.png" alt="img"></p>
<p>宿主机也创建了myHostVal目录</p>
<p><img src="/2019/02/28/docker个人总结/clip_image116.png" alt="img"></p>
<p>2.校验是否数据共通</p>
<p><img src="/2019/02/28/docker个人总结/clip_image117.png" alt="img">宿主机创建一个文本</p>
<p>查看容器是否存在hello.txt</p>
<p><img src="/2019/02/28/docker个人总结/clip_image118.png" alt="img">容器存在。</p>
<p>反之，容器创建一个文件，宿主机也会出现同样的文件。</p>
<p>尖叫提示：</p>
<p><strong>Docker挂载数据卷的默认权限是读写（rw），用户也可以通过ro指定为只读</strong></p>
<p>\3.     极端测试</p>
<p>  容器停止退出后（exit），宿主机创建或者修改文件，再重启容器（start），查看宿主机创建或者修改的文件是否有相应的变化。</p>
<p>  经测试，答案是会有相应的变化。</p>
<p>4.查看容器的内部细节</p>
<p>docker inspect 容器ID</p>
<p>   返回的json串中可以找到这样的一行描述</p>
<p><img src="/2019/02/28/docker个人总结/clip_image119.png" alt="img"></p>
<p>5.容器挂载文件夹的读写方式</p>
<p>docker run -it -v /宿主机绝对路径目录:/容器内目录:ro 镜像名</p>
<p><img src="/2019/02/28/docker个人总结/clip_image120.png" alt="img"></p>
<p>经过操作我们发现，宿主机创建或者修改的文件都能够同步到容器中，但是在容器中只能够查看对应的宿主机同步过来的文件，容器中不能够新增删除修改文件，只能够查看。</p>
<p>再次使用inspect 命令查看挂载的状态</p>
<p><img src="/2019/02/28/docker个人总结/clip_image121.png" alt="img"></p>
<p>发现可读写方式变为false，只读。</p>
<h3 id="7-1-2-第二种方式：DockerFile方式添加"><a href="#7-1-2-第二种方式：DockerFile方式添加" class="headerlink" title="7.1.2 第二种方式：DockerFile方式添加"></a>7.1.2 第二种方式：DockerFile方式添加</h3><p>DockerFile就是对于一个镜像的描述文件，类似于java代码编译后形成的.class文件，他是关于一个java类的描述。</p>
<h4 id="1初探dockerfile结构"><a href="#1初探dockerfile结构" class="headerlink" title="1初探dockerfile结构"></a>1初探dockerfile结构</h4><p>打开docker hub，随便查看一个tomcat版本的dockerfile</p>
<p><img src="/2019/02/28/docker个人总结/clip_image123.jpg" alt="img"></p>
<p>打开后得到下面的代码，下面就是</p>
<p><img src="/2019/02/28/docker个人总结/clip_image125.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image126.png" alt="img"></p>
<p>这个dockerfile文件很好的阐述了tomcat镜像文件为什么这么大，而且为什么我们能够访问8080端口。</p>
<p>查看centos的dockerfile镜像描述文件</p>
<p><img src="/2019/02/28/docker个人总结/clip_image128.jpg" alt="img"></p>
<h4 id="2-创建数据卷"><a href="#2-创建数据卷" class="headerlink" title="2.创建数据卷"></a>2.创建数据卷</h4><p>可在Dockerfile中使用<strong>VOLUME</strong>指令来给镜像添加一个或多个数据卷</p>
<p>VOLUME[“/dataVolumeContainer”,”/dataVolumeContainer2”,”/dataVolumeContainer3”]</p>
<p>说明：</p>
<p>出于可移植和分享的考虑，用-v 主机目录:容器目录这种方法不能够直接在Dockerfile中实现。</p>
<p>由于宿主机目录是依赖于特定宿主机的，并不能够保证在所有的宿主机上都存在这样的特定目录。（<strong>意思就是说容器中数据卷在linux01宿主机上关联的目录是myvolume1，但是如果该镜像在linux02宿主机上运行，那么容器容器启动后，可能找不到关联的myvolume1，因为你不能够保证linux02宿主机的相关目录结构是跟linux01一样的，所以使用dockerfile的方式创建数据卷的时候，单方面的指定容器中数据卷目录位置，容器启动后，会帮我们自动创建相关联的宿主机的目录</strong>）</p>
<p>   <strong>也就是说，VOLUME命令只能够单方面的在容器中创建数据卷，不能够指明对应宿主机关联的目录（但是他会自动在宿主机创建相关联的目录）</strong></p>
<p>\1.     宿主机创建dockerfile文件，依赖已经存在的centos镜像。</p>
<p>也就是说我们以现有的centos为某一层创建一个新的镜像（符合UnionFS）</p>
<p> 在宿主机创建一个文件夹，存放创建的dockerfile文件</p>
<pre><code>![img](docker个人总结\clip_image129.png)
</code></pre><p> 新建的dockerfile文件dc。内容</p>
<p><img src="/2019/02/28/docker个人总结/clip_image130.png" alt="img"></p>
<p>\2.     根据dockerfile文件dc，构建新镜像</p>
<p><img src="/2019/02/28/docker个人总结/clip_image132.jpg" alt="img"></p>
<p>Docker images 查看现存在的镜像</p>
<p><img src="/2019/02/28/docker个人总结/clip_image134.jpg" alt="img"></p>
<p>启动我们创建的centos镜像</p>
<p><img src="/2019/02/28/docker个人总结/clip_image136.jpg" alt="img"></p>
<p>确实主动给我们创建了两个数据卷，那么他们关联的宿主机的目录是什么呢？</p>
<p>  使用docekr inspect命令查看</p>
<p><img src="/2019/02/28/docker个人总结/clip_image138.jpg" alt="img"></p>
<h2 id="7-2数据卷容器"><a href="#7-2数据卷容器" class="headerlink" title="7.2数据卷容器"></a>7.2数据卷容器</h2><p>使用特定容器维护数据卷。7.1中使用的数据卷的方式是宿主机直接映射到容器进行数据传输，但是如果我们想两个容器之间共享传递数据怎么办呢？</p>
<p>就需要创建数据卷容器</p>
<h3 id="7-2-1先启动一个父容器dc01"><a href="#7-2-1先启动一个父容器dc01" class="headerlink" title="7.2.1先启动一个父容器dc01"></a>7.2.1先启动一个父容器dc01</h3><p>以上一步新建的镜像kingge/centos为模板并运行容器dc01</p>
<p><img src="/2019/02/28/docker个人总结/clip_image139.png" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image141.jpg" alt="img"></p>
<p>在创建容器卷dataVolumeContainer2新增内容，touch hello1.txt</p>
<h3 id="7-2-2-创建dc02、03继承自dc01"><a href="#7-2-2-创建dc02、03继承自dc01" class="headerlink" title="7.2.2 创建dc02、03继承自dc01"></a>7.2.2 创建dc02、03继承自dc01</h3><p>使用–volumes-from关键命令</p>
<p><img src="/2019/02/28/docker个人总结/clip_image142.png" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image144.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image146.jpg" alt="img"></p>
<p>在dc02、03的dataVolumeContainer2目录下查看是否存在dc01创建的hello1txt，很明显是可以看到的。</p>
<h3 id="7-2-3测试数据共通性"><a href="#7-2-3测试数据共通性" class="headerlink" title="7.2.3测试数据共通性"></a>7.2.3测试数据共通性</h3><p>1.dc02/dc03分别在dataVolumeContainer2各自新增内容，touch hello2.txt和touch hello3.txt</p>
<p>分别查看dc01 dc02 dc03的dataVolumeContainer2目录下是否存在hello1.txt hello2.txt hello3.txt 这三个文件，答案是：<strong>都存在这三个文件</strong></p>
<p>\2. 删除dc01，dc02修改后dc03可否访问</p>
<p><img src="/2019/02/28/docker个人总结/clip_image148.jpg" alt="img"></p>
<p>答案很明显是存在的，也就是说删除dc01并不会影响dc02和dc03的数据互通</p>
<p><strong>结论：容器之间配置信息的传递，数据卷的生命周期一直持续到没有容器使用它为止</strong></p>
<h1 id="八、DockerFile解析"><a href="#八、DockerFile解析" class="headerlink" title="八、DockerFile解析"></a>八、DockerFile解析</h1><h2 id="8-1-dockerfile概念"><a href="#8-1-dockerfile概念" class="headerlink" title="8.1 dockerfile概念"></a>8.1 dockerfile概念</h2><p>Dockerfile是用来构建Docker镜像的构建文件，是由一系列命令和参数构成的脚本。通过：编写Dockerfile文件-&gt; docker build -&gt; docker run，生成一个镜像文件</p>
<p>查看centos的dockerfile镜像描述文件</p>
<p><img src="/2019/02/28/docker个人总结/clip_image149.jpg" alt="img"></p>
<p>1：每条保留字指令都必须为大写字母且后面要跟随至少一个参数</p>
<p>2：指令按照从上到下，顺序执行</p>
<p>3：#表示注释</p>
<p>4：每条指令都会创建一个新的镜像层，并对镜像进行提交</p>
<p>（1）docker从基础镜像运行一个容器（from scratch）</p>
<p>（2）执行一条指令并对容器作出修改</p>
<p>（3）执行类似docker commit的操作提交一个新的镜像层</p>
<p>（4）docker再基于刚提交的镜像运行一个新容器</p>
<p>（5）执行dockerfile中的下一条指令直到所有指令都执行完成</p>
<p>从应用软件的角度来看，Dockerfile、Docker镜像与Docker容器分别代表软件的三个不同阶段，</p>
<p>*  Dockerfile是软件的原材料</p>
<p>*  Docker镜像是软件的交付品</p>
<p>*  Docker容器则可以认为是软件的运行态。</p>
<p>Dockerfile面向开发，Docker镜像成为交付标准，Docker容器则涉及部署与运维，三者缺一不可，合力充当Docker体系的基石。</p>
<p><img src="/2019/02/28/docker个人总结/clip_image151.jpg" alt="graphic"></p>
<p>1 Dockerfile，需要定义一个Dockerfile，Dockerfile定义了进程需要的一切东西。Dockerfile涉及的内容包括执行代码或者是文件、环境变量、依赖包、运行时环境、动态链接库、操作系统的发行版、服务进程和内核进程(当应用进程需要和系统服务和内核进程打交道，这时需要考虑如何设计namespace的权限控制)等等;</p>
<p>2 Docker镜像，在用Dockerfile定义一个文件之后，docker build时会产生一个Docker镜像，当运行 Docker镜像时，会真正开始提供服务;</p>
<p>3 Docker容器，容器是直接提供服务的。</p>
<p><strong>尖叫提示</strong>：Docker Hub 中 99% 的镜像都是通过在 base 镜像中安装和配置需要的软件构建出来的<img src="/2019/02/28/docker个人总结/clip_image152.png" alt="img"></p>
<h2 id="8-2-dockerfile指令（保留字指令）"><a href="#8-2-dockerfile指令（保留字指令）" class="headerlink" title="8.2 dockerfile指令（保留字指令）"></a>8.2 dockerfile指令（保留字指令）</h2><h3 id="FROM"><a href="#FROM" class="headerlink" title="FROM"></a>FROM</h3><pre><code>基础镜像，当前新镜像是基于哪个镜像的
</code></pre><h3 id="MAINTAINER"><a href="#MAINTAINER" class="headerlink" title="MAINTAINER"></a>MAINTAINER</h3><pre><code>镜像维护者的姓名和邮箱地址
</code></pre><h3 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h3><pre><code>容器构建时需要运行的命令
</code></pre><h3 id="EXPOSE"><a href="#EXPOSE" class="headerlink" title="EXPOSE"></a>EXPOSE</h3><pre><code>当前容器对外暴露出的端口
</code></pre><h3 id="WORKDIR"><a href="#WORKDIR" class="headerlink" title="WORKDIR"></a>WORKDIR</h3><p>指定在创建容器后，终端默认登陆的进来工作目录，一个落脚点</p>
<p><img src="/2019/02/28/docker个人总结/clip_image154.jpg" alt="img"></p>
<h3 id="ENV"><a href="#ENV" class="headerlink" title="ENV"></a>ENV</h3><pre><code>用来在构建镜像过程中设置环境变量
</code></pre><h3 id="ADD"><a href="#ADD" class="headerlink" title="ADD"></a>ADD</h3><pre><code>将宿主机目录下的文件拷贝进镜像且ADD命令会自动处理URL和**解压tar压缩包**
</code></pre><h3 id="COPY"><a href="#COPY" class="headerlink" title="COPY"></a>COPY</h3><p>类似ADD，拷贝文件和目录到镜像中。 将从构建上下文目录中 &lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的 &lt;目标路径&gt; 位置，<strong>没有解压功能</strong></p>
<p>COPY src dest</p>
<p>COPY [“src”, “dest”]</p>
<h3 id="VOLUME"><a href="#VOLUME" class="headerlink" title="VOLUME"></a>VOLUME</h3><pre><code>容器数据卷，用于数据保存和持久化工作
</code></pre><h3 id="CMD"><a href="#CMD" class="headerlink" title="CMD"></a>CMD</h3><pre><code>指定一个容器启动时要运行的命令
</code></pre><p><strong>Dockerfile</strong> <strong>中可以有多个</strong> <strong>CMD</strong> <strong>指令，但只有最后一个生效，CMD</strong> <strong>会被</strong> <strong>docker run</strong> <strong>之后的参数替换（跟</strong>ENTRYPOINT指令的区别）</p>
<p>举个例子，查看tomcat 的dockerfile文件，我们可以发现最后是通过cmd命令启动了tomcat<img src="/2019/02/28/docker个人总结/clip_image155.png" alt="img">。那么为了证明CMD会不会被docker run后面的参数替换，请看下面例子。</p>
<p><img src="/2019/02/28/docker个人总结/clip_image157.jpg" alt="img"></p>
<h3 id="ENTRYPOINT"><a href="#ENTRYPOINT" class="headerlink" title="ENTRYPOINT"></a>ENTRYPOINT</h3><pre><code>指定一个容器启动时要运行的命令
</code></pre><p>ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数，但是他是以追加的形式而不是覆盖</p>
<p>docker run 之后的参数会被当做参数传递给 ENTRYPOINT，之后形成新的命令组合</p>
<h3 id="ONBUILD"><a href="#ONBUILD" class="headerlink" title="ONBUILD"></a>ONBUILD</h3><p>当构建一个被继承的Dockerfile时运行命令，父镜像在被子继承后父镜像的onbuild被触发</p>
<p><img src="/2019/02/28/docker个人总结/clip_image158.png" alt="img"></p>
<p>  小总结</p>
<p><img src="/2019/02/28/docker个人总结/clip_image160.jpg" alt="graphic"></p>
<h2 id="8-3-案例"><a href="#8-3-案例" class="headerlink" title="8.3 案例"></a>8.3 案例</h2><h3 id="案例一"><a href="#案例一" class="headerlink" title="案例一"></a>案例一</h3><p>需求：修改默认的centos，修改他的落脚点（默认运行centos后容器进入的根目录）和添加vim指令、ifconfig（默认centos镜像没有安装这两个组件）</p>
<p><img src="/2019/02/28/docker个人总结/clip_image162.jpg" alt="img"></p>
<p>\1.     创建dockefile镜像描述文件</p>
<p><img src="/2019/02/28/docker个人总结/clip_image163.png" alt="img"></p>
<p>内容是</p>
<p><img src="/2019/02/28/docker个人总结/clip_image165.jpg" alt="img"></p>
<p>   FROM centos   MAINTAINER kingge<a href="&#109;&#x61;&#x69;&#x6c;&#x74;&#111;&#58;&#51;&#57;&#51;&#x32;&#49;&#53;&#x36;&#x36;&#49;&#64;&#113;&#x71;&#46;&#99;&#x6f;&#109;">&#51;&#57;&#51;&#x32;&#49;&#53;&#x36;&#x36;&#49;&#64;&#113;&#x71;&#46;&#99;&#x6f;&#109;</a>       ENV MYPATH /usr/local   WORKDIR $MYPATH       RUN yum -y install vim   RUN yum -y install net-tools       EXPOSE 80       CMD echo $MYPATH   CMD echo “success————–ok”   CMD /bin/bash   </p>
<p>\2. 根据创建的Dockerfile构建镜像</p>
<p>docker build -t 新镜像名字:TAG . （注意这里还有一个点，表示当前文件夹）</p>
<p>默认去找当前目录下名字为Dockerfile的文件构建镜像。</p>
<p>也可以用这个命令指定dockerfile：</p>
<p>docker build -f /mydockerfile/Dockerfile -t kingge/mycentos:1.1 .</p>
<p><img src="/2019/02/28/docker个人总结/clip_image166.png" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image168.jpg" alt="img"></p>
<p>很明显跟原先从docker hub上拉取下来的centos多个两百多M，因为我们安装了vim和net-tools指令。</p>
<p>\3. 列出镜像的变更历史</p>
<pre><code>docker history 镜像名（imagesid）
</code></pre><p><img src="/2019/02/28/docker个人总结/clip_image170.jpg" alt="img"></p>
<p>可以看到构建这个镜像的每一层相关的操作。</p>
<p>4.运行构建的镜像</p>
<p><img src="/2019/02/28/docker个人总结/clip_image171.png" alt="img"></p>
<p>可以看到容器登陆后落脚点变更为了我们设定的/usr/local，同时也支持了vim 和ifconfig命令。</p>
<p><img src="/2019/02/28/docker个人总结/clip_image173.jpg" alt="img"></p>
<h3 id="案例2"><a href="#案例2" class="headerlink" title="案例2"></a>案例2</h3><p>通过自定义一个tomcat的方式我们来使用一些dockerfile常用的指令</p>
<h4 id="2-1-新建一个工作目录"><a href="#2-1-新建一个工作目录" class="headerlink" title="2.1 新建一个工作目录"></a>2.1 新建一个工作目录</h4><p><img src="/2019/02/28/docker个人总结/clip_image174.png" alt="img"></p>
<p>存放待传输到容器中的压缩包（测试ADD命令专用）和一个文本文件（测试COPY指令专用）</p>
<h4 id="2-2-根据原版centos新建Dockerfile文件"><a href="#2-2-根据原版centos新建Dockerfile文件" class="headerlink" title="2.2 根据原版centos新建Dockerfile文件"></a>2.2 根据原版centos新建Dockerfile文件</h4><p><img src="/2019/02/28/docker个人总结/clip_image175.png" alt="img"></p>
<p>内容是：</p>
<p>   FROM         centos   MAINTAINER      kingge<a href="&#x6d;&#97;&#x69;&#x6c;&#116;&#111;&#58;&#51;&#x39;&#x33;&#50;&#x31;&#53;&#54;&#54;&#x31;&#x40;&#x71;&#113;&#46;&#99;&#111;&#109;">&#51;&#x39;&#x33;&#50;&#x31;&#53;&#54;&#54;&#x31;&#x40;&#x71;&#113;&#46;&#99;&#111;&#109;</a>   #把宿主机当前上下文的hello.txt拷贝到容器/usr/local/路径下   #并重命名为helloNewName.txt   COPY hello.txt /usr/local/helloNewName.txt   #把java与tomcat添加到容器中   ADD jdk-8u144-linux-x64.tar.gz /usr/local/   ADD apache-tomcat-9.0.21.tar.gz /usr/local/   #安装vim编辑器   RUN yum -y install vim   #设置工作访问时候的WORKDIR路径，登录落脚点   ENV MYPATH /usr/local   WORKDIR $MYPATH   #配置java与tomcat环境变量   ENV JAVA_HOME /usr/local/jdk1.8.0_144   ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar   ENV CATALINA_HOME /usr/local/apache-tomcat-9.0.21   ENV CATALINA_BASE /usr/local/apache-tomcat-9.0.21   ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin   #容器运行时监听的端口   EXPOSE  8080   #启动时运行tomcat   # ENTRYPOINT   [“/usr/local/apache-tomcat-9.0.21/bin/startup.sh” ]   # CMD   [“/usr/local/apache-tomcat-9.0.21/bin/catalina.sh”,”run”]   CMD /usr/local/apache-tomcat-9.0.21/bin/startup.sh &amp;&amp; tail -F   /usr/local/apache-tomcat-9.0.21/bin/logs/catalina.out   </p>
<h4 id="2-3-构建"><a href="#2-3-构建" class="headerlink" title="2.3 构建"></a>2.3 构建</h4><p><img src="/2019/02/28/docker个人总结/clip_image177.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image179.jpg" alt="img"></p>
<p>构建完成</p>
<h4 id="2-4-执行（RUN）"><a href="#2-4-执行（RUN）" class="headerlink" title="2.4 执行（RUN）"></a>2.4 执行（RUN）</h4><p>   docker run -d -p 9080:8080 –name myt9 -v   /mydockerfile/mytomcat/tomcat9/project:/usr/local/apache-tomcat-9.0.21/webapps/project   -v /mydockerfile/mytomcat/tomcat9/logs/:/usr/local/apache-tomcat-9.0.21/logs   –privileged=true mytomcat921   </p>
<p>命令的意思是：后台执行tomcat镜像，docker对外暴露8080端口，外部可以通过9080端口访问docker容器的8080端口。</p>
<p><strong>–name</strong>：启动的容器重命名为myt9 </p>
<p><strong>-v</strong>：新建两个数据卷</p>
<p><strong>–privileged=true</strong>: Docker挂载主机目录Docker访问出现cannot open directory .: Permission denied解决办法：在挂载目录后多加一个–privileged=true参数即可</p>
<p><img src="/2019/02/28/docker个人总结/clip_image181.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image183.jpg" alt="img"></p>
<p>启动成功</p>
<h4 id="2-5-验证"><a href="#2-5-验证" class="headerlink" title="2.5 验证"></a>2.5 验证</h4><p>1.首先验证两个tar包是否已经上传到容器并解压成功，hello.txt文件是否已经copy到容器、容器登录后落脚点是否是在我们设置的/usr/local</p>
<p><img src="/2019/02/28/docker个人总结/clip_image184.png" alt="img"></p>
<p>2.查看数据卷是否创建成功</p>
<p>宿主机对应数据卷创建成功</p>
<p><img src="/2019/02/28/docker个人总结/clip_image185.png" alt="img"></p>
<p>容器数据卷创建成功，project出现</p>
<p><img src="/2019/02/28/docker个人总结/clip_image187.jpg" alt="img"></p>
<p>3.校验数据卷</p>
<p><img src="/2019/02/28/docker个人总结/clip_image189.jpg" alt="img"></p>
<h4 id="2-6-部署项目"><a href="#2-6-部署项目" class="headerlink" title="2.6 部署项目"></a>2.6 部署项目</h4><p>因为我们在创建数据卷的时候：</p>
<p>/mydockerfile/mytomcat/tomcat9/project:/usr/local/apache-tomcat-9.0.21/webapps/project</p>
<p>宿主机的/tomcat9/project目录映射到了容器的webapps/project目录，那么可以利用数据卷的数据共通原理。在宿主机的project目录上传一个项目，然后重启容器，那么就可以实现项目的发布。</p>
<p>上传解压后的项目文件</p>
<p><img src="/2019/02/28/docker个人总结/clip_image190.png" alt="img"></p>
<p>很明显会自动同步到容器的webapps/project目录下</p>
<p><img src="/2019/02/28/docker个人总结/clip_image192.jpg" alt="img"></p>
<p>重启容器</p>
<p><img src="/2019/02/28/docker个人总结/clip_image193.png" alt="img"></p>
<p>访问项目</p>
<p><img src="/2019/02/28/docker个人总结/clip_image194.png" alt="img"></p>
<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p><img src="/2019/02/28/docker个人总结/clip_image196.jpg" alt="graphic"></p>
<h1 id="九、常用插件安装"><a href="#九、常用插件安装" class="headerlink" title="九、常用插件安装"></a>九、常用插件安装</h1><p><a href="https://www.runoob.com/docker/docker-install-mysql.html" target="_blank" rel="external">https://www.runoob.com/docker/docker-install-mysql.html</a></p>
<h2 id="9-1总体步骤"><a href="#9-1总体步骤" class="headerlink" title="9.1总体步骤"></a>9.1总体步骤</h2><p>搜索镜像、拉取镜像、查看镜像、启动镜像、停止容器、移除容器</p>
<h2 id="9-2-tomcat安装"><a href="#9-2-tomcat安装" class="headerlink" title="9.2 tomcat安装"></a>9.2 tomcat安装</h2><h3 id="9-2-1-docker-hub上面查找tomcat镜像"><a href="#9-2-1-docker-hub上面查找tomcat镜像" class="headerlink" title="9.2.1 docker hub上面查找tomcat镜像"></a>9.2.1 docker hub上面查找tomcat镜像</h3><p>  docker search tomcat</p>
<p><img src="/2019/02/28/docker个人总结/clip_image198.jpg" alt="img"></p>
<p>  或者直接使用浏览器登录docker hub查找也可以</p>
<h3 id="9-2-2-从docker-hub上拉取tomcat镜像到本地"><a href="#9-2-2-从docker-hub上拉取tomcat镜像到本地" class="headerlink" title="9.2.2 从docker hub上拉取tomcat镜像到本地"></a>9.2.2 从docker hub上拉取tomcat镜像到本地</h3><p>  docker pull tomcat</p>
<h3 id="9-2-3-docker-images查看是否有拉取到的tomcat"><a href="#9-2-3-docker-images查看是否有拉取到的tomcat" class="headerlink" title="9.2.3 docker images查看是否有拉取到的tomcat"></a>9.2.3 docker images查看是否有拉取到的tomcat</h3><p><img src="/2019/02/28/docker个人总结/clip_image200.jpg" alt="img"></p>
<p>为什么拉取下来的tomcat有五百多M?上面文章已经做了解释（因为里面包含了jdk等等，这个也就是为什么我们可以直接运行tomcat镜像而不用配置jdk环境的原因）</p>
<h3 id="9-2-4-使用tomcat镜像创建容器-也叫运行镜像"><a href="#9-2-4-使用tomcat镜像创建容器-也叫运行镜像" class="headerlink" title="9.2.4 使用tomcat镜像创建容器(也叫运行镜像)"></a>9.2.4 使用tomcat镜像创建容器(也叫运行镜像)</h3><p>  docker run -it -p 8080:8080 tomcat</p>
<pre><code>-p 主机端口:docker容器端口

-P 随机分配端口

i:交互

t:终端
</code></pre><h2 id="9-3安装mysql"><a href="#9-3安装mysql" class="headerlink" title="9.3安装mysql"></a>9.3安装mysql</h2><p><a href="https://hub.docker.com/_/mysql" target="_blank" rel="external">https://hub.docker.com/_/mysql</a>  官网文档</p>
<h3 id="9-3-1-docker-hub上面查找mysql镜像"><a href="#9-3-1-docker-hub上面查找mysql镜像" class="headerlink" title="9.3.1 docker hub上面查找mysql镜像"></a>9.3.1 docker hub上面查找mysql镜像</h3><h3 id="9-3-2-从docker-hub上-阿里云加速器-拉取mysql镜像到本地标签为5-6"><a href="#9-3-2-从docker-hub上-阿里云加速器-拉取mysql镜像到本地标签为5-6" class="headerlink" title="9.3.2 从docker hub上(阿里云加速器)拉取mysql镜像到本地标签为5.6"></a>9.3.2 从docker hub上(阿里云加速器)拉取mysql镜像到本地标签为5.6</h3><p><img src="/2019/02/28/docker个人总结/clip_image202.jpg" alt="img"></p>
<h3 id="9-3-3-使用mysql5-6镜像创建容器-也叫运行镜像"><a href="#9-3-3-使用mysql5-6镜像创建容器-也叫运行镜像" class="headerlink" title="9.3.3 使用mysql5.6镜像创建容器(也叫运行镜像)"></a>9.3.3 使用mysql5.6镜像创建容器(也叫运行镜像)</h3><p>   docker run -p 12345:3306 –name mysql    -v  /kingge/mysql/conf:/etc/mysql/conf.d      -v / kingge /mysql/logs:/logs    -v / kingge /mysql/data:/var/lib/mysql    -e MYSQL_ROOT_PASSWORD=123456   -d mysql:5.6   </p>
<p>   命令说明：   -p 12345:3306：将主机的12345端口映射到docker容器的3306端口。   –name mysql：运行服务名字   -v / kingge /mysql/conf:/etc/mysql/conf.d ：将主机/ kingge /mysql录下的conf/my.cnf 挂载到容器的   /etc/mysql/conf.d   -v / kingge /mysql/logs:/logs：将主机/ kingge /mysql目录下的 logs 目录挂载到容器的 /logs。   -v / kingge /mysql/data:/var/lib/mysql ：将主机/ kingge /mysql目录下的data目录挂载到容器的 /var/lib/mysql      -e MYSQL_ROOT_PASSWORD=123456：初始化 root 用户的密码。   -d mysql:5.6 : 后台程序运行mysql5.6   </p>
<p><img src="/2019/02/28/docker个人总结/clip_image204.jpg" alt="img"></p>
<p>登录测试</p>
<p>docker exec -it  954efcffa04d /bin/bash</p>
<p><img src="/2019/02/28/docker个人总结/clip_image206.jpg" alt="img"></p>
<p>成功</p>
<p><img src="/2019/02/28/docker个人总结/clip_image208.jpg" alt="img"></p>
<p>外部软件连接成功</p>
<h2 id="9-4-安装redis"><a href="#9-4-安装redis" class="headerlink" title="9.4 安装redis"></a>9.4 安装redis</h2><h3 id="9-4-1-从docker-hub上-阿里云加速器-拉取redis镜像到本地标签为3-2"><a href="#9-4-1-从docker-hub上-阿里云加速器-拉取redis镜像到本地标签为3-2" class="headerlink" title="9.4.1 从docker hub上(阿里云加速器)拉取redis镜像到本地标签为3.2"></a>9.4.1 从docker hub上(阿里云加速器)拉取redis镜像到本地标签为3.2</h3><p><img src="/2019/02/28/docker个人总结/clip_image209.png" alt="img"></p>
<h3 id="9-4-2-使用redis3-2镜像创建容器-也叫运行镜像"><a href="#9-4-2-使用redis3-2镜像创建容器-也叫运行镜像" class="headerlink" title="9.4.2 使用redis3.2镜像创建容器(也叫运行镜像)"></a>9.4.2 使用redis3.2镜像创建容器(也叫运行镜像)</h3><p>   docker run -p 6379:6379 -v   /kingge/myredis/data:/data -v   /kingge/myredis/conf/redis.conf:/usr/local/etc/redis/redis.conf  -d redis:3.2 redis-server   /usr/local/etc/redis/redis.conf –appendonly yes   </p>
<p><img src="/2019/02/28/docker个人总结/clip_image211.jpg" alt="img"></p>
<p><strong>这个时候可以直接连接redis了：</strong></p>
<p>命令：docker exec -it 运行着Rediis服务的容器ID redis-cli</p>
<p><img src="/2019/02/28/docker个人总结/clip_image212.png" alt="img"></p>
<p><strong>设置redis配置文件：</strong></p>
<p>  在主机/kingge/myredis/conf/redis.conf目录下新建redis.conf文件 vim / kingge /myredis/conf/redis.conf/redis.conf</p>
<p>Accept connections on the specified port, default is 6379 (IANA   #815344).   # If port 0 is specified Redis will not listen on a TCP socket.   port 6379   。。。。省略   </p>
<p><strong>测试持久化文件生成</strong></p>
<p><img src="/2019/02/28/docker个人总结/clip_image214.jpg" alt="img"></p>
<h1 id="十、本地镜像发布到阿里云"><a href="#十、本地镜像发布到阿里云" class="headerlink" title="十、本地镜像发布到阿里云"></a>十、本地镜像发布到阿里云</h1><p><img src="/2019/02/28/docker个人总结/clip_image216.jpg" alt="graphic"></p>
<h2 id="1-镜像生成方式"><a href="#1-镜像生成方式" class="headerlink" title="1.镜像生成方式"></a>1.镜像生成方式</h2><p>（1）使用DockerFile的方式创建镜像</p>
<p>（2）根据运行的容器创建一个新的镜像 docker commit [OPTIONS] 容器ID [REPOSITORY[:TAG]] （参见6.3章节的补充模块的Docker镜像commit）</p>
<h2 id="2-将本地镜像推送到阿里云"><a href="#2-将本地镜像推送到阿里云" class="headerlink" title="2. 将本地镜像推送到阿里云"></a>2. 将本地镜像推送到阿里云</h2><h3 id="2-1-登录阿里云，创建镜像仓库"><a href="#2-1-登录阿里云，创建镜像仓库" class="headerlink" title="2.1 登录阿里云，创建镜像仓库"></a>2.1 登录阿里云，创建镜像仓库</h3><p><a href="https://cr.console.aliyun.com/cn-hangzhou/instances/repositories" target="_blank" rel="external">https://cr.console.aliyun.com/cn-hangzhou/instances/repositories</a></p>
<p><img src="/2019/02/28/docker个人总结/clip_image218.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image220.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image222.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image224.jpg" alt="img"></p>
<h3 id="2-2-创建命名空间"><a href="#2-2-创建命名空间" class="headerlink" title="2.2 创建命名空间"></a>2.2 创建命名空间</h3><p><img src="/2019/02/28/docker个人总结/clip_image225.png" alt="img"></p>
<h3 id="2-3-点击镜像仓库的管理"><a href="#2-3-点击镜像仓库的管理" class="headerlink" title="2.3 点击镜像仓库的管理"></a>2.3 点击镜像仓库的管理</h3><p><img src="/2019/02/28/docker个人总结/clip_image227.jpg" alt="img"></p>
<p>可以获取推送镜像到阿里云仓库的地址</p>
<p><img src="/2019/02/28/docker个人总结/clip_image229.jpg" alt="img"></p>
<p>   $ sudo docker login –username=393215661@qq.com   registry.cn-hangzhou.aliyuncs.com   $ sudo docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/kingge/myrepo:[镜像版本号]   $ sudo docker push registry.cn-hangzhou.aliyuncs.com/kingge/myrepo:[镜像版本号]   </p>
<h3 id="2-4-推送镜像到阿里云"><a href="#2-4-推送镜像到阿里云" class="headerlink" title="2.4 推送镜像到阿里云"></a>2.4 推送镜像到阿里云</h3><p>首先进行登录</p>
<p><img src="/2019/02/28/docker个人总结/clip_image231.jpg" alt="img"></p>
<p>标记我们需要上传的镜像</p>
<p><img src="/2019/02/28/docker个人总结/clip_image233.jpg" alt="img"></p>
<p>开始推送</p>
<p><img src="/2019/02/28/docker个人总结/clip_image235.jpg" alt="img"></p>
<p>推送成功</p>
<p><img src="/2019/02/28/docker个人总结/clip_image237.jpg" alt="img"></p>
<h3 id="2-5-查看是否推送成功"><a href="#2-5-查看是否推送成功" class="headerlink" title="2.5 查看是否推送成功"></a>2.5 查看是否推送成功</h3><p><img src="/2019/02/28/docker个人总结/clip_image239.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image241.jpg" alt="img"></p>
<h3 id="2-6-从阿里云下载我们推送的镜像"><a href="#2-6-从阿里云下载我们推送的镜像" class="headerlink" title="2.6 从阿里云下载我们推送的镜像"></a>2.6 从阿里云下载我们推送的镜像</h3><p><img src="/2019/02/28/docker个人总结/clip_image243.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image245.jpg" alt="img"></p>
<h1 id="十一、新建本地仓库"><a href="#十一、新建本地仓库" class="headerlink" title="十一、新建本地仓库"></a>十一、新建本地仓库</h1><p>   本质就是通过一个名字为registry的镜像，构建仓库</p>
<p>（1）拉取私有仓库镜像 </p>
<pre><code>docker pull registry
</code></pre><p>（2）启动私有仓库容器</p>
<pre><code>docker run -di --name=registry -p 5000:5000 registry
</code></pre><p>（3）打开浏览器 输入地址<a href="http://49.234.188.74:5000/v2/_catalog看到{&quot;repositories&quot;:[]}" target="_blank" rel="external">http://49.234.188.74:5000/v2/_catalog看到{&quot;repositories&quot;:[]}</a> 表示私有仓库搭建成功并且内容为空</p>
<p>或者使用crul 命令查看也可以</p>
<p><img src="/2019/02/28/docker个人总结/clip_image247.jpg" alt="img"></p>
<p>这里有个hello-world镜像，是本人之前上传的。如果没有上传过，那么这个应该返回的是{“repositories”:[]}</p>
<p>（4）修改daemon.json</p>
<pre><code>vi /etc/docker/daemon.json
</code></pre><p>添加以下内容，保存退出。</p>
<p>{“insecure-registries”:[“49.234.188.74:5000”]} </p>
<p>例如</p>
<p><img src="/2019/02/28/docker个人总结/clip_image249.jpg" alt="img"></p>
<p>此步用于让 docker信任私有仓库地址</p>
<p>（5）重启docker 服务</p>
<pre><code>systemctl restart docker
</code></pre><h2 id="上传镜像到本地仓库"><a href="#上传镜像到本地仓库" class="headerlink" title="上传镜像到本地仓库"></a>上传镜像到本地仓库</h2><p>（1）标记此镜像为私有仓库的镜像</p>
<pre><code>docker tag hello-world 49.234.188.74:5000/ hello-world （本质就是创建一个关于hello-world的引用，镜像名字更改为hello-world 49.234.188.74:5000/hello-world ）
</code></pre><p>（2）再次启动私服容器</p>
<pre><code>docker start registry
</code></pre><p>（3）上传标记的镜像</p>
<pre><code>docker push 49.234.188.74:5000/ hello-world
</code></pre><p> (4)查看是否上传成功</p>
<p><img src="/2019/02/28/docker个人总结/clip_image247.jpg" alt="img"></p>
<h2 id="其他服务器获取上传的容器"><a href="#其他服务器获取上传的容器" class="headerlink" title="其他服务器获取上传的容器"></a>其他服务器获取上传的容器</h2><p>需求：192.168.1.105 服务器需要从 49.234.188.74 服务器创建的本地仓库获取上床的hello-world镜像</p>
<p>\1.     192.168.1.105设置可信任仓库站点</p>
<pre><code>vi /etc/docker/daemon.json
</code></pre><p>添加以下内容，保存退出。</p>
<p>{“insecure-registries”:[“49.234.188.74:5000”]} </p>
<p><img src="/2019/02/28/docker个人总结/clip_image251.jpg" alt="img"></p>
<p><strong>如果不设置这一步，那么在从49.234.188.74服务器pull镜像的时候会报以下错误</strong></p>
<p>   默认不支持http请求的方式获取镜像</p>
<p><img src="/2019/02/28/docker个人总结/clip_image253.jpg" alt="img"></p>
<p>\2.     拉取镜像成功</p>
<p><img src="/2019/02/28/docker个人总结/clip_image255.jpg" alt="img"></p>
<h1 id="十二、使用DockerMaven插件构建项目"><a href="#十二、使用DockerMaven插件构建项目" class="headerlink" title="十二、使用DockerMaven插件构建项目"></a>十二、使用DockerMaven插件构建项目</h1><p>微服务部署有两种方法：</p>
<p>（1）手动部署：首先基于源码打包生成jar包（或war包）,将jar包（或war包）上传至虚 拟机并拷贝至JDK容器。</p>
<p>（2）通过Maven插件自动部署。</p>
<p>对于数量众多的微服务，手动部署无疑是非常麻烦的做法，并且容易出错。</p>
<h2 id="（1）修改宿主机的docker配置，让其可以远程访问"><a href="#（1）修改宿主机的docker配置，让其可以远程访问" class="headerlink" title="（1）修改宿主机的docker配置，让其可以远程访问"></a>（1）修改宿主机的docker配置，让其可以远程访问</h2><p>Vi  /lib/systemd/system/docker.service</p>
<p>其中ExecStart=后添加配置 ‐H tcp://0.0.0.0:2375 ‐H unix:///var/run/docker.sock</p>
<p><img src="/2019/02/28/docker个人总结/clip_image257.jpg" alt="img"></p>
<h2 id="（2）刷新配置，重启服务"><a href="#（2）刷新配置，重启服务" class="headerlink" title="（2）刷新配置，重启服务"></a>（2）刷新配置，重启服务</h2><p>systemctl daemon‐reload  </p>
<p>systemctl restart docker  </p>
<p>docker start registry   （这里使用的是本地仓库）</p>
<h2 id="（3）-springboot的pom文件添加插件"><a href="#（3）-springboot的pom文件添加插件" class="headerlink" title="（3） springboot的pom文件添加插件"></a>（3） springboot的pom文件添加插件</h2><p><img src="/2019/02/28/docker个人总结/clip_image259.jpg" alt="img"></p>
<p><img src="/2019/02/28/docker个人总结/clip_image261.jpg" alt="img"></p>
<p>最后执行：mvn clean package docker:build</p>
<p>即可把镜像上传到本地仓库中</p>
<p><img src="/2019/02/28/docker个人总结/clip_image263.jpg" alt="img"></p>
<p>上面的方式是构建 项目到本地仓库的方式。如果我们自己申请了阿里云仓库，那么可以使用下面的方式将项目推送到阿里云仓库中。</p>
<p>使用SpringBoot2.0+DockerFile+Maven插件构建镜像并推送到阿里云仓库</p>
<p><a href="https://blog.csdn.net/haogexiang9700/article/details/88318867" target="_blank" rel="external">https://blog.csdn.net/haogexiang9700/article/details/88318867</a></p>
<h1 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h1><h2 id="1-启动mysql后使用外部数据库连接工具访问时，报错"><a href="#1-启动mysql后使用外部数据库连接工具访问时，报错" class="headerlink" title="1 启动mysql后使用外部数据库连接工具访问时，报错"></a>1 启动mysql后使用外部数据库连接工具访问时，报错</h2><p>错误提示 2059 - authentication plugin ‘caching_sha2_password’”</p>
<p>通过查看本人启动mysql容器，mysql的版本是：</p>
<p><img src="/2019/02/28/docker个人总结/clip_image265.jpg" alt="img"></p>
<p>经过查询得知：出现这个问题的原因是mysql8 之前的版本中加密规则是mysql_native_password,而在mysql8之后,加密规则是caching_sha2_password, 解决问题方法是把mysql用户登录密码加密规则还原成mysql_native_password</p>
<p>也就是数据库访问工具还是使用mysql_native_password这样的价码规则访问数据库。</p>
<p>关键的位置是在：mysql数据库中的user表</p>
<p><img src="/2019/02/28/docker个人总结/clip_image267.jpg" alt="img"></p>
<p>解决方法：</p>
<p> 通过命令行的方式登陆数据库 mysql -uroot -p密码</p>
<p>然后分别执行以下代码</p>
<p>use mysql;</p>
<p>ALTER USER ‘root’@’localhost’ IDENTIFIED WITH mysql_native_password BY ‘123456’;</p>
<p>ALTER USER ‘root’@’%’ IDENTIFIED WITH mysql_native_password BY ‘123456’;</p>
<p>FLUSH PRIVILEGES;</p>
<p>修改完毕</p>
<p>修改host为localhost和%(任意客户端)的密码认证方式</p>
<p>官方文档对应mysql8的更新说明</p>
<p><a href="https://dev.mysql.com/doc/refman/8.0/en/upgrading-from-previous-series.html" target="_blank" rel="external">https://dev.mysql.com/doc/refman/8.0/en/upgrading-from-previous-series.html</a></p>
<p><img src="/2019/02/28/docker个人总结/clip_image269.jpg" alt="img"></p>
<h2 id="2-docker数据卷权限问题"><a href="#2-docker数据卷权限问题" class="headerlink" title="2.docker数据卷权限问题"></a>2.docker数据卷权限问题</h2><p>参见《持续集成和容器管理》-《额外补充》章节，启动jenkins dokcer容器时，添加数据卷权限问题。</p>
<p><a href="https://www.cnblogs.com/jackluo/p/5783116.html" target="_blank" rel="external">https://www.cnblogs.com/jackluo/p/5783116.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前学习过docker，但是很浅显的使用，概念和流程各个方面总结的不够到位，下面根据旧版本的文档，重新的梳理。&lt;/p&gt;
&lt;h1 id=&quot;一、docker出现的契机&quot;&gt;&lt;a href=&quot;#一、docker出现的契机&quot; class=&quot;headerlink&quot; title=&quot;一、d
    
    </summary>
    
      <category term="docker" scheme="http://kingge.top/categories/docker/"/>
    
    
      <category term="docker" scheme="http://kingge.top/tags/docker/"/>
    
      <category term="容器" scheme="http://kingge.top/tags/%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>springboot个人总结</title>
    <link href="http://kingge.top/2019/01/30/springboot%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/"/>
    <id>http://kingge.top/2019/01/30/springboot个人总结/</id>
    <published>2019-01-30T14:21:59.000Z</published>
    <updated>2019-08-25T04:05:13.223Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一．前言"><a href="#一．前言" class="headerlink" title="一．前言"></a>一．前言</h1><h2 id="1-1-什么是微服务？"><a href="#1-1-什么是微服务？" class="headerlink" title="1.1 什么是微服务？"></a>1.1 什么是微服务？</h2><p><strong>单服务场景</strong></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image002.jpg" alt="img"></p>
<p><strong>开发简单，测试简单，部署简单</strong></p>
<p>下面举个例子，一种单一的服务场景：所有的模块都是打包成一个war包的形式，然后部署到tomcat中。</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image004.jpg" alt="img"></p>
<p>缺点：</p>
<p>1)      只能采用同一种技术，很难用不同的语言或者语言不同版本开发不同模块；</p>
<p>2)      系统耦合性强，一旦其中一个模块有问题，整个系统就瘫痪了；一旦升级其中一个模块，整个系统就停机了；</p>
<p>3)      集群只能是复制整个系统，即使只是其中一个模块压力大。（可能整个订单处理，仅仅是支付模块压力过大， 按道理只需要升级支付模块，但是在单一场景里面是不能的）</p>
<h2 id="1-2-微服务概念"><a href="#1-2-微服务概念" class="headerlink" title="1.2 微服务概念"></a>1.2 微服务概念</h2><p><img src="/2019/01/30/springboot个人总结/clip_image006.jpg" alt="img"></p>
<p>下面是微服务（Micro-Service）架构，<strong>不同模块放到不同的进程**</strong>/<strong>**服务器上，模块之间通过网络通讯进行协作。</strong></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image008.jpg" alt="img"></p>
<p>各个模块都部署在不同的服务器上面，模块之间可以通过http请求进行协作。例如web服务器收到请求，那么可以根据请求的业务吧请求分配到响应的处理服务器，例如短信消息服务器。</p>
<p>优点：</p>
<p>1)      可以用不同的语言或者语言不同版本开发不同模块；</p>
<p>2)      系统耦合性弱，其中一个模块有问题，可以通过“降级熔断”等手段来保证不停机；</p>
<p>3)      可以对不同模块用不同的集群策略，哪里慢集群哪里。</p>
<p>缺点：</p>
<p>1)      开发难度大，系统结构更复杂；</p>
<p>2)      运行效率低； （模块之间相互请求时间长等等）</p>
<p>  <a href="https://martinfowler.com/articles/microservices.html#MicroservicesAndSoa" target="_blank" rel="external">详细参照微服务文档</a></p>
<p><a href="https://martinfowler.com/articles/microservices.html#MicroservicesAndSoa" target="_blank" rel="external">https://martinfowler.com/articles/microservices.html#MicroservicesAndSoa</a></p>
<p>所以就衍生出了 springboot和springcloud两个框架，当然springboot并不能代表微服务的概念，springcloud才是。</p>
<p>  因为springboot只是简化了单一web服务开发的流程，摒弃了大量的xml配置，提供了大量的自动化配置。</p>
<p>   那么springboot跟springcloud是什么关系呢？ SpringBoot专注于快速方便的开发单个个体微服务。SpringCloud是关注全局的微服务协调整理治理框架，它将SpringBoot开发的一个个单体微服务整合并管理起来，为各个微服务之间提供，配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等集成服务。SpringBoot可以离开SpringCloud独立使用开发项目，但是SpringCloud离不开SpringBoot，属于依赖的关系.</p>
<p>SpringBoot专注于快速、方便的开发单个微服务个体，SpringCloud关注全局的服务治理框架。</p>
<h2 id="1-3-spring的演化"><a href="#1-3-spring的演化" class="headerlink" title="1.3 spring的演化"></a>1.3 spring的演化</h2><h3 id="Spring1-x-时代"><a href="#Spring1-x-时代" class="headerlink" title="Spring1.x 时代"></a>Spring1.x 时代</h3><p>在Spring1.x时代，都是通过xml文件配置bean，随着项目的不断扩大，需要将xml配置分放到不同的配置文件中，需要频繁的在java类和xml配置文件中切换。</p>
<h3 id="Spring2-x时代"><a href="#Spring2-x时代" class="headerlink" title="Spring2.x时代"></a>Spring2.x时代</h3><p>随着JDK 1.5带来的注解支持，Spring2.x可以使用注解对Bean进行申明和注入，大大的减少了xml配置文件，同时也大大简化了项目的开发。</p>
<p>那么，问题来了，究竟是应该使用xml还是注解呢？</p>
<p>最佳实践：</p>
<p>1、  应用的基本配置用xml，比如：数据源、资源文件等；</p>
<p>2、  业务开发用注解，比如：Service中注入bean等；</p>
<h3 id="Spring3-x到Spring4-x"><a href="#Spring3-x到Spring4-x" class="headerlink" title="Spring3.x到Spring4.x"></a>Spring3.x到Spring4.x</h3><p>从Spring3.x开始提供了Java配置方式，使用Java配置方式可以更好的理解你配置的Bean，现在我们就处于这个时代，并且Spring4.x和Spring boot都推荐使用java配置的方式。</p>
<h2 id="1-4为什么要学习SpringBoot"><a href="#1-4为什么要学习SpringBoot" class="headerlink" title="1.4为什么要学习SpringBoot"></a>1.4为什么要学习SpringBoot</h2><p>java一直被人诟病的一点就是臃肿、麻烦。当我们还在辛苦的搭建项目时，可能Python程序员已经把功能写好了，究其原因主要是两点：</p>
<p>·        复杂的配置</p>
<p>项目各种配置其实是开发时的损耗， 因为在思考 Spring 特性配置和解决业务问题之间需要进行思维切换，所以写配置挤占了写应用程序逻辑的时间。</p>
<p>·        混乱的依赖管理</p>
<p><strong>项目的依赖管理也是件吃力不讨好的事情。决定项目里要用哪些库就已经够让人头痛的了，你还要知道这些库的哪个版本和其他库不会有冲突，这也是件棘手的问题。并且，依赖管理也是一种损耗，添加依赖不是写应用程序代码。一旦选错了依赖的版本，随之而来的不兼容问题毫无疑问会是生产力杀手</strong>。</p>
<p>而SpringBoot让这一切成为过去！</p>
<h1 id="二．-什么是springboot"><a href="#二．-什么是springboot" class="headerlink" title="二． 什么是springboot"></a>二． 什么是springboot</h1><p><img src="/2019/01/30/springboot个人总结/clip_image010.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image012.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image014.jpg" alt="img"></p>
<h1 id="三．Springboot使用"><a href="#三．Springboot使用" class="headerlink" title="三．Springboot使用"></a>三．Springboot使用</h1><p>这里开发工具使用的是sts和idea，他们两者开发springboot 的方式没有什么区别，所以下面两种方式我都会嵌套使用。下面的工程采用springboot版本是：1.5.9。</p>
<h2 id="3-1-使用maven方式手动搭建sb项目"><a href="#3-1-使用maven方式手动搭建sb项目" class="headerlink" title="3.1 使用maven方式手动搭建sb项目"></a>3.1 使用maven方式手动搭建sb项目</h2><p>Idea maven环境配置</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image016.png" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image018.png" alt="img"></p>
<p>编码设置：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image020.png" alt="img"></p>
<p>需求：浏览器发送hello请求，服务器接受请求并处理，响应Hello World字符串；</p>
<h3 id="1、创建一个maven工程"><a href="#1、创建一个maven工程" class="headerlink" title="1、创建一个maven工程"></a>1、创建一个maven工程</h3><h3 id="2、导入spring-boot相关的依赖"><a href="#2、导入spring-boot相关的依赖" class="headerlink" title="2、导入spring boot相关的依赖"></a>2、导入spring boot相关的依赖</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;parent&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;</div><div class="line">&lt;/parent&gt;</div><div class="line">&lt;dependencies&gt;</div><div class="line">    &lt;dependency&gt;</div><div class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</div><div class="line">    &lt;/dependency&gt;</div><div class="line">&lt;/dependencies&gt;</div></pre></td></tr></table></figure>
<pre><code>&lt;parent&gt;             &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;             &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;             &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;       &lt;/parent&gt;       &lt;dependencies&gt;           &lt;dependency&gt;                 &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                 &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;           &lt;/dependency&gt;       &lt;/dependencies&gt;   
</code></pre><h3 id="3、-编写一个主程序；启动Spring-Boot应用"><a href="#3、-编写一个主程序；启动Spring-Boot应用" class="headerlink" title="3、        编写一个主程序；启动Spring Boot应用"></a>3、        编写一个主程序；启动Spring Boot应用</h3><p>   /<em>*    </em>  @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用    */   @SpringBootApplication   public class HelloWorldMainApplication {       public static void   main(String[] args) {           // Spring应用启动起来           SpringApplication.run(HelloWorldMainApplication.class,args);       }   }   </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">/**</div><div class="line"> *  @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用</div><div class="line"> */</div><div class="line">@SpringBootApplication</div><div class="line">public class HelloWorldMainApplication &#123;</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        // Spring应用启动起来</div><div class="line">      SpringApplication.run(HelloWorldMainApplication.class,args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="4、编写相关的Controller、Service"><a href="#4、编写相关的Controller、Service" class="headerlink" title="4、编写相关的Controller、Service"></a>4、编写相关的Controller、Service</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Controller</div><div class="line">public class HelloController &#123;</div><div class="line">    @ResponseBody</div><div class="line">    @RequestMapping(&quot;/hello&quot;)</div><div class="line">    public String hello()&#123;</div><div class="line">        return &quot;Hello World!&quot;;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>   @Controller   public class HelloController {       @ResponseBody         @RequestMapping(“/hello”)       public String hello(){           return “Hello   World!”;       }   }   </p>
<h3 id="5、运行主程序测试"><a href="#5、运行主程序测试" class="headerlink" title="5、运行主程序测试"></a>5、运行主程序测试</h3><p>直接运行HelloWorldMainApplication的main方法，启动sb程序。</p>
<p>在浏览器输入 127.0.0.1:8080/hello 可看到输出 Hello World!</p>
<h3 id="6、打包成嵌入式web的可执行jar包"><a href="#6、打包成嵌入式web的可执行jar包" class="headerlink" title="6、打包成嵌入式web的可执行jar包"></a>6、打包成嵌入式web的可执行jar包</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!-- 这个插件，可以将应用打包成一个可执行的jar包；--&gt;</div><div class="line">    &lt;build&gt;</div><div class="line">        &lt;plugins&gt;</div><div class="line">            &lt;plugin&gt;</div><div class="line">                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;</div><div class="line">            &lt;/plugin&gt;</div><div class="line">        &lt;/plugins&gt;</div><div class="line">    &lt;/build&gt;</div></pre></td></tr></table></figure>
<p>运行maven的 mvn package 打包命令，可以看到生成的jar包。</p>
<p>直接使用java -jar的命令进行执行，效果同 5 。</p>
<h2 id="3-2-使用Spring-Initializer快速创建Spring-Boot项目-推荐"><a href="#3-2-使用Spring-Initializer快速创建Spring-Boot项目-推荐" class="headerlink" title="3.2 使用Spring Initializer快速创建Spring Boot项目-推荐"></a>3.2 使用Spring Initializer快速创建Spring Boot项目-推荐</h2><h3 id="3-2-1-sts编译器方式"><a href="#3-2-1-sts编译器方式" class="headerlink" title="3.2.1 sts编译器方式"></a>3.2.1 sts编译器方式</h3><p>STS工具下创建CRUD的步骤（IDEA相同的步骤）</p>
<h4 id="1-主菜单：File→New→Spring-Starter-Project。"><a href="#1-主菜单：File→New→Spring-Starter-Project。" class="headerlink" title="1.主菜单：File→New→Spring Starter Project。"></a>1.主菜单：File→New→Spring Starter Project。</h4><p>在Type中选Maven，Package选War</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image022.jpg" alt="img"></p>
<pre><code>下一步中搜索勾选Web。
</code></pre><p><img src="/2019/01/30/springboot个人总结/clip_image024.jpg" alt="img"></p>
<pre><code>点击【Finish】会创建项目，第一次创建完成后会进行maven包的下载等，需要几分钟。项目创建成功后，他会生成一个springboot的启动类。后面就是靠他来启动springboot
</code></pre><h4 id="2-新建一个Controller"><a href="#2-新建一个Controller" class="headerlink" title="2.新建一个Controller"></a>2.新建一个Controller</h4><p><img src="/2019/01/30/springboot个人总结/clip_image026.jpg" alt="img"></p>
<h4 id="3-新建一个index-html"><a href="#3-新建一个index-html" class="headerlink" title="3.新建一个index.html"></a>3.新建一个index.html</h4><p>  需要注意的是，界面要放置在 resouces – templates 目录下（不是放在我们以前的webroot下面了）</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image027.png" alt="img"></p>
<h4 id="4-启动程序，访问。"><a href="#4-启动程序，访问。" class="headerlink" title="4.启动程序，访问。"></a>4.启动程序，访问。</h4><p><img src="/2019/01/30/springboot个人总结/clip_image029.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image031.jpg" alt="img"></p>
<p>可以看到，他非常的简单。不需要配置一大堆文件</p>
<h3 id="3-2-2-IDEA编译器方式"><a href="#3-2-2-IDEA编译器方式" class="headerlink" title="3.2.2  IDEA编译器方式"></a>3.2.2  IDEA编译器方式</h3><p>方式同上</p>
<p>IDE都支持使用Spring的项目创建向导快速创建一个Spring Boot项目；</p>
<p>选择我们需要的模块；向导会联网创建Spring Boot项目；</p>
<p>默认生成的Spring Boot项目；</p>
<p>- 主程序已经生成好了，我们只需要我们自己的逻辑</p>
<p>- resources文件夹中目录结构</p>
<p>  - static：保存所有的静态资源； js css  images；</p>
<p>  - templates：保存所有的模板页面；（Spring Boot默认jar包使用嵌入式的Tomcat，默认不支持JSP页面）；可以使用模板引擎（freemarker、thymeleaf）；</p>
<p>  - application.properties：Spring Boot应用的配置文件；可以修改一些默认设置；例如修改服务器端口号</p>
<h1 id="四-Springboot核心"><a href="#四-Springboot核心" class="headerlink" title="四.  Springboot核心"></a>四.  Springboot核心</h1><p>下面分析根据helloworld 源码。</p>
<h2 id="4-1、POM文件"><a href="#4-1、POM文件" class="headerlink" title="4.1、POM文件"></a>4.1、POM文件</h2><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;parent&gt;</div><div class="line">	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">	&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</div><div class="line">	&lt;version&gt;2.1.5.RELEASE&lt;/version&gt;</div><div class="line">	&lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;</div><div class="line">&lt;/parent&gt;</div></pre></td></tr></table></figure>
<pre><code>&lt;parent&gt;                 &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                 &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;                 &lt;version&gt;2.1.5.RELEASE&lt;/version&gt;                 &lt;relativePath/&gt;   &lt;!-- lookup parent from repository --&gt;          &lt;/parent&gt;   
</code></pre><p>单击进去查看，发现他的父项目是：</p>
<pre><code>&lt;parent&gt;         &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;         &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;         &lt;version&gt;2.1.5.RELEASE&lt;/version&gt;         &lt;relativePath&gt;../../spring-boot-dependencies&lt;/relativePath&gt;     &lt;/parent&gt;   
</code></pre><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;parent&gt;</div><div class="line">  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">  &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;</div><div class="line">  &lt;version&gt;2.1.5.RELEASE&lt;/version&gt;</div><div class="line">  &lt;relativePath&gt;../../spring-boot-dependencies&lt;/relativePath&gt;</div><div class="line">&lt;/parent&gt;</div></pre></td></tr></table></figure>
<p>再单击进去发现</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image032.png" alt="img"></p>
<p>它里面配置了很多properties,定义了各种依赖的版本。<strong><em>也就是说他是用来真正管理Spring Boot应用里面的所有依赖版本，Spring Boot的版本仲裁中心；以后我们导入依赖默认是不需要写版本；（没有在dependencies里面管理的依赖自然需要声明版本号-）</em></strong></p>
<h3 id="4-2、web启动器"><a href="#4-2、web启动器" class="headerlink" title="4.2、web启动器"></a>4.2、web启动器</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">	&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<pre><code>&lt;dependency&gt;                        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;                 &lt;/dependency&gt;   
</code></pre><p>spring-boot-starter-web：</p>
<pre><code>spring-boot-starter：spring-boot场景启动器；帮我们导入了web模块正常运行所依赖的组件；
</code></pre><p><img src="/2019/01/30/springboot个人总结/clip_image033.png" alt="img"></p>
<p>Spring Boot将所有的功能场景都抽取出来，做成一个个的starters（启动器），只需要在项目里面引入这些starter相关场景的所有依赖都会导入进来。要用什么功能就导入什么场景的启动器</p>
<h2 id="4-2、主程序类，主入口类"><a href="#4-2、主程序类，主入口类" class="headerlink" title="4.2、主程序类，主入口类"></a>4.2、主程序类，主入口类</h2><p>   /<em>*    </em>  @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用    */   @SpringBootApplication   public class HelloWorldMainApplication {       public static void main(String[]   args) {           // Spring应用启动起来             SpringApplication.run(HelloWorldMainApplication.class,args);       }   }   </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">/**</div><div class="line"> *  @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用</div><div class="line"> */</div><div class="line">@SpringBootApplication</div><div class="line">public class HelloWorldMainApplication &#123;</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        // Spring应用启动起来</div><div class="line">        SpringApplication.run(HelloWorldMainApplication.class,args);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="1-注解分析-SpringBootApplication"><a href="#1-注解分析-SpringBootApplication" class="headerlink" title="1 注解分析-@SpringBootApplication"></a>1 注解分析-@SpringBootApplication</h3><p>@SpringBootApplication:    Spring Boot应用标注在某个类上说明这个类是SpringBoot的主配置类，SpringBoot就应该运行这个类的main方法来启动SpringBoot应用；</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image035.jpg" alt="img"></p>
<h4 id="1．-SpringBootConfiguration"><a href="#1．-SpringBootConfiguration" class="headerlink" title="1．@SpringBootConfiguration"></a>1．@SpringBootConfiguration</h4><p><img src="/2019/01/30/springboot个人总结/clip_image036.png" alt="img"></p>
<p>@SpringBootConfiguration:Spring Boot的配置类，sb自定义的一个注解，标注在某个类上，表示这是一个Spring Boot的配置类。</p>
<p>点进去发现实际上他是使用spring的@Configuration来注解的，而@Configuration的上一层是@Component。</p>
<p>在Spring Boot项目中推荐使用@ SpringBootConfiguration替代@Configuration</p>
<pre><code>**总的来说：这个注解的作用是把当前启动类加入到spring容器中，同时当做一个配置类来使用。**
</code></pre><h4 id="2-EnableAutoConfiguration"><a href="#2-EnableAutoConfiguration" class="headerlink" title="2. @EnableAutoConfiguration"></a>2. @<strong>EnableAutoConfiguration</strong></h4><p><img src="/2019/01/30/springboot个人总结/clip_image037.png" alt="img"></p>
<p>@<strong>EnableAutoConfiguration</strong>：<strong>开启自动配置功能</strong>，以前我们需要配置的东西，Spring Boot帮我们自动配置；例如：我们添加了spring-boot-starter-web的依赖，项目中也就会引入SpringMVC的依赖，Spring Boot就会自动配置tomcat和SpringMVC，下面我们查看这个注解具体的作用。</p>
<h5 id="AutoConfigurationPackage：自动配置包"><a href="#AutoConfigurationPackage：自动配置包" class="headerlink" title="@AutoConfigurationPackage：自动配置包"></a>@AutoConfigurationPackage：自动配置包</h5><p><img src="/2019/01/30/springboot个人总结/clip_image038.png" alt="img"></p>
<p>利用Spring的底层注解@Import，给IOC容器中导入组件，导入的组件由AutoConfigurationPackages.Registrar.class来控制。</p>
<blockquote>
<p>额外提示：</p>
</blockquote>
<p><strong>可以参见在网站上发布的《spring注解》文章，关于@import注解导入bean的三种方式</strong></p>
<p><strong>（1）源码分析</strong></p>
<p>查看AutoConfigurationPackages的内部类Registrar，他实现了ImportBeanDefinitionRegistrar接口。通过这个接口的重载方法registerBeanDefinitions（），控制导入IOC容器的bean。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">static class Registrar implements ImportBeanDefinitionRegistrar,</div><div class="line">DeterminableImports &#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public void registerBeanDefinitions(AnnotationMetadata metadata,</div><div class="line">			BeanDefinitionRegistry registry) &#123;</div><div class="line">	1.	register(registry, new PackageImport(metadata).getPackageName());</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public Set&lt;Object&gt; determineImports(AnnotationMetadata metadata) &#123;</div><div class="line">		return Collections.singleton(new PackageImport(metadata));</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<pre><code>static class Registrar   implements ImportBeanDefinitionRegistrar,    DeterminableImports {                     @Override                 public void   registerBeanDefinitions(AnnotationMetadata metadata,                               BeanDefinitionRegistry   registry) {                 1.    register(registry, new   PackageImport(metadata).getPackageName());                 }                     @Override                 public   Set&lt;Object&gt; determineImports(AnnotationMetadata metadata) {                        return   Collections.singleton(new PackageImport(metadata));                 }              }   
</code></pre><p>会去调用registerBeanDefinitions方法注册bean，紧接着registerBeanDefinitions方法调用register方法。</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image040.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/5C1566700814119.png" alt="1566700814119"></p>
<p>该方法会首先判断，IOC容器中是否存在</p>
<p>org.springframework.boot.autoconfigure.AutoConfigurationPackages 类，不存在则把该类注册到容器中，不存在则创建</p>
<blockquote>
<p>在1处打个断点</p>
</blockquote>
<p><strong>发现获取的metadata元数据信息是HelloWorldMainApplication的。计算new PackageImport(metadata).getPackageName()的值得出的是HelloWorldMainApplication所在包的包名。Registry是IOC容器实例</strong></p>
<blockquote>
<p>  总结：</p>
</blockquote>
<p><strong>@AutoConfigurationPackage注解的作用是将主配置类（@SpringBootApplication标注的类）的所在包及下面所有子包里面的所有组件扫描到Spring容器，也就是说，如果controller，service等等类不在这个包下的话，是不会注册到spring容器中的，所以需要注意。</strong></p>
<blockquote>
<p>尖叫提示：</p>
</blockquote>
<p><strong>我们知道spring启动的时候会默认扫描启动类所在的包下面的所有类，注入springioc容器中，但是如果我们需要注入ioc容器的类不在启动类包下，那么我们可以通过这个@ImportResource(locations = {“classpath:beans.xml”})</strong><br><strong>注解进行注入额外的类（注解加在 启动类上）</strong></p>
<p><strong>注解进行注入额外的类（注解加在</strong> <strong>启动类上）</strong></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image042.jpg" alt="img"></p>
<h5 id="Import-AutoConfigurationImportSelector-class"><a href="#Import-AutoConfigurationImportSelector-class" class="headerlink" title="@Import(AutoConfigurationImportSelector.class)"></a>@Import(AutoConfigurationImportSelector.class)</h5><p><strong>（1）整体结构分析</strong></p>
<p><a href="mailto:还是利用了@import注解导入了AutoConfigurationImportSelector.class" target="_blank" rel="external">还是利用了@import注解导入了AutoConfigurationImportSelector.class</a> 类，</p>
<p>查看他的继承结构。</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image044.jpg" alt="img"></p>
<blockquote>
<pre><code>题外话：
</code></pre></blockquote>
<p><strong>可以看到很多组件都实现了Aware接口，关于实现Aware的作用是，我们可以在自定义组件中使用Spring底层的一些组件，例如创建一个bean时候，我们想查看IOC容器的信息或者查看当前系统的信息，那么这个时候就需要用到Aware接口，注入这些底层组件，供自定义组件调用。</strong></p>
<hr>
<blockquote>
<p><strong>可以参见在网站上发布的《spring注解》文章，关于Aware接口</strong></p>
<p>关键代码</p>
</blockquote>
<p><img src="/2019/01/30/springboot个人总结/clip_image046.jpg" alt="img"></p>
<p><strong>selectImports方法，返回的是需要导入到IOC容器的bean的全类名</strong>。类似</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image048.jpg" alt="img"></p>
<p><strong>(2)详细分析</strong></p>
<ol>
<li>查看selectImport()，可以看到最终返回的是自动配置实体类autoConfigurationEntry. getConfigurations()方法的返回值，就是一个List<string></string></li>
</ol>
<p><img src="/2019/01/30/springboot个人总结/clip_image050.jpg" alt="img"></p>
<p>那么很明显获取自动配置实体类的代码是接下来我们所要关注的重点。</p>
<p>2.进入AutoConfigurationImportSelector.getAutoConfigurationEntry()方法</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image052.jpg" alt="img"></p>
<p>同理可得，关键代码是：List<string> configurations</string></p>
<p>3.接着看getCandidateConfigurations方法里面的关键代码段。</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image054.jpg" alt="img"></p>
<p> 关键代码：loadFactoryNames()方法，他的第一个参数通过debug我们可以得知，也就是getSpringFactoriesLoaderFactoryClass()方法的值是：</p>
<p>EnableAutoConfiguration.class –&gt; org.springframework.boot.autoconfigure.EnableAutoConfiguration </p>
<p><strong>SpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class,classLoader)**</strong>；**</p>
<p>深入查看loadFactoryNames方法可知。</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image056.jpg" alt="img"></p>
<p>他是通过</p>
<p>最终loadFactoryNames()方法的返回值是：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image058.jpg" alt="img"></p>
<p><strong>（3）总结：</strong></p>
<p>@Import(AutoConfigurationImportSelector.class)注解的作用是，通过以key为</p>
<p>org.springframework.boot.autoconfigure.EnableAutoConfiguration，然后在META-INF/spring.factories文件中，获取key对应的value值，然后打包成一个值是全类名的List<string>，最终返回到selectImport()方法，然后调用IOC容器把这些List<string>里面bean，注册到IOC容器中，完成自动配置。</string></string></p>
<p>META-INF/spring.factories文件的位置。</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image060.png" alt="img"></p>
<p><strong>J2EE**</strong>的整体整合解决方案和自动配置都在<strong>**spring-boot-autoconfigure-2.0.5.RELEASE.jar</strong></p>
<p><strong>关于自动配置：下面的5.12章节也会阐述到。</strong></p>
<h4 id="3-ComponentScan"><a href="#3-ComponentScan" class="headerlink" title="3. @ComponentScan"></a>3. @ComponentScan</h4><p><img src="/2019/01/30/springboot个人总结/clip_image062.jpg" alt="img"></p>
<h2 id="4-3-关闭自动配置"><a href="#4-3-关闭自动配置" class="headerlink" title="4.3 关闭自动配置"></a>4.3 关闭自动配置</h2><p>通过上述，我们得知，Spring Boot会根据项目中的jar包依赖，自动做出配置，Spring Boot支持的自动配置如下（非常多）：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image064.jpg" alt="img"></p>
<p>如果我们不需要Spring Boot自动配置，想关闭某一项的自动配置，该如何设置呢？</p>
<p>比如：我们不想自动配置Redis，想手动配置。</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image066.jpg" alt="img"></p>
<p>当然了，其他的配置就类似了。</p>
<h2 id="4-4-自定义Banner-了解即可-没什么用"><a href="#4-4-自定义Banner-了解即可-没什么用" class="headerlink" title="4.4 自定义Banner-了解即可-没什么用"></a>4.4 自定义Banner-了解即可-没什么用</h2><p>启动Spring Boot项目后会看到这样的图案：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image068.jpg" alt="img"></p>
<p>这个图片其实是可以自定义的：</p>
<p>\1.       打开网站：</p>
<p><a href="http://patorjk.com/software/taag/#p=display&amp;h=3&amp;v=3&amp;f=4Max&amp;t=itcast%20Spring%20Boot" target="_blank" rel="external">http://patorjk.com/software/taag/#p=display&amp;h=3&amp;v=3&amp;f=4Max&amp;t=itcast%20Spring%20Boot</a><br> <img src="/2019/01/30/springboot个人总结/clip_image070.jpg" alt="img">拷贝生成的字符到一个文本文件中，并且将该文件命名为banner.txt</p>
<p>\2.       将banner.txt拷贝到项目的resources目录中：<br> <img src="/2019/01/30/springboot个人总结/clip_image071.png" alt="img"></p>
<p>\3.       重新启动程序，查看效果：</p>
<p>如果不想看到任何的banner，也是可以将其关闭的：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image073.jpg" alt="img"></p>
<h2 id="4-5全局配置文件"><a href="#4-5全局配置文件" class="headerlink" title="4.5全局配置文件"></a>4.5全局配置文件</h2><p>Spring Boot项目使用一个全局的配置文件application.properties或者是application.yml，在resources目录下或者类路径下的/config下，一般我们放到resources下。</p>
<p>1、  修改tomcat的端口为8088<br> <img src="/2019/01/30/springboot个人总结/clip_image074.png" alt="img"><br> 重新启动应用，查看效果：<br> <img src="/2019/01/30/springboot个人总结/clip_image076.jpg" alt="img"></p>
<p>2、  修改进入DispatcherServlet的规则为：*.html<br> <img src="/2019/01/30/springboot个人总结/clip_image077.png" alt="img"><br> 测试：<br> <img src="/2019/01/30/springboot个人总结/clip_image078.png" alt="img"><br> <img src="/2019/01/30/springboot个人总结/clip_image080.jpg" alt="img"></p>
<h1 id="五-配置文件"><a href="#五-配置文件" class="headerlink" title="五. 配置文件"></a>五. 配置文件</h1><p><strong>SpringBoot使用一个全局的配置文件，配置文件名是固定的（名字不能更改否则无效）</strong></p>
<p>•application.properties （默认生成）</p>
<p>•application.yml</p>
<p><strong>而且通过观察发现</strong> <strong>application.properties</strong> <strong>的优先级别比</strong> <strong>application.yml</strong> <strong>高，同样的属性配置，**</strong>properties<strong><strong>会覆盖</strong></strong>yml<strong>**的配置</strong></p>
<p>配置文件的作用：修改SpringBoot自动配置的默认值，SpringBoot在底层都给我们自动配置好。</p>
<h2 id="5-1-YAML"><a href="#5-1-YAML" class="headerlink" title="5.1 YAML"></a>5.1 YAML</h2><p>他是一种标记语言</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image082.jpg" alt="img"></p>
<h2 id="5-2YAML语法"><a href="#5-2YAML语法" class="headerlink" title="5.2YAML语法"></a>5.2YAML语法</h2><p><img src="/2019/01/30/springboot个人总结/clip_image084.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image086.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image088.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image090.jpg" alt="img"></p>
<h2 id="5-3配置文件值注入"><a href="#5-3配置文件值注入" class="headerlink" title="5.3配置文件值注入"></a>5.3配置文件值注入</h2><p><img src="/2019/01/30/springboot个人总结/clip_image092.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image094.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image096.jpg" alt="img"></p>
<h2 id="5-4-Value获取值和-ConfigurationProperties获取值比较"><a href="#5-4-Value获取值和-ConfigurationProperties获取值比较" class="headerlink" title="5.4 @Value获取值和@ConfigurationProperties获取值比较"></a>5.4 @Value获取值和@ConfigurationProperties获取值比较</h2><p><img src="/2019/01/30/springboot个人总结/clip_image098.jpg" alt="img"></p>
<h2 id="5-5、配置文件注入值数据校验"><a href="#5-5、配置文件注入值数据校验" class="headerlink" title="5.5、配置文件注入值数据校验"></a>5.5、配置文件注入值数据校验</h2><p><img src="/2019/01/30/springboot个人总结/clip_image100.jpg" alt="img"></p>
<h2 id="5-6、-PropertySource-amp-ImportResource-amp-Bean"><a href="#5-6、-PropertySource-amp-ImportResource-amp-Bean" class="headerlink" title="5.6、@PropertySource&amp;@ImportResource&amp;@Bean"></a>5.6、@PropertySource&amp;@ImportResource&amp;@Bean</h2><p><strong>1. @PropertySource：加载指定的配置文件；</strong></p>
<p>应用场景，我们知道application.properties是项目的整体配置文件，但是如果存在大量跟项目关系不是那么密切的配置信息，我们是可以配置到其他的配置的文件中去，避免造成application.peoperties文件的大小过大。这个时候就需要PropertySource注解进行指定。</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image102.jpg" alt="img"></p>
<p><strong>2.</strong> <strong>@ImportResource**</strong>：**</p>
<p>导入Spring的配置文件，让配置文件里面的内容生效，Spring Boot里面没有Spring的配置文件，我们自己编写的配置文件，也不能自动识别，想让Spring的配置文件生效，加载进来，@<strong>ImportResource</strong>标注在一个配置类上。</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image104.jpg" alt="img"></p>
<p><strong>3.@bean</strong></p>
<p>Bean注解一般是配合着@Configure注解使用</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image106.jpg" alt="img"></p>
<h2 id="5-7比较application-properties和application-yml和自定义properti的优先级别"><a href="#5-7比较application-properties和application-yml和自定义properti的优先级别" class="headerlink" title="5.7比较application.properties和application.yml和自定义properti的优先级别"></a>5.7比较application.properties和application.yml和自定义properti的优先级别</h2><p>同样的属性配置 ：  application.properties &gt; application.yml &gt; 自定义properties</p>
<p><strong>前者会覆盖后者</strong></p>
<h2 id="5-8、配置文件占位符"><a href="#5-8、配置文件占位符" class="headerlink" title="5.8、配置文件占位符"></a>5.8、配置文件占位符</h2><p><img src="/2019/01/30/springboot个人总结/clip_image108.jpg" alt="img"></p>
<h2 id="5-9、Profile"><a href="#5-9、Profile" class="headerlink" title="5.9、Profile"></a>5.9、Profile</h2><p>使用场景，针对于配置文件。例如我们在开发过程中使用的是开发环境的properties，那么生产使用的是生产的properties。那么我们怎么指定呢？ spring提供了profile功能</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image110.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image112.jpg" alt="img"></p>
<h2 id="5-10、配置文件加载位置-Important"><a href="#5-10、配置文件加载位置-Important" class="headerlink" title="5.10、配置文件加载位置(Important)"></a>5.10、配置文件加载位置(Important)</h2><p>springboot 启动会扫描以下位置的application.properties或者application.yml文件作为Spring boot的默认配置文件</p>
<p>–file:./config/    （在项目的的根目录下新建config）</p>
<p>–file:./                  （在项目的的根目录下）</p>
<p>–classpath:/config/  （项目的resource目录下新建config）</p>
<p>–classpath:/     （默认生成的application.properties是在类路径下面的）</p>
<p>优先级由高到底，高优先级的配置会覆盖低优先级的配置；</p>
<p>SpringBoot会从这四个位置全部加载主配置文件；互补配置；</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image114.jpg" alt="img"></p>
<h2 id="5-11、外部配置加载顺序"><a href="#5-11、外部配置加载顺序" class="headerlink" title="5.11、外部配置加载顺序"></a>5.11、外部配置加载顺序</h2><p><img src="/2019/01/30/springboot个人总结/clip_image116.jpg" alt="img"></p>
<p><a href="https://docs.spring.io/spring-boot/docs/1.5.9.RELEASE/reference/htmlsingle/#boot-features-external-config" target="_blank" rel="external">参考官方文档</a></p>
<h2 id="5-11-bookstrap-yml"><a href="#5-11-bookstrap-yml" class="headerlink" title="5.11 bookstrap.yml"></a>5.11 bookstrap.yml</h2><p>其实还有一个系统级别的配置文件，这个是springcloud的在使用configserver组件的时候使用的，详情可查看后续的springcloud文章-springcloud的配置中心。</p>
<h2 id="5-12、自动配置原理"><a href="#5-12、自动配置原理" class="headerlink" title="5.12、自动配置原理"></a>5.12、自动配置原理</h2><p>配置文件到底能写什么？怎么写？自动配置原理；</p>
<p><a href="https://docs.spring.io/spring-boot/docs/1.5.9.RELEASE/reference/htmlsingle/#common-application-properties" target="_blank" rel="external">配置文件能配置的属性参照</a></p>
<h3 id="1、自动配置原理"><a href="#1、自动配置原理" class="headerlink" title="1、自动配置原理"></a>1、<strong>自动配置原理</strong></h3><p>1）、SpringBoot启动的时候加载主配置类，开启了自动配置功能通过这个注解@EnableAutoConfiguration</p>
<p><strong>2）、@EnableAutoConfiguration作用：</strong></p>
<p>·        利用EnableAutoConfigurationImportSelector给容器中导入一些组件？</p>
<p>·        可以查看selectImports()方法的内容；</p>
<p>·        List<string> configurations = getCandidateConfigurations(annotationMetadata, attributes);获取候选的配置</string></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">SpringFactoriesLoader.loadFactoryNames()</div><div class="line"></div><div class="line">扫描所有jar包类路径下  META-INF/spring.factories</div><div class="line"></div><div class="line">把扫描到的这些文件的内容包装成properties对象</div><div class="line"></div><div class="line">从properties中获取到EnableAutoConfiguration.class类（类名）对应的值，然后把他们添加在容器中</div></pre></td></tr></table></figure>
<p><strong>将</strong> <strong>类路径下</strong> <strong>META-INF/spring.factories</strong> <strong>里面配置的所有**</strong>EnableAutoConfiguration<strong>**的值加入到了容器中</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Auto Configure</div><div class="line"></div><div class="line">org.springframework.boot.autoconfigure.EnableAutoConfiguration=\</div><div class="line"></div><div class="line">org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\</div><div class="line"></div><div class="line">org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\</div><div class="line"></div><div class="line">org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\</div><div class="line"></div><div class="line">org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\</div><div class="line"></div><div class="line">org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\</div><div class="line"></div><div class="line">org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\</div><div class="line"></div><div class="line">org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\</div><div class="line"></div><div class="line">org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\</div><div class="line"></div><div class="line">org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\</div><div class="line"></div><div class="line">org.springframework.boot.autoconfigure.context.PropertyPlaceholderAu</div><div class="line">。。。。。。。。。。。。。。。。等等</div></pre></td></tr></table></figure>
<p>每一个这样的 xxxAutoConfiguration类都是容器中的一个组件，都加入到容器中；用他们来做自动配置；</p>
<p>3）、每一个自动配置类进行自动配置功能；</p>
<p>4）、以<strong>HttpEncodingAutoConfiguration（Http编码自动配置）</strong>为例解释自动配置原理；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Configuration   //表示这是一个配置类，以前编写的配置文件一样，也可以给容器中添加组件</div><div class="line"></div><div class="line">@EnableConfigurationProperties(HttpEncodingProperties.class)  //启动指定类的ConfigurationProperties功能；将配置文件中对应的值和HttpEncodingProperties绑定起来；并把HttpEncodingProperties加入到ioc容器中</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">@ConditionalOnWebApplication //Spring底层@Conditional注解（Spring注解版），根据不同的条件，如果满足指定的条件，整个配置类里面的配置就会生效；    判断当前应用是否是web应用，如果是，当前配置类生效</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">@ConditionalOnClass(CharacterEncodingFilter.class)  //判断当前项目有没有这个类CharacterEncodingFilter；SpringMVC中进行乱码解决的过滤器；</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">@ConditionalOnProperty(prefix = &quot;spring.http.encoding&quot;, value = &quot;enabled&quot;, matchIfMissing = true)  //判断配置文件中是否存在某个配置  spring.http.encoding.enabled；如果不存在，判断也是成立的</div><div class="line"></div><div class="line">//即使我们配置文件中不配置pring.http.encoding.enabled=true，也是默认生效的；</div><div class="line"></div><div class="line">public class HttpEncodingAutoConfiguration &#123;</div><div class="line"></div><div class="line">  </div><div class="line"></div><div class="line">    //他已经和SpringBoot的配置文件映射了</div><div class="line"></div><div class="line">    private final HttpEncodingProperties properties;</div><div class="line"></div><div class="line">  </div><div class="line"></div><div class="line">   //只有一个有参构造器的情况下，参数的值就会从容器中拿</div><div class="line"></div><div class="line">    public HttpEncodingAutoConfiguration(HttpEncodingProperties properties) &#123;</div><div class="line"></div><div class="line">        this.properties = properties;</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">  </div><div class="line"></div><div class="line">    @Bean   //给容器中添加一个组件，这个组件的某些值需要从properties中获取</div><div class="line"></div><div class="line">    @ConditionalOnMissingBean(CharacterEncodingFilter.class) //判断容器没有这个组件？</div><div class="line"></div><div class="line">    public CharacterEncodingFilter characterEncodingFilter() &#123;</div><div class="line"></div><div class="line">        CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter();</div><div class="line"></div><div class="line">        filter.setEncoding(this.properties.getCharset().name());</div><div class="line"></div><div class="line">        filter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST));</div><div class="line"></div><div class="line">        filter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE));</div><div class="line"></div><div class="line">        return filter;</div><div class="line"></div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>根据当前不同的条件判断，决定这个配置类是否生效？</p>
<p>一但这个配置类生效；这个配置类就会给容器中添加各种组件；这些组件的属性是从对应的properties类中获取的，这些类里面的每一个属性又是和配置文件绑定的；</p>
<p>5）、所有在配置文件中能配置的属性都是在xxxxProperties类中封装者。配置文件能配置什么就可以参照某个功能对应的这个属性类</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@ConfigurationProperties(prefix = &quot;spring.http.encoding&quot;)  //从配置文件中获取指定的值和bean的属性进行绑定</div><div class="line"></div><div class="line">public class HttpEncodingProperties &#123;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">   public static final Charset DEFAULT_CHARSET = Charset.forName(&quot;UTF-8&quot;);</div></pre></td></tr></table></figure>
<p><strong>精髓：</strong></p>
<p> <strong>1**</strong>）、<strong><strong>SpringBoot</strong></strong>启动会加载大量的自动配置类**</p>
<p> <strong>2**</strong>）、我们看我们需要的功能有没有<strong><strong>SpringBoot</strong></strong>默认写好的自动配置类；**</p>
<p> <strong>3**</strong>）、我们再来看这个自动配置类中到底配置了哪些组件；（只要我们要用的组件有，我们就不需要再来配置了）**</p>
<p> <strong>4**</strong>）、给容器中自动配置类添加组件的时候，会从<strong><strong>properties</strong></strong>类中获取某些属性。我们就可以在配置文件中指定这些属性的值；**</p>
<p>xxxxAutoConfigurartion：自动配置类；</p>
<p>给容器中添加组件</p>
<p>xxxxProperties:封装配置文件中相关属性；</p>
<h3 id="2、细节"><a href="#2、细节" class="headerlink" title="2、细节"></a>2、细节</h3><h4 id="1、-Conditional派生注解（Spring注解版原生的-Conditional作用）"><a href="#1、-Conditional派生注解（Spring注解版原生的-Conditional作用）" class="headerlink" title="1、@Conditional派生注解（Spring注解版原生的@Conditional作用）"></a>1、@Conditional派生注解（Spring注解版原生的@Conditional作用）</h4><p>作用：必须是@Conditional指定的条件成立，才给容器中添加组件，配置配里面的所有内容才生效；</p>
<table>
<thead>
<tr>
<th><strong>@Conditional**</strong>扩展注解**</th>
<th><strong>作用（判断是否满足当前指定条件）</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>@ConditionalOnJava</td>
<td>系统的java版本是否符合要求</td>
</tr>
<tr>
<td>@ConditionalOnBean</td>
<td>容器中存在指定Bean；</td>
</tr>
<tr>
<td>@ConditionalOnMissingBean</td>
<td>容器中不存在指定Bean；</td>
</tr>
<tr>
<td>@ConditionalOnExpression</td>
<td>满足SpEL表达式指定</td>
</tr>
<tr>
<td>@ConditionalOnClass</td>
<td>系统中有指定的类</td>
</tr>
<tr>
<td>@ConditionalOnMissingClass</td>
<td>系统中没有指定的类</td>
</tr>
<tr>
<td>@ConditionalOnSingleCandidate</td>
<td>容器中只有一个指定的Bean，或者这个Bean是首选Bean</td>
</tr>
<tr>
<td>@ConditionalOnProperty</td>
<td>系统中指定的属性是否有指定的值</td>
</tr>
<tr>
<td>@ConditionalOnResource</td>
<td>类路径下是否存在指定资源文件</td>
</tr>
<tr>
<td>@ConditionalOnWebApplication</td>
<td>当前是web环境</td>
</tr>
<tr>
<td>@ConditionalOnNotWebApplication</td>
<td>当前不是web环境</td>
</tr>
<tr>
<td>@ConditionalOnJndi</td>
<td>JNDI存在指定项</td>
</tr>
</tbody>
</table>
<p><strong>自动配置类必须在一定的条件下才能生效；</strong></p>
<p>我们怎么知道哪些自动配置类生效；</p>
<p><strong>==**</strong>我们可以通过在<strong><strong>application.properties</strong></strong>中启用<strong> </strong>debug=true<strong><strong>属性；来让控制台打印自动配置报告</strong></strong>==**，这样我们就可以很方便的知道哪些自动配置类生效；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">=========================</div><div class="line"></div><div class="line">AUTO-CONFIGURATION REPORT</div><div class="line"></div><div class="line">=========================</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">Positive matches:（自动配置类启用的）</div><div class="line"></div><div class="line">-----------------</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">   DispatcherServletAutoConfiguration matched:</div><div class="line"></div><div class="line">      - @ConditionalOnClass found required class &apos;org.springframework.web.servlet.DispatcherServlet&apos;; @ConditionalOnMissingClass did not find unwanted class (OnClassCondition)</div><div class="line"></div><div class="line">      - @ConditionalOnWebApplication (required) found StandardServletEnvironment (OnWebApplicationCondition)</div><div class="line"></div><div class="line">        </div><div class="line"></div><div class="line">    </div><div class="line"></div><div class="line">Negative matches:（没有启动，没有匹配成功的自动配置类）</div><div class="line"></div><div class="line">-----------------</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">   ActiveMQAutoConfiguration:</div><div class="line"></div><div class="line">      Did not match:</div><div class="line"></div><div class="line">         - @ConditionalOnClass did not find required classes &apos;javax.jms.ConnectionFactory&apos;, &apos;org.apache.activemq.ActiveMQConnectionFactory&apos; (OnClassCondition)</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">   AopAutoConfiguration:</div><div class="line"></div><div class="line">      Did not match:</div><div class="line"></div><div class="line">         - @ConditionalOnClass did not find required classes &apos;org.aspectj.lang.annotation.Aspect&apos;, &apos;org.aspectj.lang.reflect.Advice&apos; (OnClassCondition)</div></pre></td></tr></table></figure>
<h1 id="六．日志"><a href="#六．日志" class="headerlink" title="六．日志"></a>六．日志</h1><h1 id="七-springboot的web开发"><a href="#七-springboot的web开发" class="headerlink" title="七 springboot的web开发"></a>七 springboot的web开发</h1><h2 id="7-1-引言"><a href="#7-1-引言" class="headerlink" title="7.1 引言"></a>7.1 引言</h2><p>使用SpringBoot；</p>
<p><strong>1**</strong>）、创建<strong><strong>SpringBoot</strong></strong>应用，选中我们需要的模块；**</p>
<p><strong>2**</strong>）、<strong><strong>SpringBoot</strong></strong>已经默认将这些场景配置好了，只需要在配置文件中指定少量配置就可以运行起来**</p>
<p><strong>3**</strong>）、自己编写业务代码；**</p>
<p>我们知道sb框架已经给我们自动配置了很多相关的配置，我们只需要着重于业务代码的编写，但是有些细则还是需要了解的，例如我们打包的sb程序成jar包的形式，那么我们网站的css js等等资源是放置在那个目录呢？换言说，静态资源的访问是个怎么流程呢？</p>
<h2 id="7-2、SpringBoot对静态资源的映射规则"><a href="#7-2、SpringBoot对静态资源的映射规则" class="headerlink" title="7.2、SpringBoot对静态资源的映射规则"></a>7.2、SpringBoot对静态资源的映射规则</h2><p><strong>1.Web**</strong>开发的自动配置类**</p>
<p>org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration</p>
<p>查看关键代码</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image118.jpg" alt="img"></p>
<h3 id="7-2-1-查看第一层映射关系"><a href="#7-2-1-查看第一层映射关系" class="headerlink" title="7.2.1 查看第一层映射关系"></a>7.2.1 查看第一层映射关系</h3><p>这段代码的意思是：所有/webjars/**的请求 ，都去classpath:/META-INF/resources/webjars/ 找资源。</p>
<p>例如请求jauery的请求 localhost:8080/webjars/jquery/3.3.1/jquery.js </p>
<p><strong>1.**</strong>什么是<strong><strong>webjars</strong></strong>？**</p>
<p>以jar包的方式引入静态资源，可登陆这个网址了解<a href="http://www.webjars.org/" target="_blank" rel="external">http://www.webjars.org/</a></p>
<p>也就是说，网站需要的jq等等资源你可以通过maven的方式导入到项目中。</p>
   <!--引入jquery-webjar-->在访问的时候只需要写webjars下面资源的名称即可                 <dependency>                        <groupid>org.webjars</groupid>                        <artifactid>jquery</artifactid>                        <version>3.3.1</version>                 </dependency><br><br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!--引入jquery-webjar--&gt;在访问的时候只需要写webjars下面资源的名称即可</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;org.webjars&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;jquery&lt;/artifactId&gt;</div><div class="line">			&lt;version&gt;3.3.1&lt;/version&gt;</div><div class="line">		&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p>导入到sb项目后查看依赖</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image119.png" alt="img"></p>
<p>启动项目请求：localhost:8080/webjars/jquery/3.3.1/jquery.js。  输出jquery内容。</p>
<p>总结：</p>
<p>也就是说，如果我们需要引用网上相关的资源可以使用webjars的方式导入相关的组件，<strong>但是有个问题，那就是如果我们项目中已经存在某些**</strong>css<strong><strong>和</strong></strong>js<strong><strong>，那么怎么引用到</strong></strong>sb<strong>**项目中呢（也就是请求不满足第一层映射关系）</strong>？</p>
<p>例如：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image120.png" alt="img"></p>
<h3 id="7-2-2-第二层映射关系"><a href="#7-2-2-第二层映射关系" class="headerlink" title="7.2.2 第二层映射关系"></a>7.2.2 第二层映射关系</h3><p><img src="/2019/01/30/springboot个人总结/clip_image122.jpg" alt="img"></p>
<p>查看staticPathPattern的值：staticPathPattern = “/<strong>“。</strong>也就是说改代码块匹配访问当前项目任何资源的请求**</p>
<p>那么他是去哪里寻找资源回应请求呢？</p>
<p>查看getStaticLocations()方法，通过查看发现：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">private static final String[] CLASSPATH_RESOURCE_LOCATIONS = &#123;</div><div class="line">		&quot;classpath:/META-INF/resources/&quot;, &quot;classpath:/resources/&quot;,</div><div class="line">		&quot;classpath:/static/&quot;, &quot;classpath:/public/&quot; &#125;;</div></pre></td></tr></table></figure>
<pre><code>private static final String[] CLASSPATH_RESOURCE_LOCATIONS   = {                        &quot;classpath:/META-INF/resources/&quot;,   &quot;classpath:/resources/&quot;,                        &quot;classpath:/static/&quot;,   &quot;classpath:/public/&quot; };   
</code></pre><p>也就是说，请求会去类路径的根路径下的这个几个目录寻找相应的资源响应。</p>
<p>类路径是指：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image123.png" alt="img">例如sbp项目中，java和resources都是属于类路径的根路径。静态资源，我们可以在resources下创建 resources目录存放，或者创建public目录存放，<strong>static**</strong>目录默认已经创建**</p>
<h4 id="2-案例"><a href="#2-案例" class="headerlink" title="2.案例"></a>2.案例</h4><p><img src="/2019/01/30/springboot个人总结/clip_image124.png" alt="img"></p>
<p>我们把一些样式文件放置到static目录下</p>
<p>启动sb项目，访问静态资源。<a href="http://127.0.0.1:8080/asserts/img/4D74191A.jpg" target="_blank" rel="external">http://127.0.0.1:8080/asserts/img/4D74191A.jpg</a></p>
<p>访问成功。<strong>很明显不满足第一层映射关系，走的是第二层映射关系的逻辑</strong></p>
<h3 id="7-2-3-欢迎页配置"><a href="#7-2-3-欢迎页配置" class="headerlink" title="7.2.3 欢迎页配置"></a>7.2.3 欢迎页配置</h3><p><img src="/2019/01/30/springboot个人总结/clip_image126.jpg" alt="img"></p>
<p>通过查看他也是从7.2.2章节中静态资源存放目录下寻找index.html。</p>
<p>localhost:8080/ 找index页面</p>
<h3 id="7-2-4-网站图标"><a href="#7-2-4-网站图标" class="headerlink" title="7.2.4 网站图标"></a>7.2.4 网站图标</h3><p>所有的 **/favicon.ico 都是在静态资源文件下找；==（也是从7.2.2章节中静态资源存放目录下）</p>
<h3 id="7-2-5-修改静态资源文件夹路径"><a href="#7-2-5-修改静态资源文件夹路径" class="headerlink" title="7.2.5 修改静态资源文件夹路径"></a>7.2.5 修改静态资源文件夹路径</h3><p><img src="/2019/01/30/springboot个人总结/clip_image128.jpg" alt="img"></p>
<h2 id="7-3、模板引擎"><a href="#7-3、模板引擎" class="headerlink" title="7.3、模板引擎"></a>7.3、模板引擎</h2><p>常用的模板引擎有JSP、Velocity、Freemarker、Thymeleaf。核心理念是，通过传入模板代码和需要替换的数据到模板引擎中，模板引擎自动转化成静态的界面显示</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image130.jpg" alt="img"></p>
<p>SpringBoot推荐的Thymeleaf，语法更简单，功能更强大；</p>
<h3 id="1、引入thymeleaf"><a href="#1、引入thymeleaf" class="headerlink" title="1、引入thymeleaf"></a>1、引入thymeleaf</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">	&lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p>我这里默认导入的是3.011版本。</p>
<p>如果你们想要修改导入版本，那么也是可以的：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image132.jpg" alt="img"></p>
<p>Pom.xml文件中添加版本覆盖即可</p>
<h3 id="2、Thymeleaf使用"><a href="#2、Thymeleaf使用" class="headerlink" title="2、Thymeleaf使用"></a>2、Thymeleaf使用</h3><p>我们通过查看他的自动配置源码来了解一下他的加载结构：</p>
<p>org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration</p>
<p>的ThymeleafProperties 属性</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image134.jpg" alt="img"></p>
<p>发下它默认加载类路径下的templates目录下的后缀为html的文件。</p>
<p><strong>只要我们把HTML页面放在classpath:/templates/，thymeleaf就能自动渲染；</strong></p>
<h4 id="2-1-案例1（常规使用）"><a href="#2-1-案例1（常规使用）" class="headerlink" title="2.1 案例1（常规使用）"></a>2.1 案例1（常规使用）</h4><p>（1）    在templates目录下新建ok.html界面</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image135.png" alt="img"></p>
<p>（2）    在controller中添加请求处理，最终是跳转到ok.html界面</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image136.png" alt="img"></p>
<p>（3）启动sb项目，并访问<a href="http://127.0.0.1:8080/ok" target="_blank" rel="external">http://127.0.0.1:8080/ok</a> </p>
<h4 id="2-2-动态赋值"><a href="#2-2-动态赋值" class="headerlink" title="2.2 动态赋值"></a>2.2 动态赋值</h4><p>1.修改ok.html界面 </p>
<p><img src="/2019/01/30/springboot个人总结/clip_image138.jpg" alt="img"></p>
<p>2.修改请求处理方法 ok()</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image139.png" alt="img"></p>
<p>3.启动sb项目，并访问<a href="http://127.0.0.1:8080/ok" target="_blank" rel="external">http://127.0.0.1:8080/ok</a></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image140.png" alt="img"></p>
<p>总结：</p>
<p>这里建议给html界面加上命名空间，这样在使用thyeleaf语法时会有提示</p>
   <html lang="en" xmlns:th="http://www.thymeleaf.org">   









<h3 id="4-Thymeleaf语法"><a href="#4-Thymeleaf语法" class="headerlink" title="4.     Thymeleaf语法"></a>4.     Thymeleaf语法</h3><p><a href="https://www.thymeleaf.org/" target="_blank" rel="external">https://www.thymeleaf.org/</a> 官方地址</p>
<p>1）、th:text；改变当前元素里面的文本内容；</p>
<p> th：任意html属性；来替换原生属性的值</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image142.jpg" alt="img"></p>
<p>2）、表达式？</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image144.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image146.jpg" alt="img"></p>
<h2 id="7-4、SpringMVC自动配置"><a href="#7-4、SpringMVC自动配置" class="headerlink" title="7.4、SpringMVC自动配置"></a>7.4、SpringMVC自动配置</h2><p><a href="https://docs.spring.io/spring-boot/docs/2.1.5.RELEASE/reference/html/boot-features-developing-web-applications.html#boot-features-spring-mvc-auto-configuration" target="_blank" rel="external">https://docs.spring.io/spring-boot/docs/2.1.5.RELEASE/reference/html/boot-features-developing-web-applications.html#boot-features-spring-mvc-auto-configuration</a> 官方文档</p>
<h3 id="1-Spring-MVC-auto-configuration"><a href="#1-Spring-MVC-auto-configuration" class="headerlink" title="1. Spring MVC auto-configuration"></a>1. Spring MVC auto-configuration</h3><p>通过查看官方文档查看springboot为springmvc自动配置了那些工作</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image148.jpg" alt="img"></p>
<p>逐句分析：</p>
<p>Spring Boot 自动配置好了SpringMVC</p>
<p>以下是SpringBoot对SpringMVC的默认配置:关键类WebMvcAutoConfiguration</p>
<p><strong>1 Inclusion of ContentNegotiatingViewResolver and BeanNameViewResolver beans.</strong></p>
<p>  - 自动配置了ViewResolver（视图解析器：根据方法的返回值得到视图对象（View），视图对象决定如何渲染（转发或者重定向））</p>
<p>  - ContentNegotiatingViewResolver：组合所有的视图解析器的；</p>
<p>  - <strong>如何定制：我们可以自己给容器中添加一个视图解析器；自动的将其组合进来</strong></p>
<p><strong>2.Support for serving static resources, including support for WebJars (see below).静态资源文件夹路径,webjars</strong></p>
<p><strong>3.Static index.html support.</strong> <strong>静态首页访问</strong></p>
<p><strong>4.Custom Favicon support (see below).  favicon.ico</strong></p>
<p><strong>5.自动注册了</strong> <strong>of Converter, GenericConverter, Formatter beans.</strong></p>
<p>  - Converter：转换器；  public String hello(User user)：类型转换使用Converter</p>
<p>  - Formatter  格式化器；  2017.12.17===Date；</p>
<p>关键代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Bean</div><div class="line">@ConditionalOnProperty(prefix = &quot;spring.mvc&quot;, name = &quot;date-format&quot;)//在文件中配置日期格式化的规则</div><div class="line">public Formatter&lt;Date&gt; dateFormatter() &#123;</div><div class="line">	return new DateFormatter(this.mvcProperties.getDateFormat());//日期格式化组件</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<pre><code>@Bean                 @ConditionalOnProperty(prefix =   &quot;spring.mvc&quot;, name = &quot;date-format&quot;)//在文件中配置日期格式化的规则                 public Formatter&lt;Date&gt; dateFormatter() {                        return new   DateFormatter(this.mvcProperties.getDateFormat());//日期格式化组件                 }   
</code></pre><p><strong>自己添加的格式化器转换器，我们只需要放在容器中即可</strong></p>
<p><strong>6**</strong>.Support for HttpMessageConverters (see below).**</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image150.jpg" alt="img"></p>
<p><strong>7**</strong>. Automatic registration of MessageCodesResolver (see below).<strong>**定义错误代码生成规则</strong></p>
<p><strong>8**</strong>. Automatic use of a ConfigurableWebBindingInitializer bean (see below).**</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image152.jpg" alt="img"></p>
<h3 id="2、扩展SpringMVC"><a href="#2、扩展SpringMVC" class="headerlink" title="2、扩展SpringMVC"></a>2、扩展SpringMVC</h3><p>虽然springboot框架给我们自动配置了很多组件，但是在真实的应用场景中，肯定还需要自己实现一些组件，来扩展我们的springboot程序，例如我们需要定义一个拦截器和一个特定功能的视图解析器。那么就需要扩展了。</p>
<p>官方文档有段话，给我们阐述了如果扩展：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image154.jpg" alt="img"></p>
<p><strong>总的来说：编写一个配置类（@Configuration），是WebMvcConfigurer类型，不能标注@EnableWebMvc，即可实现扩展功能。</strong></p>
<pre><code>**尖叫提示：有些文档还是使用WebMvcConfigurerAdapter。**
</code></pre><p><strong>需要注意的是：在springboot2.0版本以上，WebMvcConfigurerAdapter类已经过时，需要使用WebMvcConfigurer 接口或者WebMvcConfigurationSupport</strong></p>
<p>   过时原因：原因是springboot2.0以后，引用的是spring5.0，而spring5.0取消了<strong>WebMvcConfigurerAdapter</strong> </p>
<h4 id="2-1-案例"><a href="#2-1-案例" class="headerlink" title="2.1 案例"></a>2.1 案例</h4><p>实现一个视图解析器，将请求是/no时，直接重定向到success界面(<strong>也就是说不用编写controller**</strong>方法**)。</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image156.jpg" alt="img"></p>
<p>访问请求：<a href="http://127.0.0.1:8080/no" target="_blank" rel="external">http://127.0.0.1:8080/no</a> </p>
<h4 id="重要总结"><a href="#重要总结" class="headerlink" title="重要总结"></a>重要总结</h4><p><strong>总结：建议以后所有关于**</strong>mvc<strong><strong>扩展的自定义的功能组件（视图解析器，国际化，拦截器等等），都放在某一个自实现的</strong></strong>mvcConfig<strong><strong>中（例如上面的</strong></strong>MyViewConfig<strong><strong>），方便管理，也可以实现多个扩展的</strong></strong>webMvcConfig,<strong>**按照功能放置自定义的组件。</strong></p>
<h4 id="2-2-扩展mvc原理"><a href="#2-2-扩展mvc原理" class="headerlink" title="2.2 扩展mvc原理"></a>2.2 扩展mvc原理</h4><p>查看<strong>WebMvcAutoConfiguration**</strong>代码的适配器代码，可以知道关键代码是<strong>**@Import(EnableWebMvcConfiguration.class)</strong></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image158.jpg" alt="img"></p>
<p>点进去 <strong>EnableWebMvcConfiguration.class**</strong>，发现他还是<strong><strong>WebMvcAutoConfiguration</strong></strong>的一个内部类。**</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image160.jpg" alt="img"></p>
<p><strong>查看</strong> <strong>DelegatingWebMvcConfiguration</strong> <strong>类。</strong></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image162.jpg" alt="img"></p>
<p><strong>可以看到他是加载了容器中所有**</strong>WebMvcConfigurer<strong><strong>类型的配置类，然后逐个调用。这里也可以证明了，我们自定义的扩展类仅仅只是扩展了</strong></strong>mvc<strong>**的功能而已，并没有让其他自动配置功能失效。</strong></p>
<h3 id="3、全面接管SpringMVC"><a href="#3、全面接管SpringMVC" class="headerlink" title="3、全面接管SpringMVC"></a>3、全面接管SpringMVC</h3><p>全面接管也就意味着：<strong>SpringBoot**</strong>对<strong><strong>SpringMVC</strong></strong>的自动配置不需要了，所有都是我们自己配置，所有的<strong><strong>SpringMVC</strong></strong>的自动配置都会失效。**</p>
<p><strong>我们需要在配置类中添加**</strong>@EnableWebMvc<strong>**即可</strong></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image164.jpg" alt="img"></p>
<p>访问：发现提示界面找不到了。</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image166.jpg" alt="img"></p>
<p>加上注解，启动springboot项目，我们通过控制台输出的日志中我们发现少了一些filter。然后我们对于静态资源的默认访问路径等等都失效了。也就是说，访问html界面等等都行不通了。</p>
<p><strong>这些代码都会失效，所以请求访问不到静态界面</strong></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image168.jpg" alt="img"></p>
<h4 id="3-1-原理"><a href="#3-1-原理" class="headerlink" title="3.1 原理"></a>3.1 原理</h4><p><strong>1**</strong>）<strong><strong>@EnableWebMvc</strong></strong>的核心**</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image170.jpg" alt="img"></p>
<p>可以看到他的核心是导入一个类 DelegatingWebMvcConfiguration</p>
<p><strong>2**</strong>）<strong><strong>DelegatingWebMvcConfiguration</strong></strong>类**</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image172.jpg" alt="img"></p>
<p>这个类就是我们上面2.2节查看注册各种适配器的关键代码，那么这里并没有什么代码控制 <strong>mvc**</strong>自动配置失效** </p>
<p><strong>发现它继承</strong> <strong>WebMvcConfigurationSupport</strong> <strong>，这个类我们好像在那里看见过</strong></p>
<p><strong>2**</strong>）查看<strong>**WebMvcAutoConfiguration</strong></p>
<p>让我们回过头查看mvc自动配置类</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image174.jpg" alt="img"></p>
<p>注意到一段代码：@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)</p>
<p>意思是：当WebMvcConfigurationSupport类在容器中找不到时，执行自动配置类。</p>
<p>那么我们加上了<strong>@EnableWebMvc**</strong>注解，就相当于把<strong><strong>WebMvcConfigurationSupport</strong></strong>类注入到了容器中，所以<strong><strong>WebMvcAutoConfiguration</strong></strong>自动配置类失效。**</p>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p><strong>3**</strong>）、<strong><strong>@EnableWebMvc</strong></strong>将<strong><strong>WebMvcConfigurationSupport</strong></strong>组件导入进来；**</p>
<p><strong>4**</strong>）、导入的<strong><strong>WebMvcConfigurationSupport</strong></strong>只是<strong><strong>SpringMVC</strong></strong>最基本的功能；**</p>
<h2 id="7-5-默认访问首页"><a href="#7-5-默认访问首页" class="headerlink" title="7.5 默认访问首页"></a>7.5 默认访问首页</h2><p>通过查看WebMVCAutoConfiguration源代码可以知道，默认的”/”请求是会定向到类路径</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image175.png" alt="img"></p>
<p>下的index.html界面，那么我们可不可以手动控制他呢？</p>
<p>很明显是可以的。</p>
<h3 id="1-实现方式1"><a href="#1-实现方式1" class="headerlink" title="1.实现方式1"></a>1.实现方式1</h3><p>实现一个controller，映射”/”请求</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image177.jpg" alt="img"></p>
<p>​    </p>
<h3 id="2-实现方式2"><a href="#2-实现方式2" class="headerlink" title="2.实现方式2"></a>2.实现方式2</h3><p><img src="/2019/01/30/springboot个人总结/clip_image179.jpg" alt="img"></p>
<h2 id="7-6-国际化"><a href="#7-6-国际化" class="headerlink" title="7.6 国际化"></a>7.6 国际化</h2><p><strong>1**</strong>）、编写国际化配置文件；**</p>
<p>2）、使用ResourceBundleMessageSource管理国际化资源文件</p>
<p>3）、在页面使用fmt:message取出国际化内容</p>
<p>步骤：</p>
<p>1）、编写国际化配置文件，抽取页面需要显示的国际化消息</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image180.png" alt="img"></p>
<p>第一个properties表示是在没有指定语言的情况下，默认的显示值</p>
<p>2）、SpringBoot自动配置好了管理国际化资源文件的组件；</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image182.jpg" alt="img"></p>
<p>3）、配置国际化基础名</p>
<p>   在application.properties中设置</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image184.jpg" alt="img"></p>
<p>3）、去页面获取国际化的值；</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image186.jpg" alt="img"></p>
<p>效果：根据浏览器语言设置的信息切换了国际化；</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>国际化的核心是：</p>
<p> 国际化Locale（区域信息对象）；LocaleResolver（获取区域信息对象）；</p>
<p>查看默认的区域信息解析器：</p>
<p>在WebMvcAutoConfiguration中</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image188.jpg" alt="img"></p>
<p>初始化了一个区域信息解析器，查看获取区域信息相关带代码</p>
<p>AcceptHeaderLocaleResolver ，看到这个类，我们可以猜测他是通过请求头中获取区域编码</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image190.jpg" alt="img"></p>
<p>看到 Accept-Language 说明上面我们的猜测是正确的。</p>
<p><strong>也就是说，国际化的区域信息，默认是通过请求头中获取。而且需要注意的是当**</strong>spring<strong><strong>容器中如果缺失</strong></strong>LocaleResolver<strong><strong>这个</strong></strong>bean<strong>**实例，那么才会去加载默认的，区域化信息解析器。（下面的点击链接切换国际化就是很好的利用了这个注解）</strong></p>
<h3 id="点击链接切换国际化"><a href="#点击链接切换国际化" class="headerlink" title="点击链接切换国际化"></a>点击链接切换国际化</h3><p>知道了上的原理，我们就可以手动的控制，切换语言环境。</p>
<p>1.实现一个区域信息解析器，通过获取请求中l的值，设定响应的语言环境。</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image192.jpg" alt="img"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">因为我们自定义实现了LocalResolver，那么根据@ConditionalOnMissingBean这个注解</div></pre></td></tr></table></figure>
<p><img src="/2019/01/30/springboot个人总结/clip_image193.png" alt="img"></p>
<p>那么springboot默认的区域化解析器就会失效。</p>
<p>\2. 实例化到spring容器中</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image195.jpg" alt="img"></p>
<p><strong>上面的两个步骤可以整合在一起，最终实现：</strong></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image197.jpg" alt="img"></p>
<p>在自定义的LocaleResolver中直接注入到spring容器中。<strong>注意需要指明**</strong>bean<strong><strong>的</strong></strong>id<strong><strong>是</strong></strong>localeResolver**</p>
<p>3.通过链接实现</p>
<p><a href="http://127.0.0.1:8080/login.html?i=en_US" target="_blank" rel="external">http://127.0.0.1:8080/login.html?i=en_US</a></p>
<p><a href="http://127.0.0.1:8080/login.html?i=en_US" target="_blank" rel="external">http://127.0.0.1:8080/login.html?i=en_US</a></p>
<h2 id="7-7-themleaf关闭缓存"><a href="#7-7-themleaf关闭缓存" class="headerlink" title="7.7 themleaf关闭缓存"></a>7.7 themleaf关闭缓存</h2><p>Thymeleaf会在第一次对模板解析之后进行缓存，极大的提高了并发处理能力，但是在开发期间模板引擎页面修改以后，要实时生效，所以我们开发阶段可以关掉缓存使用</p>
<p>1）、禁用模板引擎的缓存</p>
<pre><code>\# 禁用缓存

spring.thymeleaf.cache=false 
</code></pre><p>2）、页面修改完成以后ctrl+f9：重新编译；</p>
<h2 id="7-8-自定义拦截器"><a href="#7-8-自定义拦截器" class="headerlink" title="7.8 自定义拦截器"></a>7.8 自定义拦截器</h2><p><img src="/2019/01/30/springboot个人总结/clip_image199.jpg" alt="img"></p>
<h3 id="1-第一种实现方式"><a href="#1-第一种实现方式" class="headerlink" title="1. 第一种实现方式"></a>1. 第一种实现方式</h3><p>继承WebMvcConfigurerAdapter</p>
<p>1.定义一个拦截器实现HandlerInterceptor接口</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image201.jpg" alt="img"></p>
<p>2.注册到容器中</p>
<p>我们把扩展mvc的组件都放在自定义mvc扩展类中：MyMvcConfig</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image203.jpg" alt="img"></p>
<h3 id="2-第二种方式（常见）"><a href="#2-第二种方式（常见）" class="headerlink" title="2. 第二种方式（常见）"></a>2. 第二种方式（常见）</h3><p>1.</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image205.jpg" alt="img"></p>
<p>\2. 然后定义配置类，注册拦截器</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image207.jpg" alt="img"></p>
<p>3.运行输出</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image208.png" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image209.png" alt="img"></p>
<p>接下来运行并查看日志：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image211.jpg" alt="img"></p>
<p>你会发现日志中只有这些打印信息，springMVC的日志信息都没有，因为springMVC记录的log级别是debug，springboot默认是显示info以上，我们需要进行配置。</p>
<p>SpringBoot通过logging.level.<em>=debug来配置日志级别，</em>填写包名</p>
<p># 设置org.springframework包的日志级别为debug</p>
<p>logging.level.org.springframework=debug</p>
<p>设置完后，访问请求，查看输出</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image213.jpg" alt="img"></p>
<p>相比springmvc，springboot已经帮我们做好了静态资源的映射访问，所以不需要额外处理。</p>
<h2 id="7-9-springmvc默认日期类型转化"><a href="#7-9-springmvc默认日期类型转化" class="headerlink" title="7.9 springmvc默认日期类型转化"></a>7.9 springmvc默认日期类型转化</h2><p>例如从前台传回一个时间字符串，后台通过date日期类型进行映射获取。那么如果前台日期格式是：2017/12/12 ，那么mvc会自动转化为date类型，因为他的默认时间转换器是以/ 进行分割的。</p>
<p>   如果是2017-12-12、2017.12.12   这样的日期格式，那么就需要我们自己实现日期转换器</p>
<p>  通过查看WebMvcAutoConfiguration的源码得知：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image215.jpg" alt="img"></p>
<p>默认的日期格式是使用反斜杠来分割。</p>
<p>–修改默认的日期格式化：</p>
<p> 只需要在applicatio.proeprties文件中，覆盖默认的日期格式即可</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image216.png" alt="img"></p>
<h2 id="7-10-post-get请求转化为put或其他"><a href="#7-10-post-get请求转化为put或其他" class="headerlink" title="7.10 post/get请求转化为put或其他"></a>7.10 post/get请求转化为put或其他</h2><p>我们知道html的form表单只支持get/post两种请求，那么我们使用restful url进行请求数据的时候，那么需要使用到put请求，那么怎么转化呢？</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image218.jpg" alt="img"></p>
<h2 id="7-11错误处理机制"><a href="#7-11错误处理机制" class="headerlink" title="7.11错误处理机制"></a>7.11错误处理机制</h2><h3 id="1）、SpringBoot默认的错误处理机制"><a href="#1）、SpringBoot默认的错误处理机制" class="headerlink" title="1）、SpringBoot默认的错误处理机制"></a>1）、SpringBoot默认的错误处理机制</h3><p>当我们访问一个不存在的资源时，那么springboot默认帮我们跳转到一个错误界面</p>
<p>1.使用pc浏览器访问</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image220.jpg" alt="img"></p>
<p>2.使用其他工具访问（postman）</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image222.jpg" alt="img"></p>
<p>我们不难发现，他返回错误的形式都是不一样的，前者返回一个html界面，后者返回的是一个json字符串。为什么会有两种错误请求返回方式呢？接下来看源码就知道了。</p>
<p>原理：</p>
<pre><code>  可以参照ErrorMvcAutoConfiguration；错误处理的自动配置；

给容器中添加了以下四个组件

  1、DefaultErrorAttributes：
</code></pre><p><img src="/2019/01/30/springboot个人总结/clip_image224.jpg" alt="img"></p>
<pre><code>2、BasicErrorController：他是一个基本的错误控制类。处理默认/error请求
</code></pre><p><img src="/2019/01/30/springboot个人总结/clip_image226.jpg" alt="img"></p>
<p>是一个controller，处理/error请求</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image228.jpg" alt="img"></p>
<p><strong>这里就解释了为什么会出现，两种错误请求响应方式（**</strong>html<strong><strong>和</strong></strong>josn<strong>**）</strong></p>
<p><strong>那么会产生另一个问题，他是怎么知道客户端是**</strong>pc<strong><strong>还是其他访问工具呢？究竟怎么选择返回哪种格式的错误消息</strong></strong>??????????**</p>
<p>  很明显是通过请求头进行区分的。</p>
<p>1.通过postman发出的请求，请求头是：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image230.jpg" alt="img"></p>
<p>2.通过浏览器发出的请求，请求头是：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image231.png" alt="img"></p>
<p>3、ErrorPageCustomizer：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image233.jpg" alt="img"></p>
<p>查看getpath()，</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image235.jpg" alt="img"></p>
<p>总的来说：系统出现错误以后来到error请求进行处理；（类似我们在web.xml注册的错误页面规则-根据不同的错误码，响应不同的错误界面：使用<error-page>标签）</error-page></p>
<p>4、DefaultErrorViewResolver：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image237.jpg" alt="img"></p>
<p>主要解析代码：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image239.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image241.jpg" alt="img"></p>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><pre><code>步骤：




        一但系统出现4xx或者5xx之类的错误；ErrorPageCustomizer就会生效（定制错误的响应规则）；就会来到/error请求；就会被BasicErrorController处理；




        1）响应页面；去哪个页面是由DefaultErrorViewResolver解析得到的；
</code></pre><p><img src="/2019/01/30/springboot个人总结/clip_image243.jpg" alt="img"></p>
<h3 id="2）、如果定制错误响应："><a href="#2）、如果定制错误响应：" class="headerlink" title="2）、如果定制错误响应："></a>2）、如果定制错误响应：</h3><h4 id="1）、如何定制错误的页面；"><a href="#1）、如何定制错误的页面；" class="headerlink" title="1）、如何定制错误的页面；"></a>1）、如何定制错误的页面；</h4><p><strong>1**</strong>）、有模板引擎的情况下**；error/状态码; 【将错误页面命名为  错误状态码.html 放在模板引擎文件夹里面的 error文件夹下】，发生此状态码的错误就会来到对应的页面；</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image244.png" alt="img"></p>
<p>那么就会存在一个缺点，那就是如果我想把所有4开头的错误码都定向到一个错误界面怎么办呢？</p>
<p>我们回过头查看DefaultErrorViewResolver 源代码发现，他默认注册了两个规则4xx和5xx。</p>
<p><strong>我们可以使用**</strong>4xx<strong><strong>和</strong></strong>5xx<strong><strong>作为错误页面的文件名来匹配这种类型的所有错误，精确优先（优先寻找精确的状态码</strong></strong>.html<strong>**）；</strong>        </p>
<p>页面能获取的信息（我们可以在自定义的错误界面获取到这些信息，参见DefaultErrorAttributes源码）</p>
<p>timestamp：时间戳</p>
<p>status：状态码</p>
<p>error：错误提示</p>
<p>exception：异常对象</p>
<p>message：异常消息</p>
<p>errors：JSR303数据校验的错误都在这里</p>
<p>2）、<strong>没有模板引擎</strong>（模板引擎找不到这个错误页面），静态资源文件夹（static）下找</p>
<p>3）、<strong>以上都没有错误页面</strong>，就是默认来到SpringBoot默认的错误提示页面</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image246.jpg" alt="img"></p>
<h4 id="2）、如何定制错误的json数据；"><a href="#2）、如何定制错误的json数据；" class="headerlink" title="2）、如何定制错误的json数据；"></a>2）、如何定制错误的json数据；</h4><p>1）、自定义异常处理&amp;返回定制json数据；</p>
<p>实现一个异常处理controller</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image248.jpg" alt="img"></p>
<p>只要是UserNotExistEception的异常都交由此方法处理，并返回自己自己定制json信息。</p>
<p>   缺点: 永远返回json格式信息，没有html界面（7.11.1.1）。</p>
<p>2）、转发到/error进行自适应响应效果处理</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image250.jpg" alt="img"></p>
<p>缺点：自定义的map错误数据，没有携带过去。</p>
<h4 id="3）、将我们的定制数据携带出去；"><a href="#3）、将我们的定制数据携带出去；" class="headerlink" title="3）、将我们的定制数据携带出去；"></a>3）、将我们的定制数据携带出去；</h4><p>出现错误以后，会来到/error请求，会被BasicErrorController处理，响应出去可以获取的数据是由getErrorAttributes得到的（是AbstractErrorController（ErrorController）规定的方法）；</p>
<p>1、完全来编写一个ErrorController的实现类【或者是编写AbstractErrorController的子类】，放在容器中（<strong>这种方式太过麻烦不推荐</strong>）</p>
<p>2、页面上能用的数据，或者是json返回能用的数据都是通过errorAttributes.getErrorAttributes得到（<strong>推荐这种方法</strong>）</p>
<p>容器中DefaultErrorAttributes.getErrorAttributes()；默认进行数据处理的；</p>
<p>自定义ErrorAttributes</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image252.jpg" alt="img"></p>
<h1 id="八-默认嵌套的Servlet服务器"><a href="#八-默认嵌套的Servlet服务器" class="headerlink" title="八. 默认嵌套的Servlet服务器"></a>八. 默认嵌套的Servlet服务器</h1><p><img src="/2019/01/30/springboot个人总结/clip_image254.jpg" alt="img"></p>
<p>打开springboot项目的pom文件，查看依赖。</p>
<h2 id="8-1如何定制和修改Servlet容器的相关配置"><a href="#8-1如何定制和修改Servlet容器的相关配置" class="headerlink" title="8.1如何定制和修改Servlet容器的相关配置"></a>8.1如何定制和修改Servlet容器的相关配置</h2><p>1、修改和server有关的配置（ServerProperties也是EmbeddedServletContainerCustomizer的实现）-<strong>第一种方式</strong></p>
<p>就是我们直接在application.properties文件中的修改操作</p>
<p>   server.port=8081   server.context-path=/crud   server.tomcat.uri-encoding=UTF-8   </p>
<p>2、编写一个EmbeddedServletContainerCustomizer：嵌入式的Servlet容器的定制器；来修改Servlet容器的配置 – <strong>第二种方式</strong></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image256.jpg" alt="img"></p>
<h2 id="8-2-替换为其他嵌入式Servlet容器"><a href="#8-2-替换为其他嵌入式Servlet容器" class="headerlink" title="8.2 替换为其他嵌入式Servlet容器"></a>8.2 替换为其他嵌入式Servlet容器</h2><p>Springboot 完美的集成了下面这三款servlet容器，只需要做一些小改动即可切换使用。</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image258.jpg" alt="img"></p>
<p>具体实现的容器工厂类。</p>
<h3 id="1-默认使用tomcat"><a href="#1-默认使用tomcat" class="headerlink" title="1. 默认使用tomcat"></a>1. 默认使用tomcat</h3><p><img src="/2019/01/30/springboot个人总结/clip_image260.jpg" alt="img"></p>
<h3 id="2-Jetty"><a href="#2-Jetty" class="headerlink" title="2. Jetty"></a>2. Jetty</h3><p><img src="/2019/01/30/springboot个人总结/clip_image262.jpg" alt="img"></p>
<p>做法其实很简单，那就是一出web模块自动装配的tomcat 组件，然后引入jetty组件即可。Jetty适合在开发长连接的项目中使用（例如聊天类的项目）</p>
<h3 id="3-Undertow"><a href="#3-Undertow" class="headerlink" title="3. Undertow"></a>3. Undertow</h3><p><img src="/2019/01/30/springboot个人总结/clip_image264.jpg" alt="img"></p>
<p>Undertow不支持jsp界面</p>
<h2 id="8-3-嵌入式Servlet容器自动配置原理"><a href="#8-3-嵌入式Servlet容器自动配置原理" class="headerlink" title="8.3 嵌入式Servlet容器自动配置原理"></a>8.3 嵌入式Servlet容器自动配置原理</h2><h3 id="1-源码分析"><a href="#1-源码分析" class="headerlink" title="1. 源码分析"></a>1. 源码分析</h3><p>EmbeddedServletContainerAutoConfiguration：嵌入式的Servlet容器自动配置</p>
<p>  <img src="/2019/01/30/springboot个人总结/clip_image266.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image268.jpg" alt="img"></p>
<p>可以看到容器的切换，是通过注解来进行控制。<strong>通过容器工厂进行创建相应的容器</strong></p>
<p>1）、EmbeddedServletContainerFactory（嵌入式Servlet容器工厂）</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image270.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image272.jpg" alt="img"></p>
<p>通过 getEmbeddedServletContainer()获得相应的servlet容器。</p>
<p>2）、EmbeddedServletContainer：（嵌入式的Servlet容器）</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image274.jpg" alt="img"></p>
<p>总的来说：通过servlet容器工厂类来创建相应的servlet容器</p>
<h3 id="2-以tomcat容器工厂为例，分析流程"><a href="#2-以tomcat容器工厂为例，分析流程" class="headerlink" title="2.以tomcat容器工厂为例，分析流程"></a>2.以tomcat容器工厂为例，分析流程</h3><p> 1.查看<strong>TomcatEmbeddedServletContainerFactory</strong></p>
<pre><code>**重点是：****getEmbeddedServletContainer****方法**
</code></pre><p><img src="/2019/01/30/springboot个人总结/clip_image276.jpg" alt="img"></p>
<h3 id="3-ServerProperties、EmbeddedServletContainerCustomizer"><a href="#3-ServerProperties、EmbeddedServletContainerCustomizer" class="headerlink" title="3. ServerProperties、EmbeddedServletContainerCustomizer"></a>3. ServerProperties、EmbeddedServletContainerCustomizer</h3><p>我们知道我们修改application.properties都是映射成ServerProperties</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image278.jpg" alt="img"></p>
<p>他实现了EmbeddedServletContainerCustomizer接口，所以衍生出了，第二种修改servlet容器的配置的方法：</p>
<pre><code>自定义实现EmbeddedServletContainerCustomizer：
</code></pre><p><img src="/2019/01/30/springboot个人总结/clip_image279.jpg" alt="img"></p>
<p>那么这些改动是怎么样生效的呢?</p>
<p>容器中导入了<strong>EmbeddedServletContainerCustomizerBeanPostProcessor</strong></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image281.jpg" alt="img"></p>
<p>步骤：</p>
<p>1）、SpringBoot根据导入的依赖情况，给容器中添加相应的EmbeddedServletContainerFactory【TomcatEmbeddedServletContainerFactory】</p>
<p>2）、容器中某个组件要创建对象就会惊动后置处理器；EmbeddedServletContainerCustomizerBeanPostProcessor；</p>
<p>只要是嵌入式的Servlet容器工厂，后置处理器就工作；</p>
<p>3）、后置处理器，从容器中获取所有的EmbeddedServletContainerCustomizer，调用定制器的定制方法</p>
<h2 id="8-4-嵌入式Servlet容器启动原理"><a href="#8-4-嵌入式Servlet容器启动原理" class="headerlink" title="8.4 嵌入式Servlet容器启动原理"></a>8.4 嵌入式Servlet容器启动原理</h2><p>什么时候创建嵌入式的Servlet容器工厂？什么时候获取嵌入式的Servlet容器并启动Tomcat；</p>
<p>获取嵌入式的Servlet容器工厂：</p>
<p>1）、SpringBoot应用启动运行run方法</p>
<p>2）、refreshContext(context);SpringBoot刷新IOC容器【创建IOC容器对象，并初始化容器，创建容器中的每一个组件】；如果是web应用创建<strong>AnnotationConfigEmbeddedWebApplicationContext</strong>，否则：<strong>AnnotationConfigApplicationContext</strong></p>
<p>3）、refresh(context);<strong>刷新刚才创建好的**</strong>ioc<strong>**容器；</strong></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image283.jpg" alt="img"></p>
<p>4）、 onRefresh(); web的ioc容器重写了onRefresh方法</p>
<p>5）、webioc容器会创建嵌入式的Servlet容器；<strong>createEmbeddedServletContainer</strong>();</p>
<p><strong>6**</strong>）、获取嵌入式的<strong><strong>Servlet</strong></strong>容器工厂：**</p>
<p>EmbeddedServletContainerFactory containerFactory = getEmbeddedServletContainerFactory();</p>
<p> 从ioc容器中获取EmbeddedServletContainerFactory 组件；<strong>TomcatEmbeddedServletContainerFactory</strong>创建对象，后置处理器一看是这个对象，就获取所有的定制器来先定制Servlet容器的相关配置；</p>
<p>7）、<strong>使用容器工厂获取嵌入式的**</strong>Servlet<strong>**容器</strong>：this.embeddedServletContainer = containerFactory .getEmbeddedServletContainer(getSelfInitializer());</p>
<p>8）、嵌入式的Servlet容器创建对象并启动Servlet容器；</p>
<p><strong>先启动嵌入式的**</strong>Servlet<strong><strong>容器，再将</strong></strong>ioc<strong>**容器中剩下没有创建出的对象获取出来；</strong></p>
<p><strong>==IOC**</strong>容器启动创建嵌入式的<strong><strong>Servlet</strong></strong>容器<strong>**==</strong></p>
<h1 id="九．-springboot注册三大组件"><a href="#九．-springboot注册三大组件" class="headerlink" title="九． springboot注册三大组件"></a>九． springboot注册三大组件</h1><p>三大组件：servlet、filter、listenner</p>
<p>传统的web项目，我们可以在webroot/WEB_INFO/web.xml 中配置我们三大组件，但是springboot打包方式采用jar的方式，内嵌servlet容器，那么我们应该在哪里注册这三大组件呢？</p>
<h2 id="9-1-注册servle"><a href="#9-1-注册servle" class="headerlink" title="9.1 注册servle"></a>9.1 注册servle</h2><p>1.首先自定义一个servler</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image285.jpg" alt="img"></p>
<p>2.通过ServletRegistrationBean注册自定义servle</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image287.jpg" alt="img"></p>
<p> 注意：<strong>如果存在一个**</strong>controller<strong><strong>同时映射了</strong></strong>/myServlet<strong> </strong>请求，那么就会失效（被自定义<strong><strong>servlet</strong></strong>所覆盖）。**</p>
<h2 id="9-2-注册filter"><a href="#9-2-注册filter" class="headerlink" title="9.2 注册filter"></a>9.2 注册filter</h2><p>1.首先自定义一个filter</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image289.jpg" alt="img"></p>
<p>2.FilterRegistrationBean</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image291.jpg" alt="img"></p>
<h2 id="9-3-注册listenner"><a href="#9-3-注册listenner" class="headerlink" title="9.3 注册listenner"></a>9.3 注册listenner</h2><p>1.首先自定义一个listenner</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image293.jpg" alt="img"></p>
<p>2.ServletListenerRegistrationBean</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image295.jpg" alt="img"></p>
<h2 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h2><p>SpringBoot帮我们自动SpringMVC的时候，自动的注册SpringMVC的前端控制器；DIspatcherServlet；</p>
<p>DispatcherServletAutoConfiguration中：</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image297.jpg" alt="img"></p>
<h1 id="10-使用外置的Servlet容器"><a href="#10-使用外置的Servlet容器" class="headerlink" title="10 使用外置的Servlet容器"></a>10 使用外置的Servlet容器</h1><p>嵌入式Servlet容器：应用打成可执行的jar</p>
<pre><code>优点：简单、便携

缺点：默认不支持JSP、优化定制比较复杂（虽然可以使用定制器【ServerProperties、自定义EmbeddedServletContainerCustomizer】，自己编写嵌入式Servlet容器的创建工厂【EmbeddedServletContainerFactory】等方式修改配置，但是还是在需要通读代码的情况下才能够修改）
</code></pre><p>外置的Servlet容器：外面安装Tomcat—应用war包的方式打包</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p>1）、必须创建一个项目打包类型为war的项目；（利用idea创建好目录结构，因为默认生成的springboot项目是没有webapp和web.xml等文件，需要手动创建）</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image299.jpg" alt="img"></p>
<p>下一步</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image301.jpg" alt="img"></p>
<p>完成</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image303.jpg" alt="img"></p>
<p><strong>很明显没有生成相应的**</strong>webapp<strong><strong>目录，同时</strong></strong>tomcat<strong><strong>的作用域修改为了运行时使用，打包不使用，这个也就是为我们使用外置</strong></strong>servlet<strong>**容器打下基础。</strong></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image305.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image307.jpg" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image309.jpg" alt="img"></p>
<p><strong>项目最终目录结构</strong></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image311.jpg" alt="img"></p>
<p>2）、将嵌入式的Tomcat指定为provided；</p>
<p><strong>Springboot**</strong>默认已经帮我们完成**</p>
<p>3）、必须编写一个SpringBootServletInitializer的子类，并调用configure方法</p>
<pre><code>**Springboot****默认已经帮我们完成**
</code></pre><p>4）、启动服务器就可以使用</p>
<p>   可以编写一个jsp界面，访问测试</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image312.png" alt="img"></p>
<p><img src="/2019/01/30/springboot个人总结/clip_image313.png" alt="img"></p>
<h2 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h2><p>jar包：执行SpringBoot主类的main方法，启动ioc容器，创建嵌入式的Servlet容器</p>
<p>war包：启动服务器，服务器启动SpringBoot应用【SpringBootServletInitializer】，启动ioc容器</p>
<p>实现方式：Servlet3.0是一次Java EE规范</p>
<p><a href="https://blog.csdn.net/f641385712/article/details/87474907" target="_blank" rel="external">https://blog.csdn.net/f641385712/article/details/87474907</a> 相关连接</p>
<h3 id="规则："><a href="#规则：" class="headerlink" title="规则："></a>规则：</h3><pre><code>1）、服务器启动（web应用启动）会创建当前web应用里面每一个jar包里面ServletContainerInitializer实例

2）、ServletContainerInitializer的实现放在jar包的META-INF/services文件夹下，有一个名为javax.servlet.ServletContainerInitializer的文件，内容就是ServletContainerInitializer的实现类的全类名

3）、还可以使用@HandlesTypes，在应用启动的时候加载我们感兴趣的类
</code></pre><h3 id="流程："><a href="#流程：" class="headerlink" title="流程："></a>流程：</h3><p>1）、启动Tomcat</p>
<p>2）、org\springframework\spring-web\4.3.14.RELEASE\spring-web-4.3.14.RELEASE.jar!\META-INF\services\javax.servlet.ServletContainerInitializer：</p>
<p>Spring的web模块里面有这个文件：org.springframework.web.SpringServletContainerInitializer</p>
<p>3）、SpringServletContainerInitializer将@HandlesTypes(WebApplicationInitializer.class)标注的所有这个类型的类都传入到onStartup方法的Set<class<?>&gt;；为这些WebApplicationInitializer类型的类创建实例；</class<?></p>
<p>4）、每一个WebApplicationInitializer都调用自己的onStartup；</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image314.png" alt="img"></p>
<p>5）、相当于我们的SpringBootServletInitializer的类会被创建对象，并执行onStartup方法</p>
<p>6）、SpringBootServletInitializer实例执行onStartup的时候会createRootApplicationContext；创建容器</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image316.jpg" alt="img"></p>
<p>7）、Spring的应用就启动并且创建IOC容器</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image318.jpg" alt="img"></p>
<p><strong>==**</strong>启动<strong><strong>Servlet</strong></strong>容器，再启动<strong><strong>SpringBoot</strong></strong>应用<strong>**==</strong></p>
<h1 id="十一、Springboot整合其他技术"><a href="#十一、Springboot整合其他技术" class="headerlink" title="十一、Springboot整合其他技术"></a>十一、Springboot整合其他技术</h1><h2 id="11-1-整合Mybatis"><a href="#11-1-整合Mybatis" class="headerlink" title="11.1 整合Mybatis"></a>11.1 整合Mybatis</h2><h3 id="1-Idea创建一个springboot项目并选择以下依赖"><a href="#1-Idea创建一个springboot项目并选择以下依赖" class="headerlink" title="1.Idea创建一个springboot项目并选择以下依赖"></a>1.Idea创建一个springboot项目并选择以下依赖</h3><p><img src="/2019/01/30/springboot个人总结/clip_image320.jpg" alt="img"></p>
<p>点击下一步完成项目创建，查看项目的pom文件</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image322.jpg" alt="img"></p>
<h3 id="2-完善项目的目录结构（MVC结构）"><a href="#2-完善项目的目录结构（MVC结构）" class="headerlink" title="2.完善项目的目录结构（MVC结构）"></a>2.完善项目的目录结构（MVC结构）</h3><p><img src="/2019/01/30/springboot个人总结/clip_image324.jpg" alt="img"></p>
<p><strong>在资源文件夹中新建**</strong>application.yml<strong>**文件</strong></p>
<h3 id="3-在application-yml文件中书写数据库配置"><a href="#3-在application-yml文件中书写数据库配置" class="headerlink" title="3.在application.yml文件中书写数据库配置"></a>3.在application.yml文件中书写数据库配置</h3><p><img src="/2019/01/30/springboot个人总结/clip_image326.jpg" alt="img"></p>
<p>   spring:     profiles:       active: dev   mybatis:     type-aliases-package: com.kingge.entity     mapper-locations: classpath:mapper/*.xml           —   spring:     profiles: dev         datasource:       url:   jdbc:mysql://127.0.0.1:3306/test?serverTimezone=GMT       driver-class-name: com.mysql.cj.jdbc.Driver       username: root       password: 123   #com.mysql.jdbc.Driver 注意这个已经过时，推荐使用上面那个   </p>
<h3 id="4-编写entity、dao、service、serviceimpl、xml、conrtoller"><a href="#4-编写entity、dao、service、serviceimpl、xml、conrtoller" class="headerlink" title="4.编写entity、dao、service、serviceimpl、xml、conrtoller"></a>4.编写entity、dao、service、serviceimpl、xml、conrtoller</h3><p>4.1 User</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image328.jpg" alt="img"></p>
<p>4.2 dao</p>
<p>需要注意，配置文件没有配置mapper接口扫描包，因此我们需要给每一个Mapper/dao接口添加@Mapper注解，才能被识别。</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image330.jpg" alt="img"></p>
<p>4.3  service</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image332.jpg" alt="img"></p>
<p>4.4 serviceimpl</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image334.jpg" alt="img"></p>
<p>4.5 mapper.xml</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image336.jpg" alt="img"></p>
<p>4.6 controller</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image338.jpg" alt="img"></p>
<p>完整目录结构展示</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image340.jpg" alt="img"></p>
<h3 id="5-运行项目访问请求"><a href="#5-运行项目访问请求" class="headerlink" title="5.     运行项目访问请求"></a>5.     运行项目访问请求</h3><p><img src="/2019/01/30/springboot个人总结/clip_image342.jpg" alt="img"></p>
<p>访问成功！！！！！！</p>
<h3 id="6-通过junit方式测试"><a href="#6-通过junit方式测试" class="headerlink" title="6.通过junit方式测试"></a>6.通过junit方式测试</h3><p><img src="/2019/01/30/springboot个人总结/clip_image344.jpg" alt="img"></p>
<h2 id="11-2-整合Spring-Data-JPA"><a href="#11-2-整合Spring-Data-JPA" class="headerlink" title="11.2.整合Spring Data JPA"></a>11.2.整合Spring Data JPA</h2><h3 id="1-添加Spring-Data-JPA的起步依赖"><a href="#1-添加Spring-Data-JPA的起步依赖" class="headerlink" title="1 添加Spring Data JPA的起步依赖"></a>1 添加Spring Data JPA的起步依赖</h3><pre><code>&lt;!-- springBoot JPA的起步依赖 --&gt;       &lt;dependency&gt;             &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;             &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;       &lt;/dependency&gt;   
</code></pre><h3 id="2-添加数据库驱动依赖"><a href="#2-添加数据库驱动依赖" class="headerlink" title="2 添加数据库驱动依赖"></a>2 添加数据库驱动依赖</h3><pre><code>&lt;!-- MySQL连接驱动 --&gt;

&lt;dependency&gt;

    &lt;groupId&gt;mysql&lt;/groupId&gt;

    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;

&lt;/dependency&gt;
</code></pre><h3 id="3-在application-properties中配置数据库和jpa的相关属性"><a href="#3-在application-properties中配置数据库和jpa的相关属性" class="headerlink" title="3 在application.properties中配置数据库和jpa的相关属性"></a>3 在application.properties中配置数据库和jpa的相关属性</h3><p>DB   Configuration:   spring.datasource.driverClassName=com.mysql.jdbc.Driver   spring.datasource.url=jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&amp;characterEncoding=utf8   spring.datasource.username=root   spring.datasource.password=root       #JPA   Configuration:   spring.jpa.database=MySQL   spring.jpa.show-sql=true   spring.jpa.generate-ddl=true   spring.jpa.hibernate.ddl-auto=update   spring.jpa.hibernate.naming_strategy=org.hibernate.cfg.ImprovedNamingStrategy   </p>
<h3 id="4-创建实体配置实体"><a href="#4-创建实体配置实体" class="headerlink" title="4 创建实体配置实体"></a>4 创建实体配置实体</h3><p>   @Entity   public   class User {       // 主键       @Id       @GeneratedValue(strategy =   GenerationType.IDENTITY)       private Long id;       // 用户名       private String username;       // 密码       private String password;       // 姓名       private String name;       //此处省略setter和getter方法… …   }   </p>
<h3 id="5-编写UserRepository"><a href="#5-编写UserRepository" class="headerlink" title="5 编写UserRepository"></a>5 编写UserRepository</h3><pre><code>public interface UserRepository extends JpaRepository&lt;User,Long&gt;{

    public List&lt;User&gt; findAll();

}
</code></pre><h3 id="6-编写测试类"><a href="#6-编写测试类" class="headerlink" title="6 编写测试类"></a>6 编写测试类</h3><p>   @RunWith(SpringRunner.class)   @SpringBootTest(classes=MySpringBootApplication.class)   public class JpaTest {           @Autowired       private UserRepository userRepository;       @Test       public void test(){           List<user> users =   userRepository.findAll();           System.out.println(users);       }   }   </user></p>
<h3 id="7-控制台打印信息"><a href="#7-控制台打印信息" class="headerlink" title="7 控制台打印信息"></a>7 控制台打印信息</h3><p><img src="/2019/01/30/springboot个人总结/clip_image346.jpg" alt="img"></p>
<p>注意：如果是jdk9，执行报错如下：</p>
<p>原因：jdk缺少相应的jar</p>
<p>解决方案：手动导入对应的maven坐标，如下：</p>
<pre><code>&lt;!--jdk9需要导入如下坐标--&gt;

&lt;dependency&gt;

    &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt;

    &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt;

    &lt;version&gt;2.3.0&lt;/version&gt;

&lt;/dependency&gt;
</code></pre><h1 id="11-3-整合redis"><a href="#11-3-整合redis" class="headerlink" title="11.3 整合redis"></a>11.3 整合redis</h1><h2 id="1-添加redis的起步依赖"><a href="#1-添加redis的起步依赖" class="headerlink" title="1 添加redis的起步依赖"></a>1 添加redis的起步依赖</h2><p>   <!-- 配置使用redis启动器 -->   <dependency>         <groupid>org.springframework.boot</groupid>         <artifactid>spring-boot-starter-data-redis</artifactid>   </dependency>   </p>
<h2 id="2-配置redis的连接信息"><a href="#2-配置redis的连接信息" class="headerlink" title="2 配置redis的连接信息"></a>2 配置redis的连接信息</h2><p>#Redis</p>
<p>spring.redis.host=127.0.0.1</p>
<p>spring.redis.port=6379</p>
<h2 id="3-注入RedisTemplate测试redis操作"><a href="#3-注入RedisTemplate测试redis操作" class="headerlink" title="3 注入RedisTemplate测试redis操作"></a>3 注入RedisTemplate测试redis操作</h2><p>   @RunWith(SpringRunner.class)   @SpringBootTest(classes = SpringbootJpaApplication.class)   public class RedisTest {           @Autowired       private UserRepository userRepository;       @Autowired       private RedisTemplate<string, string=""> redisTemplate;           @Test       public void test() throws   JsonProcessingException {             //从redis缓存中获得指定的数据           String userListData =   redisTemplate.boundValueOps(“user.findAll”).get();           //如果redis中没有数据的话           if(null==userListData){               //查询数据库获得数据               List<user> all =   userRepository.findAll();               //转换成json格式字符串               ObjectMapper om = new   ObjectMapper();               userListData =   om.writeValueAsString(all);               //将数据存储到redis中，下次在查询直接从redis中获得数据，不用在查询数据库                 redisTemplate.boundValueOps(“user.findAll”).set(userListData);                 System.out.println(“===============从数据库获得数据===============”);           }else{                 System.out.println(“===============从redis缓存中获得数据===============”);           }           System.out.println(userListData);       }   }   </user></string,></p>
<h1 id="十二、springboot运行流程回顾"><a href="#十二、springboot运行流程回顾" class="headerlink" title="十二、springboot运行流程回顾"></a>十二、springboot运行流程回顾</h1><h2 id="1-启动柜springboot程序"><a href="#1-启动柜springboot程序" class="headerlink" title="1.启动柜springboot程序"></a>1.启动柜springboot程序</h2><p><img src="/2019/01/30/springboot个人总结/clip_image348.jpg" alt="img"></p>
<p>断点进入-step into 发现</p>
<p><img src="/2019/01/30/springboot个人总结/clip_image350.jpg" alt="img"></p>
<p>停在了这里，也就是说他会首先创建SpringApplication对象</p>
<h2 id="2-创建SpringApplication对象"><a href="#2-创建SpringApplication对象" class="headerlink" title="2. 创建SpringApplication对象"></a>2. 创建SpringApplication对象</h2><p>创建SpringApplication对象运行run方法</p>
<p>继续进入方法</p>
</html>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一．前言&quot;&gt;&lt;a href=&quot;#一．前言&quot; class=&quot;headerlink&quot; title=&quot;一．前言&quot;&gt;&lt;/a&gt;一．前言&lt;/h1&gt;&lt;h2 id=&quot;1-1-什么是微服务？&quot;&gt;&lt;a href=&quot;#1-1-什么是微服务？&quot; class=&quot;headerlink&quot; ti
    
    </summary>
    
      <category term="SpringBoot" scheme="http://kingge.top/categories/SpringBoot/"/>
    
    
      <category term="分布式" scheme="http://kingge.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="springboot" scheme="http://kingge.top/tags/springboot/"/>
    
      <category term="微服务" scheme="http://kingge.top/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>dubbo分布式服务框架</title>
    <link href="http://kingge.top/2019/01/05/dubbo%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6/"/>
    <id>http://kingge.top/2019/01/05/dubbo分布式服务框架/</id>
    <published>2019-01-05T02:21:59.000Z</published>
    <updated>2019-08-25T02:24:55.615Z</updated>
    
    <content type="html"><![CDATA[<p>Dubbo分布式服务框架**</p>
<h1 id="一、分布式概念"><a href="#一、分布式概念" class="headerlink" title="一、分布式概念"></a>一、分布式概念</h1><p>分布式的概念：某个业务逻辑的完成，拆分成几个功能/服务来实现，这些服务部署在不同的机器上。</p>
<blockquote>
<p>官方解释：</p>
<p>分布式系统是由一组<strong>通过网络</strong>进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。分布式系统的出现是为了用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务。其目的是利用更多的机器，处理更多的数据。</p>
<p>　　首先需要明确的是，<strong>只有当单个节点的处理能力无法满足日益增长的计算、存储任务的时候，且硬件的提升（加内存、加磁盘、使用更好的CPU）高昂到得不偿失的时候，应用程序也不能进一步优化的时候，我们才需要考虑分布式系统</strong>。因为，分布式系统要解决的问题本身就是和单机系统一样的，而由于分布式系统多节点、通过网络通信的拓扑结构，会引入很多单机系统没有的问题，为了解决这些问题又会引入更多的机制、协议，带来更多的问题。</p>
</blockquote>
<p>​    随着互联网的发展，网站应用的规模不断扩大，常规的<strong>垂直应用架构</strong>已无法应对，分布式服务架构以及流动计算架构势在必行，需一个治理系统确保架构有条不紊的演进。</p>
<h2 id="1-1分布式的演化"><a href="#1-1分布式的演化" class="headerlink" title="1.1分布式的演化"></a>1.1分布式的演化</h2><p><img src="/2019/01/05/dubbo分布式服务框架/1566286104187.png" alt="1566286104187"></p>
<h3 id="1-1-1单一应用架构"><a href="#1-1-1单一应用架构" class="headerlink" title="1.1.1单一应用架构"></a>1.1.1单一应用架构</h3><p>当网站流量很小时，只需一个应用，将所有功能都部署在一起(例如)，以减少部署节点和成本。</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566287100179.png" alt="1566287100179"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566287125516.png" alt="1566287125516"></p>
<p><strong>总的来说，一个项目就打包成一个war包，然后订单业务处理、商品等等所有业务都在这个war包里。</strong></p>
<p>适用于小型网站，小型管理系统，将所有功能都部署到一个功能里，简单易用。</p>
<blockquote>
<p>缺点：</p>
</blockquote>
<p>1、性能扩展比较难</p>
<p>2、存在重复性开发的代码</p>
<p>3、不利于升级维护</p>
<p>4、 只能采用同一种技术，很难用不同的语言或者语言不同版本开发不同模块；</p>
<p>5、系统耦合性强，一旦其中一个模块有问题，整个系统就瘫痪了；一旦升级其中一个模块，整个系统就停机了；</p>
<p>6、 集群只能是复制整个系统，即使只是其中一个模块压力大。（可能整个订单处理，仅仅是支付模块压力过大， 按道理只需要升级支付模块，但是在单一场景里面是不能的）</p>
<p>最直观问题就是，</p>
<blockquote>
<p>1.代码不够整洁，多个业务的功能都堆在一个包中，例如UserService、OrderService等等功能都放在com.kingge.service包中。当功能增多时，这个包会变得更加臃肿，代码阅读性很差。</p>
<p>2.服务之间依赖错综复杂不够清晰。</p>
<p>3.只能够通过部署集群来提高系统性能，资源浪费</p>
</blockquote>
<h3 id="1-1-2垂直应用架构"><a href="#1-1-2垂直应用架构" class="headerlink" title="1.1.2垂直应用架构"></a>1.1.2垂直应用架构</h3><p>​    当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用<strong>拆成互不相干</strong>的几个应用，以提升效率，<strong>这样就可以单独修改某个模块而不用重启或者影响其他模块，同时也可以给某个访问量剧增的模块，单独添加服务器</strong>。</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566287183867.png" alt="1566287183867"></p>
<p>​    通过切分业务来实现各个模块独立部署，降低了维护和部署的难度，团队各司其职更易管理，性能扩展也更方便，更有针对性。</p>
<p>缺点： 公用模块无法重复利用，开发性的浪费</p>
<p>面对突变的应用场景，可能某个模块对于web界面会频繁修改，但是模块业务功能没有变化，这样会造成单个应用频繁修改。所以需要<strong>界面+业务逻辑的实现分离。</strong></p>
<p>没有处理好应用之间的交互问题，例如订单模块可能会需要查询商品模块的信息。</p>
<h3 id="1-1-3分布式服务架构"><a href="#1-1-3分布式服务架构" class="headerlink" title="1.1.3分布式服务架构"></a>1.1.3分布式服务架构</h3><p>​    当垂直应用越来越多，<strong>应用之间交互不可避免</strong>，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的<strong>分布式服务框架(RPC)</strong>是关键（例如Dubbo）。（<strong>springcloud比他更全面，Dubbo只是相当于Spring Cloud中的Eureka模块</strong>）</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566289053579.png" alt="1566289053579"></p>
<p><strong>分布式服务框架很好的解决了垂直应用架构的缺点，实现界面和服务的分离，实现界面和服务，以及服务与服务之间的调度。</strong></p>
<p><strong>但是存在一个问题，那就是没有</strong>一个基于访问压力的调度中心和服务注册中心，容易造成资源浪费，什么意思呢？假设用户服务部署了200台服务器，但是在某个时间段，他的访问压力很小，订单服务的访问压力剧增，服务器不够用。那么就会造成资源浪费和倾斜，存在服务器闲置或者请求量少的情况。</p>
<h3 id="1-1-4流动计算架构"><a href="#1-1-4流动计算架构" class="headerlink" title="1.1.4流动计算架构"></a>1.1.4流动计算架构</h3><p>当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于<strong>提高机器利用率的资源调度和治理中心(SOA)[ Service Oriented Architecture]是关键</strong>。</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566289240354.png" alt="1566289240354"></p>
<p>很好的解决了分布式架构的缺点。</p>
<p>SOA解决了服务的管理和注册，但是还是缺少服务容灾处理，网关处理以及全局配置模块等等（分别对应springcloud的hystrix、zuul、config）</p>
<h3 id="1-1-5-微服务架构"><a href="#1-1-5-微服务架构" class="headerlink" title="1.1.5 微服务架构"></a>1.1.5 微服务架构</h3><p>其实SOA架构跟微服务架构是很接近的，其实我也不是那么清晰的能够分别这种两种架构，所以这一章节暂缺。</p>
<p>但是他提供了比SOA架构更加细致化的服务拆分和管理，一般常用restful的方式进行数据的传输，SOA架构的传输技术是比较复杂多样的。</p>
<p>他的实现，见springcloud架构</p>
<h2 id="1-2-RPC"><a href="#1-2-RPC" class="headerlink" title="1.2 RPC"></a>1.2 RPC</h2><h3 id="1-2-1什么叫RPC"><a href="#1-2-1什么叫RPC" class="headerlink" title="1.2.1什么叫RPC"></a>1.2.1什么叫RPC</h3><p>RPC【Remote Procedure Call】是指远程过程调用，是一种进程间通信方式，他是一种技术的思想，而不是规范。它允许程序调用另一个地址空间（通常是共享网络的另一台机器上）的过程或函数，而不用程序员显式编码这个远程调用的细节。即程序员无论是调用本地的还是远程的函数，本质上编写的调用代码基本相同。</p>
<h3 id="1-2-2RPC基本原理"><a href="#1-2-2RPC基本原理" class="headerlink" title="1.2.2RPC基本原理"></a>1.2.2RPC基本原理</h3><p><img src="/2019/01/05/dubbo分布式服务框架/1566289474934.png" alt="1566289474934"></p>
<p>​    模型中多了一个stub的组件，这个是约定的接口，也就是server提供的服务。注意这里的”接口”，不是指JAVA中的interface，因为RPC是跨平台跨语言的，用JAVA写的客户端，应该能够调用用C语言提供的过程</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566289516712.png" alt="1566289516712"></p>
<p>一次完整的RPC调用流程（同步调用，异步另说）如下：<br>1）服务消费方（client）调用以本地调用方式调用服务；<br>2）client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体；<br>3）client stub找到服务地址，并将消息发送到服务端；<br>4）server stub收到消息后进行解码；<br>5）server stub根据解码结果调用本地的服务；<br>6）本地服务执行并将结果返回给server stub；<br>7）server stub将返回结果打包成消息并发送至消费方；<br>8）client stub接收到消息，并进行解码；<br>9）服务消费方得到最终结果。</p>
<p><strong>RPC两个核心模块：通讯，序列化。</strong></p>
<p>也就是说决定RPC连接效率的核心因素了，服务之间通讯的速度，以及消息序列化和反序列化的速度（<strong>这个就是为什么hadoop会采用自己的反序列化机制而不是java的反序列化，Java的序列化是一个重量级序列化框架（Serializable），一个对象被序列化后，会附带很多额外的信息（各种校验信息，header，继承体系等），不便于在网络中高效传输。所以，hadoop自己开发了一套序列化机制（Writable），精简、高效</strong>）</p>
<p>常用的RPC框架：dubbo，gRPC，thrift。HSF</p>
<h1 id="二、Dubbo概念和理解"><a href="#二、Dubbo概念和理解" class="headerlink" title="二、Dubbo概念和理解"></a>二、Dubbo概念和理解</h1><h2 id="2-1-概念"><a href="#2-1-概念" class="headerlink" title="2.1 概念"></a>2.1 概念</h2><p>官网：</p>
<p><a href="http://dubbo.apache.org/" target="_blank" rel="external">[http://dubbo.apache.org/]{}</a></p>
<p>Apache Dubbo 是一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：<strong>面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现</strong>。<strong>即是：提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案</strong></p>
<p>Dubbo是阿里巴巴公司开源的一个高性能优秀的服务框架，后来Dubbo 进入 Apache 孵化器。</p>
<p>Dubbo 采用全 Spring 配置方式，透明化接入应用，对应用没有任何 API 侵入，只需用 Spring 加载 Dubbo 的配置即可，Dubbo 基于 <a href="https://docs.spring.io/spring/docs/4.2.x/spring-framework-reference/html/xsd-configuration.html" target="_blank" rel="external">Spring 的 Schema 扩展</a> 进行加载。</p>
<p>如果不想使用 Spring 配置，可以通过 <a href="http://dubbo.apache.org/zh-cn/docs/user/configuration/api.html" target="_blank" rel="external">API 的方式</a> 进行调用。</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290381952.png" alt="1566290381952"></p>
<p>官方文档</p>
<p><a href="http://dubbo.apache.org/zh-cn/docs/user/quick-start.html" target="_blank" rel="external">http://dubbo.apache.org/zh-cn/docs/user/quick-start.html</a></p>
<h2 id="2-2-dubbo结构"><a href="#2-2-dubbo结构" class="headerlink" title="2.2 dubbo结构"></a>2.2 dubbo结构</h2><p><img src="/2019/01/05/dubbo分布式服务框架/1566290406638.png" alt="1566290406638"></p>
<p><strong>服务提供者（Provider）</strong>：暴露服务的服务提供方，服务提供者在启动时，向注册中心注册自己提供的服务。</p>
<p><strong>服务消费者（Consumer）</strong>: 调用远程服务的服务消费方，服务消费者在启动时，向注册中心订阅自己所需的服务，服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。</p>
<p><strong>注册中心（Registry）</strong>：注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者</p>
<p><strong>监控中心（Monitor）</strong>：服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心</p>
<blockquote>
<p>调用关系说明</p>
</blockquote>
<ul>
<li>服务容器负责启动，加载，运行服务提供者。</li>
<li>服务提供者在启动时，向注册中心注册自己提供的服务。</li>
<li>服务消费者在启动时，向注册中心订阅自己所需的服务。</li>
<li>注册中心返回<strong>服务提供者地址列表</strong>给消费者，<strong>如果有变更，注册中心将基于长连接推送变更数据给消费者</strong>。</li>
<li>服务消费者，从提供者地址列表中，基于<strong>软负载均衡算法（不是硬件级别的负载均衡）</strong>，选一台提供者进行调用，如果调用失败，再选另一台调用。</li>
<li>服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。</li>
</ul>
<h2 id="2-3-dubbo架构"><a href="#2-3-dubbo架构" class="headerlink" title="2.3 dubbo架构"></a>2.3 dubbo架构</h2><p>Dubbo 架构具有以下几个特点，分别是连通性、健壮性、伸缩性、以及向未来架构的升级性。</p>
<blockquote>
<p>连通性</p>
</blockquote>
<ul>
<li>注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小</li>
<li>监控中心负责统计各服务调用次数，调用时间等，统计先在内存汇总后每分钟一次发送到监控中心服务器，并以报表展示</li>
<li>服务提供者向注册中心注册其提供的服务，并汇报调用时间到监控中心，此时间不包含网络开销</li>
<li>服务消费者向注册中心获取服务提供者地址列表，并根据负载算法直接调用提供者，同时汇报调用时间到监控中心，此时间包含网络开销</li>
<li><strong>注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外</strong></li>
<li>注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者</li>
<li>注册中心和监控中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表</li>
<li>注册中心和监控中心都是可选的，服务消费者可以直连服务提供者</li>
</ul>
<blockquote>
<p>健壮性</p>
</blockquote>
<ul>
<li>监控中心宕掉不影响使用，只是丢失部分采样数据</li>
<li>数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务</li>
<li>注册中心对等集群，任意一台宕掉后，将自动切换到另一台</li>
<li>注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯</li>
<li>服务提供者无状态，任意一台宕掉后，不影响使用</li>
<li>服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复</li>
</ul>
<blockquote>
<p>伸缩性</p>
</blockquote>
<ul>
<li>注册中心为对等集群，可动态增加机器部署实例，所有客户端将自动发现新的注册中心</li>
<li>服务提供者无状态，可动态增加机器部署实例，注册中心将推送新的服务提供者信息给消费者</li>
</ul>
<blockquote>
<p>升级性</p>
</blockquote>
<p>当服务集群规模进一步扩大，带动IT治理结构进一步升级，需要实现动态部署，进行流动计算，现有分布式服务架构不会带来阻力。下图是未来可能的一种架构：</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/C1566315977504.png" alt="1566315977504"></p>
<blockquote>
<p>节点角色说明</p>
</blockquote>
<table>
<thead>
<tr>
<th>节点</th>
<th>角色说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Deployer</code></td>
<td>自动部署服务的本地代理</td>
</tr>
<tr>
<td><code>Repository</code></td>
<td>仓库用于存储服务应用发布包</td>
</tr>
<tr>
<td><code>Scheduler</code></td>
<td>调度中心基于访问压力自动增减服务提供者</td>
</tr>
<tr>
<td><code>Admin</code></td>
<td>统一管理控制台</td>
</tr>
<tr>
<td><code>Registry</code></td>
<td>服务注册与发现的注册中心</td>
</tr>
<tr>
<td><code>Monitor</code></td>
<td>统计服务的调用次数和调用时间的监控中心</td>
</tr>
</tbody>
</table>
<h1 id="三、Dubbo环境搭建"><a href="#三、Dubbo环境搭建" class="headerlink" title="三、Dubbo环境搭建"></a>三、Dubbo环境搭建</h1><h2 id="3-1-windows下搭建dubbo环境"><a href="#3-1-windows下搭建dubbo环境" class="headerlink" title="3.1 windows下搭建dubbo环境"></a>3.1 windows下搭建dubbo环境</h2><h3 id="3-1-1-安装zookeeper"><a href="#3-1-1-安装zookeeper" class="headerlink" title="3.1.1 安装zookeeper"></a>3.1.1 安装zookeeper</h3><p>Dubbo推荐使用zookeeper作为注册中心</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290541231.png" alt="1566290541231"></p>
<h4 id="1-登录zookeeper官网下载zookeeper"><a href="#1-登录zookeeper官网下载zookeeper" class="headerlink" title="1.登录zookeeper官网下载zookeeper"></a>1.登录zookeeper官网下载zookeeper</h4><p><a href="https://archive.apache.org/dist/zookeeper/zookeeper-3.4.13/" target="_blank" rel="external">[https://archive.apache.org/dist/zookeeper/zookeeper-3.4.13/]{.underline}</a></p>
<p>这里以zookeeper-3.4.13为例</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290557194.png" alt="1566290557194"></p>
<h4 id="2-下载后解压修改zoo-cfg配置文件"><a href="#2-下载后解压修改zoo-cfg配置文件" class="headerlink" title="2.下载后解压修改zoo.cfg配置文件"></a>2.下载后解压修改zoo.cfg配置文件</h4><p>将conf下的zoo_sample.cfg复制一份改名为zoo.cfg即可。</p>
<p>注意几个重要位置：</p>
<p>dataDir=./ 临时数据存储的目录（可写相对路径）</p>
<p>clientPort=2181 zookeeper的端口号</p>
<p>修改完成后启动zookeeper</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290595424.png" alt="1566290595424"></p>
<p>在zookeeeper目录下新建zooData目录保存数据</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290609336.png" alt="1566290609336"></p>
<h4 id="3-运行zkServer-cmd"><a href="#3-运行zkServer-cmd" class="headerlink" title="3. 运行zkServer.cmd"></a>3. 运行zkServer.cmd</h4><p>启动成功后，使用zkCli.cmd测试</p>
<p>ls /：列出zookeeper根目录下保存的所有节点</p>
<p>create  -e /kingge 123：创建一个临时的kingge节点，值为123 </p>
<p>get / kingge：获取/ kingge节点的值</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/5C1566316581085.png" alt="1566316581085"></p>
<h3 id="3-1-2安装dubbo-admin管理控制台"><a href="#3-1-2安装dubbo-admin管理控制台" class="headerlink" title="3.1.2安装dubbo-admin管理控制台"></a>3.1.2安装dubbo-admin管理控制台</h3><p>dubbo本身并不是一个服务软件。它其实就是一个jar包能够帮你的java程序连接到zookeeper，并利用zookeeper消费、提供服务。所以你不用在Linux上启动什么dubbo服务。</p>
<p>但是为了让用户更好的管理监控众多的dubbo服务，官方提供了一个可视化的监控程序，不过这个监控即使不装也不影响使用。</p>
<h5 id="1、下载dubbo-admin"><a href="#1、下载dubbo-admin" class="headerlink" title="1、下载dubbo-admin"></a>1、下载dubbo-admin</h5><p><a href="https://github.com/apache/incubator-dubbo-ops" target="_blank" rel="external">[https://github.com/apache/incubator-dubbo-ops]{.underline}</a></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290668291.png" alt="1566290668291"></p>
<p>下载下来后解压</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290676682.png" alt="1566290676682"></p>
<h5 id="2、进入目录，修改dubbo-admin配置"><a href="#2、进入目录，修改dubbo-admin配置" class="headerlink" title="2、进入目录，修改dubbo-admin配置"></a>2、进入目录，修改dubbo-admin配置</h5><p>修改 src\main\resources\application.properties 指定zookeeper地址</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290697445.png" alt="1566290697445"></p>
<h5 id="3、打包dubbo-admin（maven环境已经配置好）"><a href="#3、打包dubbo-admin（maven环境已经配置好）" class="headerlink" title="3、打包dubbo-admin（maven环境已经配置好）"></a>3、打包dubbo-admin（maven环境已经配置好）</h5><p>mvn clean package -Dmaven.test.skip=true</p>
<h5 id="4、运行dubbo-admin"><a href="#4、运行dubbo-admin" class="headerlink" title="4、运行dubbo-admin"></a>4、运行dubbo-admin</h5><p>java -jar dubbo-admin-0.0.1-SNAPSHOT.jar （springboot方式启动项目）</p>
<p><strong>注意：【有可能控制台看着启动了，但是网页打不开，需要在控制台按下ctrl+c即可】</strong></p>
<p>默认使用root/root 登陆</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290717831.png" alt="1566290717831"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290725111.png" alt="1566290725111"></p>
<h2 id="3-2-linux下搭建dubbo环境"><a href="#3-2-linux下搭建dubbo环境" class="headerlink" title="3.2 linux下搭建dubbo环境"></a>3.2 linux下搭建dubbo环境</h2><h3 id="3-2-1安装zookeeper"><a href="#3-2-1安装zookeeper" class="headerlink" title="3.2.1安装zookeeper"></a>3.2.1安装zookeeper</h3><h4 id="1、安装jdk"><a href="#1、安装jdk" class="headerlink" title="1、安装jdk"></a>1、安装jdk</h4><h5 id="1、下载jdk"><a href="#1、下载jdk" class="headerlink" title="1、下载jdk"></a>1、下载jdk</h5><p><a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="external">[http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html]{.underline}</a></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290751589.png" alt="1566290751589"></p>
<p>不要使用wget命令获取jdk链接，这是默认不同意，导致下载来的jdk压缩内容错误</p>
<h5 id="2、上传到服务器并解压"><a href="#2、上传到服务器并解压" class="headerlink" title="2、上传到服务器并解压"></a>2、上传到服务器并解压</h5><p><img src="/2019/01/05/dubbo分布式服务框架/1566290768923.png" alt="1566290768923"></p>
<h5 id="3、设置环境变量"><a href="#3、设置环境变量" class="headerlink" title="3、设置环境变量"></a>3、设置环境变量</h5><p>/usr/local/java/jdk1.8.0_171</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290797058.png" alt="1566290797058"></p>
<p>文件末尾加入下面配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">export JAVA_HOME=/usr/local/java/jdk1.8.0_171</div><div class="line">export JRE_HOME=$&#123;JAVA_HOME&#125;/jre</div><div class="line">export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib</div><div class="line">export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH</div></pre></td></tr></table></figure>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290830224.png" alt="1566290830224"></p>
<h5 id="4、使环境变量生效-amp-测试JDK"><a href="#4、使环境变量生效-amp-测试JDK" class="headerlink" title="4、使环境变量生效&amp;测试JDK"></a>4、使环境变量生效&amp;测试JDK</h5><p><img src="/2019/01/05/dubbo分布式服务框架/1566290857129.png" alt="1566290857129"></p>
<h4 id="2、安装zookeeper"><a href="#2、安装zookeeper" class="headerlink" title="2、安装zookeeper"></a>2、安装zookeeper</h4><h5 id="1、下载zookeeper"><a href="#1、下载zookeeper" class="headerlink" title="1、下载zookeeper"></a>1、下载zookeeper</h5><p>网址 <a href="https://archive.apache.org/dist/zookeeper/zookeeper-3.4.11/" target="_blank" rel="external">[https://archive.apache.org/dist/zookeeper/zookeeper-3.4.11/]{.underline}</a></p>
<p>wget <a href="https://archive.apache.org/dist/zookeeper/zookeeper-3.4.11/zookeeper-3.4.11.tar.gz" target="_blank" rel="external">[https://archive.apache.org/dist/zookeeper/zookeeper-3.4.11/zookeeper-3.4.11.tar.gz]{.underline}</a></p>
<h5 id="2、解压"><a href="#2、解压" class="headerlink" title="2、解压"></a>2、解压</h5><p><img src="/2019/01/05/dubbo分布式服务框架/1566290893977.png" alt="1566290893977"></p>
<h5 id="3、移动到指定位置并改名为zookeeper"><a href="#3、移动到指定位置并改名为zookeeper" class="headerlink" title="3、移动到指定位置并改名为zookeeper"></a>3、移动到指定位置并改名为zookeeper</h5><p><img src="/2019/01/05/dubbo分布式服务框架/1566290917596.png" alt="1566290917596"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290924377.png" alt="1566290924377"></p>
<h4 id="3、开机启动zookeeper（可选）"><a href="#3、开机启动zookeeper（可选）" class="headerlink" title="3、开机启动zookeeper（可选）"></a>3、开机启动zookeeper（可选）</h4><p>1）-复制如下脚本</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290945358.png" alt="1566290945358"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">#!/bin/bash</div><div class="line">#chkconfig:2345 20 90</div><div class="line">#description:zookeeper</div><div class="line">#processname:zookeeper</div><div class="line">ZK_PATH=/usr/local/zookeeper</div><div class="line">export JAVA_HOME=/usr/local/java/jdk1.8.0_171</div><div class="line">case $1 in</div><div class="line">         start) sh  $ZK_PATH/bin/zkServer.sh start;;</div><div class="line">         stop)  sh  $ZK_PATH/bin/zkServer.sh stop;;</div><div class="line">         status) sh  $ZK_PATH/bin/zkServer.sh status;;</div><div class="line">         restart) sh $ZK_PATH/bin/zkServer.sh restart;;</div><div class="line">         *)  echo &quot;require start|stop|status|restart&quot;  ;;</div><div class="line">esac</div></pre></td></tr></table></figure>
<p>2）-把脚本注册为Service</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290980024.png" alt="1566290980024"></p>
<p>3）-增加权限</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566290989654.png" alt="1566290989654"></p>
<h4 id="4、配置zookeeper"><a href="#4、配置zookeeper" class="headerlink" title="4、配置zookeeper"></a>4、配置zookeeper</h4><h5 id="1、初始化zookeeper配置文件"><a href="#1、初始化zookeeper配置文件" class="headerlink" title="1、初始化zookeeper配置文件"></a>1、初始化zookeeper配置文件</h5><p>拷贝/usr/local/zookeeper/conf/zoo_sample.cfg</p>
<p>到同一个目录下改个名字叫zoo.cfg</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566291008251.png" alt="1566291008251"></p>
<h5 id="2、启动zookeeper"><a href="#2、启动zookeeper" class="headerlink" title="2、启动zookeeper"></a>2、启动zookeeper</h5><p><img src="/2019/01/05/dubbo分布式服务框架/1566291018179.png" alt="1566291018179"></p>
<h3 id="3-2-2安装dubbo-admin管理控制台"><a href="#3-2-2安装dubbo-admin管理控制台" class="headerlink" title="3.2.2安装dubbo-admin管理控制台"></a>3.2.2安装dubbo-admin管理控制台</h3><h4 id="1、安装Tomcat8（旧版dubbo-admin是war，新版是jar不需要安装Tomcat）"><a href="#1、安装Tomcat8（旧版dubbo-admin是war，新版是jar不需要安装Tomcat）" class="headerlink" title="1、安装Tomcat8（旧版dubbo-admin是war，新版是jar不需要安装Tomcat）"></a>1、安装Tomcat8（旧版dubbo-admin是war，新版是jar不需要安装Tomcat）</h4><h5 id="1、下载Tomcat8并解压"><a href="#1、下载Tomcat8并解压" class="headerlink" title="1、下载Tomcat8并解压"></a>1、下载Tomcat8并解压</h5><p><a href="https://tomcat.apache.org/download-80.cgi" target="_blank" rel="external">[https://tomcat.apache.org/download-80.cgi]{.underline}</a></p>
<p>wget<a href="http://mirrors.shu.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz" target="_blank" rel="external">[http://mirrors.shu.edu.cn/apache/tomcat/tomcat-8/v8.5.32/bin/apache-tomcat-8.5.32.tar.gz]{.underline}</a></p>
<p>提供两种访问方式</p>
<h5 id="2、解压移动到指定位置"><a href="#2、解压移动到指定位置" class="headerlink" title="2、解压移动到指定位置"></a>2、解压移动到指定位置</h5><p><img src="/2019/01/05/dubbo分布式服务框架/1566291034045.png" alt="1566291034045"></p>
<h5 id="3、开机启动tomcat8"><a href="#3、开机启动tomcat8" class="headerlink" title="3、开机启动tomcat8"></a>3、开机启动tomcat8</h5><p><img src="/2019/01/05/dubbo分布式服务框架/1566291058211.png" alt="1566291058211"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">复制如下脚本</div><div class="line">#!/bin/bash</div><div class="line">#chkconfig:2345 21 90</div><div class="line">#description:apache-tomcat-8</div><div class="line">#processname:apache-tomcat-8</div><div class="line">CATALANA_HOME=/opt/apache-tomcat-8.5.32</div><div class="line">export JAVA_HOME=/opt/java/jdk1.8.0_171</div><div class="line">case $1 in</div><div class="line">start)</div><div class="line">    echo &quot;Starting Tomcat...&quot;  </div><div class="line">    $CATALANA_HOME/bin/startup.sh</div><div class="line">    ;;</div><div class="line"></div><div class="line">stop)</div><div class="line">    echo &quot;Stopping Tomcat...&quot;  </div><div class="line">    $CATALANA_HOME/bin/shutdown.sh</div><div class="line">    ;;</div><div class="line"></div><div class="line">restart)</div><div class="line">    echo &quot;Stopping Tomcat...&quot;  </div><div class="line">    $CATALANA_HOME/bin/shutdown.sh</div><div class="line">    sleep 2</div><div class="line">    echo  </div><div class="line">    echo &quot;Starting Tomcat...&quot;  </div><div class="line">    $CATALANA_HOME/bin/startup.sh</div><div class="line">    ;;</div><div class="line">*)</div><div class="line">    echo &quot;Usage: tomcat &#123;start|stop|restart&#125;&quot;  </div><div class="line">    ;; esac</div></pre></td></tr></table></figure>
<h5 id="4、注册服务-amp-添加权限"><a href="#4、注册服务-amp-添加权限" class="headerlink" title="4、注册服务&amp;添加权限"></a>4、注册服务&amp;添加权限</h5><p><img src="/2019/01/05/dubbo分布式服务框架/1566291080594.png" alt="1566291080594"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566291085955.png" alt="1566291085955"></p>
<h5 id="5、启动服务-amp-访问tomcat测试"><a href="#5、启动服务-amp-访问tomcat测试" class="headerlink" title="5、启动服务&amp;访问tomcat测试"></a>5、启动服务&amp;访问tomcat测试</h5><p><img src="/2019/01/05/dubbo分布式服务框架/1566291099386.png" alt="1566291099386"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566291105871.png" alt="1566291105871"></p>
<h4 id="2、安装dubbo-admin"><a href="#2、安装dubbo-admin" class="headerlink" title="2、安装dubbo-admin"></a>2、安装dubbo-admin</h4><p>dubbo本身并不是一个服务软件。它其实就是一个jar包能够帮你的java程序连接到zookeeper，并利用zookeeper消费、提供服务。所以你不用在Linux上启动什么dubbo服务。</p>
<p>但是为了让用户更好的管理监控众多的dubbo服务，官方提供了一个可视化的监控程序，不过这个监控即使不装也不影响使用。</p>
<h5 id="1、下载dubbo-admin-1"><a href="#1、下载dubbo-admin-1" class="headerlink" title="1、下载dubbo-admin"></a>1、下载dubbo-admin</h5><p><a href="https://github.com/apache/incubator-dubbo-ops" target="_blank" rel="external">[https://github.com/apache/incubator-dubbo-ops]{.underline}</a></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/Users\Administrator\AppData\Roaming\Typora\typora-user-images\1566291121104.png" alt="1566291121104"></p>
<h5 id="2、进入目录，修改dubbo-admin配置-1"><a href="#2、进入目录，修改dubbo-admin配置-1" class="headerlink" title="2、进入目录，修改dubbo-admin配置"></a>2、进入目录，修改dubbo-admin配置</h5><p>修改 src\main\resources\application.properties 指定zookeeper地址</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566291151295.png" alt="1566291151295"></p>
<h5 id="3、打包dubbo-admin"><a href="#3、打包dubbo-admin" class="headerlink" title="3、打包dubbo-admin"></a>3、打包dubbo-admin</h5><p>mvn clean package -Dmaven.test.skip=true</p>
<h5 id="4、运行dubbo-admin-1"><a href="#4、运行dubbo-admin-1" class="headerlink" title="4、运行dubbo-admin"></a>4、运行dubbo-admin</h5><p>java -jar dubbo-admin-0.0.1-SNAPSHOT.jar</p>
<p>默认使用root/root 登陆</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566291170915.png" alt="1566291170915"></p>
<h2 id="3-3-测试dubbo（dubbo-hello）"><a href="#3-3-测试dubbo（dubbo-hello）" class="headerlink" title="3.3 测试dubbo（dubbo-hello）"></a>3.3 测试dubbo（dubbo-hello）</h2><p><a href="http://dubbo.apache.org/zh-cn/docs/user/quick-start.html" target="_blank" rel="external">[http://dubbo.apache.org/zh-cn/docs/user/quick-start.html]{.underline}</a> 官方例子</p>
<h3 id="4-1）、提出需求"><a href="#4-1）、提出需求" class="headerlink" title="4.1）、提出需求"></a>4.1）、提出需求</h3><p>某个电商系统，订单服务需要调用用户服务获取某个用户的所有地址；</p>
<p>我们现在 需要创建两个服务模块进行测试</p>
<table>
<thead>
<tr>
<th>模块</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td>订单服务web模块</td>
<td>创建订单等</td>
</tr>
<tr>
<td>用户服务service模块</td>
<td>查询用户地址等</td>
</tr>
</tbody>
</table>
<p>测试预期结果：</p>
<p>订单服务web模块在A服务器，用户服务模块在B服务器，A可以远程调用B的功能。</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566291213865.png" alt="1566291213865"></p>
<h3 id="4-2）、工程架构"><a href="#4-2）、工程架构" class="headerlink" title="4.2）、工程架构"></a>4.2）、工程架构</h3><p>根据 dubbo《服务化最佳实践》</p>
<p><a href="http://dubbo.apache.org/zh-cn/docs/user/best-practice.html" target="_blank" rel="external">http://dubbo.apache.org/zh-cn/docs/user/best-practice.html</a></p>
<h4 id="1、分包（就是抽取公共的接口或者实体类到一个工程）"><a href="#1、分包（就是抽取公共的接口或者实体类到一个工程）" class="headerlink" title="1、分包（就是抽取公共的接口或者实体类到一个工程）"></a>1、分包（就是抽取公共的接口或者实体类到一个工程）</h4><p>​    建议将服务接口，服务模型，服务异常等均放在 API 包中，因为服务模型及异常也是 API 的一部分，同时，这样做也符合分包原则：重用发布等价原则(REP)，共同重用原则(CRP)。</p>
<p>​    如果需要，也可以考虑在 API 包中放置一份 spring 的引用配置，这样使用方，只需在 spring 加载过程中引用此配置即可，配置建议放在模块的包目录下，以免冲突，如：com/alibaba/china/xxx/dubbo-reference.xml。</p>
<p>​    <strong>就是为了避免重复书写某些代码，抽取公共部分代码形成一个模块（例如下面的common-interface），其他模块需要用到时，添加依赖即可（pom文件）</strong></p>
<h4 id="2、粒度"><a href="#2、粒度" class="headerlink" title="2、粒度"></a>2、粒度</h4><p>​    服务接口尽可能大粒度，每个服务方法应代表一个功能，而不是某功能的一个步骤，否则将面临分布式事务问题，Dubbo 暂未提供分布式事务支持。服务接口建议以业务场景为单位划分，并对相近业务做抽象，防止接口数量爆炸。不建议使用过于抽象的通用接口，如：Map query(Map)，这样的接口没有明确语义，会给后期维护带来不便。</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566291645433.png" alt="1566291645433"></p>
<h3 id="4-3）、创建模块"><a href="#4-3）、创建模块" class="headerlink" title="4.3）、创建模块"></a>4.3）、创建模块</h3><h4 id="1、common-interface：公共接口层（model，service，exception…）（符合分包理念）"><a href="#1、common-interface：公共接口层（model，service，exception…）（符合分包理念）" class="headerlink" title="1、common-interface：公共接口层（model，service，exception…）（符合分包理念）"></a>1、common-interface：公共接口层（model，service，exception…）（符合分包理念）</h4><p>作用：定义公共接口，也可以导入公共依赖，保存服务提供者和服务消费者的接口</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566291490450.png" alt="1566291490450"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566291499745.png" alt="1566291499745"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566291506690.png" alt="1566291506690"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566291515781.png" alt="1566291515781"></p>
<p>好处就是，可以让服务生产者和消费者同时依赖这个公共接口层maven项目，避免书写重复代码。</p>
<h4 id="2、user-module：用户模块（对用户接口的实现，服务提供者）"><a href="#2、user-module：用户模块（对用户接口的实现，服务提供者）" class="headerlink" title="2、user-module：用户模块（对用户接口的实现，服务提供者）"></a>2、user-module：用户模块（对用户接口的实现，服务提供者）</h4><ol>
<li>pom.xml (引用公共接口层)</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">	  &lt;groupId&gt;com.kingge.common&lt;/groupId&gt;</div><div class="line">	  &lt;artifactId&gt;common-interface&lt;/artifactId&gt;</div><div class="line">	  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;	</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<ol>
<li>用户接口实现</li>
</ol>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566291685692.png" alt="1566291685692"></p>
<p><strong>这里为了快速演示，就做了一些虚拟数据，不会去连接数据库。</strong></p>
<p>到时候订单模块只需要调用即可</p>
<h4 id="4、order-module：订单模块（调用用户模块）"><a href="#4、order-module：订单模块（调用用户模块）" class="headerlink" title="4、order-module：订单模块（调用用户模块）"></a>4、order-module：订单模块（调用用户模块）</h4><p>1. pom.xml (引用公共接口层)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">	  &lt;groupId&gt;com.kingge.common&lt;/groupId&gt;</div><div class="line">	  &lt;artifactId&gt;common-interface&lt;/artifactId&gt;</div><div class="line">	  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;	</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p>2. 订单接口实现</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566291757761.png" alt="1566291757761"></p>
<p><strong>现在这样是无法进行调用的。我们order-module引入了common-interface，但是common-interface公用模块里的用户接口的具体实现在user-module，我们并没有引入user-module模块，所以上诉代码调用肯定是失败的。而且user-module模块可能还在别的服务器中（不在同一个进程中）</strong>。</p>
<p>​    <strong>所以我们需要把user-module模块的用户接口的实现类暴露出去，供order-module模块使用。</strong></p>
<p>接下来使用dubbo来实现这样的功能。</p>
<h3 id="4-4）、使用dubbo改造"><a href="#4-4）、使用dubbo改造" class="headerlink" title="4.4）、使用dubbo改造"></a>4.4）、使用dubbo改造</h3><h4 id="1、改造user-module作为服务提供者"><a href="#1、改造user-module作为服务提供者" class="headerlink" title="1、改造user-module作为服务提供者"></a>1、改造user-module作为服务提供者</h4><p>（1）引入dubbo （pom.xml引入依赖）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">	&lt;!-- 引入dubbo --&gt;</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;com.alibaba&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;dubbo&lt;/artifactId&gt;</div><div class="line">			&lt;version&gt;2.6.2&lt;/version&gt;</div><div class="line">		&lt;/dependency&gt;</div><div class="line">	&lt;!-- 由于我们使用zookeeper作为注册中心，所以需要操作zookeeper</div><div class="line">dubbo 2.6以前的版本引入zkclient操作zookeeper </div><div class="line">dubbo 2.6及以后的版本引入curator操作zookeeper</div><div class="line">下面两个zk客户端根据dubbo版本2选1即可</div><div class="line">--&gt;</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;com.101tec&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;zkclient&lt;/artifactId&gt;</div><div class="line">			&lt;version&gt;0.10&lt;/version&gt;</div><div class="line">		&lt;/dependency&gt;</div><div class="line">		&lt;!-- curator-framework --&gt;</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;org.apache.curator&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;curator-framework&lt;/artifactId&gt;</div><div class="line">			&lt;version&gt;2.12.0&lt;/version&gt;</div><div class="line">		&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p>（2）配置提供者（新建provider.xml文件）</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566291871894.png" alt="1566291871894"></p>
<blockquote>
<p>内容如下：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!-- 1、指定当前服务/应用的名字（同样的服务名字相同，不要和别的服务同名） --&gt;</div><div class="line">	&lt;dubbo:application name=&quot;user-module&quot;&gt;&lt;/dubbo:application&gt;</div><div class="line">&lt;!-- 2、指定注册中心的位置 --&gt;</div><div class="line">&lt;!-- &lt;dubbo:registry address=&quot;zookeeper://127.0.0.1:2181&quot;&gt;&lt;/dubbo:registry&gt;  这种方式也可以 --&gt;</div><div class="line">	&lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;127.0.0.1:2181&quot;&gt;&lt;/dubbo:registry&gt;    &lt;!--使用dubbo协议，将服务暴露在20880端口 consumer和provider连接的协议，协议由提供方指定，消费方被动接受 --&gt;</div><div class="line">    &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot; /&gt;</div><div class="line">&lt;!-- 指定需要暴露的服务 --&gt;</div><div class="line"></div><div class="line">&lt;dubbo:service interface=&quot;com.kingge.common.service.UserService&quot; ref=&quot;userServiceImpl&quot; &gt;&lt;/dubbo:service&gt;</div><div class="line"></div><div class="line">	&lt;!-- 服务的实现 --&gt;</div><div class="line">&lt;bean id=&quot;userServiceImpl&quot; class=&quot;com.kingge.user.service.impl.UserServiceImpl&quot;&gt;&lt;/bean&gt;</div></pre></td></tr></table></figure>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566291960341.png" alt="1566291960341"></p>
<p>dubbo支持多种传输协议</p>
<p>（3）启动服务</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"></div><div class="line">public class MainApplication &#123;</div><div class="line">	public static void main(String[] args) throws IOException &#123;</div><div class="line">		ClassPathXmlApplicationContext ioc = new ClassPathXmlApplicationContext(&quot;provider.xml&quot;);</div><div class="line">		ioc.start();</div><div class="line">		System.in.read();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>运行后，打开我们之前配置的dubbo-admin</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292031775.png" alt="1566292031775"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292041006.png" alt="1566292041006"></p>
<h4 id="2、改造order-module作为服务消费者"><a href="#2、改造order-module作为服务消费者" class="headerlink" title="2、改造order-module作为服务消费者"></a>2、改造order-module作为服务消费者</h4><p>（1）引入dubbo （pom.xml引入依赖）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">	&lt;!-- 引入dubbo --&gt;</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;com.alibaba&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;dubbo&lt;/artifactId&gt;</div><div class="line">			&lt;version&gt;2.6.2&lt;/version&gt;</div><div class="line">		&lt;/dependency&gt;</div><div class="line">	&lt;!-- 由于我们使用zookeeper作为注册中心，所以需要操作zookeeper</div><div class="line">dubbo 2.6以前的版本引入zkclient操作zookeeper </div><div class="line">dubbo 2.6及以后的版本引入curator操作zookeeper</div><div class="line">下面两个zk客户端根据dubbo版本2选1即可</div><div class="line">--&gt;</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;com.101tec&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;zkclient&lt;/artifactId&gt;</div><div class="line">			&lt;version&gt;0.10&lt;/version&gt;</div><div class="line">		&lt;/dependency&gt;</div><div class="line">		&lt;!-- curator-framework --&gt;</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;org.apache.curator&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;curator-framework&lt;/artifactId&gt;</div><div class="line">			&lt;version&gt;2.12.0&lt;/version&gt;</div><div class="line">		&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p>（2）配置消费者信息</p>
<p>新建consumer.xml文件</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292086774.png" alt="1566292086774"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!—配置包扫描 --&gt;</div><div class="line">&lt;context:component-scan base-package=&quot;com.kingge.order.service.impl&quot;&gt;&lt;/context:component-scan&gt;</div><div class="line">&lt;!-- 应用名 --&gt;</div><div class="line">	&lt;dubbo:application name=&quot;order-module&quot;&gt;&lt;/dubbo:application&gt;</div><div class="line">&lt;!-- 指定注册中心地址 --&gt;</div><div class="line">	&lt;dubbo:registry address=&quot;zookeeper://127.0.0.1:2181&quot; /&gt;</div><div class="line">&lt;!-- 生成远程服务代理，可以和本地bean一样使用userService --&gt;</div><div class="line">&lt;dubbo:reference interface=&quot;com.kingge.common.service.UserService&quot; id=&quot;userService&quot; &gt;&lt;/dubbo:reference&gt;</div></pre></td></tr></table></figure>
<p>（3）修改OrderServiceImpl</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292128737.png" alt="1566292128737"></p>
<p>（4）创建启动类，启动consumer</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292167651.png" alt="1566292167651"></p>
<h4 id="3、测试调用"><a href="#3、测试调用" class="headerlink" title="3、测试调用"></a>3、测试调用</h4><p>调用成功</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292239959.png" alt="1566292239959"></p>
<p>查看dubbo admin</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292253424.png" alt="1566292253424"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292258292.png" alt="1566292258292"></p>
<h2 id="3-4-配置dubbo监控中心"><a href="#3-4-配置dubbo监控中心" class="headerlink" title="3.4 配置dubbo监控中心"></a>3.4 配置dubbo监控中心</h2><h3 id="3-4-1-dubbo-admin"><a href="#3-4-1-dubbo-admin" class="headerlink" title="3.4.1 dubbo-admin"></a>3.4.1 dubbo-admin</h3><p>图形化的服务管理页面；安装时需要指定注册中心地址，即可从注册中心中获取到所有的提供者/消费者进行配置管理</p>
<p>安装和使用方式在上面我们已经说过了，这里就不在阐述。</p>
<h3 id="3-4-2-dubbo-monitor-simple"><a href="#3-4-2-dubbo-monitor-simple" class="headerlink" title="3.4.2 dubbo-monitor-simple"></a>3.4.2 dubbo-monitor-simple</h3><p>简单的监控中心；</p>
<h4 id="1、下载-dubbo-ops"><a href="#1、下载-dubbo-ops" class="headerlink" title="1、下载 dubbo-ops"></a>1、下载 dubbo-ops</h4><p><a href="https://github.com/apache/incubator-dubbo-ops" target="_blank" rel="external">https://github.com/apache/incubator-dubbo-ops</a></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292295799.png" alt="1566292295799"></p>
<h4 id="2、修改配置指定注册中心地址"><a href="#2、修改配置指定注册中心地址" class="headerlink" title="2、修改配置指定注册中心地址"></a>2、修改配置指定注册中心地址</h4><p>进入 dubbo-monitor-simple\src\main\resources\conf</p>
<p>修改 dubbo.properties文件</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292309213.png" alt="1566292309213"></p>
<h4 id="3、打包dubbo-monitor-simple"><a href="#3、打包dubbo-monitor-simple" class="headerlink" title="3、打包dubbo-monitor-simple"></a>3、打包dubbo-monitor-simple</h4><p>mvn clean package -Dmaven.test.skip=true</p>
<p>打包完成后，打开target目录，解压下面的tar.gz包</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292325687.png" alt="1566292325687"></p>
<p>他跟3.4.1 的dubbo-admin不一样，不是一个springboot项目，不能够直接使用java –jar命令执行。</p>
<p>打开解压后的目录</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292337531.png" alt="1566292337531"></p>
<p>Conf目录存放就是我们的dubbo.properties</p>
<p>assembly.bin目录存放运行dubbo-monitor-simple 的可执行文件</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292359272.png" alt="1566292359272"></p>
<p>双击 start.bat 执行</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292369604.png" alt="1566292369604"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292380240.png" alt="1566292380240"></p>
<h4 id="4-在项目中使用simple监控中心"><a href="#4-在项目中使用simple监控中心" class="headerlink" title="4.在项目中使用simple监控中心"></a>4.在项目中使用simple监控中心</h4><p><img src="/2019/01/05/dubbo分布式服务框架/1566292395114.png" alt="1566292395114"></p>
<p>以3.3的例子为例：</p>
<p>分别在provider.xml和consumer.xml中添加以下代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;dubbo:monitor protocol=&quot;registry&quot;&gt;&lt;/dubbo:monitor&gt; </div><div class="line">&lt;!-- &lt;dubbo:monitor address=&quot;127.0.0.1:7070&quot;&gt;&lt;/dubbo:monitor&gt;--&gt;</div></pre></td></tr></table></figure>
<p>然后重新运行项目，再查看</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292420989.png" alt="1566292420989"></p>
<h1 id="四、dubbo整合springboot"><a href="#四、dubbo整合springboot" class="headerlink" title="四、dubbo整合springboot"></a>四、dubbo整合springboot</h1><p>改造4.3章节普通的maven项目为springboot项目，关键代码没有变化，主要是一些配置和依赖发生了变化</p>
<p>关于idea怎么创建多模块项目这里就不阐述了，详情可参见一下网址</p>
<p><a href="https://blog.csdn.net/tiantangdizhibuxiang/article/details/81130297" target="_blank" rel="external">[https://blog.csdn.net/tiantangdizhibuxiang/article/details/81130297]{.underline}</a></p>
<p><a href="https://www.cnblogs.com/zjfjava/p/9696086.html" target="_blank" rel="external">https://www.cnblogs.com/zjfjava/p/9696086.html</a></p>
<h2 id="4-1-新建boot-common-interface：公共接口层（model，service，exception…）（符合分包理念）"><a href="#4-1-新建boot-common-interface：公共接口层（model，service，exception…）（符合分包理念）" class="headerlink" title="4.1 新建boot-common-interface：公共接口层（model，service，exception…）（符合分包理念）"></a>4.1 新建boot-common-interface：公共接口层（model，service，exception…）（符合分包理念）</h2><p><img src="/2019/01/05/dubbo分布式服务框架/1566292452656.png" alt="1566292452656"></p>
<p>一路next完成。</p>
<p>复制4.3.1 章节common-interface的相关代码到此工程</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292474717.png" alt="1566292474717"></p>
<h2 id="4-2-新建boot-user-module：用户模块"><a href="#4-2-新建boot-user-module：用户模块" class="headerlink" title="4.2 新建boot-user-module：用户模块"></a>4.2 新建boot-user-module：用户模块</h2><h3 id="4-2-1-新建模块"><a href="#4-2-1-新建模块" class="headerlink" title="4.2.1 新建模块"></a>4.2.1 新建模块</h3><p><img src="/2019/01/05/dubbo分布式服务框架/1566292489020.png" alt="1566292489020"></p>
<p>一路next创建即可。</p>
<h3 id="4-2-2-代码实现"><a href="#4-2-2-代码实现" class="headerlink" title="4.2.2 代码实现"></a>4.2.2 代码实现</h3><p>4.2.2同理复制章节4.3.2 user-module项目代码到此项目并修改pom.xml文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">添加一下依赖</div><div class="line"></div><div class="line">		&lt;!--引用公用模块--&gt;</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;com.kingge&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;boot-common-interface&lt;/artifactId&gt;</div><div class="line">			&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;</div><div class="line">		&lt;/dependency&gt;</div><div class="line">		&lt;!--引入dubbo starter--&gt;</div><div class="line">		&lt;dependency&gt;</div><div class="line">			&lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt;</div><div class="line">			&lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt;</div><div class="line">			&lt;version&gt;0.2.0&lt;/version&gt;</div><div class="line">		&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p><strong>需要注意的是：</strong></p>
<p><strong>注意springboot的starter版本跟dubbo版本适配：</strong></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292539737.png" alt="1566292539737"></p>
<p><strong>因为本人使用的是springboot2.1.6版本，故使用0.2.0版本dubbo starter</strong></p>
<h3 id="4-2-3修改application-proeprties文件"><a href="#4-2-3修改application-proeprties文件" class="headerlink" title="4.2.3修改application.proeprties文件"></a>4.2.3修改application.proeprties文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">dubbo.application.name=boot-user-module</div><div class="line">dubbo.registry.protocol=zookeeper</div><div class="line">dubbo.registry.address=127.0.0.1:2181</div><div class="line"></div><div class="line">#开启包扫描，可替代 @EnableDubbo 注解</div><div class="line">#dubbo.scan.base-packages=com.kingge.order</div><div class="line">dubbo.protocol.name=dubbo</div><div class="line">dubbo.protocol.port=20880</div><div class="line"></div><div class="line">dubbo.monitor.protocol=registry</div></pre></td></tr></table></figure>
<p>application.name就是服务名，不能跟别的dubbo提供端重复</p>
<p>registry.protocol 是指定注册中心协议</p>
<p>registry.address 是注册中心的地址加端口号</p>
<p>protocol.name 是分布式固定是dubbo,不要改。</p>
<p>dubbo.scan.base-packages 需要暴露的接口的实现类所在的包（跟启动类在同一个包或者子包下都不需要配置这个属性的值，因为springboot启动类会扫描注入。）</p>
<p>dubbo.monitor.protocol 开启simple检测中心</p>
<h3 id="4-2-4-配置需要暴露的服务（通过注解方式）"><a href="#4-2-4-配置需要暴露的服务（通过注解方式）" class="headerlink" title="4.2.4 配置需要暴露的服务（通过注解方式）"></a>4.2.4 配置需要暴露的服务（通过注解方式）</h3><p><img src="/2019/01/05/dubbo分布式服务框架/1566292610602.png" alt="1566292610602"></p>
<h3 id="4-2-5-boot启动类开启dubbo功能"><a href="#4-2-5-boot启动类开启dubbo功能" class="headerlink" title="4.2.5 boot启动类开启dubbo功能"></a>4.2.5 boot启动类开启dubbo功能</h3><p><img src="/2019/01/05/dubbo分布式服务框架/1566292619945.png" alt="1566292619945"></p>
<h3 id="4-2-6-完整项目结构和启动服务提供者"><a href="#4-2-6-完整项目结构和启动服务提供者" class="headerlink" title="4.2.6 完整项目结构和启动服务提供者"></a>4.2.6 完整项目结构和启动服务提供者</h3><p><img src="/2019/01/05/dubbo分布式服务框架/1566292632557.png" alt="1566292632557"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292639565.png" alt="1566292639565"></p>
<h2 id="4-3-新建boot-order-module：订单模块"><a href="#4-3-新建boot-order-module：订单模块" class="headerlink" title="4.3 新建boot-order-module：订单模块"></a>4.3 新建boot-order-module：订单模块</h2><p>4.3.1 因为我们打算通过web的方式访问controller，再去调用暴露的接口，所以需要引入web依赖</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292654499.png" alt="1566292654499"></p>
<p>一路next即可</p>
<h3 id="4-3-2-代码实现"><a href="#4-3-2-代码实现" class="headerlink" title="4.3.2 代码实现"></a>4.3.2 代码实现</h3><p>4.3.2 同理复制章节4.3.3 order-module项目代码到此项目并修改pom.xml文件</p>
<p>添加一下依赖</p>
<pre><code>&lt;!--引用公用模块--&gt;
&lt;dependency&gt;
       &lt;groupId&gt;com.kingge&lt;/groupId&gt;
       &lt;artifactId&gt;boot-common-interface&lt;/artifactId&gt;
       &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
&lt;/dependency&gt;
&lt;!--引入dubbo starter--&gt;
&lt;dependency&gt;
       &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt;
       &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt;
       &lt;version&gt;0.2.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><h3 id="4-3-3-修改application-proeprties文件"><a href="#4-3-3-修改application-proeprties文件" class="headerlink" title="4.3.3 修改application.proeprties文件"></a>4.3.3 修改application.proeprties文件</h3><p>dubbo.application.name=boot-order-module</p>
<p>dubbo.registry.address= zookeeper://127.0.0.1:2181</p>
<p>dubbo.monitor.protocol=registry</p>
<h3 id="4-3-4-service使用-reference调用暴露接口"><a href="#4-3-4-service使用-reference调用暴露接口" class="headerlink" title="4.3.4 service使用@reference调用暴露接口"></a>4.3.4 service使用@reference调用暴露接口</h3><p><img src="/2019/01/05/dubbo分布式服务框架/1566292707472.png" alt="1566292707472"></p>
<h3 id="4-3-5-实现一个controller，接受请求"><a href="#4-3-5-实现一个controller，接受请求" class="headerlink" title="4.3.5 实现一个controller，接受请求"></a>4.3.5 实现一个controller，接受请求</h3><p><img src="/2019/01/05/dubbo分布式服务框架/1566292718314.png" alt="1566292718314"></p>
<h3 id="4-3-6-boot启动类开启dubbo功能"><a href="#4-3-6-boot启动类开启dubbo功能" class="headerlink" title="4.3.6 boot启动类开启dubbo功能"></a>4.3.6 boot启动类开启dubbo功能</h3><p><img src="/2019/01/05/dubbo分布式服务框架/1566292727605.png" alt="1566292727605"></p>
<h3 id="4-3-7-启动工程，并访问请求"><a href="#4-3-7-启动工程，并访问请求" class="headerlink" title="4.3.7 启动工程，并访问请求"></a>4.3.7 启动工程，并访问请求</h3><p><img src="/2019/01/05/dubbo分布式服务框架/1566292736852.png" alt="1566292736852"></p>
<p>服务调用成功</p>
<h2 id="4-4-补充"><a href="#4-4-补充" class="headerlink" title="4.4 补充"></a>4.4 补充</h2><p>整合dubbo的三种方式：官网</p>
<p><a href="http://dubbo.apache.org/zh-cn/docs/user/configuration/api.html" target="_blank" rel="external">[http://dubbo.apache.org/zh-cn/docs/user/configuration/api.html]{.underline}</a></p>
<p>* SpringBoot与dubbo整合的三种方式：</p>
<p>* 1）、导入dubbo-starter，在application.properties配置属性，使用\@Service【暴露服务】使用@Reference【引用服务】使用\@EnableDubbo，开启dubbo注解功能（<strong>上面例子我们使用的就是这种方式</strong>）</p>
<p>* 2）、保留dubbo xml配置文件</p>
<p>* 导入dubbo-starter，使用\@ImportResource导入dubbo的配置文件即可</p>
<p>* 3）、使用注解API的方式：</p>
<p>* 将每一个组件手动创建到容器中,让dubbo来扫描其他的组件</p>
<p>第二种整合方式解决：</p>
<p>如果我们需要在boot-user-module服务提供者配置方法级别的超时时间，那么有没有响应的注解配置呢？ 答案是没有的，那么就需要我们使用xml的方式进行配置。</p>
<p>1. 首先去掉@Service、@Reference、@EnableDubbo等注解</p>
<p>2. @ImportResource(locations=\”classpath:provider.xml\”) 使用</p>
<p>ImportResource注解导入外部xml文件</p>
<h1 id="五、Dubbo配置"><a href="#五、Dubbo配置" class="headerlink" title="五、Dubbo配置"></a>五、Dubbo配置</h1><p><a href="http://dubbo.apache.org/zh-cn/docs/user/configuration/annotation.html" target="_blank" rel="external">[http://dubbo.apache.org/zh-cn/docs/user/configuration/annotation.html]{.underline}</a></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292811339.png" alt="1566292811339"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292823850.png" alt="1566292823850"></p>
<p>JVM 启动 -D 参数优先，这样可以使用户在部署和启动时进行参数重写，比如在启动时需改变协议的端口。</p>
<p>XML（<strong>springboot项目中对应的是application.properties文件</strong>） 次之，如果在 XML 中有配置，则 dubbo.properties 和代码中的相应配置项无效。</p>
<p>使用代码设置的方式优先级排在第三。</p>
<p>Properties 最后，相当于缺省值，只有 XML 没有配置时，dubbo.properties 的相应配置项才会生效，通常用于共享公共配置，比如应用名。</p>
<h1 id="六、Dubbo官方提供的例子（功能）"><a href="#六、Dubbo官方提供的例子（功能）" class="headerlink" title="六、Dubbo官方提供的例子（功能）"></a>六、Dubbo官方提供的例子（功能）</h1><p><a href="http://dubbo.apache.org/zh-cn/docs/user/demos/preflight-check.html" target="_blank" rel="external">[http://dubbo.apache.org/zh-cn/docs/user/demos/preflight-check.html]{.underline}</a></p>
<h2 id="6-1启动时检查"><a href="#6-1启动时检查" class="headerlink" title="6.1启动时检查"></a>6.1启动时检查</h2><p><img src="/2019/01/05/dubbo分布式服务框架/1566292846979.png" alt="1566292846979"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292857963.png" alt="1566292857963"></p>
<h2 id="6-2-服务超时调用和重试次数"><a href="#6-2-服务超时调用和重试次数" class="headerlink" title="6.2 服务超时调用和重试次数"></a>6.2 服务超时调用和重试次数</h2><p>1. timeout属性</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292871305.png" alt="1566292871305"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292882714.png" alt="1566292882714"></p>
<p>2. retries 属性</p>
<p>默认重试2次，也就是说一共会调用提供者服务三次（第一次调用不计次数）</p>
<p>如果在注册中心，提供者有三个（a1、a2、a3），那么消费者(b1)在重试获取服务的时候，这三个都会可能去调用。</p>
<p>b1请求a1服务超时，发现注册中心存在相同的服务a2、a3那么b1会去请求a2或者a3，当然也有可能再次请求a1</p>
<p>那么什么时候使用这个字段。建议在<strong>“幂等”</strong>的业务场景下使用，不要在非幂等的场景下使用。</p>
<p>幂等：就是提供者提供的服务，调用多次跟调用一次的起到的作用是一致的（例如对数据库的delete某条数据的操作）</p>
<p>非幂等：单次调用和多次调用的结果是不一样的（数据库的insert操作）</p>
<p>设置为0，表示不进行重试，直接报异常</p>
<h2 id="6-3标签属性配置优先级"><a href="#6-3标签属性配置优先级" class="headerlink" title="6.3标签属性配置优先级"></a>6.3标签属性配置优先级</h2><p><img src="/2019/01/05/dubbo分布式服务框架/1566292898332.png" alt="1566292898332"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292904601.png" alt="1566292904601"></p>
<h2 id="6-4多版本"><a href="#6-4多版本" class="headerlink" title="6.4多版本"></a>6.4多版本</h2><p>当一个接口实现，出现不兼容升级时，可以用版本号过渡，版本号不同的服务相互间不引用。</p>
<p>可以按照以下的步骤进行版本迁移：</p>
<blockquote>
<p>1.在低压力时间段，先升级一半提供者为新版本</p>
<p>2.再将所有消费者升级为新版本</p>
<p>3.然后将剩下的一半提供者升级为新版本</p>
</blockquote>
<p>使用场景：新版接口需要替代旧版接口时。</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292919156.png" alt="1566292919156"></p>
<p>Version=”*“表示任何调用新旧版本</p>
<p>举个例子：</p>
<p>使用第四章节的例子：</p>
<p>1.boot-user-module模块，添加一个新的UserService接口实现类，作为新接口的实现</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292938701.png" alt="1566292938701"></p>
<p>给两个接口添加版本标识（标识新旧接口）</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292947114.png" alt="1566292947114"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292954668.png" alt="1566292954668"></p>
<p>2.修改boot-order-module模块消费者消费接口版本</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292966487.png" alt="1566292966487"></p>
<p>通过version属性实现新旧接口的调用</p>
<h2 id="6-5本地存根"><a href="#6-5本地存根" class="headerlink" title="6.5本地存根"></a>6.5本地存根</h2><p><img src="/2019/01/05/dubbo分布式服务框架/1566292979159.png" alt="1566292979159"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566292986964.png" alt="1566292986964"></p>
<h2 id="6-6-更多用法参见官网的事例"><a href="#6-6-更多用法参见官网的事例" class="headerlink" title="6.6 更多用法参见官网的事例"></a>6.6 更多用法参见官网的事例</h2><h1 id="七、Dubbo高可用"><a href="#七、Dubbo高可用" class="headerlink" title="七、Dubbo高可用"></a>七、Dubbo高可用</h1><h2 id="7-1、zookeeper宕机与dubbo直连"><a href="#7-1、zookeeper宕机与dubbo直连" class="headerlink" title="7.1、zookeeper宕机与dubbo直连"></a>7.1、zookeeper宕机与dubbo直连</h2><p>现象：zookeeper注册中心宕机，还可以消费dubbo暴露的服务。</p>
<p>原因：</p>
<p>健壮性</p>
<ul>
<li>监控中心宕掉不影响使用，只是丢失部分采样数据</li>
<li>数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务</li>
<li>注册中心对等集群，任意一台宕掉后，将自动切换到另一台</li>
<li><strong>注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯</strong></li>
<li>服务提供者无状态，任意一台宕掉后，不影响使用</li>
<li>服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复</li>
</ul>
<p>高可用：通过设计，减少系统不能提供服务的时间；</p>
<p>直连dubbo：因为我们知道zookeeper注册中心保存的信息主要是消息提供者的位置，那么我们消费者可以通过url的方式直接访问消息提供者提供的服务地址也是可以的。</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293000779.png" alt="1566293000779"></p>
<h2 id="7-2、集群下dubbo负载均衡配置"><a href="#7-2、集群下dubbo负载均衡配置" class="headerlink" title="7.2、集群下dubbo负载均衡配置"></a>7.2、集群下dubbo负载均衡配置</h2><p>在集群负载均衡时，Dubbo 提供了多种均衡策略，缺省为 random 随机调用。</p>
<p>负载均衡策略</p>
<p><a href="http://dubbo.apache.org/zh-cn/docs/user/demos/loadbalance.html" target="_blank" rel="external">http://dubbo.apache.org/zh-cn/docs/user/demos/loadbalance.html</a></p>
<p><strong>1.Random LoadBalance</strong></p>
<p>随机，按权重设置随机概率。</p>
<p>在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293015243.png" alt="1566293015243"></p>
<p>可以在Dubbo-admin设置某个服务的权重</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293025840.png" alt="1566293025840"></p>
<p><strong>2.RoundRobin LoadBalance</strong></p>
<p>轮循，按公约后的权重设置轮循比率。</p>
<p>存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。</p>
<p><strong>3.LeastActive LoadBalance</strong></p>
<p>最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。</p>
<p>使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。</p>
<p>在消费服务的时候，总是查询上一个服务处理请求处理最快的那一台服务器</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293037414.png" alt="1566293037414"></p>
<p>很明显请求会发到一号服务器，因为他处理最快。每次都记录请求处理的时间。</p>
<p><strong>4.ConsistentHash LoadBalance</strong></p>
<p>一致性 Hash，相同参数的请求总是发到同一提供者。</p>
<p>当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。算法参见：<a href="http://en.wikipedia.org/wiki/Consistent\_hashing" target="_blank" rel="external">http://en.wikipedia.org/wiki/Consistent\_hashing</a></p>
<p>缺省只对第一个参数 Hash，如果要修改，请配置 \<dubbo:parameter key="\" hash.arguments\""="" value="\" 0,1\""="" \=""></dubbo:parameter></p>
<p>缺省用 160 份虚拟节点，如果要修改，请配置 \<dubbo:parameter key="\" hash.nodes\""="" value="\" 320\""="" \=""></dubbo:parameter></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293053652.png" alt="1566293053652"></p>
<h2 id="7-3、整合hystrix，服务熔断与降级处理"><a href="#7-3、整合hystrix，服务熔断与降级处理" class="headerlink" title="7.3、整合hystrix，服务熔断与降级处理"></a>7.3、整合hystrix，服务熔断与降级处理</h2><h3 id="1、服务降级"><a href="#1、服务降级" class="headerlink" title="1、服务降级"></a>1、服务降级</h3><p><strong>什么是服务降级？</strong></p>
<p><strong>当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心交易正常运作或高效运作。</strong></p>
<p>可以通过服务降级功能临时屏蔽某个出错的非关键服务，并定义降级后的返回策略。</p>
<p>向注册中心写入动态配置覆盖规则：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">RegistryFactory registryFactory =</div><div class="line"> ExtensionLoader.getExtensionLoader(RegistryFactory.class).getAdaptiveExtension();</div><div class="line">Registry registry =</div><div class="line"> registryFactory.getRegistry(URL.valueOf(&quot;zookeeper://10.20.153.10:2181&quot;));</div><div class="line">registry.register(URL.valueOf(&quot;override://0.0.0.0/com.foo.BarService?category=configurators&amp;dynamic=false&amp;application=foo&amp;mock=force:return+null&quot;));</div></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li>mock=force:return+null 表示消费方对<strong>该服务的方法调用都直接返回 null 值</strong>，不发起远程调用。用来屏蔽不重要服务不可用时对调用方的影响。</li>
</ul>
<blockquote>
<p>相当于在dubbo-admin中设置如下：</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293085820.png" alt="1566293085820"></p>
</blockquote>
<ul>
<li>还可以改为 mock=fail:return+null 表示消费方对该服务的方法调用在失败后，再返回 null 值，不抛异常。用来容忍不重要服务不稳定时对调用方的影响。</li>
</ul>
<blockquote>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293099118.png" alt="1566293099118"></p>
</blockquote>
<h3 id="2、集群容错"><a href="#2、集群容错" class="headerlink" title="2、集群容错"></a>2、集群容错</h3><p><a href="http://dubbo.apache.org/zh-cn/docs/user/demos/fault-tolerent-strategy.html" target="_blank" rel="external">[http://dubbo.apache.org/zh-cn/docs/user/demos/fault-tolerent-strategy.html]{.underline}</a></p>
<p>在集群调用失败时，Dubbo 提供了多种容错方案，缺省为 failover 重试。</p>
<p><strong>集群容错模式</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">Failover Cluster</div><div class="line">失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries=&quot;2&quot; 来设置重试次数(不含第一次)。</div><div class="line"></div><div class="line">重试次数配置如下：</div><div class="line">&lt;dubbo:service retries=&quot;2&quot; /&gt;</div><div class="line">或</div><div class="line">&lt;dubbo:reference retries=&quot;2&quot; /&gt;</div><div class="line">或</div><div class="line">&lt;dubbo:reference&gt;</div><div class="line">    &lt;dubbo:method name=&quot;findFoo&quot; retries=&quot;2&quot; /&gt;</div><div class="line">&lt;/dubbo:reference&gt;</div><div class="line"></div><div class="line">Failfast Cluster</div><div class="line">快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。</div><div class="line"></div><div class="line">Failsafe Cluster</div><div class="line">失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。</div><div class="line"></div><div class="line">Failback Cluster</div><div class="line">失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。</div><div class="line"></div><div class="line">Forking Cluster</div><div class="line">并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks=&quot;2&quot; 来设置最大并行数。</div><div class="line"></div><div class="line">Broadcast Cluster</div><div class="line">广播调用所有提供者，逐个调用，任意一台报错则报错 [2]。通常用于通知所有提供者更新缓存或日志等本地资源信息。</div><div class="line"></div><div class="line">集群模式配置</div><div class="line">按照以下示例在服务提供方和消费方配置集群模式</div><div class="line">&lt;dubbo:service cluster=&quot;failsafe&quot; /&gt;</div><div class="line">或</div><div class="line">&lt;dubbo:reference cluster=&quot;failsafe&quot; /&gt;</div></pre></td></tr></table></figure>
<h3 id="3、整合hystrix"><a href="#3、整合hystrix" class="headerlink" title="3、整合hystrix"></a>3、整合hystrix</h3><p>Hystrix 旨在通过控制那些访问远程系统、服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力。Hystrix具备拥有回退机制和断路器功能的线程和信号隔离，请求缓存和请求打包，以及监控和配置等功能</p>
<h4 id="1、配置spring-cloud-starter-netflix-hystrix"><a href="#1、配置spring-cloud-starter-netflix-hystrix" class="headerlink" title="1、配置spring-cloud-starter-netflix-hystrix"></a>1、配置spring-cloud-starter-netflix-hystrix</h4><p>spring boot官方提供了对hystrix的集成，直接在pom.xml里加入依赖：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;1.4.4.RELEASE&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p>然后在Application类上增加\@EnableHystrix来启用hystrix starter：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@SpringBootApplication</div><div class="line">@EnableHystrix</div><div class="line">public class ProviderApplication &#123;</div></pre></td></tr></table></figure>
<h4 id="2、配置Provider端"><a href="#2、配置Provider端" class="headerlink" title="2、配置Provider端"></a>2、配置Provider端</h4><p>在Dubbo的Provider上增加\@HystrixCommand配置，这样子调用就会经过Hystrix代理。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@com.alibaba.dubbo.config.annotation.Service (version = &quot;1.0.0&quot;)</div><div class="line">public class HelloServiceImpl implements HelloService &#123;</div><div class="line">    @HystrixCommand(commandProperties = &#123;</div><div class="line">     @HystrixProperty(name = &quot;circuitBreaker.requestVolumeThreshold&quot;, value = &quot;10&quot;),</div><div class="line">     @HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value = &quot;2000&quot;) &#125;)</div><div class="line">    @Override</div><div class="line">    public String sayHello(String name) &#123;</div><div class="line">        // System.out.println(&quot;async provider received: &quot; + name);</div><div class="line">        // return &quot;annotation: hello, &quot; + name;</div><div class="line">        throw new RuntimeException(&quot;Exception to show hystrix enabled.&quot;);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="3、配置Consumer端"><a href="#3、配置Consumer端" class="headerlink" title="3、配置Consumer端"></a>3、配置Consumer端</h4><p>对于Consumer端，则可以增加一层method调用，并在method上配置@HystrixCommand。当调用出错时，会走到fallbackMethod = \”reliable\”的调用里。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Reference(version = &quot;1.0.0&quot;)</div><div class="line">private HelloService demoService;</div><div class="line"></div><div class="line">@HystrixCommand(fallbackMethod = &quot;reliable&quot;)</div><div class="line">public String doSayHello(String name) &#123;</div><div class="line">    return demoService.sayHello(name);</div><div class="line">&#125;</div><div class="line">public String reliable(String name) &#123;</div><div class="line">    return &quot;hystrix fallback value&quot;;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="八、Dubbo原理"><a href="#八、Dubbo原理" class="headerlink" title="八、Dubbo原理"></a>八、Dubbo原理</h1><h2 id="1、RPC原理"><a href="#1、RPC原理" class="headerlink" title="1、RPC原理"></a>1、RPC原理</h2><p><img src="/2019/01/05/dubbo分布式服务框架/1566293222964.png" alt="1566293222964"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">一次完整的RPC调用流程（同步调用，异步另说）如下： </div><div class="line">1）服务消费方（client）调用以本地调用方式调用服务； </div><div class="line">2）client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体； </div><div class="line">3）client stub找到服务地址，并将消息发送到服务端； </div><div class="line">4）server stub收到消息后进行解码； </div><div class="line">5）server stub根据解码结果调用本地的服务； </div><div class="line">6）本地服务执行并将结果返回给server stub； </div><div class="line">7）server stub将返回结果打包成消息并发送至消费方； </div><div class="line">8）client stub接收到消息，并进行解码； </div><div class="line">9）服务消费方得到最终结果。</div><div class="line">RPC框架的目标就是要2~8这些步骤都封装起来，这些细节对用户来说是透明的，不可见的。</div></pre></td></tr></table></figure>
<h2 id="2、netty通信原理"><a href="#2、netty通信原理" class="headerlink" title="2、netty通信原理"></a>2、netty通信原理</h2><p>Netty是一个异步事件驱动的网络应用程序框架， 用于快速开发可维护的高性能协议服务器和客户端。它极大地简化并简化了TCP和UDP套接字服务器等网络编程。</p>
<p>BIO：(Blocking IO)</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293252955.png" alt="1566293252955"></p>
<p>NIO (Non-Blocking IO)</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293263838.png" alt="1566293263838"></p>
<p>Selector 一般称 为<strong>选择器</strong> ，也可以翻译为 <strong>多路复用器，</strong></p>
<p>Connect（连接就绪）、Accept（接受就绪）、Read（读就绪）、Write（写就绪）</p>
<p>Netty基本原理：</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293279559.png" alt="1566293279559"></p>
<h2 id="3、dubbo原理"><a href="#3、dubbo原理" class="headerlink" title="3、dubbo原理"></a>3、dubbo原理</h2><h3 id="1、dubbo原理-框架设计"><a href="#1、dubbo原理-框架设计" class="headerlink" title="1、dubbo原理 -框架设计"></a>1、dubbo原理 -框架设计</h3><p><a href="http://dubbo.apache.org/zh-cn/docs/dev/design.html" target="_blank" rel="external">[http://dubbo.apache.org/zh-cn/docs/dev/design.html]{.underline}</a></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293295570.png" alt="1566293295570"></p>
<ul>
<li>config 配置层：对外配置接口，以 ServiceConfig, ReferenceConfig 为中心，可以直接初始化配置类，也可以通过 spring 解析配置生成配置类</li>
<li>proxy 服务代理层：服务接口透明代理，生成服务的客户端 Stub 和服务器端 Skeleton, 以 ServiceProxy 为中心，扩展接口为 ProxyFactory</li>
<li>registry 注册中心层：封装服务地址的注册与发现，以服务 URL 为中心，扩展接口为 RegistryFactory, Registry, RegistryService</li>
<li>cluster 路由层：封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance</li>
<li>monitor 监控层：RPC 调用次数和调用时间监控，以 Statistics 为中心，扩展接口为 MonitorFactory, Monitor, MonitorService</li>
<li>protocol 远程调用层：封装 RPC 调用，以 Invocation, Result 为中心，扩展接口为 Protocol, Invoker, Exporter</li>
<li>exchange 信息交换层：封装请求响应模式，同步转异步，以 Request, Response 为中心，扩展接口为 Exchanger, ExchangeChannel, ExchangeClient, ExchangeServer</li>
<li>transport 网络传输层：抽象 mina 和 netty 为统一接口，以 Message 为中心，扩展接口为 Channel, Transporter, Client, Server, Codec</li>
<li>serialize 数据序列化层：可复用的一些工具，扩展接口为 Serialization, ObjectInput, ObjectOutput, ThreadPool</li>
</ul>
<h3 id="2、dubbo原理-启动解析、加载配置信息"><a href="#2、dubbo原理-启动解析、加载配置信息" class="headerlink" title="2、dubbo原理 -启动解析、加载配置信息"></a>2、dubbo原理 -启动解析、加载配置信息</h3><p>我们知道spring加载配置文件，是通过BeanDefinitionparser这个接口的实现类进行绑定的</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293308924.png" alt="1566293308924"></p>
<p>调用parse方法，解析标签</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293318845.png" alt="1566293318845"></p>
<p>根据xml文件的每一行进行处理解析</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293328013.png" alt="1566293328013"></p>
<p>不同的标签处理逻辑是不一样的</p>
<p>那么每一个标签对应的类是哪一个。这个是哪里定义的呢？</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293340338.png" alt="1566293340338"></p>
<p>通过DubboNamespaceHandler来定义标签对应的解析类</p>
<h3 id="3、dubbo原理-服务暴露"><a href="#3、dubbo原理-服务暴露" class="headerlink" title="3、dubbo原理 -服务暴露"></a>3、dubbo原理 -服务暴露</h3><p>通过上面的配置文件解析，我们知道服务相关的信息是通过解析后存放在ServiceBean中</p>
<hr>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">public class ServiceBean&lt;T&gt; extends ServiceConfig&lt;T&gt; implements InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener&lt;ContextRefreshedEvent&gt;, BeanNameAware &#123;</div></pre></td></tr></table></figure>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293383877.png" alt="1566293383877"></p>
<p>关键的两个接口</p>
<p>InitializingBean Spring的接口,当组件创建完对象之后, 组件属性设置完成，会调用InitializingBean中的afterPropertiesSet方法</p>
<p>ApplicationListener应用监听器 监听IOC容器的刷新事件.当IOC容器中，所有对象都创建完成会回调onApplicationEvent方法</p>
<p>设置了延迟暴露，dubbo在Spring实例化bean（initializeBean）的时候会对实现了InitializingBean的类进行回调，回调方法是afterPropertySet()</p>
<p>没有设置延迟或者延迟为-1，dubbo会在Spring实例化完bean之后，在刷新容器最后一步发布ContextRefreshEvent事件的时候，通知实现了ApplicationListener的类进行回调onApplicationEvent</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293404027.png" alt="1566293404027"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293411759.png" alt="1566293411759"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293420019.png" alt="1566293420019"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293437832.png" alt="1566293437832"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293450707.png" alt="1566293450707"></p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293459991.png" alt="1566293459991"></p>
<p>总的调用接口如下：</p>
<p><img src="/2019/01/05/dubbo分布式服务框架/1566293466646.png" alt="1566293466646"></p>
<h3 id="4、dubbo原理-服务引用"><a href="#4、dubbo原理-服务引用" class="headerlink" title="4、dubbo原理 -服务引用"></a>4、dubbo原理 -服务引用</h3><p><img src="/2019/01/05/dubbo分布式服务框架/1566293477806.png" alt="1566293477806"></p>
<h3 id="5、dubbo原理-服务调用"><a href="#5、dubbo原理-服务调用" class="headerlink" title="5、dubbo原理 -服务调用"></a>5、dubbo原理 -服务调用</h3><p><img src="/2019/01/05/dubbo分布式服务框架/1566293490630.png" alt="1566293490630"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Dubbo分布式服务框架**&lt;/p&gt;
&lt;h1 id=&quot;一、分布式概念&quot;&gt;&lt;a href=&quot;#一、分布式概念&quot; class=&quot;headerlink&quot; title=&quot;一、分布式概念&quot;&gt;&lt;/a&gt;一、分布式概念&lt;/h1&gt;&lt;p&gt;分布式的概念：某个业务逻辑的完成，拆分成几个功能/服务来
    
    </summary>
    
      <category term="dubbo" scheme="http://kingge.top/categories/dubbo/"/>
    
    
      <category term="dubbo" scheme="http://kingge.top/tags/dubbo/"/>
    
      <category term="分布式" scheme="http://kingge.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="rpc" scheme="http://kingge.top/tags/rpc/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ消息队列</title>
    <link href="http://kingge.top/2018/09/03/RabbitMQ%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    <id>http://kingge.top/2018/09/03/RabbitMQ消息队列/</id>
    <published>2018-09-03T12:53:09.000Z</published>
    <updated>2019-09-03T13:00:57.208Z</updated>
    
    <content type="html"><![CDATA[<h1 id="RabbitMQ-简介"><a href="#RabbitMQ-简介" class="headerlink" title="RabbitMQ 简介"></a>RabbitMQ 简介</h1><p>​         MQ全称为Message Queue，即消息队列， RabbitMQ是由erlang语言开发，基于AMQP（Advanced MessageQueue 高级消息队列协议）协议实现的消息队列，它是一种应用程序之间的通信方法，消息队列在分布式系统开</p>
<p>​    发中应用非常广泛。RabbitMQ官方地址：<a href="http://www.rabbitmq.com/" target="_blank" rel="external">http://www.rabbitmq.com/</a></p>
<blockquote>
<p>开发中消息队列通常有如下应用场景：</p>
</blockquote>
<p>1、任务异步处理。<br>将不需要同步处理的并且耗时长的操作由消息队列通知消息接收方进行异步处理。提高了应用程序的响应时间。</p>
<p>2、应用程序解耦合<br>MQ相当于一个中介，生产方通过MQ与消费方交互，它将应用程序进行解耦合。</p>
<blockquote>
<p>市场上还有哪些消息队列？</p>
</blockquote>
<p>ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ、Redis。</p>
<p>为什么使用RabbitMQ呢？<br>1、使得简单，功能强大。<br>2、基于AMQP协议。<br>3、社区活跃，文档完善。<br>4、高并发性能好，这主要得益于Erlang语言。<br>5、Spring Boot默认已集成RabbitMQ</p>
<h2 id="其它相关知识"><a href="#其它相关知识" class="headerlink" title="其它相关知识"></a>其它相关知识</h2><blockquote>
<p>AMQP是什么 ？</p>
</blockquote>
<p>​    AMQP是一套公开的消息队列协议，最早在2003年被提出，它旨在从协议层定义消息通信数据的标准格式，<br>为的就是解决MQ市场上协议不统一的问题。RabbitMQ就是遵循AMQP标准协议开发的MQ服务。</p>
<p>官方：<a href="http://www.amqp.org/" target="_blank" rel="external">http://www.amqp.org/</a></p>
<blockquote>
<p>JMS是什么？</p>
</blockquote>
<p>​    JMS是java提供的一套消息服务API标准，其目的是为所有的java应用程序提供统一的消息通信的标准，类似java的jdbc，只要遵循jms标准的应用程序之间都可以进行消息通信。它和AMQP有什么 不同，jms是java语言专属的消息服务标准，它是在api层定义标准，并且只能用于java应用；而AMQP是在协议层定义的标准，是跨语言的 。</p>
<h2 id="RabbitMQ的工作原理"><a href="#RabbitMQ的工作原理" class="headerlink" title="RabbitMQ的工作原理"></a>RabbitMQ的工作原理</h2><p><img src="/2018/09/03/RabbitMQ消息队列/1567148945077.png" alt="1567148945077"></p>
<p>组成部分说明如下：</p>
<ul>
<li>Broker：消息队列服务进程，此进程包括两个部分：Exchange和Queue。</li>
</ul>
<p>​        Exchange：消息队列交换机，按一定的规则将消息路由转发到某个队列，对消息进行过虑。</p>
<p>​        Queue：消息队列，存储消息的队列，消息到达队列并转发给指定的消费方。</p>
<ul>
<li>Producer：消息生产者，即生产方客户端，生产方客户端将消息发送到MQ。</li>
<li>Consumer：消息消费者，即消费方客户端，接收MQ转发的消息。</li>
</ul>
<blockquote>
<p>消息发布接收流程：</p>
</blockquote>
<p>—–发送消息—–<br>1、生产者和Broker建立TCP连接。<br>2、生产者和Broker建立通道。<br>3、生产者通过通道消息发送给Broker，由Exchange将消息进行转发。<br>4、Exchange将消息转发到指定的Queue（队列）</p>
<p>—-接收消息—–<br>1、消费者和Broker建立TCP连接<br>2、消费者和Broker建立通道<br>3、消费者监听指定的Queue（队列）<br>4、当有消息到达Queue时Broker默认将消息推送给消费者。<br>5、消费者接收到消息。</p>
<h1 id="安装使用"><a href="#安装使用" class="headerlink" title="安装使用"></a>安装使用</h1><h2 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h2><p>​     RabbitMQ由Erlang语言开发，Erlang语言用于并发及分布式系统的开发，在电信领域应用广泛，OTP（Open<br>Telecom Platform）作为Erlang语言的一部分，包含了很多基于Erlang开发的中间件及工具库，安装RabbitMQ需<br>要安装Erlang/OTP，并保持版本匹配，如下图：</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567149365706.png" alt="1567149365706"></p>
<p>RabbitMQ的下载地址：<a href="http://www.rabbitmq.com/download.html" target="_blank" rel="external">http://www.rabbitmq.com/download.html</a></p>
<p>erlang的下载地址：<a href="http://erlang.org/download/otp_win64_20.3.exe" target="_blank" rel="external">http://erlang.org/download/otp_win64_20.3.exe</a></p>
<p><strong>这里使用：Erlang/OTP 20.3版本和RabbitMQ3.7.3版本。</strong></p>
<blockquote>
<p>特别提示</p>
<ul>
<li>安装erlang和rabbitMQ以管理员身份运行。</li>
<li>当卸载重新安装时会出现RabbitMQ服务注册失败，此时需要进入注册表清理erlang搜索RabbitMQ、ErlSrv，将对应的项全部删除。</li>
</ul>
</blockquote>
<h3 id="安装erlang"><a href="#安装erlang" class="headerlink" title="安装erlang"></a>安装erlang</h3><p>下载完成后，右键管理员运行安装，都是下一步安装完成即可。</p>
<p>配置erlang环境变量：  ERLANG_HOME=D:\erl9.3  在path中添<br>加%ERLANG_HOME%\bin;</p>
<h3 id="安装RabbitMQ"><a href="#安装RabbitMQ" class="headerlink" title="安装RabbitMQ"></a>安装RabbitMQ</h3><p>以管理员方式运行此文件，安装。</p>
<h2 id="启动RabbitMQ"><a href="#启动RabbitMQ" class="headerlink" title="启动RabbitMQ"></a>启动RabbitMQ</h2><p>安装成功后会自动创建RabbitMQ服务并且启动。</p>
<p>1）从开始菜单启动RabbitMQ</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567149729197.png" alt="1567149729197"></p>
<blockquote>
<p>RabbitMQ Service-install :安装服务<br>RabbitMQ Service-remove 删除服务<br>RabbitMQ Service-start 启动<br>RabbitMQ Service-stop 启动</p>
</blockquote>
<p>2）通过命令启动RabbitMQ</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567149795884.png" alt="1567149795884"></p>
<p>1.安装并运行服务<br>        rabbitmq-service.bat install 安装服务 </p>
<p>​        rabbitmq-service.bat stop 停止服务 </p>
<p>​        rabbitmq-service.bat start 启动服务</p>
<p>2.安装管理插件<br>    安装rabbitMQ的管理插件，方便在浏览器端管理RabbitMQ<br>    管理员身份运行命令： rabbitmq-plugins.bat enable rabbitmq_management</p>
<p>3.启动成功 登录RabbitMQ</p>
<p>​        进入浏览器，输入：<a href="http://localhost:15672" target="_blank" rel="external">http://localhost:15672</a></p>
<p>​        <strong>初始账号和密码：guest/guest</strong></p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567149894028.png" alt="1567149894028"></p>
<h2 id="官方-Hello-World-入门例子"><a href="#官方-Hello-World-入门例子" class="headerlink" title="官方 Hello World 入门例子"></a>官方 Hello World 入门例子</h2><p>官方各个语言集成RabbitMQ说明：<strong><a href="https://www.rabbitmq.com/devtools.html" target="_blank" rel="external">https://www.rabbitmq.com/devtools.html</a></strong></p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567152640556.png" alt="1567152640556"></p>
<p>下面的例子我们暂时使用，javaClient的方式，通过导入<a href="http://repo1.maven.org/maven2/com/rabbitmq/amqp-client/5.7.2/amqp-client-5.7.2.jar" target="_blank" rel="external">amqp-client-5.7.2.jar</a>完成例子的使用</p>
<p>我们先用 rabbitMQ官方提供的java client测试，目的是对RabbitMQ的交互过程有个清晰的认识。<br>参考 ：<a href="https://github.com/rabbitmq/rabbitmq-java-client/" target="_blank" rel="external">https://github.com/rabbitmq/rabbitmq-java-client/</a></p>
<p>官网例子地址：<a href="https://www.rabbitmq.com/getstarted.html" target="_blank" rel="external">https://www.rabbitmq.com/getstarted.html</a></p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567150030457.png" alt="1567150030457"></p>
<h3 id="创建maven工程-这里为了方面后面的集成，直接创建springboot项目"><a href="#创建maven工程-这里为了方面后面的集成，直接创建springboot项目" class="headerlink" title="创建maven工程-这里为了方面后面的集成，直接创建springboot项目"></a>创建maven工程-这里为了方面后面的集成，直接创建springboot项目</h3><p>创建生产者工程和消费者工程，分别加入RabbitMQ java client的依赖。</p>
<p>test-rabbitmq-producer：生产者工程<br>test-rabbitmq-consumer：消费者工程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;amqp‐client&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;4.0.3&lt;/version&gt;&lt;!‐‐此版本与spring boot 1.5.9版本匹配‐‐&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spring‐boot‐starter‐logging&lt;/artifactId&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
<p>完整项目目录：</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567152933030.png" alt="1567152933030"></p>
<h3 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h3><p>在生产者工程下的test中创建测试类如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">import com.rabbitmq.client.Channel;</div><div class="line">import com.rabbitmq.client.Connection;</div><div class="line">import com.rabbitmq.client.ConnectionFactory;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line">import java.util.concurrent.TimeoutException;</div><div class="line"></div><div class="line">public class Producer01 &#123;</div><div class="line"></div><div class="line">    //队列</div><div class="line">    private static final String QUEUE = &quot;helloworld&quot;;</div><div class="line"></div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        //通过连接工厂创建新的连接和mq建立连接</div><div class="line">        ConnectionFactory connectionFactory = new ConnectionFactory();</div><div class="line">        connectionFactory.setHost(&quot;127.0.0.1&quot;);</div><div class="line">        connectionFactory.setPort(5672);//端口</div><div class="line">        connectionFactory.setUsername(&quot;guest&quot;);</div><div class="line">        connectionFactory.setPassword(&quot;guest&quot;);</div><div class="line">        //设置虚拟机，一个mq服务可以设置多个虚拟机，每个虚拟机就相当于一个独立的mq</div><div class="line">        connectionFactory.setVirtualHost(&quot;/&quot;);</div><div class="line"></div><div class="line">        Connection connection = null;</div><div class="line">        Channel channel = null;</div><div class="line">        try &#123;</div><div class="line">            //建立新连接</div><div class="line">            connection = connectionFactory.newConnection();</div><div class="line">            //创建会话通道,生产者和mq服务所有通信都在channel通道中完成</div><div class="line">            channel = connection.createChannel();</div><div class="line">            //声明队列，如果队列在mq 中没有则要创建</div><div class="line">            //参数：String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments</div><div class="line">            /**</div><div class="line">             * 参数明细</div><div class="line">             * 1、queue 队列名称</div><div class="line">             * 2、durable 是否持久化，如果持久化，mq重启后队列还在</div><div class="line">             * 3、exclusive 是否独占连接，队列只允许在该连接中访问，如果connection连接关闭队列则自动删除,如果将此参数设置true可用于临时队列的创建</div><div class="line">             * 4、autoDelete 自动删除，队列不再使用时是否自动删除此队列，如果将此参数和exclusive参数设置为true就可以实现临时队列（队列不用了就自动删除）</div><div class="line">             * 5、arguments 参数，可以设置一个队列的扩展参数，比如：可设置存活时间</div><div class="line">             */</div><div class="line">            channel.queueDeclare(QUEUE,true,false,false,null);</div><div class="line">            //发送消息</div><div class="line">            //参数：String exchange, String routingKey, BasicProperties props, byte[] body</div><div class="line">            /**</div><div class="line">             * 参数明细：</div><div class="line">             * 1、exchange，交换机，如果不指定将使用mq的默认交换机（设置为&quot;&quot;）</div><div class="line">             * 2、routingKey，路由key，交换机根据路由key来将消息转发到指定的队列，如果使用默认交换机，routingKey设置为队列的名称</div><div class="line">             * 3、props，消息的属性</div><div class="line">             * 4、body，消息内容</div><div class="line">             */</div><div class="line">            //消息内容</div><div class="line">            String message = &quot;hello world kingge发送消息2&quot;;</div><div class="line">            channel.basicPublish(&quot;&quot;,QUEUE,null,message.getBytes());</div><div class="line">            System.out.println(&quot;send to mq &quot;+message);</div><div class="line">        &#125; catch (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125; finally &#123;</div><div class="line">            //关闭连接</div><div class="line">            //先关闭通道</div><div class="line">            try &#123;</div><div class="line">                channel.close();</div><div class="line">            &#125; catch (IOException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125; catch (TimeoutException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125;</div><div class="line">            try &#123;</div><div class="line">                connection.close();</div><div class="line">            &#125; catch (IOException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"></div><div class="line">import com.rabbitmq.client.*;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line">import java.util.concurrent.TimeoutException;</div><div class="line"></div><div class="line">public class Consumer01 &#123;</div><div class="line"></div><div class="line">    //队列</div><div class="line">    private static final String QUEUE = &quot;helloworld&quot;;</div><div class="line"></div><div class="line">    public static void main(String[] args) throws IOException, TimeoutException &#123;</div><div class="line">        //通过连接工厂创建新的连接和mq建立连接</div><div class="line">        ConnectionFactory connectionFactory = new ConnectionFactory();</div><div class="line">        connectionFactory.setHost(&quot;127.0.0.1&quot;);</div><div class="line">        connectionFactory.setPort(5672);//端口</div><div class="line">        connectionFactory.setUsername(&quot;guest&quot;);</div><div class="line">        connectionFactory.setPassword(&quot;guest&quot;);</div><div class="line">        //设置虚拟机，一个mq服务可以设置多个虚拟机，每个虚拟机就相当于一个独立的mq</div><div class="line">        connectionFactory.setVirtualHost(&quot;/&quot;);</div><div class="line"></div><div class="line">        //建立新连接</div><div class="line">        Connection connection = connectionFactory.newConnection();</div><div class="line">        //创建会话通道,生产者和mq服务所有通信都在channel通道中完成</div><div class="line">        Channel channel = connection.createChannel();</div><div class="line"></div><div class="line">        //监听队列</div><div class="line">        //声明队列，如果队列在mq 中没有则要创建</div><div class="line">        //参数：String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments</div><div class="line">        /**</div><div class="line">         * 参数明细</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、durable 是否持久化，如果持久化，mq重启后队列还在</div><div class="line">         * 3、exclusive 是否独占连接，队列只允许在该连接中访问，如果connection连接关闭队列则自动删除,如果将此参数设置true可用于临时队列的创建</div><div class="line">         * 4、autoDelete 自动删除，队列不再使用时是否自动删除此队列，如果将此参数和exclusive参数设置为true就可以实现临时队列（队列不用了就自动删除）</div><div class="line">         * 5、arguments 参数，可以设置一个队列的扩展参数，比如：可设置存活时间</div><div class="line">         */</div><div class="line">        channel.queueDeclare(QUEUE,true,false,false,null);</div><div class="line"></div><div class="line">        //实现消费方法</div><div class="line">        DefaultConsumer defaultConsumer = new DefaultConsumer(channel)&#123;</div><div class="line"></div><div class="line">            /**</div><div class="line">             * 当接收到消息后此方法将被调用</div><div class="line">             * @param consumerTag  消费者标签，用来标识消费者的，在监听队列时设置channel.basicConsume</div><div class="line">             * @param envelope 信封，通过envelope</div><div class="line">             * @param properties 消息属性</div><div class="line">             * @param body 消息内容</div><div class="line">             * @throws IOException</div><div class="line">             */</div><div class="line">            @Override</div><div class="line">            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123;</div><div class="line">                //交换机</div><div class="line">                String exchange = envelope.getExchange();</div><div class="line">                //消息id，mq在channel中用来标识消息的id，可用于确认消息已接收（因为如果下面的autoAck设置为false就需要自行回复mq消息已经接受）</div><div class="line">                long deliveryTag = envelope.getDeliveryTag();</div><div class="line">                //消息内容</div><div class="line">                String message= new String(body,&quot;utf-8&quot;);</div><div class="line">                System.out.println(&quot;receive message:&quot;+message);</div><div class="line">            &#125;</div><div class="line">        &#125;;</div><div class="line"></div><div class="line">        //监听队列</div><div class="line">        //参数：String queue, boolean autoAck, Consumer callback</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、autoAck 自动回复，当消费者接收到消息后要告诉mq消息已接收，如果将此参数设置为tru表示会自动回复mq，如果设置为false要通过编程实现回复</div><div class="line">         * 3、callback，消费方法，当消费者接收到消息要执行的方法</div><div class="line">         */</div><div class="line">        channel.basicConsume(QUEUE,true,defaultConsumer);</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>（1）启动消费者：发送消息</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567153167144.png" alt="1567153167144"></p>
<p>（2）查询RabbitMQ后台管理浏览器</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567153233103.png" alt="1567153233103"></p>
<p>（3）启动消费者</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567153297099.png" alt="1567153297099"></p>
<p>消息消费成功</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567153329648.png" alt="1567153329648"></p>
<p>已经变为了0</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><blockquote>
<p>1、发送端操作流程</p>
</blockquote>
<p> 1）创建连接</p>
<p> 2）创建通道</p>
<p> 3）声明队列</p>
<p> 4）发送消息</p>
<blockquote>
<p>2、接收端</p>
</blockquote>
<p> 1）创建连接</p>
<p> 2）创建通道</p>
<p> 3）声明队列</p>
<p> 4）监听队列</p>
<p> 5）接收消息</p>
<p> 6）ack回复</p>
<p>通过代码我们不难发现，生产者和消费者的代码，其实前半段都是一模一样的。（创建连接工厂，创建连接，创建通道，声明队列）</p>
<h1 id="RabbitMQ工作模式"><a href="#RabbitMQ工作模式" class="headerlink" title="RabbitMQ工作模式"></a>RabbitMQ工作模式</h1><p>RabbitMQ有以下几种工作模式 ：<br><a href="https://www.rabbitmq.com/getstarted.html" target="_blank" rel="external">https://www.rabbitmq.com/getstarted.html</a></p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567153810391.png" alt="1567153810391"></p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567153833818.png" alt="1567153833818"></p>
<p><strong>每后一个模式都能够实现前一个模式的功能</strong></p>
<h2 id="Work-queues"><a href="#Work-queues" class="headerlink" title="Work queues"></a>Work queues</h2><p>​    work queues与入门程序相比，多了一个消费端，两个消费端共同消费同一个队列中的消息，而且它支持负载均衡的方式消费消息。</p>
<p>应用场景：对于任务过重或任务较多情况使用工作队列可以提高任务处理的速度（<strong>开启多个消费者消费同一个队列，处理相应的业务</strong>）。</p>
<h3 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h3><p>1、使用入门程序，启动多个消费者（启动多次即可）。</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567154096753.png" alt="1567154096753"></p>
<p>这里启动了两个消费者，都是监听helloworld队列。</p>
<p>2、生产者发送多个消息。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">修改入门例子：</div><div class="line"></div><div class="line">            for(int i=0;i&lt;5;i++)&#123;</div><div class="line">                //消息内容</div><div class="line">                String message = &quot;this is a msg&quot;;</div><div class="line">                channel.basicPublish(&quot;&quot;,QUEUE,null,message.getBytes());</div><div class="line">                System.out.println(&quot;send to mq &quot;+message);</div><div class="line">            &#125;</div></pre></td></tr></table></figure>
<p>运行生产者</p>
<p>3.查看消费者输出</p>
<p>第一个消费者：</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567154325689.png" alt="1567154325689"></p>
<p>第二个消费者：</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567154340959.png" alt="1567154340959"></p>
<blockquote>
<p>结果：</p>
</blockquote>
<p>1、一条消息只会被一个消费者接收。<br>2、rabbit采用轮询的方式将消息是平均发送给消费者的。<br>3、消费者在处理完某条消息后，才会收到下一条消息。</p>
<h2 id="Publish-subscribe"><a href="#Publish-subscribe" class="headerlink" title="Publish/subscribe"></a>Publish/subscribe</h2><p><img src="/2018/09/03/RabbitMQ消息队列/1567154410506.png" alt="1567154410506"></p>
<p>发布订阅模式：<br>1、每个消费者监听自己的队列。<br>2、生产者将消息发给broker，由交换机将消息转发到绑定此交换机的每个队列，每个绑定交换机的队列都将接收<br>到消息（<strong>也就是说，生产者发出的消息，每个队列都会收到。例如发出五个消息，那么每个队列都会收到五个</strong>）</p>
<h3 id="案例-1"><a href="#案例-1" class="headerlink" title="案例"></a>案例</h3><p>用户通知消费通知。<strong>当用户充值成功或转账完成系统通知用户，通知方式有短信、邮件多种方法 。</strong></p>
<h4 id="1-生产者代码"><a href="#1-生产者代码" class="headerlink" title="1.生产者代码"></a>1.生产者代码</h4><p>声明Exchange_fanout_inform交换机，声明两个队列并且绑定到此交换机，绑定时不需要指定routingkey，发送消息时不需要指定routingkey</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"></div><div class="line">import com.rabbitmq.client.BuiltinExchangeType;</div><div class="line">import com.rabbitmq.client.Channel;</div><div class="line">import com.rabbitmq.client.Connection;</div><div class="line">import com.rabbitmq.client.ConnectionFactory;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line">import java.util.concurrent.TimeoutException;</div><div class="line"></div><div class="line">public class Producer02_publish &#123;</div><div class="line">    //队列名称</div><div class="line">    private static final String QUEUE_INFORM_EMAIL = &quot;queue_inform_email&quot;;</div><div class="line">    private static final String QUEUE_INFORM_SMS = &quot;queue_inform_sms&quot;;</div><div class="line">    private static final String EXCHANGE_FANOUT_INFORM=&quot;exchange_fanout_inform&quot;;</div><div class="line"></div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        //通过连接工厂创建新的连接和mq建立连接</div><div class="line">        ConnectionFactory connectionFactory = new ConnectionFactory();</div><div class="line">        connectionFactory.setHost(&quot;127.0.0.1&quot;);</div><div class="line">        connectionFactory.setPort(5672);//端口</div><div class="line">        connectionFactory.setUsername(&quot;guest&quot;);</div><div class="line">        connectionFactory.setPassword(&quot;guest&quot;);</div><div class="line">        //设置虚拟机，一个mq服务可以设置多个虚拟机，每个虚拟机就相当于一个独立的mq</div><div class="line">        connectionFactory.setVirtualHost(&quot;/&quot;);</div><div class="line"></div><div class="line">        Connection connection = null;</div><div class="line">        Channel channel = null;</div><div class="line">        try &#123;</div><div class="line">            //建立新连接</div><div class="line">            connection = connectionFactory.newConnection();</div><div class="line">            //创建会话通道,生产者和mq服务所有通信都在channel通道中完成</div><div class="line">            channel = connection.createChannel();</div><div class="line">            //声明队列，如果队列在mq 中没有则要创建</div><div class="line">            //参数：String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments</div><div class="line">            /**</div><div class="line">             * 参数明细</div><div class="line">             * 1、queue 队列名称</div><div class="line">             * 2、durable 是否持久化，如果持久化，mq重启后队列还在</div><div class="line">             * 3、exclusive 是否独占连接，队列只允许在该连接中访问，如果connection连接关闭队列则自动删除,如果将此参数设置true可用于临时队列的创建</div><div class="line">             * 4、autoDelete 自动删除，队列不再使用时是否自动删除此队列，如果将此参数和exclusive参数设置为true就可以实现临时队列（队列不用了就自动删除）</div><div class="line">             * 5、arguments 参数，可以设置一个队列的扩展参数，比如：可设置存活时间</div><div class="line">             */</div><div class="line">            channel.queueDeclare(QUEUE_INFORM_EMAIL,true,false,false,null);</div><div class="line">            channel.queueDeclare(QUEUE_INFORM_SMS,true,false,false,null);</div><div class="line">            //声明一个交换机</div><div class="line">            //参数：String exchange, String type</div><div class="line">            /**</div><div class="line">             * 参数明细：</div><div class="line">             * 1、交换机的名称</div><div class="line">             * 2、交换机的类型</div><div class="line">             * fanout：对应的rabbitmq的工作模式是 publish/subscribe</div><div class="line">             * direct：对应的Routing	工作模式</div><div class="line">             * topic：对应的Topics工作模式</div><div class="line">             * headers： 对应的headers工作模式</div><div class="line">             */</div><div class="line">            channel.exchangeDeclare(EXCHANGE_FANOUT_INFORM, BuiltinExchangeType.FANOUT);</div><div class="line">            //进行交换机和队列绑定</div><div class="line">            //参数：String queue, String exchange, String routingKey</div><div class="line">            /**</div><div class="line">             * 参数明细：</div><div class="line">             * 1、queue 队列名称</div><div class="line">             * 2、exchange 交换机名称</div><div class="line">             * 3、routingKey 路由key，作用是交换机根据路由key的值将消息转发到指定的队列中，在发布订阅模式中调协为空字符串</div><div class="line">             */</div><div class="line">            channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_FANOUT_INFORM,&quot;&quot;);</div><div class="line">            channel.queueBind(QUEUE_INFORM_SMS,EXCHANGE_FANOUT_INFORM,&quot;&quot;);</div><div class="line">            //发送消息</div><div class="line">            //参数：String exchange, String routingKey, BasicProperties props, byte[] body</div><div class="line">            /**</div><div class="line">             * 参数明细：</div><div class="line">             * 1、exchange，交换机，如果不指定将使用mq的默认交换机（设置为&quot;&quot;）</div><div class="line">             * 2、routingKey，路由key，交换机根据路由key来将消息转发到指定的队列，如果使用默认交换机，routingKey设置为队列的名称</div><div class="line">             * 3、props，消息的属性</div><div class="line">             * 4、body，消息内容</div><div class="line">             */</div><div class="line">            for(int i=0;i&lt;5;i++)&#123;</div><div class="line">                //消息内容</div><div class="line">                String message = &quot;send inform message to user&quot;;</div><div class="line">                channel.basicPublish(EXCHANGE_FANOUT_INFORM,&quot;&quot;,null,message.getBytes());</div><div class="line">                System.out.println(&quot;send to mq &quot;+message);</div><div class="line">            &#125;</div><div class="line"></div><div class="line">        &#125; catch (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125; finally &#123;</div><div class="line">            //关闭连接</div><div class="line">            //先关闭通道</div><div class="line">            try &#123;</div><div class="line">                channel.close();</div><div class="line">            &#125; catch (IOException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125; catch (TimeoutException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125;</div><div class="line">            try &#123;</div><div class="line">                connection.close();</div><div class="line">            &#125; catch (IOException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="2-邮件发送消费者"><a href="#2-邮件发送消费者" class="headerlink" title="2.邮件发送消费者"></a>2.邮件发送消费者</h4><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"></div><div class="line">import com.rabbitmq.client.*;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line">import java.util.concurrent.TimeoutException;</div><div class="line"></div><div class="line"></div><div class="line">public class Consumer02_subscribe_email &#123;</div><div class="line">    //队列名称</div><div class="line">    private static final String QUEUE_INFORM_EMAIL = &quot;queue_inform_email&quot;;</div><div class="line">    private static final String EXCHANGE_FANOUT_INFORM=&quot;exchange_fanout_inform&quot;;</div><div class="line"></div><div class="line"></div><div class="line">    public static void main(String[] args) throws IOException, TimeoutException &#123;</div><div class="line">        //通过连接工厂创建新的连接和mq建立连接</div><div class="line">        ConnectionFactory connectionFactory = new ConnectionFactory();</div><div class="line">        connectionFactory.setHost(&quot;127.0.0.1&quot;);</div><div class="line">        connectionFactory.setPort(5672);//端口</div><div class="line">        connectionFactory.setUsername(&quot;guest&quot;);</div><div class="line">        connectionFactory.setPassword(&quot;guest&quot;);</div><div class="line">        //设置虚拟机，一个mq服务可以设置多个虚拟机，每个虚拟机就相当于一个独立的mq</div><div class="line">        connectionFactory.setVirtualHost(&quot;/&quot;);</div><div class="line"></div><div class="line">        //建立新连接</div><div class="line">        Connection connection = connectionFactory.newConnection();</div><div class="line">        //创建会话通道,生产者和mq服务所有通信都在channel通道中完成</div><div class="line">        Channel channel = connection.createChannel();</div><div class="line"></div><div class="line">        /**</div><div class="line">         * 参数明细</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、durable 是否持久化，如果持久化，mq重启后队列还在</div><div class="line">         * 3、exclusive 是否独占连接，队列只允许在该连接中访问，如果connection连接关闭队列则自动删除,如果将此参数设置true可用于临时队列的创建</div><div class="line">         * 4、autoDelete 自动删除，队列不再使用时是否自动删除此队列，如果将此参数和exclusive参数设置为true就可以实现临时队列（队列不用了就自动删除）</div><div class="line">         * 5、arguments 参数，可以设置一个队列的扩展参数，比如：可设置存活时间</div><div class="line">         */</div><div class="line">        channel.queueDeclare(QUEUE_INFORM_EMAIL,true,false,false,null);</div><div class="line">        //声明一个交换机</div><div class="line">        //参数：String exchange, String type</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、交换机的名称</div><div class="line">         * 2、交换机的类型</div><div class="line">         * fanout：对应的rabbitmq的工作模式是 publish/subscribe</div><div class="line">         * direct：对应的Routing	工作模式</div><div class="line">         * topic：对应的Topics工作模式</div><div class="line">         * headers： 对应的headers工作模式</div><div class="line">         */</div><div class="line">        channel.exchangeDeclare(EXCHANGE_FANOUT_INFORM, BuiltinExchangeType.FANOUT);</div><div class="line">        //进行交换机和队列绑定</div><div class="line">        //参数：String queue, String exchange, String routingKey</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、exchange 交换机名称</div><div class="line">         * 3、routingKey 路由key，作用是交换机根据路由key的值将消息转发到指定的队列中，在发布订阅模式中调协为空字符串</div><div class="line">         */</div><div class="line">        channel.queueBind(QUEUE_INFORM_EMAIL, EXCHANGE_FANOUT_INFORM, &quot;&quot;);</div><div class="line"></div><div class="line">        //实现消费方法</div><div class="line">        DefaultConsumer defaultConsumer = new DefaultConsumer(channel)&#123;</div><div class="line"></div><div class="line">            /**</div><div class="line">             * 当接收到消息后此方法将被调用</div><div class="line">             * @param consumerTag  消费者标签，用来标识消费者的，在监听队列时设置channel.basicConsume</div><div class="line">             * @param envelope 信封，通过envelope</div><div class="line">             * @param properties 消息属性</div><div class="line">             * @param body 消息内容</div><div class="line">             * @throws IOException</div><div class="line">             */</div><div class="line">            @Override</div><div class="line">            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123;</div><div class="line">                //交换机</div><div class="line">                String exchange = envelope.getExchange();</div><div class="line">                //消息id，mq在channel中用来标识消息的id，可用于确认消息已接收</div><div class="line">                long deliveryTag = envelope.getDeliveryTag();</div><div class="line">                //消息内容</div><div class="line">                String message= new String(body,&quot;utf-8&quot;);</div><div class="line">                System.out.println(&quot;receive message:&quot;+message);</div><div class="line">            &#125;</div><div class="line">        &#125;;</div><div class="line"></div><div class="line">        //监听队列</div><div class="line">        //参数：String queue, boolean autoAck, Consumer callback</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、autoAck 自动回复，当消费者接收到消息后要告诉mq消息已接收，如果将此参数设置为tru表示会自动回复mq，如果设置为false要通过编程实现回复</div><div class="line">         * 3、callback，消费方法，当消费者接收到消息要执行的方法</div><div class="line">         */</div><div class="line">        channel.basicConsume(QUEUE_INFORM_EMAIL,true,defaultConsumer);</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="3-短信发送消费者"><a href="#3-短信发送消费者" class="headerlink" title="3.短信发送消费者"></a>3.短信发送消费者</h4><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"></div><div class="line">import com.rabbitmq.client.*;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line">import java.util.concurrent.TimeoutException;</div><div class="line"></div><div class="line"></div><div class="line">public class Consumer02_subscribe_sms &#123;</div><div class="line">    //队列名称</div><div class="line">    private static final String QUEUE_INFORM_SMS = &quot;queue_inform_sms&quot;;</div><div class="line">    private static final String EXCHANGE_FANOUT_INFORM=&quot;exchange_fanout_inform&quot;;</div><div class="line"></div><div class="line"></div><div class="line">    public static void main(String[] args) throws IOException, TimeoutException &#123;</div><div class="line">        //通过连接工厂创建新的连接和mq建立连接</div><div class="line">        ConnectionFactory connectionFactory = new ConnectionFactory();</div><div class="line">        connectionFactory.setHost(&quot;127.0.0.1&quot;);</div><div class="line">        connectionFactory.setPort(5672);//端口</div><div class="line">        connectionFactory.setUsername(&quot;guest&quot;);</div><div class="line">        connectionFactory.setPassword(&quot;guest&quot;);</div><div class="line">        //设置虚拟机，一个mq服务可以设置多个虚拟机，每个虚拟机就相当于一个独立的mq</div><div class="line">        connectionFactory.setVirtualHost(&quot;/&quot;);</div><div class="line"></div><div class="line">        //建立新连接</div><div class="line">        Connection connection = connectionFactory.newConnection();</div><div class="line">        //创建会话通道,生产者和mq服务所有通信都在channel通道中完成</div><div class="line">        Channel channel = connection.createChannel();</div><div class="line"></div><div class="line">        /**</div><div class="line">         * 参数明细</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、durable 是否持久化，如果持久化，mq重启后队列还在</div><div class="line">         * 3、exclusive 是否独占连接，队列只允许在该连接中访问，如果connection连接关闭队列则自动删除,如果将此参数设置true可用于临时队列的创建</div><div class="line">         * 4、autoDelete 自动删除，队列不再使用时是否自动删除此队列，如果将此参数和exclusive参数设置为true就可以实现临时队列（队列不用了就自动删除）</div><div class="line">         * 5、arguments 参数，可以设置一个队列的扩展参数，比如：可设置存活时间</div><div class="line">         */</div><div class="line">        channel.queueDeclare(QUEUE_INFORM_SMS,true,false,false,null);</div><div class="line">        //声明一个交换机</div><div class="line">        //参数：String exchange, String type</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、交换机的名称</div><div class="line">         * 2、交换机的类型</div><div class="line">         * fanout：对应的rabbitmq的工作模式是 publish/subscribe</div><div class="line">         * direct：对应的Routing	工作模式</div><div class="line">         * topic：对应的Topics工作模式</div><div class="line">         * headers： 对应的headers工作模式</div><div class="line">         */</div><div class="line">        channel.exchangeDeclare(EXCHANGE_FANOUT_INFORM, BuiltinExchangeType.FANOUT);</div><div class="line">        //进行交换机和队列绑定</div><div class="line">        //参数：String queue, String exchange, String routingKey</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、exchange 交换机名称</div><div class="line">         * 3、routingKey 路由key，作用是交换机根据路由key的值将消息转发到指定的队列中，在发布订阅模式中调协为空字符串</div><div class="line">         */</div><div class="line">        channel.queueBind(QUEUE_INFORM_SMS, EXCHANGE_FANOUT_INFORM, &quot;&quot;);</div><div class="line"></div><div class="line">        //实现消费方法</div><div class="line">        DefaultConsumer defaultConsumer = new DefaultConsumer(channel)&#123;</div><div class="line"></div><div class="line">            /**</div><div class="line">             * 当接收到消息后此方法将被调用</div><div class="line">             * @param consumerTag  消费者标签，用来标识消费者的，在监听队列时设置channel.basicConsume</div><div class="line">             * @param envelope 信封，通过envelope</div><div class="line">             * @param properties 消息属性</div><div class="line">             * @param body 消息内容</div><div class="line">             * @throws IOException</div><div class="line">             */</div><div class="line">            @Override</div><div class="line">            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123;</div><div class="line">                //交换机</div><div class="line">                String exchange = envelope.getExchange();</div><div class="line">                //消息id，mq在channel中用来标识消息的id，可用于确认消息已接收</div><div class="line">                long deliveryTag = envelope.getDeliveryTag();</div><div class="line">                //消息内容</div><div class="line">                String message= new String(body,&quot;utf-8&quot;);</div><div class="line">                System.out.println(&quot;receive message:&quot;+message);</div><div class="line">            &#125;</div><div class="line">        &#125;;</div><div class="line"></div><div class="line">        //监听队列</div><div class="line">        //参数：String queue, boolean autoAck, Consumer callback</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、autoAck 自动回复，当消费者接收到消息后要告诉mq消息已接收，如果将此参数设置为tru表示会自动回复mq，如果设置为false要通过编程实现回复</div><div class="line">         * 3、callback，消费方法，当消费者接收到消息要执行的方法</div><div class="line">         */</div><div class="line">        channel.basicConsume(QUEUE_INFORM_SMS,true,defaultConsumer);</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="4-测试"><a href="#4-测试" class="headerlink" title="4.测试"></a>4.测试</h4><h5 id="1-启动消息生产者，发送消息"><a href="#1-启动消息生产者，发送消息" class="headerlink" title="1.启动消息生产者，发送消息"></a>1.启动消息生产者，发送消息</h5><p><img src="/2018/09/03/RabbitMQ消息队列/1567154904126.png" alt="1567154904126"></p>
<h5 id="2-RabbitMQ的管理界面"><a href="#2-RabbitMQ的管理界面" class="headerlink" title="2.RabbitMQ的管理界面"></a>2.RabbitMQ的管理界面</h5><p>查看交换机</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567154956089.png" alt="1567154956089"></p>
<p>单击进去</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567154981512.png" alt="1567154981512"></p>
<p>可以看到他绑定了两个队列</p>
<p>查看队列信息：</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567155028986.png" alt="1567155028986"></p>
<p>两个队列各有五条消息。</p>
<h4 id="3-启动两个消费者"><a href="#3-启动两个消费者" class="headerlink" title="3.启动两个消费者"></a>3.启动两个消费者</h4><p><img src="/2018/09/03/RabbitMQ消息队列/1567155261815.png" alt="1567155261815"></p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567155244606.png" alt="1567155244606"></p>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>1.使用生产者发送若干条消息，每条消息都转发到各各队列，每消费者都接收到了消息。</p>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><blockquote>
<p>publish/subscribe与work queues有什么区别和相似点。</p>
</blockquote>
<p>区别：<br>1）work queues不用定义交换机（使用默认的交换机），而publish/subscribe需要定义交换机。<br>2）publish/subscribe的生产方是面向交换机发送消息，work queues的生产方是面向队列发送消息(底层使用默认交换机)。<br>3）publish/subscribe需要设置队列和交换机的绑定，work queues不需要设置，实质上work queues会将队列绑<br>定到默认的交换机 。</p>
<p>相同点：<br>    两者实现的发布/订阅的效果是一样的，多个消费端监听同一个队列不会重复消费消息。</p>
<p>建议使用 publish/subscribe，发布订阅模式比工作队列模式更强大，并且发布订阅模式可以指定自己专用的交换<br>机。同时发布订阅模式，可以实现工作队列模式的功能（<strong>我们可以启动两个Consumer02_subscribe_sms消费者，然后他们都监听queue_inform_sms队列，当queue_inform_sms收到消息时他们会采用工作队列模式的轮循方式消费消息</strong>）</p>
<h2 id="Routing"><a href="#Routing" class="headerlink" title="Routing"></a>Routing</h2><p>路由模式：</p>
<p>1、每个消费者监听自己的队列，并且设置routingkey。<br>2、生产者将消息发给交换机，由<strong>交换机根据routingkey来转发消息到指定的队列。</strong></p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567155625094.png" alt="1567155625094"></p>
<p>也就是说相比于发布订阅模式，他多了路由这个功能。</p>
<h3 id="案例-2"><a href="#案例-2" class="headerlink" title="案例"></a>案例</h3><p>通过rootingkey分别发送五条消息到sms队列和email队列</p>
<h4 id="1-生产者代码-1"><a href="#1-生产者代码-1" class="headerlink" title="1.生产者代码"></a>1.生产者代码</h4><p>声明exchange_routing_inform交换机，声明两个队列并且绑定到此交换机，绑定时需要指定routingkey发送消息时需要指定routingkey</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"></div><div class="line">import com.rabbitmq.client.BuiltinExchangeType;</div><div class="line">import com.rabbitmq.client.Channel;</div><div class="line">import com.rabbitmq.client.Connection;</div><div class="line">import com.rabbitmq.client.ConnectionFactory;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line">import java.util.concurrent.TimeoutException;</div><div class="line"></div><div class="line"></div><div class="line">public class Producer03_routing &#123;</div><div class="line">    //队列名称</div><div class="line">    private static final String QUEUE_INFORM_EMAIL = &quot;queue_inform_email&quot;;</div><div class="line">    private static final String QUEUE_INFORM_SMS = &quot;queue_inform_sms&quot;;</div><div class="line">    //路由交换机名称</div><div class="line">    private static final String EXCHANGE_ROUTING_INFORM=&quot;exchange_routing_inform&quot;;</div><div class="line">    //两个队列对应的rootingkey</div><div class="line">    private static final String ROUTINGKEY_EMAIL=&quot;inform_email&quot;;</div><div class="line">    private static final String ROUTINGKEY_SMS=&quot;inform_sms&quot;;</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        //通过连接工厂创建新的连接和mq建立连接</div><div class="line">        ConnectionFactory connectionFactory = new ConnectionFactory();</div><div class="line">        connectionFactory.setHost(&quot;127.0.0.1&quot;);</div><div class="line">        connectionFactory.setPort(5672);//端口</div><div class="line">        connectionFactory.setUsername(&quot;guest&quot;);</div><div class="line">        connectionFactory.setPassword(&quot;guest&quot;);</div><div class="line">        //设置虚拟机，一个mq服务可以设置多个虚拟机，每个虚拟机就相当于一个独立的mq</div><div class="line">        connectionFactory.setVirtualHost(&quot;/&quot;);</div><div class="line"></div><div class="line">        Connection connection = null;</div><div class="line">        Channel channel = null;</div><div class="line">        try &#123;</div><div class="line">            //建立新连接</div><div class="line">            connection = connectionFactory.newConnection();</div><div class="line">            //创建会话通道,生产者和mq服务所有通信都在channel通道中完成</div><div class="line">            channel = connection.createChannel();</div><div class="line">            //声明队列，如果队列在mq 中没有则要创建</div><div class="line">            //参数：String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments</div><div class="line">            /**</div><div class="line">             * 参数明细</div><div class="line">             * 1、queue 队列名称</div><div class="line">             * 2、durable 是否持久化，如果持久化，mq重启后队列还在</div><div class="line">             * 3、exclusive 是否独占连接，队列只允许在该连接中访问，如果connection连接关闭队列则自动删除,如果将此参数设置true可用于临时队列的创建</div><div class="line">             * 4、autoDelete 自动删除，队列不再使用时是否自动删除此队列，如果将此参数和exclusive参数设置为true就可以实现临时队列（队列不用了就自动删除）</div><div class="line">             * 5、arguments 参数，可以设置一个队列的扩展参数，比如：可设置存活时间</div><div class="line">             */</div><div class="line">            channel.queueDeclare(QUEUE_INFORM_EMAIL,true,false,false,null);</div><div class="line">            channel.queueDeclare(QUEUE_INFORM_SMS,true,false,false,null);</div><div class="line">            //声明一个交换机</div><div class="line">            //参数：String exchange, String type</div><div class="line">            /**</div><div class="line">             * 参数明细：</div><div class="line">             * 1、交换机的名称</div><div class="line">             * 2、交换机的类型</div><div class="line">             * fanout：对应的rabbitmq的工作模式是 publish/subscribe</div><div class="line">             * direct：对应的Routing	工作模式</div><div class="line">             * topic：对应的Topics工作模式</div><div class="line">             * headers： 对应的headers工作模式</div><div class="line">             */</div><div class="line">            channel.exchangeDeclare(EXCHANGE_ROUTING_INFORM, BuiltinExchangeType.DIRECT);</div><div class="line">            //进行交换机和队列绑定</div><div class="line">            //参数：String queue, String exchange, String routingKey</div><div class="line">            /**</div><div class="line">             * 参数明细：</div><div class="line">             * 1、queue 队列名称</div><div class="line">             * 2、exchange 交换机名称</div><div class="line">             * 3、routingKey 路由key，作用是交换机根据路由key的值将消息转发到指定的队列中，在发布订阅模式中调协为空字符串</div><div class="line">             */</div><div class="line">            channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_ROUTING_INFORM,ROUTINGKEY_EMAIL);</div><div class="line">    </div><div class="line">            channel.queueBind(QUEUE_INFORM_SMS,EXCHANGE_ROUTING_INFORM,ROUTINGKEY_SMS);</div><div class="line"></div><div class="line">            //发送消息</div><div class="line">            //参数：String exchange, String routingKey, BasicProperties props, byte[] body</div><div class="line">            /**</div><div class="line">             * 参数明细：</div><div class="line">             * 1、exchange，交换机，如果不指定将使用mq的默认交换机（设置为&quot;&quot;）</div><div class="line">             * 2、routingKey，路由key，交换机根据路由key来将消息转发到指定的队列，如果使用默认交换机，routingKey设置为队列的名称</div><div class="line">             * 3、props，消息的属性</div><div class="line">             * 4、body，消息内容</div><div class="line">             */</div><div class="line">            for(int i=0;i&lt;5;i++)&#123;</div><div class="line">                //发送消息的时候指定routingKey</div><div class="line">                String message = &quot;send email inform message to user&quot;;</div><div class="line">                channel.basicPublish(EXCHANGE_ROUTING_INFORM,ROUTINGKEY_EMAIL,null,message.getBytes());</div><div class="line">                System.out.println(&quot;send to mq &quot;+message);</div><div class="line">            &#125;</div><div class="line">            for(int i=0;i&lt;5;i++)&#123;</div><div class="line">                //发送消息的时候指定routingKey</div><div class="line">                String message = &quot;send sms inform message to user&quot;;</div><div class="line">                channel.basicPublish(EXCHANGE_ROUTING_INFORM,ROUTINGKEY_SMS,null,message.getBytes());</div><div class="line">                System.out.println(&quot;send to mq &quot;+message);</div><div class="line">            &#125;</div><div class="line"></div><div class="line">        &#125; catch (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125; finally &#123;</div><div class="line">            //关闭连接</div><div class="line">            //先关闭通道</div><div class="line">            try &#123;</div><div class="line">                channel.close();</div><div class="line">            &#125; catch (IOException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125; catch (TimeoutException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125;</div><div class="line">            try &#123;</div><div class="line">                connection.close();</div><div class="line">            &#125; catch (IOException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>跟发布订阅模式的生产者相比代码的区别：</p>
<p>1.声明一个交换机时候，类型修改为BuiltinExchangeType.DIRECT 路由工作模式</p>
<p>2.在进行交换机和队列绑定的时候（channel.queueBind）多出了指明队列指定的rootingkey这一参数</p>
<p>3.发消息时，需要指明消息发送的rootingkey（也即是要发送到哪一个队列）</p>
<h4 id="2-邮件消费者"><a href="#2-邮件消费者" class="headerlink" title="2.邮件消费者"></a>2.邮件消费者</h4><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">import com.rabbitmq.client.*;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line">import java.util.concurrent.TimeoutException;</div><div class="line"></div><div class="line">public class Consumer03_routing_email &#123;</div><div class="line">    //队列名称</div><div class="line">    private static final String QUEUE_INFORM_EMAIL = &quot;queue_inform_email&quot;;</div><div class="line">    private static final String EXCHANGE_ROUTING_INFORM=&quot;exchange_routing_inform&quot;;</div><div class="line">    private static final String ROUTINGKEY_EMAIL=&quot;inform_email&quot;;</div><div class="line"></div><div class="line">    public static void main(String[] args) throws IOException, TimeoutException &#123;</div><div class="line">        //通过连接工厂创建新的连接和mq建立连接</div><div class="line">        ConnectionFactory connectionFactory = new ConnectionFactory();</div><div class="line">        connectionFactory.setHost(&quot;127.0.0.1&quot;);</div><div class="line">        connectionFactory.setPort(5672);//端口</div><div class="line">        connectionFactory.setUsername(&quot;guest&quot;);</div><div class="line">        connectionFactory.setPassword(&quot;guest&quot;);</div><div class="line">        //设置虚拟机，一个mq服务可以设置多个虚拟机，每个虚拟机就相当于一个独立的mq</div><div class="line">        connectionFactory.setVirtualHost(&quot;/&quot;);</div><div class="line"></div><div class="line">        //建立新连接</div><div class="line">        Connection connection = connectionFactory.newConnection();</div><div class="line">        //创建会话通道,生产者和mq服务所有通信都在channel通道中完成</div><div class="line">        Channel channel = connection.createChannel();</div><div class="line"></div><div class="line">        /**</div><div class="line">         * 参数明细</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、durable 是否持久化，如果持久化，mq重启后队列还在</div><div class="line">         * 3、exclusive 是否独占连接，队列只允许在该连接中访问，如果connection连接关闭队列则自动删除,如果将此参数设置true可用于临时队列的创建</div><div class="line">         * 4、autoDelete 自动删除，队列不再使用时是否自动删除此队列，如果将此参数和exclusive参数设置为true就可以实现临时队列（队列不用了就自动删除）</div><div class="line">         * 5、arguments 参数，可以设置一个队列的扩展参数，比如：可设置存活时间</div><div class="line">         */</div><div class="line">        channel.queueDeclare(QUEUE_INFORM_EMAIL,true,false,false,null);</div><div class="line">        //声明一个交换机</div><div class="line">        //参数：String exchange, String type</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、交换机的名称</div><div class="line">         * 2、交换机的类型</div><div class="line">         * fanout：对应的rabbitmq的工作模式是 publish/subscribe</div><div class="line">         * direct：对应的Routing	工作模式</div><div class="line">         * topic：对应的Topics工作模式</div><div class="line">         * headers： 对应的headers工作模式</div><div class="line">         */</div><div class="line">        channel.exchangeDeclare(EXCHANGE_ROUTING_INFORM, BuiltinExchangeType.DIRECT);</div><div class="line">        //进行交换机和队列绑定</div><div class="line">        //参数：String queue, String exchange, String routingKey</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、exchange 交换机名称</div><div class="line">         * 3、routingKey 路由key，作用是交换机根据路由key的值将消息转发到指定的队列中，在发布订阅模式中调协为空字符串</div><div class="line">         */</div><div class="line">        channel.queueBind(QUEUE_INFORM_EMAIL, EXCHANGE_ROUTING_INFORM,ROUTINGKEY_EMAIL);</div><div class="line"></div><div class="line">        //实现消费方法</div><div class="line">        DefaultConsumer defaultConsumer = new DefaultConsumer(channel)&#123;</div><div class="line"></div><div class="line">            /**</div><div class="line">             * 当接收到消息后此方法将被调用</div><div class="line">             * @param consumerTag  消费者标签，用来标识消费者的，在监听队列时设置channel.basicConsume</div><div class="line">             * @param envelope 信封，通过envelope</div><div class="line">             * @param properties 消息属性</div><div class="line">             * @param body 消息内容</div><div class="line">             * @throws IOException</div><div class="line">             */</div><div class="line">            @Override</div><div class="line">            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123;</div><div class="line">                //交换机</div><div class="line">                String exchange = envelope.getExchange();</div><div class="line">                //消息id，mq在channel中用来标识消息的id，可用于确认消息已接收</div><div class="line">                long deliveryTag = envelope.getDeliveryTag();</div><div class="line">                //消息内容</div><div class="line">                String message= new String(body,&quot;utf-8&quot;);</div><div class="line">                System.out.println(&quot;receive message:&quot;+message);</div><div class="line">            &#125;</div><div class="line">        &#125;;</div><div class="line"></div><div class="line">        //监听队列</div><div class="line">        //参数：String queue, boolean autoAck, Consumer callback</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、autoAck 自动回复，当消费者接收到消息后要告诉mq消息已接收，如果将此参数设置为tru表示会自动回复mq，如果设置为false要通过编程实现回复</div><div class="line">         * 3、callback，消费方法，当消费者接收到消息要执行的方法</div><div class="line">         */</div><div class="line">        channel.basicConsume(QUEUE_INFORM_EMAIL,true,defaultConsumer);</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="3-短信消费者"><a href="#3-短信消费者" class="headerlink" title="3.短信消费者"></a>3.短信消费者</h4><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">import com.rabbitmq.client.*;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line">import java.util.concurrent.TimeoutException;</div><div class="line"></div><div class="line"></div><div class="line">public class Consumer03_routing_sms &#123;</div><div class="line">    //队列名称</div><div class="line">    private static final String QUEUE_INFORM_SMS = &quot;queue_inform_sms&quot;;</div><div class="line">    private static final String EXCHANGE_ROUTING_INFORM=&quot;exchange_routing_inform&quot;;</div><div class="line">    private static final String ROUTINGKEY_SMS=&quot;inform_sms&quot;;</div><div class="line"></div><div class="line">    public static void main(String[] args) throws IOException, TimeoutException &#123;</div><div class="line">        //通过连接工厂创建新的连接和mq建立连接</div><div class="line">        ConnectionFactory connectionFactory = new ConnectionFactory();</div><div class="line">        connectionFactory.setHost(&quot;127.0.0.1&quot;);</div><div class="line">        connectionFactory.setPort(5672);//端口</div><div class="line">        connectionFactory.setUsername(&quot;guest&quot;);</div><div class="line">        connectionFactory.setPassword(&quot;guest&quot;);</div><div class="line">        //设置虚拟机，一个mq服务可以设置多个虚拟机，每个虚拟机就相当于一个独立的mq</div><div class="line">        connectionFactory.setVirtualHost(&quot;/&quot;);</div><div class="line"></div><div class="line">        //建立新连接</div><div class="line">        Connection connection = connectionFactory.newConnection();</div><div class="line">        //创建会话通道,生产者和mq服务所有通信都在channel通道中完成</div><div class="line">        Channel channel = connection.createChannel();</div><div class="line"></div><div class="line">        /**</div><div class="line">         * 参数明细</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、durable 是否持久化，如果持久化，mq重启后队列还在</div><div class="line">         * 3、exclusive 是否独占连接，队列只允许在该连接中访问，如果connection连接关闭队列则自动删除,如果将此参数设置true可用于临时队列的创建</div><div class="line">         * 4、autoDelete 自动删除，队列不再使用时是否自动删除此队列，如果将此参数和exclusive参数设置为true就可以实现临时队列（队列不用了就自动删除）</div><div class="line">         * 5、arguments 参数，可以设置一个队列的扩展参数，比如：可设置存活时间</div><div class="line">         */</div><div class="line">        channel.queueDeclare(QUEUE_INFORM_SMS,true,false,false,null);</div><div class="line">        //声明一个交换机</div><div class="line">        //参数：String exchange, String type</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、交换机的名称</div><div class="line">         * 2、交换机的类型</div><div class="line">         * fanout：对应的rabbitmq的工作模式是 publish/subscribe</div><div class="line">         * direct：对应的Routing	工作模式</div><div class="line">         * topic：对应的Topics工作模式</div><div class="line">         * headers： 对应的headers工作模式</div><div class="line">         */</div><div class="line">        channel.exchangeDeclare(EXCHANGE_ROUTING_INFORM, BuiltinExchangeType.DIRECT);</div><div class="line">        //进行交换机和队列绑定</div><div class="line">        //参数：String queue, String exchange, String routingKey</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、exchange 交换机名称</div><div class="line">         * 3、routingKey 路由key，作用是交换机根据路由key的值将消息转发到指定的队列中，在发布订阅模式中调协为空字符串</div><div class="line">         */</div><div class="line">        channel.queueBind(QUEUE_INFORM_SMS, EXCHANGE_ROUTING_INFORM,ROUTINGKEY_SMS);</div><div class="line"></div><div class="line">        //实现消费方法</div><div class="line">        DefaultConsumer defaultConsumer = new DefaultConsumer(channel)&#123;</div><div class="line"></div><div class="line">            /**</div><div class="line">             * 当接收到消息后此方法将被调用</div><div class="line">             * @param consumerTag  消费者标签，用来标识消费者的，在监听队列时设置channel.basicConsume</div><div class="line">             * @param envelope 信封，通过envelope</div><div class="line">             * @param properties 消息属性</div><div class="line">             * @param body 消息内容</div><div class="line">             * @throws IOException</div><div class="line">             */</div><div class="line">            @Override</div><div class="line">            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123;</div><div class="line">                //交换机</div><div class="line">                String exchange = envelope.getExchange();</div><div class="line">                //消息id，mq在channel中用来标识消息的id，可用于确认消息已接收</div><div class="line">                long deliveryTag = envelope.getDeliveryTag();</div><div class="line">                //消息内容</div><div class="line">                String message= new String(body,&quot;utf-8&quot;);</div><div class="line">                System.out.println(&quot;receive message:&quot;+message);</div><div class="line">            &#125;</div><div class="line">        &#125;;</div><div class="line"></div><div class="line">        //监听队列</div><div class="line">        //参数：String queue, boolean autoAck, Consumer callback</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、autoAck 自动回复，当消费者接收到消息后要告诉mq消息已接收，如果将此参数设置为tru表示会自动回复mq，如果设置为false要通过编程实现回复</div><div class="line">         * 3、callback，消费方法，当消费者接收到消息要执行的方法</div><div class="line">         */</div><div class="line">        channel.basicConsume(QUEUE_INFORM_SMS,true,defaultConsumer);</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="4-测试-1"><a href="#4-测试-1" class="headerlink" title="4.测试"></a>4.测试</h4><p>1.启动生产者，打开RabbitMQ的管理界面，观察交换机绑定情况：</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567156445998.png" alt="1567156445998"></p>
<p>​    使用生产者发送若干条消息，交换机根据routingkey转发消息到指定的队列。</p>
<h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><blockquote>
<p>Routing模式和Publish/subscibe的区别</p>
</blockquote>
<p>Routing模式要求队列在绑定交换机时要指定routingkey，消息会转发到符合routingkey的队列。</p>
<h2 id="Topics"><a href="#Topics" class="headerlink" title="Topics"></a>Topics</h2><p><img src="/2018/09/03/RabbitMQ消息队列/1567156552085.png" alt="1567156552085"></p>
<p>我们可以称它为加强版的Routing模式：</p>
<p>1、每个消费者监听自己的队列，并且设置带统配符的routingkey。<br>2、生产者将消息发给broker，由交换机根据routingkey来转发消息到指定的队列。</p>
<ul>
<li><p>(星号) 只能替换 1 个条件。</p>
</li>
<li><p>(井号) 可替换 0 或多个条件。</p>
</li>
</ul>
<h3 id="案例-3"><a href="#案例-3" class="headerlink" title="案例"></a>案例</h3><p>​    根据用户的通知设置去通知用户，设置接收Email的用户只接收Email，设置接收sms的用户只接收sms，设置两种通知类型都接收的则两种通知都有效。</p>
<h4 id="1-生产者代码-2"><a href="#1-生产者代码-2" class="headerlink" title="1.生产者代码"></a>1.生产者代码</h4><p>声明交换机，指定topic类型：</p>
<blockquote>
<p>关键代码</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">/**</div><div class="line"> * 声明交换机</div><div class="line"> * param1：交换机名称</div><div class="line"> * param2:交换机类型 四种交换机类型：direct、fanout、topic、headers</div><div class="line"> */</div><div class="line"> channel.exchangeDeclare(EXCHANGE_TOPICS_INFORM, BuiltinExchangeType.TOPIC);</div><div class="line">//Email通知</div><div class="line">channel.basicPublish(EXCHANGE_TOPICS_INFORM, &quot;inform.email&quot;, null, message.getBytes());</div><div class="line">//sms通知</div><div class="line">channel.basicPublish(EXCHANGE_TOPICS_INFORM, &quot;inform.sms&quot;, null, message.getBytes());</div><div class="line">//两种都通知</div><div class="line">channel.basicPublish(EXCHANGE_TOPICS_INFORM, &quot;inform.sms.email&quot;, null, message.getBytes());</div></pre></td></tr></table></figure>
<blockquote>
<p>完整代码</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">import com.rabbitmq.client.BuiltinExchangeType;</div><div class="line">import com.rabbitmq.client.Channel;</div><div class="line">import com.rabbitmq.client.Connection;</div><div class="line">import com.rabbitmq.client.ConnectionFactory;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line">import java.util.concurrent.TimeoutException;</div><div class="line"></div><div class="line"></div><div class="line">public class Producer04_topics &#123;</div><div class="line">    //队列名称</div><div class="line">    private static final String QUEUE_INFORM_EMAIL = &quot;queue_inform_email&quot;;</div><div class="line">    private static final String QUEUE_INFORM_SMS = &quot;queue_inform_sms&quot;;</div><div class="line">    //交换机名称</div><div class="line">    private static final String EXCHANGE_TOPICS_INFORM=&quot;exchange_topics_inform&quot;;</div><div class="line">    //路由通配符</div><div class="line">    private static final String ROUTINGKEY_EMAIL=&quot;inform.#.email.#&quot;;</div><div class="line">    private static final String ROUTINGKEY_SMS=&quot;inform.#.sms.#&quot;;</div><div class="line">    </div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        //通过连接工厂创建新的连接和mq建立连接</div><div class="line">        ConnectionFactory connectionFactory = new ConnectionFactory();</div><div class="line">        connectionFactory.setHost(&quot;127.0.0.1&quot;);</div><div class="line">        connectionFactory.setPort(5672);//端口</div><div class="line">        connectionFactory.setUsername(&quot;guest&quot;);</div><div class="line">        connectionFactory.setPassword(&quot;guest&quot;);</div><div class="line">        //设置虚拟机，一个mq服务可以设置多个虚拟机，每个虚拟机就相当于一个独立的mq</div><div class="line">        connectionFactory.setVirtualHost(&quot;/&quot;);</div><div class="line"></div><div class="line">        Connection connection = null;</div><div class="line">        Channel channel = null;</div><div class="line">        try &#123;</div><div class="line">            //建立新连接</div><div class="line">            connection = connectionFactory.newConnection();</div><div class="line">            //创建会话通道,生产者和mq服务所有通信都在channel通道中完成</div><div class="line">            channel = connection.createChannel();</div><div class="line">            //声明队列，如果队列在mq 中没有则要创建</div><div class="line">            //参数：String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments</div><div class="line">            /**</div><div class="line">             * 参数明细</div><div class="line">             * 1、queue 队列名称</div><div class="line">             * 2、durable 是否持久化，如果持久化，mq重启后队列还在</div><div class="line">             * 3、exclusive 是否独占连接，队列只允许在该连接中访问，如果connection连接关闭队列则自动删除,如果将此参数设置true可用于临时队列的创建</div><div class="line">             * 4、autoDelete 自动删除，队列不再使用时是否自动删除此队列，如果将此参数和exclusive参数设置为true就可以实现临时队列（队列不用了就自动删除）</div><div class="line">             * 5、arguments 参数，可以设置一个队列的扩展参数，比如：可设置存活时间</div><div class="line">             */</div><div class="line">            channel.queueDeclare(QUEUE_INFORM_EMAIL,true,false,false,null);</div><div class="line">            channel.queueDeclare(QUEUE_INFORM_SMS,true,false,false,null);</div><div class="line">            //声明一个交换机</div><div class="line">            //参数：String exchange, String type</div><div class="line">            /**</div><div class="line">             * 参数明细：</div><div class="line">             * 1、交换机的名称</div><div class="line">             * 2、交换机的类型</div><div class="line">             * fanout：对应的rabbitmq的工作模式是 publish/subscribe</div><div class="line">             * direct：对应的Routing	工作模式</div><div class="line">             * topic：对应的Topics工作模式</div><div class="line">             * headers： 对应的headers工作模式</div><div class="line">             */</div><div class="line">            channel.exchangeDeclare(EXCHANGE_TOPICS_INFORM, BuiltinExchangeType.TOPIC);</div><div class="line">            //进行交换机和队列绑定</div><div class="line">            //参数：String queue, String exchange, String routingKey</div><div class="line">            /**</div><div class="line">             * 参数明细：</div><div class="line">             * 1、queue 队列名称</div><div class="line">             * 2、exchange 交换机名称</div><div class="line">             * 3、routingKey 路由key，作用是交换机根据路由key的值将消息转发到指定的队列中，在发布订阅模式中调协为空字符串</div><div class="line">             */</div><div class="line">            channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_TOPICS_INFORM,ROUTINGKEY_EMAIL);</div><div class="line">            channel.queueBind(QUEUE_INFORM_SMS,EXCHANGE_TOPICS_INFORM,ROUTINGKEY_SMS);</div><div class="line">            //发送消息</div><div class="line">            //参数：String exchange, String routingKey, BasicProperties props, byte[] body</div><div class="line">            /**</div><div class="line">             * 参数明细：</div><div class="line">             * 1、exchange，交换机，如果不指定将使用mq的默认交换机（设置为&quot;&quot;）</div><div class="line">             * 2、routingKey，路由key，交换机根据路由key来将消息转发到指定的队列，如果使用默认交换机，routingKey设置为队列的名称</div><div class="line">             * 3、props，消息的属性</div><div class="line">             * 4、body，消息内容</div><div class="line">             */</div><div class="line">            for(int i=0;i&lt;5;i++)&#123;</div><div class="line">                //发送消息的时候指定routingKey</div><div class="line">                String message = &quot;send email inform message to user&quot;;</div><div class="line">                channel.basicPublish(EXCHANGE_TOPICS_INFORM,&quot;inform.email&quot;,null,message.getBytes());</div><div class="line">                System.out.println(&quot;send to mq &quot;+message);</div><div class="line">            &#125;</div><div class="line">            for(int i=0;i&lt;5;i++)&#123;</div><div class="line">                //发送消息的时候指定routingKey</div><div class="line">                String message = &quot;send sms inform message to user&quot;;</div><div class="line">                channel.basicPublish(EXCHANGE_TOPICS_INFORM,&quot;inform.sms&quot;,null,message.getBytes());</div><div class="line">                System.out.println(&quot;send to mq &quot;+message);</div><div class="line">            &#125;</div><div class="line">            for(int i=0;i&lt;5;i++)&#123;</div><div class="line">                //发送消息的时候指定routingKey</div><div class="line">                String message = &quot;send sms and email inform message to user&quot;;</div><div class="line">                channel.basicPublish(EXCHANGE_TOPICS_INFORM,&quot;inform.sms.email&quot;,null,message.getBytes());</div><div class="line">                System.out.println(&quot;send to mq &quot;+message);</div><div class="line">            &#125;</div><div class="line"></div><div class="line"></div><div class="line">        &#125; catch (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125; finally &#123;</div><div class="line">            //关闭连接</div><div class="line">            //先关闭通道</div><div class="line">            try &#123;</div><div class="line">                channel.close();</div><div class="line">            &#125; catch (IOException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125; catch (TimeoutException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125;</div><div class="line">            try &#123;</div><div class="line">                connection.close();</div><div class="line">            &#125; catch (IOException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>分析一下规则：</p>
<p>在上面的代码中我们定义了下面两个通配符规则</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">  //路由通配符</div><div class="line">private static final String ROUTINGKEY_EMAIL=&quot;inform.#.email.#&quot;;</div><div class="line">private static final String ROUTINGKEY_SMS=&quot;inform.#.sms.#&quot;;</div></pre></td></tr></table></figure>
<p><code>#</code> 可以匹配多个词，符号*可以匹配一个词语。</p>
<p>  举例子：</p>
<p>   inform.email 和 inform.sms 分别满足上面的ROUTINGKEY_EMAIL和ROUTINGKEY_SMS，所以消息各自发送到sms队列和email队列，因为#在这里是0个。</p>
<p>那么当inform.sms.email时，同时满足ROUTINGKEY_EMAIL和ROUTINGKEY_SMS，也就是说他把消息<strong>同时发送到</strong>sms队列和email队列。</p>
<h4 id="2-邮件消费者-1"><a href="#2-邮件消费者-1" class="headerlink" title="2.邮件消费者"></a>2.邮件消费者</h4><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">import com.rabbitmq.client.*;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line">import java.util.concurrent.TimeoutException;</div><div class="line"></div><div class="line"></div><div class="line">public class Consumer04_topics_email &#123;</div><div class="line">    //队列名称</div><div class="line">    private static final String QUEUE_INFORM_EMAIL = &quot;queue_inform_email&quot;;</div><div class="line">    private static final String EXCHANGE_TOPICS_INFORM=&quot;exchange_topics_inform&quot;;</div><div class="line">    private static final String ROUTINGKEY_EMAIL=&quot;inform.#.email.#&quot;;</div><div class="line"></div><div class="line">    public static void main(String[] args) throws IOException, TimeoutException &#123;</div><div class="line">        //通过连接工厂创建新的连接和mq建立连接</div><div class="line">        ConnectionFactory connectionFactory = new ConnectionFactory();</div><div class="line">        connectionFactory.setHost(&quot;127.0.0.1&quot;);</div><div class="line">        connectionFactory.setPort(5672);//端口</div><div class="line">        connectionFactory.setUsername(&quot;guest&quot;);</div><div class="line">        connectionFactory.setPassword(&quot;guest&quot;);</div><div class="line">        //设置虚拟机，一个mq服务可以设置多个虚拟机，每个虚拟机就相当于一个独立的mq</div><div class="line">        connectionFactory.setVirtualHost(&quot;/&quot;);</div><div class="line"></div><div class="line">        //建立新连接</div><div class="line">        Connection connection = connectionFactory.newConnection();</div><div class="line">        //创建会话通道,生产者和mq服务所有通信都在channel通道中完成</div><div class="line">        Channel channel = connection.createChannel();</div><div class="line"></div><div class="line">        /**</div><div class="line">         * 参数明细</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、durable 是否持久化，如果持久化，mq重启后队列还在</div><div class="line">         * 3、exclusive 是否独占连接，队列只允许在该连接中访问，如果connection连接关闭队列则自动删除,如果将此参数设置true可用于临时队列的创建</div><div class="line">         * 4、autoDelete 自动删除，队列不再使用时是否自动删除此队列，如果将此参数和exclusive参数设置为true就可以实现临时队列（队列不用了就自动删除）</div><div class="line">         * 5、arguments 参数，可以设置一个队列的扩展参数，比如：可设置存活时间</div><div class="line">         */</div><div class="line">        channel.queueDeclare(QUEUE_INFORM_EMAIL,true,false,false,null);</div><div class="line">        //声明一个交换机</div><div class="line">        //参数：String exchange, String type</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、交换机的名称</div><div class="line">         * 2、交换机的类型</div><div class="line">         * fanout：对应的rabbitmq的工作模式是 publish/subscribe</div><div class="line">         * direct：对应的Routing	工作模式</div><div class="line">         * topic：对应的Topics工作模式</div><div class="line">         * headers： 对应的headers工作模式</div><div class="line">         */</div><div class="line">        channel.exchangeDeclare(EXCHANGE_TOPICS_INFORM, BuiltinExchangeType.TOPIC);</div><div class="line">        //进行交换机和队列绑定</div><div class="line">        //参数：String queue, String exchange, String routingKey</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、exchange 交换机名称</div><div class="line">         * 3、routingKey 路由key，作用是交换机根据路由key的值将消息转发到指定的队列中，在发布订阅模式中调协为空字符串</div><div class="line">         */</div><div class="line">        channel.queueBind(QUEUE_INFORM_EMAIL, EXCHANGE_TOPICS_INFORM,ROUTINGKEY_EMAIL);</div><div class="line"></div><div class="line">        //实现消费方法</div><div class="line">        DefaultConsumer defaultConsumer = new DefaultConsumer(channel)&#123;</div><div class="line"></div><div class="line">            /**</div><div class="line">             * 当接收到消息后此方法将被调用</div><div class="line">             * @param consumerTag  消费者标签，用来标识消费者的，在监听队列时设置channel.basicConsume</div><div class="line">             * @param envelope 信封，通过envelope</div><div class="line">             * @param properties 消息属性</div><div class="line">             * @param body 消息内容</div><div class="line">             * @throws IOException</div><div class="line">             */</div><div class="line">            @Override</div><div class="line">            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123;</div><div class="line">                //交换机</div><div class="line">                String exchange = envelope.getExchange();</div><div class="line">                //消息id，mq在channel中用来标识消息的id，可用于确认消息已接收</div><div class="line">                long deliveryTag = envelope.getDeliveryTag();</div><div class="line">                //消息内容</div><div class="line">                String message= new String(body,&quot;utf-8&quot;);</div><div class="line">                System.out.println(&quot;receive message:&quot;+message);</div><div class="line">            &#125;</div><div class="line">        &#125;;</div><div class="line"></div><div class="line">        //监听队列</div><div class="line">        //参数：String queue, boolean autoAck, Consumer callback</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、autoAck 自动回复，当消费者接收到消息后要告诉mq消息已接收，如果将此参数设置为tru表示会自动回复mq，如果设置为false要通过编程实现回复</div><div class="line">         * 3、callback，消费方法，当消费者接收到消息要执行的方法</div><div class="line">         */</div><div class="line">        channel.basicConsume(QUEUE_INFORM_EMAIL,true,defaultConsumer);</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="3-短信消费者-1"><a href="#3-短信消费者-1" class="headerlink" title="3.短信消费者"></a>3.短信消费者</h4><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">import com.rabbitmq.client.*;</div><div class="line"></div><div class="line">import java.io.IOException;</div><div class="line">import java.util.concurrent.TimeoutException;</div><div class="line"></div><div class="line"></div><div class="line">public class Consumer04_topics_sms &#123;</div><div class="line">    //队列名称</div><div class="line">    private static final String QUEUE_INFORM_SMS = &quot;queue_inform_sms&quot;;</div><div class="line">    private static final String EXCHANGE_TOPICS_INFORM=&quot;exchange_topics_inform&quot;;</div><div class="line">    private static final String ROUTINGKEY_SMS=&quot;inform.#.sms.#&quot;;</div><div class="line"></div><div class="line">    public static void main(String[] args) throws IOException, TimeoutException &#123;</div><div class="line">        //通过连接工厂创建新的连接和mq建立连接</div><div class="line">        ConnectionFactory connectionFactory = new ConnectionFactory();</div><div class="line">        connectionFactory.setHost(&quot;127.0.0.1&quot;);</div><div class="line">        connectionFactory.setPort(5672);//端口</div><div class="line">        connectionFactory.setUsername(&quot;guest&quot;);</div><div class="line">        connectionFactory.setPassword(&quot;guest&quot;);</div><div class="line">        //设置虚拟机，一个mq服务可以设置多个虚拟机，每个虚拟机就相当于一个独立的mq</div><div class="line">        connectionFactory.setVirtualHost(&quot;/&quot;);</div><div class="line"></div><div class="line">        //建立新连接</div><div class="line">        Connection connection = connectionFactory.newConnection();</div><div class="line">        //创建会话通道,生产者和mq服务所有通信都在channel通道中完成</div><div class="line">        Channel channel = connection.createChannel();</div><div class="line"></div><div class="line">        /**</div><div class="line">         * 参数明细</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、durable 是否持久化，如果持久化，mq重启后队列还在</div><div class="line">         * 3、exclusive 是否独占连接，队列只允许在该连接中访问，如果connection连接关闭队列则自动删除,如果将此参数设置true可用于临时队列的创建</div><div class="line">         * 4、autoDelete 自动删除，队列不再使用时是否自动删除此队列，如果将此参数和exclusive参数设置为true就可以实现临时队列（队列不用了就自动删除）</div><div class="line">         * 5、arguments 参数，可以设置一个队列的扩展参数，比如：可设置存活时间</div><div class="line">         */</div><div class="line">        channel.queueDeclare(QUEUE_INFORM_SMS,true,false,false,null);</div><div class="line">        //声明一个交换机</div><div class="line">        //参数：String exchange, String type</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、交换机的名称</div><div class="line">         * 2、交换机的类型</div><div class="line">         * fanout：对应的rabbitmq的工作模式是 publish/subscribe</div><div class="line">         * direct：对应的Routing	工作模式</div><div class="line">         * topic：对应的Topics工作模式</div><div class="line">         * headers： 对应的headers工作模式</div><div class="line">         */</div><div class="line">        channel.exchangeDeclare(EXCHANGE_TOPICS_INFORM, BuiltinExchangeType.TOPIC);</div><div class="line">        //进行交换机和队列绑定</div><div class="line">        //参数：String queue, String exchange, String routingKey</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、exchange 交换机名称</div><div class="line">         * 3、routingKey 路由key，作用是交换机根据路由key的值将消息转发到指定的队列中，在发布订阅模式中调协为空字符串</div><div class="line">         */</div><div class="line">        channel.queueBind(QUEUE_INFORM_SMS, EXCHANGE_TOPICS_INFORM,ROUTINGKEY_SMS);</div><div class="line"></div><div class="line">        //实现消费方法</div><div class="line">        DefaultConsumer defaultConsumer = new DefaultConsumer(channel)&#123;</div><div class="line"></div><div class="line">            /**</div><div class="line">             * 当接收到消息后此方法将被调用</div><div class="line">             * @param consumerTag  消费者标签，用来标识消费者的，在监听队列时设置channel.basicConsume</div><div class="line">             * @param envelope 信封，通过envelope</div><div class="line">             * @param properties 消息属性</div><div class="line">             * @param body 消息内容</div><div class="line">             * @throws IOException</div><div class="line">             */</div><div class="line">            @Override</div><div class="line">            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123;</div><div class="line">                //交换机</div><div class="line">                String exchange = envelope.getExchange();</div><div class="line">                //消息id，mq在channel中用来标识消息的id，可用于确认消息已接收</div><div class="line">                long deliveryTag = envelope.getDeliveryTag();</div><div class="line">                //消息内容</div><div class="line">                String message= new String(body,&quot;utf-8&quot;);</div><div class="line">                System.out.println(&quot;receive message:&quot;+message);</div><div class="line">            &#125;</div><div class="line">        &#125;;</div><div class="line"></div><div class="line">        //监听队列</div><div class="line">        //参数：String queue, boolean autoAck, Consumer callback</div><div class="line">        /**</div><div class="line">         * 参数明细：</div><div class="line">         * 1、queue 队列名称</div><div class="line">         * 2、autoAck 自动回复，当消费者接收到消息后要告诉mq消息已接收，如果将此参数设置为tru表示会自动回复mq，如果设置为false要通过编程实现回复</div><div class="line">         * 3、callback，消费方法，当消费者接收到消息要执行的方法</div><div class="line">         */</div><div class="line">        channel.basicConsume(QUEUE_INFORM_SMS,true,defaultConsumer);</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="4-测试-2"><a href="#4-测试-2" class="headerlink" title="4.测试"></a>4.测试</h4><p>1.启动生产者</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567157217159.png" alt="1567157217159"></p>
<p>查看浏览器控制台</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567157243650.png" alt="1567157243650"></p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567157280899.png" alt="1567157280899"></p>
<p>查看生产者代码解释为什么各自有10条消息</p>
<p><img src="/2018/09/03/RabbitMQ消息队列/1567157785810.png" alt="1567157785810"></p>
<p>使用生产者发送若干条消息，交换机根据routingkey统配符匹配并转发消息到指定的队列。所以这里两个队列各拥有10条消息。</p>
<h3 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h3><blockquote>
<p>本案例的需求使用Routing工作模式能否实现</p>
</blockquote>
<p>​    上面的案例的本质就是通过通配符的方式。我们可以使用Routing精确匹配也可实现。</p>
<p>使用Routing模式也可以实现本案例，共设置三个 routingkey，分别是email、sms、all，email队列绑定email和all，sms队列绑定sms和all，这样就可以实现上边案例的功能，实现过程比topics复杂。</p>
<p>Topic模式更多加强大，它可以实现Routing、publish/subscirbe模式的功能。</p>
<h2 id="Header模式"><a href="#Header模式" class="headerlink" title="Header模式"></a>Header模式</h2><p> header模式与routing不同的地方在于，header模式取消routingkey，使用header中的 key/value（键值对）匹配队列。</p>
<h3 id="案例-4"><a href="#案例-4" class="headerlink" title="案例"></a>案例</h3><p>根据用户的通知设置去通知用户，设置接收Email的用户只接收Email，设置接收sms的用户只接收sms，设置两种<br>通知类型都接收的则两种通知都有效。</p>
<h4 id="1-生产者代码-3"><a href="#1-生产者代码-3" class="headerlink" title="1.生产者代码"></a>1.生产者代码</h4><p>队列与交换机绑定的代码与之前不同，如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">Map&lt;String, Object&gt; headers_email = new Hashtable&lt;String, Object&gt;();</div><div class="line">headers_email.put(&quot;inform_type&quot;, &quot;email&quot;);</div><div class="line">Map&lt;String, Object&gt; headers_sms = new Hashtable&lt;String, Object&gt;();</div><div class="line">headers_sms.put(&quot;inform_type&quot;, &quot;sms&quot;);</div><div class="line">channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_HEADERS_INFORM,&quot;&quot;,headers_email);</div><div class="line">channel.queueBind(QUEUE_INFORM_SMS,EXCHANGE_HEADERS_INFORM,&quot;&quot;,headers_sms);</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">String message = &quot;email inform to user&quot;+i;</div><div class="line">Map&lt;String,Object&gt; headers =  new Hashtable&lt;String, Object&gt;();</div><div class="line">headers.put(&quot;inform_type&quot;, &quot;email&quot;);//匹配email通知消费者绑定的header</div><div class="line">//headers.put(&quot;inform_type&quot;, &quot;sms&quot;);//匹配sms通知消费者绑定的header</div><div class="line">AMQP.BasicProperties.Builder properties = new AMQP.BasicProperties.Builder();</div><div class="line">properties.headers(headers);</div><div class="line">//Email通知</div><div class="line">channel.basicPublish(EXCHANGE_HEADERS_INFORM, &quot;&quot;, properties.build(), message.getBytes());</div></pre></td></tr></table></figure>
<h4 id="2-邮件消费者-2"><a href="#2-邮件消费者-2" class="headerlink" title="2.邮件消费者"></a>2.邮件消费者</h4><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">channel.exchangeDeclare(EXCHANGE_HEADERS_INFORM, BuiltinExchangeType.HEADERS);</div><div class="line">Map&lt;String, Object&gt; headers_email = new Hashtable&lt;String, Object&gt;();</div><div class="line">headers_email.put(&quot;inform_email&quot;, &quot;email&quot;);</div><div class="line">//交换机和队列绑定</div><div class="line">channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_HEADERS_INFORM,&quot;&quot;,headers_email);</div><div class="line">//指定消费队列</div><div class="line">channel.basicConsume(QUEUE_INFORM_EMAIL, true, consumer);</div></pre></td></tr></table></figure>
<h4 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h4><p><img src="/2018/09/03/RabbitMQ消息队列/1567158140946.png" alt="1567158140946"></p>
<h2 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h2><p><img src="/2018/09/03/RabbitMQ消息队列/1567158158985.png" alt="1567158158985"></p>
<p>RPC即客户端远程调用服务端的方法 ，使用MQ可以实现RPC的异步调用，基于Direct交换机实现，流程如下：<br>1、客户端即是生产者就是消费者，向RPC请求队列发送RPC调用消息，同时监听RPC响应队列。<br>2、服务端监听RPC请求队列的消息，收到消息后执行服务端的方法，得到方法返回的结果<br>3、服务端将RPC方法 的结果发送到RPC响应队列<br>4、客户端（RPC调用方）监听RPC响应队列，接收到RPC调用结果。</p>
<h1 id="Spring整合RibbitMQ"><a href="#Spring整合RibbitMQ" class="headerlink" title="Spring整合RibbitMQ"></a>Spring整合RibbitMQ</h1><p>我们选择基于Spring-Rabbit去操作RabbitMQ</p>
<p><a href="https://github.com/spring-projects/spring-amqp" target="_blank" rel="external">https://github.com/spring-projects/spring-amqp</a></p>
<p>使用spring-boot-starter-amqp会自动添加spring-rabbit依赖，所以注释掉我们上面使用的java client方式引入的amqp-client依赖。</p>
<h2 id="生产者修改"><a href="#生产者修改" class="headerlink" title="生产者修改"></a>生产者修改</h2><h3 id="pom文件修改为"><a href="#pom文件修改为" class="headerlink" title="pom文件修改为"></a>pom文件修改为</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">    &lt;dependencies&gt;</div><div class="line">&lt;!--        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;amqp-client&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;4.0.3&lt;/version&gt;&amp;lt;!&amp;ndash;此版本与spring boot 1.5.9版本匹配&amp;ndash;&amp;gt;</div><div class="line">        &lt;/dependency&gt;--&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">    &lt;/dependencies&gt;</div></pre></td></tr></table></figure>
<h3 id="application-yml配置文件"><a href="#application-yml配置文件" class="headerlink" title="application.yml配置文件"></a>application.yml配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">server:</div><div class="line">  port: 44004</div><div class="line">spring:</div><div class="line">  application:</div><div class="line">    name: test-rabbitmq-consumer</div><div class="line">  rabbitmq:</div><div class="line">    host: 127.0.0.1</div><div class="line">    port: 5672</div><div class="line">    username: guest</div><div class="line">    password: guest</div><div class="line">    virtualHost: /</div></pre></td></tr></table></figure>
<h3 id="定义RabbitConﬁg类，配置Exchange、Queue、及绑定交换机"><a href="#定义RabbitConﬁg类，配置Exchange、Queue、及绑定交换机" class="headerlink" title="定义RabbitConﬁg类，配置Exchange、Queue、及绑定交换机"></a>定义RabbitConﬁg类，配置Exchange、Queue、及绑定交换机</h3><p>这里以配置Topics模式为例子。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">import org.springframework.amqp.core.*;</div><div class="line">import org.springframework.beans.factory.annotation.Qualifier;</div><div class="line">import org.springframework.context.annotation.Bean;</div><div class="line">import org.springframework.context.annotation.Configuration;</div><div class="line"></div><div class="line">@Configuration</div><div class="line">public class RabbitmqConfig &#123;</div><div class="line">    public static final String QUEUE_INFORM_EMAIL = &quot;queue_inform_email&quot;;</div><div class="line">    public static final String QUEUE_INFORM_SMS = &quot;queue_inform_sms&quot;;</div><div class="line">    public static final String EXCHANGE_TOPICS_INFORM=&quot;exchange_topics_inform&quot;;</div><div class="line">    public static final String ROUTINGKEY_EMAIL=&quot;inform.#.email.#&quot;;</div><div class="line">    public static final String ROUTINGKEY_SMS=&quot;inform.#.sms.#&quot;;</div><div class="line"></div><div class="line">    //声明交换机</div><div class="line">    @Bean(EXCHANGE_TOPICS_INFORM)</div><div class="line">    public Exchange EXCHANGE_TOPICS_INFORM()&#123;</div><div class="line">        //durable(true) 持久化，mq重启之后交换机还在</div><div class="line">        return ExchangeBuilder.topicExchange(EXCHANGE_TOPICS_INFORM).durable(true).build();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    //声明QUEUE_INFORM_EMAIL队列</div><div class="line">    @Bean(QUEUE_INFORM_EMAIL)</div><div class="line">    public Queue QUEUE_INFORM_EMAIL()&#123;</div><div class="line">        return new Queue(QUEUE_INFORM_EMAIL);</div><div class="line">    &#125;</div><div class="line">    //声明QUEUE_INFORM_SMS队列</div><div class="line">    @Bean(QUEUE_INFORM_SMS)</div><div class="line">    public Queue QUEUE_INFORM_SMS()&#123;</div><div class="line">        return new Queue(QUEUE_INFORM_SMS);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    //ROUTINGKEY_EMAIL队列绑定交换机，指定routingKey</div><div class="line">    @Bean</div><div class="line">    public Binding BINDING_QUEUE_INFORM_EMAIL(@Qualifier(QUEUE_INFORM_EMAIL) Queue queue,</div><div class="line">                                              @Qualifier(EXCHANGE_TOPICS_INFORM) Exchange exchange)&#123;</div><div class="line">        return BindingBuilder.bind(queue).to(exchange).with(ROUTINGKEY_EMAIL).noargs();</div><div class="line">    &#125;</div><div class="line">    //ROUTINGKEY_SMS队列绑定交换机，指定routingKey</div><div class="line">    @Bean</div><div class="line">    public Binding BINDING_ROUTINGKEY_SMS(@Qualifier(QUEUE_INFORM_SMS) Queue queue,</div><div class="line">                                              @Qualifier(EXCHANGE_TOPICS_INFORM) Exchange exchange)&#123;</div><div class="line">        return BindingBuilder.bind(queue).to(exchange).with(ROUTINGKEY_SMS).noargs();</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="生产端"><a href="#生产端" class="headerlink" title="生产端"></a>生产端</h3><p>使用RarbbitTemplate发送消息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">import com.alibaba.fastjson.JSON;</div><div class="line">import com.xuecheng.test.rabbitmq.config.RabbitmqConfig;</div><div class="line">import org.junit.Test;</div><div class="line">import org.junit.runner.RunWith;</div><div class="line">import org.springframework.amqp.rabbit.core.RabbitTemplate;</div><div class="line">import org.springframework.beans.factory.annotation.Autowired;</div><div class="line">import org.springframework.boot.test.context.SpringBootTest;</div><div class="line">import org.springframework.test.context.junit4.SpringRunner;</div><div class="line"></div><div class="line">import java.util.HashMap;</div><div class="line">import java.util.Map;</div><div class="line"></div><div class="line"></div><div class="line">@SpringBootTest</div><div class="line">@RunWith(SpringRunner.class)</div><div class="line">public class Producer05_topics_springboot &#123;</div><div class="line">    @Autowired</div><div class="line">    RabbitTemplate rabbitTemplate;</div><div class="line"></div><div class="line">    //使用rabbitTemplate发送消息</div><div class="line">    @Test</div><div class="line">    public void testSendEmail()&#123;</div><div class="line"></div><div class="line">        String message = &quot;send email message to user&quot;;</div><div class="line">        /**</div><div class="line">         * 参数：</div><div class="line">         * 1、交换机名称</div><div class="line">         * 2、routingKey</div><div class="line">         * 3、消息内容</div><div class="line">         */</div><div class="line">        rabbitTemplate.convertAndSend(RabbitmqConfig.EXCHANGE_TOPICS_INFORM,&quot;inform.email&quot;,message);</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id=""><a href="#" class="headerlink" title=" "></a> </h3><h2 id="消费端者修改"><a href="#消费端者修改" class="headerlink" title="消费端者修改"></a>消费端者修改</h2><h3 id="修改pom文件"><a href="#修改pom文件" class="headerlink" title="修改pom文件"></a>修改pom文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">    &lt;dependencies&gt;</div><div class="line">&lt;!--        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;amqp-client&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;4.0.3&lt;/version&gt;&amp;lt;!&amp;ndash;此版本与spring boot 1.5.9版本匹配&amp;ndash;&amp;gt;</div><div class="line">        &lt;/dependency&gt;--&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">    &lt;/dependencies&gt;</div></pre></td></tr></table></figure>
<h3 id="使用-RabbitListener注解监听队列"><a href="#使用-RabbitListener注解监听队列" class="headerlink" title="使用@RabbitListener注解监听队列"></a>使用@RabbitListener注解监听队列</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Component</div><div class="line">public class ReceiveHandler &#123;</div><div class="line"></div><div class="line">    @RabbitListener(queues = &#123;RabbitmqConfig.QUEUE_INFORM_EMAIL&#125;)</div><div class="line">    public void receive_email(String msg,Message message,Channel channel)&#123;</div><div class="line">        System.out.println(&quot;receive message is:&quot;+msg);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;RabbitMQ-简介&quot;&gt;&lt;a href=&quot;#RabbitMQ-简介&quot; class=&quot;headerlink&quot; title=&quot;RabbitMQ 简介&quot;&gt;&lt;/a&gt;RabbitMQ 简介&lt;/h1&gt;&lt;p&gt;​         MQ全称为Message Queue，即消息队列
    
    </summary>
    
      <category term="消息队列" scheme="http://kingge.top/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
      <category term="RabbitMq" scheme="http://kingge.top/tags/RabbitMq/"/>
    
      <category term="消息队列" scheme="http://kingge.top/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
      <category term="分布式通信" scheme="http://kingge.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1/"/>
    
  </entry>
  
  <entry>
    <title>hadoop在使用中的常用优化手段</title>
    <link href="http://kingge.top/2018/05/14/hadoop%E5%9C%A8%E4%BD%BF%E7%94%A8%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E4%BC%98%E5%8C%96%E6%89%8B%E6%AE%B5/"/>
    <id>http://kingge.top/2018/05/14/hadoop在使用中的常用优化手段/</id>
    <published>2018-05-14T13:59:59.000Z</published>
    <updated>2019-08-25T02:20:55.395Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h1><p>我们知道影响MapReduce运算的因素很多，主要是机器性能、网络、磁盘读写速度、I/O 操作等等有关。</p>
<p>机器的问题属于外部因素，那么下面主要是介绍关于IO操作引发的性能问题：</p>
<p>主要是有几个以下方面</p>
<blockquote>
<p>（1）数据倾斜 - <strong>重点</strong></p>
<p>（2）map和reduce数设置不合理</p>
<p>（3）map运行时间太长，导致reduce等待过久</p>
<p>（4）小文件过多 - <strong>重点</strong></p>
<p>（5）大量的不可分块的超大文件</p>
<p>（6）spill次数过多</p>
<p>（7）merge次数过多。</p>
</blockquote>
<p>​    MapReduce优化方法主要从六个方面考虑：数据输入、Map阶段、Reduce阶段、IO传输、数据倾斜问题和常用的调优参数。</p>
<p>  下面想讲解小文件的处理方式：</p>
<h2 id="1-1-HDFS小文件优化"><a href="#1-1-HDFS小文件优化" class="headerlink" title="1.1 HDFS小文件优化"></a>1.1 HDFS小文件优化</h2><p>​    <strong>HDFS上每个文件都要在namenode上建立一个索引</strong>，这个索引的大小约为<strong>150byte</strong>，这样当小文件比较多的时候，就会产生很多的索引文件，一方面会大量占用namenode的内存空间，另一方面就是索引文件过大是的索引速度变慢。</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p><strong>1）Hadoop Archive:</strong></p>
<p> 是一个高效地将小文件放入HDFS块中的文件存档工具，它能够将多个小文件打包成一个HAR文件，这样就减少了namenode的内存使用。</p>
<p><img src="/2018/05/14/hadoop在使用中的常用优化手段/1564667225107.png" alt="1564667225107"></p>
<p><strong>2）Sequence file：</strong></p>
<p> sequence file由一系列的二进制key/value组成，如果key为文件名，value为文件内容，则可以将大批小文件合并成一个大文件。</p>
<p><strong>3）CombineFileInputFormat：</strong></p>
<p>  CombineFileInputFormat是一种新的inputformat，用于将多个文件合并成一个单独的split，另外，它会考虑数据的存储位置。（之前hadoop相关的章节讲解道，可以翻翻看看）</p>
<p><strong>4）开启JVM重用</strong></p>
<p>对于大量小文件Job，可以开启JVM重用会减少45%运行时间。</p>
<p>JVM重用理解：一个map运行一个jvm，重用的话，在一个map在jvm上运行完毕后，jvm继续运行其他map。</p>
<p>具体设置：mapreduce.job.jvm.numtasks值在10-20之间。</p>
<h2 id="1-2-分阶段优化"><a href="#1-2-分阶段优化" class="headerlink" title="1.2 分阶段优化"></a>1.2 分阶段优化</h2><h3 id="数据输入阶段"><a href="#数据输入阶段" class="headerlink" title="数据输入阶段"></a>数据输入阶段</h3><blockquote>
<p>（1）合并小文件：在执行mr任务前将小文件进行合并，大量的小文件会产生大量的map任务，增大map任务装载次数，而任务的装载比较耗时，从而导致mr运行较慢。</p>
<p>（2）采用CombineTextInputFormat来作为输入，解决输入端大量小文件场景。</p>
</blockquote>
<h3 id="数据传输阶段"><a href="#数据传输阶段" class="headerlink" title="数据传输阶段"></a>数据传输阶段</h3><p><strong>1）采用数据压缩的方式</strong>，减少网络IO的的时间。安装Snappy和LZO压缩编码器。</p>
<p><strong>2）使用SequenceFile二进制文件。</strong></p>
<h3 id="进入Map阶段"><a href="#进入Map阶段" class="headerlink" title="进入Map阶段"></a>进入Map阶段</h3><blockquote>
<p><strong>1）减少溢写（spill）次数：</strong>通过调整io.sort.mb及sort.spill.percent参数值，增大触发spill的内存上限，减少spill次数，从而减少磁盘IO。</p>
<p><strong>2）减少合并（merge）次数：</strong>通过调整io.sort.factor参数，增大merge的文件数目，减少merge的次数，从而缩短mr处理时间。</p>
<p>3）在map之后，<strong>不影响业务逻辑前提下，先进行combine处理</strong>，减少 I/O。</p>
</blockquote>
<h3 id="进入Reduce阶段"><a href="#进入Reduce阶段" class="headerlink" title="进入Reduce阶段"></a>进入Reduce阶段</h3><blockquote>
<p>暂无</p>
</blockquote>
<h3 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h3><blockquote>
<p>暂无总结</p>
</blockquote>
<h3 id="常用参数哟花"><a href="#常用参数哟花" class="headerlink" title="常用参数哟花"></a>常用参数哟花</h3><blockquote>
<p>暂无</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一、前言&quot;&gt;&lt;a href=&quot;#一、前言&quot; class=&quot;headerlink&quot; title=&quot;一、前言&quot;&gt;&lt;/a&gt;一、前言&lt;/h1&gt;&lt;p&gt;我们知道影响MapReduce运算的因素很多，主要是机器性能、网络、磁盘读写速度、I/O 操作等等有关。&lt;/p&gt;
&lt;p&gt;机器
    
    </summary>
    
      <category term="hadoop" scheme="http://kingge.top/categories/hadoop/"/>
    
    
      <category term="hadoop优化" scheme="http://kingge.top/tags/hadoop%E4%BC%98%E5%8C%96/"/>
    
      <category term="大数据" scheme="http://kingge.top/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>hadoop大数据(十二)-数据压缩</title>
    <link href="http://kingge.top/2018/03/20/hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE-%E5%8D%81%E4%BA%8C-%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/"/>
    <id>http://kingge.top/2018/03/20/hadoop大数据-十二-数据压缩/</id>
    <published>2018-03-20T14:59:59.000Z</published>
    <updated>2019-08-01T13:41:44.559Z</updated>
    
    <content type="html"><![CDATA[<h2 id="4-1-概述"><a href="#4-1-概述" class="headerlink" title="4.1 概述"></a>4.1 概述</h2><p>压缩技术能够有效减少底层存储系统（HDFS）读写字节数。压缩提高了网络带宽和磁盘空间的效率。在Hadoop下，尤其是数据规模很大和工作负载密集的情况下，使用数据压缩显得非常重要。在这种情况下，I/O操作和网络数据传输要花大量的时间。还有，Shuffle与Merge过程同样也面临着巨大的I/O压力。</p>
<p>​         鉴于磁盘I/O和网络带宽是Hadoop的宝贵资源，数据压缩对于节省资源、最小化磁盘I/O和网络传输非常有帮助。不过，尽管压缩与解压操作的CPU开销不高，其性能的提升和资源的节省并非没有代价。</p>
<p>​         如果磁盘I/O和网络带宽影响了MapReduce作业性能，在任意MapReduce阶段启用压缩都可以改善端到端处理时间并减少I/O和网络流量。</p>
<p>压缩<strong>Mapreduce的一种优化策略：通过压缩编码对Mapper或者Reducer的输出进行压缩，以减少磁盘IO，提高MR程序运行速度（但相应增加了cpu运算负担）。</strong></p>
<p>注意：压缩特性运用得当能提高性能，但运用不当也可能降低性能。</p>
<p>基本原则：</p>
<p>（1）运算密集型的job，少用压缩</p>
<p>（2）IO密集型的job，多用压缩</p>
<h2 id="4-2-MR支持的压缩编码"><a href="#4-2-MR支持的压缩编码" class="headerlink" title="4.2 MR支持的压缩编码"></a>4.2 MR支持的压缩编码</h2><table>
<thead>
<tr>
<th>压缩格式</th>
<th>hadoop自带？</th>
<th>算法</th>
<th>文件扩展名</th>
<th>是否可切分</th>
<th>换成压缩格式后，原来的程序是否需要修改</th>
</tr>
</thead>
<tbody>
<tr>
<td>DEFAULT</td>
<td>是，直接使用</td>
<td>DEFAULT</td>
<td>.deflate</td>
<td>否</td>
<td>和文本处理一样，不需要修改</td>
</tr>
<tr>
<td>Gzip</td>
<td>是，直接使用</td>
<td>DEFAULT</td>
<td>.gz</td>
<td>否</td>
<td>和文本处理一样，不需要修改</td>
</tr>
<tr>
<td>bzip2</td>
<td>是，直接使用</td>
<td>bzip2</td>
<td>.bz2</td>
<td>是</td>
<td>和文本处理一样，不需要修改</td>
</tr>
<tr>
<td>LZO</td>
<td>否，需要安装</td>
<td>LZO</td>
<td>.lzo</td>
<td>是</td>
<td>需要建索引，还需要指定输入格式</td>
</tr>
<tr>
<td>Snappy</td>
<td>否，需要安装</td>
<td>Snappy</td>
<td>.snappy</td>
<td>否</td>
<td>和文本处理一样，不需要修改</td>
</tr>
</tbody>
</table>
<p>为了支持多种压缩/解压缩算法，Hadoop引入了编码/解码器，如下表所示</p>
<table>
<thead>
<tr>
<th>压缩格式</th>
<th>对应的编码/解码器</th>
</tr>
</thead>
<tbody>
<tr>
<td>DEFLATE</td>
<td>org.apache.hadoop.io.compress.DefaultCodec</td>
</tr>
<tr>
<td>gzip</td>
<td>org.apache.hadoop.io.compress.GzipCodec</td>
</tr>
<tr>
<td>bzip2</td>
<td>org.apache.hadoop.io.compress.BZip2Codec</td>
</tr>
<tr>
<td>LZO</td>
<td>com.hadoop.compression.lzo.LzopCodec</td>
</tr>
<tr>
<td>Snappy</td>
<td>org.apache.hadoop.io.compress.SnappyCodec</td>
</tr>
</tbody>
</table>
<p>压缩性能的比较</p>
<table>
<thead>
<tr>
<th>压缩算法</th>
<th>原始文件大小</th>
<th>压缩文件大小</th>
<th>压缩速度</th>
<th>解压速度</th>
</tr>
</thead>
<tbody>
<tr>
<td>gzip</td>
<td>8.3GB</td>
<td>1.8GB</td>
<td>17.5MB/s</td>
<td>58MB/s</td>
</tr>
<tr>
<td>bzip2</td>
<td>8.3GB</td>
<td>1.1GB</td>
<td>2.4MB/s</td>
<td>9.5MB/s</td>
</tr>
<tr>
<td>LZO</td>
<td>8.3GB</td>
<td>2.9GB</td>
<td>49.3MB/s</td>
<td>74.6MB/s</td>
</tr>
</tbody>
</table>
<p><a href="http://google.github.io/snappy/" target="_blank" rel="external">http://google.github.io/snappy/</a></p>
<p>On a single core of a Core i7 processor in 64-bit mode, Snappy compresses at about 250 MB/sec or more and decompresses at about 500 MB/sec or more.</p>
<h2 id="4-3-压缩方式选择"><a href="#4-3-压缩方式选择" class="headerlink" title="4.3 压缩方式选择"></a>4.3 压缩方式选择</h2><h3 id="4-3-1-Gzip压缩"><a href="#4-3-1-Gzip压缩" class="headerlink" title="4.3.1 Gzip压缩"></a>4.3.1 Gzip压缩</h3><p>优点：压缩率比较高，而且压缩/解压速度也比较快；hadoop本身支持，在应用中处理gzip格式的文件就和直接处理文本一样；大部分linux系统都自带gzip命令，使用方便。</p>
<p>缺点：不支持split。</p>
<p>应用场景：当每个文件压缩之后在130M以内的（1个块大小内），都可以考虑用gzip压缩格式。例如说一天或者一个小时的日志压缩成一个gzip文件，运行mapreduce程序的时候通过多个gzip文件达到并发。hive程序，streaming程序，和java写的mapreduce程序完全和文本处理一样，压缩之后原来的程序不需要做任何修改。</p>
<h3 id="4-3-2-Bzip2压缩"><a href="#4-3-2-Bzip2压缩" class="headerlink" title="4.3.2 Bzip2压缩"></a>4.3.2 Bzip2压缩</h3><p>优点：支持split；具有很高的压缩率，比gzip压缩率都高；hadoop本身支持，但不支持native；在linux系统下自带bzip2命令，使用方便。</p>
<p>缺点：压缩/解压速度慢；不支持native。</p>
<p>应用场景：适合对速度要求不高，但需要较高的压缩率的时候，可以作为mapreduce作业的输出格式；或者输出之后的数据比较大，处理之后的数据需要压缩存档减少磁盘空间并且以后数据用得比较少的情况；或者对单个很大的文本文件想压缩减少存储空间，同时又需要支持split，而且兼容之前的应用程序（即应用程序不需要修改）的情况。</p>
<h3 id="4-3-3-Lzo压缩"><a href="#4-3-3-Lzo压缩" class="headerlink" title="4.3.3 Lzo压缩"></a>4.3.3 Lzo压缩</h3><p>优点：压缩/解压速度也比较快，合理的压缩率；支持split，是hadoop中最流行的压缩格式；可以在linux系统下安装lzop命令，使用方便。</p>
<p>缺点：压缩率比gzip要低一些；hadoop本身不支持，需要安装；在应用中对lzo格式的文件需要做一些特殊处理（为了支持split需要建索引，还需要指定inputformat为lzo格式）。</p>
<p>应用场景：一个很大的文本文件，压缩之后还大于200M以上的可以考虑，而且单个文件越大，lzo优点越越明显。</p>
<h3 id="4-3-4-Snappy压缩"><a href="#4-3-4-Snappy压缩" class="headerlink" title="4.3.4 Snappy压缩"></a>4.3.4 Snappy压缩</h3><p>优点：高速压缩速度和合理的压缩率。</p>
<p>缺点：不支持split；压缩率比gzip要低；hadoop本身不支持，需要安装； </p>
<p>应用场景：当Mapreduce作业的Map输出的数据比较大的时候，作为Map到Reduce的中间数据的压缩格式；或者作为一个Mapreduce作业的输出和另外一个Mapreduce作业的输入。</p>
<h2 id="4-4-压缩位置选择"><a href="#4-4-压缩位置选择" class="headerlink" title="4.4 压缩位置选择"></a>4.4 压缩位置选择</h2><p>​         压缩可以在MapReduce作用的任意阶段启用。</p>
<p><img src="/2018/03/20/hadoop大数据-十二-数据压缩/64664559133.png" alt="1564664559133"></p>
<h2 id="4-5-压缩配置参数"><a href="#4-5-压缩配置参数" class="headerlink" title="4.5 压缩配置参数"></a>4.5 压缩配置参数</h2><p>要在Hadoop中启用压缩，可以配置如下参数：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>默认值</th>
<th>阶段</th>
<th>建议</th>
</tr>
</thead>
<tbody>
<tr>
<td>io.compression.codecs      （在core-site.xml中配置）</td>
<td>org.apache.hadoop.io.compress.DefaultCodec,   org.apache.hadoop.io.compress.GzipCodec, org.apache.hadoop.io.compress.BZip2Codec</td>
<td>输入压缩</td>
<td>Hadoop使用文件扩展名判断是否支持某种编解码器</td>
</tr>
<tr>
<td>mapreduce.map.output.compress（在mapred-site.xml中配置）</td>
<td>false</td>
<td>mapper输出</td>
<td>这个参数设为true启用压缩</td>
</tr>
<tr>
<td>mapreduce.map.output.compress.codec（在mapred-site.xml中配置）</td>
<td>org.apache.hadoop.io.compress.DefaultCodec</td>
<td>mapper输出</td>
<td>使用LZO或snappy编解码器在此阶段压缩数据</td>
</tr>
<tr>
<td>mapreduce.output.fileoutputformat.compress（在mapred-site.xml中配置）</td>
<td>false</td>
<td>reducer输出</td>
<td>这个参数设为true启用压缩</td>
</tr>
<tr>
<td>mapreduce.output.fileoutputformat.compress.codec（在mapred-site.xml中配置）</td>
<td>org.apache.hadoop.io.compress.   DefaultCodec</td>
<td>reducer输出</td>
<td>使用标准工具或者编解码器，如gzip和bzip2</td>
</tr>
<tr>
<td>mapreduce.output.fileoutputformat.compress.type（在mapred-site.xml中配置）</td>
<td>RECORD</td>
<td>reducer输出</td>
<td>SequenceFile输出使用的压缩类型：NONE和BLOCK</td>
</tr>
</tbody>
</table>
<h2 id="4-6-压缩实战"><a href="#4-6-压缩实战" class="headerlink" title="4.6 压缩实战"></a>4.6 压缩实战</h2><h3 id="4-6-1-数据流的压缩和解压缩"><a href="#4-6-1-数据流的压缩和解压缩" class="headerlink" title="4.6.1 数据流的压缩和解压缩"></a>4.6.1 数据流的压缩和解压缩</h3><p>​    CompressionCodec有两个方法可以用于轻松地压缩或解压缩数据。要想对正在被写入一个输出流的数据进行压缩，<strong>我们可以使用createOutputStream(OutputStreamout)方法创建一个CompressionOutputStream</strong>，将其以压缩格式写入底层的流。相反，要想对从输入流读取而来的数据进行解压缩，则调用createInputStream(InputStreamin)函数，从而获得一个CompressionInputStream，从而从底层的流读取未压缩的数据。</p>
<p>测试一下如下压缩方式：</p>
<table>
<thead>
<tr>
<th>DEFLATE</th>
<th>org.apache.hadoop.io.compress.DefaultCodec</th>
</tr>
</thead>
<tbody>
<tr>
<td>gzip</td>
<td>org.apache.hadoop.io.compress.GzipCodec</td>
</tr>
<tr>
<td>bzip2</td>
<td>org.apache.hadoop.io.compress.BZip2Codec</td>
</tr>
</tbody>
</table>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="keyword">package</span> com.kingge.mapreduce.compress;</div><div class="line"><span class="keyword">import</span> java.io.File;</div><div class="line"><span class="keyword">import</span> java.io.FileInputStream;</div><div class="line"><span class="keyword">import</span> java.io.FileNotFoundException;</div><div class="line"><span class="keyword">import</span> java.io.FileOutputStream;</div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionCodec;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionCodecFactory;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionInputStream;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionOutputStream;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.ReflectionUtils;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestCompress</span> </span>&#123;</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		compress(<span class="string">"e:/hello.txt"</span>,<span class="string">"org.apache.hadoop.io.compress.BZip2Codec"</span>);</div><div class="line"><span class="comment">//		decompress("e:/hello.txt.bz2");</span></div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">// 压缩</span></div><div class="line">	<span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">compress</span><span class="params">(String filename, String method)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">		</div><div class="line">		<span class="comment">// 1 获取输入流</span></div><div class="line">		FileInputStream fis = <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(filename));</div><div class="line">		</div><div class="line">		Class codecClass = Class.forName(method);</div><div class="line">		</div><div class="line">		CompressionCodec codec = (CompressionCodec) ReflectionUtils.newInstance(codecClass, <span class="keyword">new</span> Configuration());</div><div class="line">		</div><div class="line">		<span class="comment">// 2 获取输出流</span></div><div class="line">		FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(filename +codec.getDefaultExtension()));</div><div class="line">		CompressionOutputStream cos = codec.createOutputStream(fos);</div><div class="line">		</div><div class="line">		<span class="comment">// 3 流的对拷</span></div><div class="line">		IOUtils.copyBytes(fis, cos, <span class="number">1024</span>*<span class="number">1024</span>*<span class="number">5</span>, <span class="keyword">false</span>);</div><div class="line">		</div><div class="line">		<span class="comment">// 4 关闭资源</span></div><div class="line">		fis.close();</div><div class="line">		cos.close();</div><div class="line">		fos.close();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">// 解压缩</span></div><div class="line">	<span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">decompress</span><span class="params">(String filename)</span> <span class="keyword">throws</span> FileNotFoundException, IOException </span>&#123;</div><div class="line">		</div><div class="line">		<span class="comment">// 0 校验是否能解压缩</span></div><div class="line">		CompressionCodecFactory factory = <span class="keyword">new</span> CompressionCodecFactory(<span class="keyword">new</span> Configuration());</div><div class="line">		CompressionCodec codec = factory.getCodec(<span class="keyword">new</span> Path(filename));</div><div class="line">		</div><div class="line">		<span class="keyword">if</span> (codec == <span class="keyword">null</span>) &#123;</div><div class="line">			System.out.println(<span class="string">"cannot find codec for file "</span> + filename);</div><div class="line">			<span class="keyword">return</span>;</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		<span class="comment">// 1 获取输入流</span></div><div class="line">		CompressionInputStream cis = codec.createInputStream(<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(filename)));</div><div class="line">		</div><div class="line">		<span class="comment">// 2 获取输出流</span></div><div class="line">		FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(filename + <span class="string">".decoded"</span>));</div><div class="line">		</div><div class="line">		<span class="comment">// 3 流的对拷</span></div><div class="line">		IOUtils.copyBytes(cis, fos, <span class="number">1024</span>*<span class="number">1024</span>*<span class="number">5</span>, <span class="keyword">false</span>);</div><div class="line">		</div><div class="line">		<span class="comment">// 4 关闭资源</span></div><div class="line">		cis.close();</div><div class="line">		fos.close();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="4-6-2-Map输出端采用压缩"><a href="#4-6-2-Map输出端采用压缩" class="headerlink" title="4.6.2 Map输出端采用压缩"></a>4.6.2 Map输出端采用压缩</h3><p>​    即使你的MapReduce的输入输出文件都是未压缩的文件，你仍然可以对map任务的中间结果输出做压缩，因为它要写在硬盘并且通过网络传输到reduce节点，对其压缩可以提高很多性能，这些工作只要设置两个属性即可，我们来看下代码怎么设置：</p>
<p>1）给大家提供的hadoop源码支持的压缩格式有：<strong>BZip2Codec 、DefaultCodec</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.compress;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.IntWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.io.compress.BZip2Codec;	</div><div class="line">import org.apache.hadoop.io.compress.CompressionCodec;</div><div class="line">import org.apache.hadoop.io.compress.GzipCodec;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line">public class WordCountDriver &#123;</div><div class="line"></div><div class="line">	public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123;</div><div class="line"></div><div class="line">		Configuration configuration = new Configuration();</div><div class="line"></div><div class="line">		// 开启map端输出压缩</div><div class="line">		configuration.setBoolean(&quot;mapreduce.map.output.compress&quot;, true);</div><div class="line">		// 设置map端输出压缩方式</div><div class="line">		configuration.setClass(&quot;mapreduce.map.output.compress.codec&quot;, BZip2Codec.class, CompressionCodec.class);</div><div class="line"></div><div class="line">		Job job = Job.getInstance(configuration);</div><div class="line"></div><div class="line">		job.setJarByClass(WordCountDriver.class);</div><div class="line"></div><div class="line">		job.setMapperClass(WordCountMapper.class);</div><div class="line">		job.setReducerClass(WordCountReducer.class);</div><div class="line"></div><div class="line">		job.setMapOutputKeyClass(Text.class);</div><div class="line">		job.setMapOutputValueClass(IntWritable.class);</div><div class="line"></div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(IntWritable.class);</div><div class="line"></div><div class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</div><div class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</div><div class="line"></div><div class="line">		boolean result = job.waitForCompletion(true);</div><div class="line"></div><div class="line">		System.exit(result ? 1 : 0);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>2）Mapper保持不变</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.compress;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.IntWritable;</div><div class="line">import org.apache.hadoop.io.LongWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line">public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt;&#123;</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	protected void map(LongWritable key, Text value, Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		// 1 获取一行</div><div class="line">		String line = value.toString();</div><div class="line">		// 2 切割</div><div class="line">		String[] words = line.split(&quot; &quot;);</div><div class="line">		// 3 循环写出</div><div class="line">		for(String word:words)&#123;</div><div class="line">			context.write(new Text(word), new IntWritable(1));</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>3）Reducer保持不变</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.compress;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.IntWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line">public class WordCountReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt;&#123;</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	protected void reduce(Text key, Iterable&lt;IntWritable&gt; values,</div><div class="line">			Context context) throws IOException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		int count = 0;</div><div class="line">		// 1 汇总</div><div class="line">		for(IntWritable value:values)&#123;</div><div class="line">			count += value.get();</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">        // 2 输出</div><div class="line">		context.write(key, new IntWritable(count));</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="7-10-3-Reduce输出端采用压缩"><a href="#7-10-3-Reduce输出端采用压缩" class="headerlink" title="7.10.3 Reduce输出端采用压缩"></a>7.10.3 Reduce输出端采用压缩</h3><p>基于wordcount案例处理</p>
<p>1）修改驱动</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.compress;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.IntWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.io.compress.BZip2Codec;</div><div class="line">import org.apache.hadoop.io.compress.DefaultCodec;</div><div class="line">import org.apache.hadoop.io.compress.GzipCodec;</div><div class="line">import org.apache.hadoop.io.compress.Lz4Codec;</div><div class="line">import org.apache.hadoop.io.compress.SnappyCodec;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line">public class WordCountDriver &#123;</div><div class="line"></div><div class="line">	public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		Configuration configuration = new Configuration();</div><div class="line">		</div><div class="line">		Job job = Job.getInstance(configuration);</div><div class="line">		</div><div class="line">		job.setJarByClass(WordCountDriver.class);</div><div class="line">		</div><div class="line">		job.setMapperClass(WordCountMapper.class);</div><div class="line">		job.setReducerClass(WordCountReducer.class);</div><div class="line">		</div><div class="line">		job.setMapOutputKeyClass(Text.class);</div><div class="line">		job.setMapOutputValueClass(IntWritable.class);</div><div class="line">		</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(IntWritable.class);</div><div class="line">		</div><div class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</div><div class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</div><div class="line">		</div><div class="line">		// 设置reduce端输出压缩开启</div><div class="line">		FileOutputFormat.setCompressOutput(job, true);</div><div class="line">		</div><div class="line">		// 设置压缩的方式</div><div class="line">	    FileOutputFormat.setOutputCompressorClass(job, BZip2Codec.class); </div><div class="line">//	    FileOutputFormat.setOutputCompressorClass(job, GzipCodec.class); </div><div class="line">//	    FileOutputFormat.setOutputCompressorClass(job, DefaultCodec.class); </div><div class="line">	    </div><div class="line">		boolean result = job.waitForCompletion(true);</div><div class="line">		</div><div class="line">		System.exit(result?1:0);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>2）Mapper和Reducer保持不变（详见4.6.2）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;4-1-概述&quot;&gt;&lt;a href=&quot;#4-1-概述&quot; class=&quot;headerlink&quot; title=&quot;4.1 概述&quot;&gt;&lt;/a&gt;4.1 概述&lt;/h2&gt;&lt;p&gt;压缩技术能够有效减少底层存储系统（HDFS）读写字节数。压缩提高了网络带宽和磁盘空间的效率。在Hadoop下
    
    </summary>
    
      <category term="hadoop" scheme="http://kingge.top/categories/hadoop/"/>
    
    
      <category term="hadoop" scheme="http://kingge.top/tags/hadoop/"/>
    
      <category term="大数据" scheme="http://kingge.top/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="MapReduce" scheme="http://kingge.top/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>hadoop大数据(十一)-Mapreduce框架原理</title>
    <link href="http://kingge.top/2018/03/18/hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE-%E5%8D%81%E4%B8%80-Mapreduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/"/>
    <id>http://kingge.top/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/</id>
    <published>2018-03-18T10:59:59.000Z</published>
    <updated>2019-06-17T13:45:43.508Z</updated>
    
    <content type="html"><![CDATA[<h1 id="三-MapReduce框架原理"><a href="#三-MapReduce框架原理" class="headerlink" title="三 MapReduce框架原理"></a>三 MapReduce框架原理</h1><h2 id="3-1-MapReduce工作流程"><a href="#3-1-MapReduce工作流程" class="headerlink" title="3.1 MapReduce工作流程"></a>3.1 MapReduce工作流程</h2><p>1）流程示意图</p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/C1560701152675.png" alt="1560701152675"></p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/01246317.png" alt="1560701246317"></p>
<p>2.Submit()方法包含在这里面–<img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/clip_image005.png" alt="img"></p>
<p>然后接着是切片处理数据（128M为一片）。很明显图例200M的文件需要切成两片处理。分配两个map进行计算操作</p>
<p>3.正式提交任务到yarn上，包含一些job的相关信息。</p>
<p>4．MrAppMaster进行资源调度。根据片块数分配相应数量的MapTask（这里分配两个MapTask）</p>
<p>5.然后MapTask根据InputFormat去读取文本数据。一行一行的经过Mapper程序的map()方法进行计算操作，最后输出到分区中，并有序的存储。</p>
<p>6.等到所有MapTask计算完毕后。启动MrAppMaster启动相对应分区数量的reduce数量进行统计操作。最后生成多个分区对应的统计文件。输出。</p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/560701367268.png" alt="1560701367268"></p>
<p>2）流程详解</p>
<p>上面的流程是整个mapreduce最全工作流程，但是shuffle过程只是从第7步开始到第16步结束，具体shuffle过程详解，如下：</p>
<p>1）maptask收集我们的map()方法输出的kv对，放到内存缓冲区中</p>
<p>2）从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件</p>
<p>3）多个溢出文件会被合并成大的溢出文件</p>
<p>4）在溢出过程中，及合并的过程中，都要调用partitioner进行分区和针对key进行排序</p>
<p>5）reducetask根据自己的分区号，去各个maptask机器上取相应的结果分区数据</p>
<p>6）reducetask会取到同一个分区的来自不同maptask的结果文件，reducetask会将这些文件再进行合并（归并排序）</p>
<p>7）合并成大文件后，shuffle的过程也就结束了，后面进入reducetask的逻辑运算过程（从文件中取出一个一个的键值对group，调用用户自定义的reduce()方法）</p>
<p>3）注意</p>
<p>Shuffle中的缓冲区大小会影响到mapreduce程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快。</p>
<p>缓冲区的大小可以通过参数调整，参数：io.sort.mb  默认100M。</p>
<h2 id="3-2-InputFormat数据输入"><a href="#3-2-InputFormat数据输入" class="headerlink" title="3.2 InputFormat数据输入"></a>3.2 InputFormat数据输入</h2><h3 id="3-2-1-Job提交流程和切片源码详解"><a href="#3-2-1-Job提交流程和切片源码详解" class="headerlink" title="3.2.1 Job提交流程和切片源码详解"></a>3.2.1 Job提交流程和切片源码详解</h3><p>1）job提交流程源码详解</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">waitForCompletion()</div><div class="line">submit();</div><div class="line">// 1建立连接-主要的工作是建立集群环境，以便运行Job任务。同时会根据Configuration配置信息来辨别当前job是需要在本地LocalRunner上运行还是在真实的yarn上运行。</div><div class="line">	connect();	</div><div class="line">		// 1）创建提交job的代理</div><div class="line">		new Cluster(getConfiguration());</div><div class="line">			// （1）判断是本地yarn还是远程</div><div class="line">			initialize(jobTrackAddr, conf); </div><div class="line">	// 2 提交job</div><div class="line">submitter.submitJobInternal(Job.this, cluster)</div><div class="line">	// 1）创建给集群提交数据的Stag路径</div><div class="line">	Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);</div><div class="line">	// 2）获取jobid ，并创建job路径</div><div class="line">	JobID jobId = submitClient.getNewJobID();</div><div class="line">	// 3）拷贝jar包到集群 – 如果是在本地运行那么就不需要提交jar包，但是如果是在远程服务器上运行，那么就需要提交jar包，防止找不到</div><div class="line">copyAndConfigureFiles(job, submitJobDir);	</div><div class="line">	rUploader.uploadFiles(job, jobSubmitDir);</div><div class="line">// 4）计算切片，生成切片规划文件-默认是切一片，会去读取配置文件，获取自定义的最小切片数。切片数最大值也是有一个默认值，最大值是Long.MAX_VALUE</div><div class="line">writeSplits(job, submitJobDir);</div><div class="line">	maps = writeNewSplits(job, jobSubmitDir);</div><div class="line">		input.getSplits(job);</div><div class="line">// 5）向Stag路径写xml配置文件</div><div class="line">writeConf(conf, submitJobFile);</div><div class="line">	conf.writeXml(out);</div><div class="line">// 6）提交job,返回提交状态</div><div class="line">status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());</div></pre></td></tr></table></figure>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/1.png" alt="1560701501633"></p>
<p>2）FileInputFormat源码解析(input.getSplits(job))</p>
<p>（1）找到你数据存储的目录。</p>
<p>​         （2）开始遍历处理（规划切片）目录下的每一个文件</p>
<p>​         （3）遍历第一个文件ss.txt</p>
<p>​                 a）获取文件大小fs.sizeOf(ss.txt);</p>
<p>​                 b）计算切片大小computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))=blocksize=128M</p>
<p>​        c）<strong>默认情况下，切片大小=blocksize</strong></p>
<p>​                 d）开始切，形成第1个切片：ss.txt—0:128M 第2个切片ss.txt—128:256M 第3个切片ss.txt—256M:300M（每次切片时，都要判断切完剩下的部分是否大于块的1.1倍，不大于1.1倍就划分一块切片）</p>
<p>​                 e）将切片信息写到一个切片规划文件中</p>
<p>​                 f）整个切片的核心过程在getSplit()方法中完成。</p>
<p>​        g）数据切片只是在逻辑上对输入数据进行分片，并不会再磁盘上将其切分成分片进行存储。InputSplit只记录了分片的元数据信息，比如起始位置、长度以及所在的节点列表等。</p>
<p>​        h）注意：block是HDFS物理上存储的数据，切片是对数据逻辑上的划分。</p>
<p>​         （4）<strong>提交切片规划文件到yarn上，yarn上的MrAppMaster就可以根据切片规划文件计算开启maptask个数。</strong></p>
<h3 id="23-2-2-FileInputFormat切片机制"><a href="#23-2-2-FileInputFormat切片机制" class="headerlink" title="23.2.2 FileInputFormat切片机制"></a>23.2.2 FileInputFormat切片机制</h3><p>1）FileInputFormat中默认的切片机制：</p>
<p>（1）简单地按照文件的内容长度进行切片</p>
<p>（2）切片大小，默认等于block大小</p>
<p>（3）<strong>切片时不考虑数据集整体，而是逐个针对每一个文件单独切片(他会遍历输入目录里面的文件，一个一个处理，debug查看FileInputFormat的getSplits方法可知)</strong></p>
<p>比如待处理数据有两个文件：</p>
<p>   file1.txt    320M   file2.txt    10M   </p>
<p>经过FileInputFormat的切片机制运算后，形成的切片信息如下：  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">file1.txt.split1--  0~128</div><div class="line">file1.txt.split2--  128~256</div><div class="line">file1.txt.split3--  256~320</div><div class="line">file2.txt.split1--  0~10M</div></pre></td></tr></table></figure>
<p>2）FileInputFormat切片大小的参数配置</p>
<p>通过分析源码，在FileInputFormat中，计算切片大小的逻辑：<strong>Math.max(minSize, Math.min(maxSize, blockSize));</strong> </p>
<p>切片主要由这几个值来运算决定</p>
<p>mapreduce.input.fileinputformat.split.minsize=1 默认值为1</p>
<p>mapreduce.input.fileinputformat.split.maxsize= Long.MAXValue 默认值Long.MAXValue</p>
<p>因此，<strong>默认情况下，切片大小=blocksize。</strong></p>
<p>maxsize（切片最大值）：参数如果调得比blocksize小，则会让切片变小，而且就等于配置的这个参数的值。</p>
<p>minsize（切片最小值）：参数调的比blockSize大，则可以让切片变得比blocksize还大。</p>
<p>3）获取切片信息API</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">// 根据文件类型获取切片信息</div><div class="line">FileSplit inputSplit = (FileSplit) context.getInputSplit();</div><div class="line">// 获取切片的文件名称</div><div class="line">String name = inputSplit.getPath().getName();</div></pre></td></tr></table></figure>
<h3 id="3-2-3-CombineTextInputFormat切片机制"><a href="#3-2-3-CombineTextInputFormat切片机制" class="headerlink" title="3.2.3 CombineTextInputFormat切片机制"></a>3.2.3 CombineTextInputFormat切片机制</h3><h4 id="1）关于大量小文件的优化策略"><a href="#1）关于大量小文件的优化策略" class="headerlink" title="1）关于大量小文件的优化策略"></a><strong>1）关于大量小文件的优化策略</strong></h4><p>1）默认情况下<strong>TextInputformat对任务的切片机制是按文件规划切片，不管文件多小</strong>，都会是一个单独的切片，都会交给一个maptask，这样如果有大量小文件，就会产生大量的maptask，处理效率极其低下。</p>
<h4 id="2）优化策略"><a href="#2）优化策略" class="headerlink" title="2）优化策略"></a>2）优化策略</h4><p>​         （1）最好的办法，在数据处理系统的最前端（<strong>预处理/采集</strong>），将小文件先合并成大文件，<strong>再上传到HDFS</strong>做后续分析。</p>
<p>​         （2）补救措施：如果已经是大量小文件在HDFS中了，可以使用另一种InputFormat来做切片（CombineTextInputFormat），它的切片逻辑跟TextFileInputFormat不同：它可以将多个小文件<strong>从逻辑上规划到一个切片</strong>中，这样，多个小文件就可以交给一个maptask。</p>
<p>​         （3）优先满足最小切片大小，不超过最大切片大小</p>
<p>​                 CombineTextInputFormat.<em>setMaxInputSplitSize</em>(job, 4194304);// 4m</p>
<p>​                 CombineTextInputFormat.<em>setMinInputSplitSize</em>(job, 2097152);// 2m</p>
<p>​         举例：0.5m+1m+0.3m+5m=2m + 4.8m=2m + 4m + 0.8m</p>
<p>​        <strong>0.5+1+0.3 = 1.8<em>没有满足最小切片大小，所以向5借0.2M,最后合并成2+4.8</em>，但是4.8大于最大切片数，所以拆成4+0.8</strong> <strong>，所以这个四个小文件最后合并成三个文件</strong></p>
<h4 id="3）具体实现步骤"><a href="#3）具体实现步骤" class="headerlink" title="3）具体实现步骤"></a>3）具体实现步骤</h4><p>注意CombineTextInputFormat的jar包是：<img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/60701587833.png" alt="1560701587833"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">//  如果不设置InputFormat,它默认用的是TextInputFormat.class</div><div class="line">job.setInputFormatClass(CombineTextInputFormat.class)</div><div class="line">CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);// 4m</div><div class="line">CombineTextInputFormat.setMinInputSplitSize(job, 2097152);// 2m</div></pre></td></tr></table></figure>
<h4 id="4）案例"><a href="#4）案例" class="headerlink" title="4）案例"></a>4）案例</h4><p>​         大量小文件的切片优化（CombineTextInputFormat）。</p>
<h5 id="4-1-数据准备"><a href="#4-1-数据准备" class="headerlink" title="4.1 数据准备"></a>4.1 数据准备</h5><p>准备5个小文件（这里准备五个txt文本）</p>
<h5 id="4-2-我们依旧使用我们上一个章节使用的统计文本中单词出现个数的代码"><a href="#4-2-我们依旧使用我们上一个章节使用的统计文本中单词出现个数的代码" class="headerlink" title="4.2 我们依旧使用我们上一个章节使用的统计文本中单词出现个数的代码"></a>4.2 我们依旧使用我们上一个章节使用的统计文本中单词出现个数的代码</h5><p><strong>代码详见 《hadoop大数据(十)-Mapreduce基础 的 1.5 4） 章节案例》</strong></p>
<p> 先不进行任何的改造操作，直接用着五个小文件当做输入，运行后查看日志。</p>
<p>（1）不做任何处理，运行需求1中的wordcount程序，观察切片个数为5</p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/774204813.png" alt="1560774204813"></p>
<p>（2）在WordcountDriver中增加如下代码，运行程序，并观察运行的切片个数为1</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">// 如果不设置InputFormat，它默认用的是TextInputFormat.class</div><div class="line">job.setInputFormatClass(CombineTextInputFormat.class);</div><div class="line">CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);// 4m</div><div class="line">CombineTextInputFormat.setMinInputSplitSize(job, 2097152);// 2m</div></pre></td></tr></table></figure>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/0774257244.png" alt="1560774257244"></p>
<h3 id="3-2-4-InputFormat接口实现类"><a href="#3-2-4-InputFormat接口实现类" class="headerlink" title="3.2.4 InputFormat接口实现类"></a>3.2.4 InputFormat接口实现类</h3><p>MapReduce任务的输入文件一般是存储在HDFS里面。输入的文件格式包括：基于行的日志文件、二进制格式文件等。这些文件一般会很大，达到数十GB，甚至更大。那么MapReduce是如何读取这些数据的呢？下面我们首先学习InputFormat接口。</p>
<p>InputFormat常见的接口实现类包括：TextInputFormat、KeyValueTextInputFormat、NLineInputFormat、CombineTextInputFormat和自定义InputFormat等。</p>
<p>1）TextInputFormat</p>
<p>TextInputFormat是默认的InputFormat。每条记录是一行输入。<strong>键是LongWritable类型，存储该行在整个文件中的字节偏移量。值是这行的内容，不包括任何行终止符（换行符和回车符）</strong>。</p>
<p>以下是一个示例，比如，一个分片包含了如下4条文本记录。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">Rich learning form</div><div class="line">Intelligent learning engine</div><div class="line">Learning more convenient</div><div class="line">From the real demand for more close to the enterprise</div></pre></td></tr></table></figure>
<p>每条记录表示为以下键/值对：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">(0,Rich learning form)</div><div class="line">(19,Intelligent learning engine)</div><div class="line">(47,Learning more convenient)</div><div class="line">(72,From the real demand for more close to the enterprise)</div></pre></td></tr></table></figure>
<p>很明显，键并不是行号。一般情况下，很难取得行号，因为文件按字节而不是按行切分为分片。</p>
<p>2）KeyValueTextInputFormat</p>
<p>每一行均为一条记录，被分隔符分割为key，value。<strong>可以通过在驱动类中设置conf.set(KeyValueLineRecordReader.KEY_VALUE_SEPERATOR, “ “);来设定分隔符。默认分隔符是tab（\t）</strong>。</p>
<p>以下是一个示例，输入是一个包含4条记录的分片。其中——&gt;表示一个（水平方向的）制表符。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">line1 ——&gt;Rich learning form</div><div class="line">line2 ——&gt;Intelligent learning engine</div><div class="line">line3 ——&gt;Learning more convenient</div><div class="line">line4 ——&gt;From the real demand for more close to the enterprise</div></pre></td></tr></table></figure>
<p>每条记录表示为以下键/值对：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">(line1,Rich learning form)</div><div class="line">(line2,Intelligent learning engine)</div><div class="line">(line3,Learning more convenient)</div><div class="line">(line4,From the real demand for more close to the enterprise)</div></pre></td></tr></table></figure>
<p> 此时的键是每行排在制表符之前的Text序列。</p>
<p> 3）NLineInputFormat</p>
<p>如果使用NlineInputFormat，<strong>代表每个map进程处理的InputSplit不再按block块去划分，而是按NlineInputFormat指定的行数N来划分</strong>。即输入文件的总行数/N=切片数，如果不整除，切片数=商+1。</p>
<p>以下是一个示例，仍然以上面的4行输入为例。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">Rich learning form</div><div class="line">Intelligent learning engine</div><div class="line">Learning more convenient</div><div class="line">From the real demand for more close to the enterprise</div></pre></td></tr></table></figure>
<p> 例如，如果N是2，则每个输入分片包含两行。开启2个maptask。</p>
<p>   (0,Rich learning form)  </p>
<p>   (19,Intelligent learning   engine)   </p>
<p>另一个 mapper 则收到后两行：</p>
<p>   (47,Learning more   convenient)  </p>
<p>   (72,From the real demand   for more close to the enterprise)   </p>
<p>​        这里的键和值与TextInputFormat生成的一样。</p>
<h3 id="3-2-5-自定义InputFormat"><a href="#3-2-5-自定义InputFormat" class="headerlink" title="3.2.5 自定义InputFormat"></a>3.2.5 自定义InputFormat</h3><h4 id="1）概述"><a href="#1）概述" class="headerlink" title="1）概述"></a>1）概述</h4><p>（1）自定义一个类继承FileInputFormat。</p>
<p>（2）改写RecordReader，实现一次读取一个完整文件封装为KV。</p>
<p>（3）在输出时使用SequenceFileOutPutFormat输出合并文件。</p>
<h4 id="2）案例"><a href="#2）案例" class="headerlink" title="2）案例"></a>2）案例</h4><p>​      无论hdfs还是mapreduce，对于小文件都有损效率，实践中，又难免面临处理大量小文件的场景，此时，就需要有相应解决方案。将多个小文件合并成一个文件SequenceFile，SequenceFile里面存储着多个文件，存储的形式为文件路径+名称为key，文件内容为value。</p>
<p>   <strong>小文件的优化无非以下几种方式：</strong></p>
<blockquote>
<p>（1）在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS</p>
<p>（2）在业务处理之前，在HDFS上使用mapreduce程序对小文件进行合并</p>
<p>（3）在mapreduce处理时，可采用CombineTextInputFormat提高效率</p>
</blockquote>
<h5 id="2-1-数据准备"><a href="#2-1-数据准备" class="headerlink" title="2.1 数据准备"></a>2.1 数据准备</h5><p>准备三个文本文件。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">aa.txt:包含以下内容</div><div class="line">yongpeng weidong weinan</div><div class="line">sanfeng luozong xiaoming</div><div class="line"></div><div class="line">bb.txt:包含以下内容</div><div class="line">longlong fanfan</div><div class="line">mazong kailun yuhang yixin</div><div class="line">longlong fanfan</div><div class="line">mazong kailun yuhang yixin</div><div class="line"></div><div class="line">cc.txt:包含以下内容</div><div class="line">shuaige changmo zhenqiang </div><div class="line">dongli lingu xuanxuan</div></pre></td></tr></table></figure>
<p>最终预期文件格式：</p>
<p>part-r-00000</p>
<h5 id="2-2-代码实现"><a href="#2-2-代码实现" class="headerlink" title="2.2 代码实现"></a>2.2 代码实现</h5><p>使用自定义InputFormat的方式，处理输入小文件的问题。</p>
<p>（1）自定义一个类继承FileInputFormat</p>
<p>（2）改写RecordReader，实现一次读取一个完整文件封装为KV</p>
<p>（3）在输出时使用SequenceFileOutPutFormat输出合并文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">（1）自定义InputFromat</div><div class="line">package com.kingge.mapreduce.inputformat;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.BytesWritable;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.mapreduce.InputSplit;</div><div class="line">import org.apache.hadoop.mapreduce.JobContext;</div><div class="line">import org.apache.hadoop.mapreduce.RecordReader;</div><div class="line">import org.apache.hadoop.mapreduce.TaskAttemptContext;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"></div><div class="line">// 定义类继承FileInputFormat</div><div class="line">public class WholeFileInputformat extends FileInputFormat&lt;NullWritable, BytesWritable&gt;&#123;</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	protected boolean isSplitable(JobContext context, Path filename) &#123;</div><div class="line">		return false;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public RecordReader&lt;NullWritable, BytesWritable&gt; createRecordReader(InputSplit split, TaskAttemptContext context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		WholeRecordReader recordReader = new WholeRecordReader();</div><div class="line">		recordReader.initialize(split, context);</div><div class="line">		</div><div class="line">		return recordReader;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（2）自定义RecordReader</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.inputformat;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.FSDataInputStream;</div><div class="line">import org.apache.hadoop.fs.FileSystem;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.BytesWritable;</div><div class="line">import org.apache.hadoop.io.IOUtils;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.mapreduce.InputSplit;</div><div class="line">import org.apache.hadoop.mapreduce.RecordReader;</div><div class="line">import org.apache.hadoop.mapreduce.TaskAttemptContext;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileSplit;</div><div class="line"></div><div class="line">public class WholeRecordReader extends RecordReader&lt;NullWritable, BytesWritable&gt;&#123;</div><div class="line"></div><div class="line">	private Configuration configuration;</div><div class="line">	private FileSplit split;</div><div class="line">	</div><div class="line">	private boolean processed = false;</div><div class="line">	private BytesWritable value = new BytesWritable();</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	public void initialize(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		this.split = (FileSplit)split;</div><div class="line">		configuration = context.getConfiguration();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public boolean nextKeyValue() throws IOException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		if (!processed) &#123;</div><div class="line">			// 1 定义缓存区</div><div class="line">			byte[] contents = new byte[(int)split.getLength()];</div><div class="line">			</div><div class="line">			FileSystem fs = null;</div><div class="line">			FSDataInputStream fis = null;</div><div class="line">			</div><div class="line">			try &#123;</div><div class="line">				// 2 获取文件系统</div><div class="line">				Path path = split.getPath();</div><div class="line">				fs = path.getFileSystem(configuration);</div><div class="line">				</div><div class="line">				// 3 读取数据</div><div class="line">				fis = fs.open(path);</div><div class="line">				</div><div class="line">				// 4 读取文件内容</div><div class="line">				IOUtils.readFully(fis, contents, 0, contents.length);</div><div class="line">				</div><div class="line">				// 5 输出文件内容</div><div class="line">				value.set(contents, 0, contents.length);</div><div class="line">			&#125; catch (Exception e) &#123;</div><div class="line">				</div><div class="line">			&#125;finally &#123;</div><div class="line">				IOUtils.closeStream(fis);</div><div class="line">			&#125;</div><div class="line">			</div><div class="line">			processed = true;</div><div class="line">			</div><div class="line">			return true;</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		return false;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public NullWritable getCurrentKey() throws IOException, InterruptedException &#123;</div><div class="line">		return NullWritable.get();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public BytesWritable getCurrentValue() throws IOException, InterruptedException &#123;</div><div class="line">		return value;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public float getProgress() throws IOException, InterruptedException &#123;</div><div class="line">		return processed? 1:0;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public void close() throws IOException &#123;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（3）SequenceFileMapper处理流程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.inputformat;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.BytesWritable;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileSplit;</div><div class="line"></div><div class="line">public class SequenceFileMapper extends Mapper&lt;NullWritable, BytesWritable, Text, BytesWritable&gt;&#123;</div><div class="line">	</div><div class="line">	Text k = new Text();</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	protected void setup(Mapper&lt;NullWritable, BytesWritable, Text, BytesWritable&gt;.Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		// 1 获取文件切片信息</div><div class="line">		FileSplit inputSplit = (FileSplit) context.getInputSplit();</div><div class="line">		// 2 获取切片名称</div><div class="line">		String name = inputSplit.getPath().toString();</div><div class="line">		// 3 设置key的输出</div><div class="line">		k.set(name);</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	protected void map(NullWritable key, BytesWritable value,</div><div class="line">			Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line"></div><div class="line">		context.write(k, value);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（4）SequenceFileReducer处理流程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.inputformat;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.BytesWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line">public class SequenceFileReducer extends Reducer&lt;Text, BytesWritable, Text, BytesWritable&gt; &#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	protected void reduce(Text key, Iterable&lt;BytesWritable&gt; values, Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line"></div><div class="line">		context.write(key, values.iterator().next());</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（5）SequenceFileDriver处理流程</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.inputformat;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.BytesWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;</div><div class="line"></div><div class="line">public class SequenceFileDriver &#123;</div><div class="line"></div><div class="line">	public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		args = new String[] &#123; &quot;e:/input/inputinputformat&quot;, &quot;e:/output1&quot; &#125;;</div><div class="line">		Configuration conf = new Configuration();</div><div class="line"></div><div class="line">		Job job = Job.getInstance(conf);</div><div class="line">		job.setJarByClass(SequenceFileDriver.class);</div><div class="line">		job.setMapperClass(SequenceFileMapper.class);</div><div class="line">		job.setReducerClass(SequenceFileReducer.class);</div><div class="line"></div><div class="line">        // 设置输入的inputFormat</div><div class="line">		job.setInputFormatClass(WholeFileInputformat.class);</div><div class="line">        // 设置输出的outputFormat</div><div class="line">		job.setOutputFormatClass(SequenceFileOutputFormat.class);</div><div class="line"></div><div class="line">		job.setMapOutputKeyClass(Text.class);</div><div class="line">		job.setMapOutputValueClass(BytesWritable.class);</div><div class="line">		</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(BytesWritable.class);</div><div class="line"></div><div class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</div><div class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</div><div class="line"></div><div class="line">		boolean result = job.waitForCompletion(true);</div><div class="line"></div><div class="line">		System.exit(result ? 0 : 1);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="3-3-MapTask工作机制"><a href="#3-3-MapTask工作机制" class="headerlink" title="3.3 MapTask工作机制"></a>3.3 MapTask工作机制</h2><h3 id="3-3-1-并行度决定机制"><a href="#3-3-1-并行度决定机制" class="headerlink" title="3.3.1 并行度决定机制"></a>3.3.1 并行度决定机制</h3><p>1）问题引出</p>
<p>maptask的并行度决定map阶段的任务处理并发度，进而影响到整个job的处理速度。那么，mapTask并行任务是否越多越好呢？</p>
<p>2）MapTask并行度决定机制</p>
<p>​         <strong>一个job的map阶段MapTask并行度（个数），由客户端提交job时的切片个数决定。</strong></p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/2.png" alt="1560701631551"></p>
<h3 id="3-3-2-MapTask工作机制"><a href="#3-3-2-MapTask工作机制" class="headerlink" title="3.3.2 MapTask工作机制"></a>3.3.2 MapTask工作机制</h3><p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/3.png" alt="1560701684388"></p>
<p>​         （1）Read阶段：Map Task通过用户编写的RecordReader，从输入InputSplit中解析出一个个key/value。</p>
<p>​         （2）Map阶段：该节点主要是将解析出的key/value交给用户编写map()函数处理，并产生一系列新的key/value。</p>
<p>​         （3）Collect收集阶段：在用户编写map()函数中，当数据处理完成后，一般会调用OutputCollector.collect()输出结果。在该函数内部，它会将生成的key/value分区（调用Partitioner—调用用户自定义getPartition方法），并写入一个环形内存缓冲区中。</p>
<p>​         （4）Spill阶段：即“溢写”，当环形缓冲区满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。</p>
<p>​         溢写阶段详情：</p>
<p>​         步骤1：利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号partition进行排序，然后按照key进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照key有序。</p>
<p>​         步骤2：按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件output/spillN.out（N表示当前溢写次数）中。如果用户设置了Combiner，则写入文件之前，对每个分区中的数据进行一次聚集操作。</p>
<p>​         步骤3：将分区数据的元信息写到内存索引数据结构SpillRecord中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过1MB，则将内存索引写到文件output/spillN.out.index中。</p>
<p>​         （5）Combine阶段：当所有数据处理完成后，MapTask对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。</p>
<p>​         当所有数据处理完后，MapTask会将所有临时文件合并成一个大文件，并保存到文件output/file.out中，同时生成相应的索引文件output/file.out.index。</p>
<p>​         在进行文件合并过程中，MapTask以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的方式。每轮合并io.sort.factor（默认100）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。</p>
<p>​         让每个MapTask最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销。</p>
<p><a href="https://blog.csdn.net/qq_41455420/article/details/79288764" target="_blank" rel="external">https://blog.csdn.net/qq_41455420/article/details/79288764</a></p>
<p><strong>好的总结：</strong></p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/5.png" alt=""></p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/6.png" alt=""></p>
<h2 id="3-4-Shuffle机制"><a href="#3-4-Shuffle机制" class="headerlink" title="3.4 Shuffle机制"></a>3.4 Shuffle机制</h2><h3 id="3-4-1-Shuffle机制"><a href="#3-4-1-Shuffle机制" class="headerlink" title="3.4.1 Shuffle机制"></a>3.4.1 Shuffle机制</h3><p>Mapreduce确保每个reducer的输入都是按键排序的。系统执行排序的过程（即将map输出作为输入传给reducer）称为shuffle。</p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/7.png" alt=""></p>
<p> <img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/8.png" alt="1560701949794"></p>
<p> <img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/9.png" alt=""></p>
<h3 id="3-4-2-Partition分区"><a href="#3-4-2-Partition分区" class="headerlink" title="3.4.2 Partition分区"></a>3.4.2 Partition分区</h3><p>  <strong>分区的行为在每一次的map操作都会调用一或者多次</strong></p>
<p>0）问题引出：要求将统计结果按照条件输出到不同文件中（分区）。比如：将统计结果按照手机归属地不同省份输出到不同文件中（分区）</p>
<p><strong>默认只输出到一个分区，也就是结果输出到一个文件</strong></p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/11.png" alt=""></p>
<p>1）默认partition分区</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">public class HashPartitioner&lt;K, V&gt; extends Partitioner&lt;K, V&gt; &#123;</div><div class="line">  public int getPartition(K key, V value, int numReduceTasks) &#123;</div><div class="line">    return (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>​         默认分区是根据key的hashCode对reduceTasks个数取模得到的。用户没法控制哪个key存储到哪个分区。（<strong>numReduceTasks默认是1，也就是说，默认返回0，也就是只创建一个分区，所以是part-r-00000</strong>）</p>
<p>2）自定义Partitioner步骤</p>
<p>​         （1）自定义类继承Partitioner，重写getPartition()方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">	public class ProvincePartitioner extends Partitioner&lt;Text, FlowBean&gt; &#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public int getPartition(Text key, FlowBean value, int numPartitions) &#123;</div><div class="line"></div><div class="line">// 1 获取电话号码的前三位</div><div class="line">		String preNum = key.toString().substring(0, 3);</div><div class="line">		</div><div class="line">		int partition = 4;</div><div class="line">		</div><div class="line">		// 2 判断是哪个省</div><div class="line">		if (&quot;136&quot;.equals(preNum)) &#123;</div><div class="line">			partition = 0;</div><div class="line">		&#125;else if (&quot;137&quot;.equals(preNum)) &#123;</div><div class="line">			partition = 1;</div><div class="line">		&#125;else if (&quot;138&quot;.equals(preNum)) &#123;</div><div class="line">			partition = 2;</div><div class="line">		&#125;else if (&quot;139&quot;.equals(preNum)) &#123;</div><div class="line">			partition = 3;</div><div class="line">		&#125;</div><div class="line">		return partition;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>​         （2）在job驱动中，设置自定义partitioner： </p>
<p>​                    job.setPartitionerClass(CustomPartitioner.class);   </p>
<p>​         （3）自定义partition后，要根据自定义partitioner的逻辑设置相应数量的reduce task</p>
<p>​                      job.setNumReduceTasks(5);   </p>
<p>3）注意：</p>
<p><strong>如果reduceTask的数量&gt; getPartition的结果数，则会多产生几个空的输出文件part-r-000xx；</strong></p>
<p><strong>如果1&lt;reduceTask的数量&lt;getPartition的结果数，则有一部分分区数据无处安放，会Exception；</strong></p>
<p><strong>如果reduceTask的数量=1，则不管mapTask端输出多少个分区文件，最终结果都交给这一个reduceTask，最终也就只会产生一个结果文件 part-r-00000；</strong></p>
<p>​         例如：假设自定义分区数为5，则</p>
<p><strong>（1）job.setNumReduceTasks(1);会正常运行，只不过会产生一个输出文件</strong></p>
<p><strong>（2）job.setNumReduceTasks(2);会报错</strong></p>
<p><strong>（3）job.setNumReduceTasks(6);大于5，程序会正常运行，会产生空文件</strong></p>
<h4 id="4）案例-1"><a href="#4）案例-1" class="headerlink" title="4）案例"></a>4）案例</h4><h5 id="4-1-案例1"><a href="#4-1-案例1" class="headerlink" title="4.1 案例1"></a>4.1 案例1</h5><p>​        将统计结果按照手机归属地不同省份输出到不同文件中（分区）</p>
<p>1）数据准备</p>
<p>phone.txt</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">1363157985066 	13726230503	00-FD-07-A4-72-B8:CMCC	120.196.100.82	i02.c.aliimg.com		24	27	2481	24681	200</div><div class="line">1363157995052 	13826544101	5C-0E-8B-C7-F1-E0:CMCC	120.197.40.4			4	0	264	0	200</div><div class="line">1363157991076 	13926435656	20-10-7A-28-CC-0A:CMCC	120.196.100.99			2	4	132	1512	200</div><div class="line">1363154400022 	13926251106	5C-0E-8B-8B-B1-50:CMCC	120.197.40.4			4	0	240	0	200</div><div class="line">1363157993044 	18211575961	94-71-AC-CD-E6-18:CMCC-EASY	120.196.100.99	iface.qiyi.com	视频网站	15	12	1527	2106	200</div><div class="line">1363157995074 	84138413	5C-0E-8B-8C-E8-20:7DaysInn	120.197.40.4	122.72.52.12		20	16	4116	1432	200</div><div class="line">1363157993055 	13560439658	C4-17-FE-BA-DE-D9:CMCC	120.196.100.99			18	15	1116	954	200</div><div class="line">1363157995033 	15920133257	5C-0E-8B-C7-BA-20:CMCC	120.197.40.4	sug.so.360.cn	信息安全	20	20	3156	2936	200</div><div class="line">1363157983019 	13719199419	68-A1-B7-03-07-B1:CMCC-EASY	120.196.100.82			4	0	240	0	200</div><div class="line">1363157984041 	13660577991	5C-0E-8B-92-5C-20:CMCC-EASY	120.197.40.4	s19.cnzz.com	站点统计	24	9	6960	690	200</div><div class="line">1363157973098 	15013685858	5C-0E-8B-C7-F7-90:CMCC	120.197.40.4	rank.ie.sogou.com	搜索引擎	28	27	3659	3538	200</div><div class="line">1363157986029 	15989002119	E8-99-C4-4E-93-E0:CMCC-EASY	120.196.100.99	www.umeng.com	站点统计	3	3	1938	180	200</div><div class="line">1363157992093 	13560439658	C4-17-FE-BA-DE-D9:CMCC	120.196.100.99			15	9	918	4938	200</div><div class="line">1363157986041 	13480253104	5C-0E-8B-C7-FC-80:CMCC-EASY	120.197.40.4			3	3	180	180	200</div><div class="line">1363157984040 	13602846565	5C-0E-8B-8B-B6-00:CMCC	120.197.40.4	2052.flash2-http.qq.com	综合门户	15	12	1938	2910	200</div><div class="line">1363157995093 	13922314466	00-FD-07-A2-EC-BA:CMCC	120.196.100.82	img.qfc.cn		12	12	3008	3720	200</div><div class="line">1363157982040 	13502468823	5C-0A-5B-6A-0B-D4:CMCC-EASY	120.196.100.99	y0.ifengimg.com	综合门户	57	102	7335	110349	200</div><div class="line">1363157986072 	18320173382	84-25-DB-4F-10-1A:CMCC-EASY	120.196.100.99	input.shouji.sogou.com	搜索引擎	21	18	9531	2412	200</div><div class="line">1363157990043 	13925057413	00-1F-64-E1-E6-9A:CMCC	120.196.100.55	t3.baidu.com	搜索引擎	69	63	11058	48243	200</div><div class="line">1363157988072 	13760778710	00-FD-07-A4-7B-08:CMCC	120.196.100.82			2	2	120	120	200</div><div class="line">1363157985066 	13726238888	00-FD-07-A4-72-B8:CMCC	120.196.100.82	i02.c.aliimg.com		24	27	2481	24681	200</div><div class="line">1363157993055 	13560436666	C4-17-FE-BA-DE-D9:CMCC	120.196.100.99			18	15	1116	954	200</div></pre></td></tr></table></figure>
<p>2）分析</p>
<p>（1）Mapreduce中会将map输出的kv对，按照相同key分组，然后分发给不同的reducetask。默认的分发规则为：根据key的hashcode%reducetask数来分发</p>
<p>（2）如果要按照我们自己的需求进行分组，则需要改写数据分发（分组）组件Partitioner</p>
<p>自定义一个CustomPartitioner继承抽象类：Partitioner</p>
<p>（3）在job驱动中，设置自定义partitioner： job.setPartitionerClass(CustomPartitioner.class)</p>
<p>3）在&lt;<strong>hadoop大数据(十)-Mapreduce基础 章节的2.6.2 案例&gt;</strong>的基础上，增加一个分区类</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.flowsum;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Partitioner;</div><div class="line">//他的key和value就是map输出的kv</div><div class="line">public class ProvincePartitioner extends Partitioner&lt;Text, FlowBean&gt; &#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public int getPartition(Text key, FlowBean value, int numPartitions) &#123;</div><div class="line">		// 1 获取电话号码的前三位</div><div class="line">		String preNum = key.toString().substring(0, 3);</div><div class="line">		</div><div class="line">		int partition = 4;</div><div class="line">		</div><div class="line">		// 2 判断是哪个省</div><div class="line">		if (&quot;136&quot;.equals(preNum)) &#123;</div><div class="line">			partition = 0;</div><div class="line">		&#125;else if (&quot;137&quot;.equals(preNum)) &#123;</div><div class="line">			partition = 1;</div><div class="line">		&#125;else if (&quot;138&quot;.equals(preNum)) &#123;</div><div class="line">			partition = 2;</div><div class="line">		&#125;else if (&quot;139&quot;.equals(preNum)) &#123;</div><div class="line">			partition = 3;</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		return partition;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p> 在驱动函数中增加自定义数据分区设置和reduce task设置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.flowsum;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line">public class FlowsumDriver &#123;</div><div class="line"></div><div class="line">	public static void main(String[] args) throws IllegalArgumentException, IOException, ClassNotFoundException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		// 1 获取配置信息，或者job对象实例</div><div class="line">		Configuration configuration = new Configuration();</div><div class="line">		Job job = Job.getInstance(configuration);</div><div class="line"></div><div class="line">		// 6 指定本程序的jar包所在的本地路径</div><div class="line">		job.setJarByClass(FlowsumDriver.class);</div><div class="line"></div><div class="line">		// 2 指定本业务job要使用的mapper/Reducer业务类</div><div class="line">		job.setMapperClass(FlowCountMapper.class);</div><div class="line">		job.setReducerClass(FlowCountReducer.class);</div><div class="line"></div><div class="line">		// 3 指定mapper输出数据的kv类型</div><div class="line">		job.setMapOutputKeyClass(Text.class);</div><div class="line">		job.setMapOutputValueClass(FlowBean.class);</div><div class="line"></div><div class="line">		// 4 指定最终输出的数据的kv类型</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(FlowBean.class);</div><div class="line"></div><div class="line">		// 8 指定自定义数据分区</div><div class="line">		job.setPartitionerClass(ProvincePartitioner.class);</div><div class="line">		// 9 同时指定相应数量的reduce task</div><div class="line">		job.setNumReduceTasks(5);</div><div class="line">		</div><div class="line">		// 5 指定job的输入原始文件所在目录</div><div class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</div><div class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</div><div class="line"></div><div class="line">		// 7 将job中配置的相关参数，以及job所用的java类所在的jar包， 提交给yarn去运行</div><div class="line">		boolean result = job.waitForCompletion(true);</div><div class="line">		System.exit(result ? 0 : 1);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h5 id="4-2-案例2"><a href="#4-2-案例2" class="headerlink" title="4.2 案例2"></a>4.2 案例2</h5><p>​    把单词按照ASCII码奇偶分区（Partitioner），结合&lt;<strong>hadoop大数据(十)-Mapreduce基础 的 1.5 4） 章节–统计一堆文件中单词出现的个数</strong>&gt;</p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/5967813.png" alt=""></p>
<p>只需要在此代码的基础上，添加自定义分区</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.wordcount;</div><div class="line">import org.apache.hadoop.io.IntWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Partitioner;</div><div class="line"></div><div class="line">public class WordCountPartitioner extends Partitioner&lt;Text, IntWritable&gt;&#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public int getPartition(Text key, IntWritable value, int numPartitions) &#123;</div><div class="line">		</div><div class="line">		// 1 获取单词key  </div><div class="line">		String firWord = key.toString().substring(0, 1);</div><div class="line">		char[] charArray = firWord.toCharArray();</div><div class="line">		int result = charArray[0];</div><div class="line">		// int result  = key.toString().charAt(0);</div><div class="line"></div><div class="line">		// 2 根据奇数偶数分区</div><div class="line">		if (result % 2 == 0) &#123;</div><div class="line">			return 0;</div><div class="line">		&#125;else &#123;</div><div class="line">			return 1;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在驱动类中配置加载分区，设置reducetask个数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">job.setPartitionerClass(WordCountPartitioner.class);</div><div class="line">job.setNumReduceTasks(2);//想分多少个区，这里必须开多少个reduce，否则默认只会生成一个分区，那么自定义分区失效</div></pre></td></tr></table></figure>
<h4 id="5）总结"><a href="#5）总结" class="headerlink" title="5）总结"></a>5）总结</h4><p>l  <strong>结果输出文件，跟分区数量和reduce数量有关系</strong></p>
<p>l  getPartition方法是在<strong>map</strong>调用之后才会进入<strong>，而且是每一次map可能会调用多次getPartition。</strong>为什么说是多次调用分区方法呢？我们知道每一次进入map方法都是一行数据（例如<strong> hello.txt的第一行hello kingge</strong>），那么经过分割后生成两个单词，调用两次**context.write（）所以为了确定这两个单词所属那个分区，那么就需要调用两次getPartition。也就说在这个例子中，一次map调用处理完后需要调用两次getPartition。（即：context.write（）内部会进行分区）</p>
<p>l  如果job.setNumReduceTasks(1)（也就是保持默认值），那么就是生成一个分区，不会进入自定义的分区方法。Redeucetask必须大于1，自定义分区方法才会生效。</p>
<h3 id="3-4-3-WritableComparable排序"><a href="#3-4-3-WritableComparable排序" class="headerlink" title="3.4.3 WritableComparable排序"></a>3.4.3 WritableComparable排序</h3><p>排序是MapReduce框架中最重要的操作之一。Map Task和Reduce Task均会对数据（按照key）进行排序。该操作属于Hadoop的默认行为。任何应用程序中的数据均会被排序，而不管逻辑上是否需要。<strong>默认排序是按照字典顺序排序，且实现该排序的方法是快速排序。</strong></p>
<p>​         对于Map Task，它会将处理的结果暂时放到一个缓冲区中，当缓冲区使用率达到一定阈值后，再对缓冲区中的数据进行一次排序，并将这些有序数据写到磁盘上，而当数据处理完毕后，它会对磁盘上所有文件进行一次合并，以将这些文件合并成一个大的有序文件。</p>
<p>​         对于Reduce Task，它从每个Map Task上远程拷贝相应的数据文件，如果文件大小超过一定阈值，则放到磁盘上，否则放到内存中。如果磁盘上文件数目达到一定阈值，则进行一次合并以生成一个更大文件；如果内存中文件大小或者数目超过一定阈值，则进行一次合并后将数据写到磁盘上。当所有数据拷贝完毕后，Reduce Task统一对内存和磁盘上的所有数据进行一次合并。</p>
<p><strong>每个阶段的默认排序</strong></p>
<h4 id="1）排序的分类："><a href="#1）排序的分类：" class="headerlink" title="1）排序的分类："></a>1）排序的分类：</h4><p>​         （1）部分排序：</p>
<p>MapReduce根据输入记录的键对数据集排序。保证输出的每个文件内部排序。<strong>例如输出文件到五个分区，那么部分排序能够保证各个五个分区的数据都是有序的。</strong></p>
<p>​         （2）全排序：</p>
<p>如何用Hadoop产生一个全局排序的文件？<strong>最简单的方法是使用一个分区，那么这个分区里面的数据全局都是排序的</strong>。但该方法在处理大型文件时效率极低，因为一台机器必须处理所有输出文件，从而完全丧失了MapReduce所提供的并行架构。</p>
<p>​         <strong>替代方案</strong>：首先创建一系列排好序的文件；其次，串联这些文件；最后，生成一个全局排序的文件。主要思路是使用一个分区来描述输出的全局排序。例如：可以为上述文件创建3个分区，在第一分区中，记录的单词首字母a-g，第二分区记录单词首字母h-n, 第三分区记录单词首字母o-z。<strong>这种方式可以达到全排序的功能</strong></p>
<p>（3）辅助排序：（GroupingComparator分组）</p>
<p>​         Mapreduce框架在记录到达reducer之前按键对记录排序，但键所对应的值并没有被排序。甚至在不同的执行轮次中，这些值的排序也不固定，因为它们来自不同的map任务且这些map任务在不同轮次中完成时间各不相同。一般来说，大多数MapReduce程序会避免让reduce函数依赖于值的排序。但是，有时也需要通过特定的方法对键进行排序和分组等以实现对值的排序。</p>
<p>​         （4）二次排序：</p>
<p>​         在自定义排序过程中，如果compareTo中的判断条件为两个即为二次排序。</p>
<h4 id="2）自定义排序WritableComparable"><a href="#2）自定义排序WritableComparable" class="headerlink" title="2）自定义排序WritableComparable"></a>2）自定义排序WritableComparable</h4><p>（1）原理分析</p>
<p><strong>bean对象实现WritableComparable接口重写compareTo方法，就可以实现排序</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Override</div><div class="line">public int compareTo(FlowBean o) &#123;</div><div class="line">	// 倒序排列，从大到小</div><div class="line">	return this.sumFlow &gt; o.getSumFlow() ? -1 : 1;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="3）案例"><a href="#3）案例" class="headerlink" title="3）案例"></a>3）案例</h4><h5 id="3-1-案例1"><a href="#3-1-案例1" class="headerlink" title="3.1 案例1"></a>3.1 案例1</h5><p>在&lt;<strong>hadoop大数据(十)-Mapreduce基础 章节的2.6.2 案例&gt;</strong>输出结果的基础上增加一个新的需求</p>
<p>根据2.6.2 案例输出的结果：再次对总流量进行排序</p>
<p>1）数据准备 phone.txt</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">1363157985066 	13726230503	00-FD-07-A4-72-B8:CMCC	120.196.100.82	i02.c.aliimg.com		24	27	2481	24681	200</div><div class="line">1363157995052 	13826544101	5C-0E-8B-C7-F1-E0:CMCC	120.197.40.4			4	0	264	0	200</div><div class="line">1363157991076 	13926435656	20-10-7A-28-CC-0A:CMCC	120.196.100.99			2	4	132	1512	200</div><div class="line">1363154400022 	13926251106	5C-0E-8B-8B-B1-50:CMCC	120.197.40.4			4	0	240	0	200</div><div class="line">1363157993044 	18211575961	94-71-AC-CD-E6-18:CMCC-EASY	120.196.100.99	iface.qiyi.com	视频网站	15	12	1527	2106	200</div><div class="line">1363157995074 	84138413	5C-0E-8B-8C-E8-20:7DaysInn	120.197.40.4	122.72.52.12		20	16	4116	1432	200</div><div class="line">1363157993055 	13560439658	C4-17-FE-BA-DE-D9:CMCC	120.196.100.99			18	15	1116	954	200</div><div class="line">1363157995033 	15920133257	5C-0E-8B-C7-BA-20:CMCC	120.197.40.4	sug.so.360.cn	信息安全	20	20	3156	2936	200</div><div class="line">1363157983019 	13719199419	68-A1-B7-03-07-B1:CMCC-EASY	120.196.100.82			4	0	240	0	200</div><div class="line">1363157984041 	13660577991	5C-0E-8B-92-5C-20:CMCC-EASY	120.197.40.4	s19.cnzz.com	站点统计	24	9	6960	690	200</div><div class="line">1363157973098 	15013685858	5C-0E-8B-C7-F7-90:CMCC	120.197.40.4	rank.ie.sogou.com	搜索引擎	28	27	3659	3538	200</div><div class="line">1363157986029 	15989002119	E8-99-C4-4E-93-E0:CMCC-EASY	120.196.100.99	www.umeng.com	站点统计	3	3	1938	180	200</div><div class="line">1363157992093 	13560439658	C4-17-FE-BA-DE-D9:CMCC	120.196.100.99			15	9	918	4938	200</div><div class="line">1363157986041 	13480253104	5C-0E-8B-C7-FC-80:CMCC-EASY	120.197.40.4			3	3	180	180	200</div><div class="line">1363157984040 	13602846565	5C-0E-8B-8B-B6-00:CMCC	120.197.40.4	2052.flash2-http.qq.com	综合门户	15	12	1938	2910	200</div><div class="line">1363157995093 	13922314466	00-FD-07-A2-EC-BA:CMCC	120.196.100.82	img.qfc.cn		12	12	3008	3720	200</div><div class="line">1363157982040 	13502468823	5C-0A-5B-6A-0B-D4:CMCC-EASY	120.196.100.99	y0.ifengimg.com	综合门户	57	102	7335	110349	200</div><div class="line">1363157986072 	18320173382	84-25-DB-4F-10-1A:CMCC-EASY	120.196.100.99	input.shouji.sogou.com	搜索引擎	21	18	9531	2412	200</div><div class="line">1363157990043 	13925057413	00-1F-64-E1-E6-9A:CMCC	120.196.100.55	t3.baidu.com	搜索引擎	69	63	11058	48243	200</div><div class="line">1363157988072 	13760778710	00-FD-07-A4-7B-08:CMCC	120.196.100.82			2	2	120	120	200</div><div class="line">1363157985066 	13726238888	00-FD-07-A4-72-B8:CMCC	120.196.100.82	i02.c.aliimg.com		24	27	2481	24681	200</div><div class="line">1363157993055 	13560436666	C4-17-FE-BA-DE-D9:CMCC	120.196.100.99			18	15	1116	954	200</div></pre></td></tr></table></figure>
<p>2）分析</p>
<p>​         （1）把程序分两步走，第一步正常统计总流量，第二步再把结果进行排序</p>
<p>​         （2）context.write(总流量，手机号)</p>
<p>​         （3）FlowBean实现WritableComparable接口重写compareTo方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Override</div><div class="line">public int compareTo(FlowBean o) &#123;</div><div class="line">	// 倒序排列，从大到小</div><div class="line">	return this.sumFlow &gt; o.getSumFlow() ? -1 : 1;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>3）代码实现</p>
<p>（1）FlowBean对象在在需求2.6.2基础上增加了比较功能（compareTo）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.sort;</div><div class="line">import java.io.DataInput;</div><div class="line">import java.io.DataOutput;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.WritableComparable;</div><div class="line"></div><div class="line">public class FlowBean implements WritableComparable&lt;FlowBean&gt; &#123;</div><div class="line"></div><div class="line">	private long upFlow;</div><div class="line">	private long downFlow;</div><div class="line">	private long sumFlow;</div><div class="line"></div><div class="line">	// 反序列化时，需要反射调用空参构造函数，所以必须有</div><div class="line">	public FlowBean() &#123;</div><div class="line">		super();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public FlowBean(long upFlow, long downFlow) &#123;</div><div class="line">		super();</div><div class="line">		this.upFlow = upFlow;</div><div class="line">		this.downFlow = downFlow;</div><div class="line">		this.sumFlow = upFlow + downFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void set(long upFlow, long downFlow) &#123;</div><div class="line">		this.upFlow = upFlow;</div><div class="line">		this.downFlow = downFlow;</div><div class="line">		this.sumFlow = upFlow + downFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public long getSumFlow() &#123;</div><div class="line">		return sumFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setSumFlow(long sumFlow) &#123;</div><div class="line">		this.sumFlow = sumFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public long getUpFlow() &#123;</div><div class="line">		return upFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setUpFlow(long upFlow) &#123;</div><div class="line">		this.upFlow = upFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public long getDownFlow() &#123;</div><div class="line">		return downFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setDownFlow(long downFlow) &#123;</div><div class="line">		this.downFlow = downFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	/**</div><div class="line">	 * 序列化方法</div><div class="line">	 * @param out</div><div class="line">	 * @throws IOException</div><div class="line">	 */</div><div class="line">	@Override</div><div class="line">	public void write(DataOutput out) throws IOException &#123;</div><div class="line">		out.writeLong(upFlow);</div><div class="line">		out.writeLong(downFlow);</div><div class="line">		out.writeLong(sumFlow);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	/**</div><div class="line">	 * 反序列化方法 注意反序列化的顺序和序列化的顺序完全一致</div><div class="line">	 * @param in</div><div class="line">	 * @throws IOException</div><div class="line">	 */</div><div class="line">	@Override</div><div class="line">	public void readFields(DataInput in) throws IOException &#123;</div><div class="line">		upFlow = in.readLong();</div><div class="line">		downFlow = in.readLong();</div><div class="line">		sumFlow = in.readLong();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public String toString() &#123;</div><div class="line">		return upFlow + &quot;\t&quot; + downFlow + &quot;\t&quot; + sumFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public int compareTo(FlowBean o) &#123;</div><div class="line">		// 倒序排列，从大到小</div><div class="line">		return this.sumFlow &gt; o.getSumFlow() ? -1 : 1;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（2）编写mapper</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.sort;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.LongWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line">public class FlowCountSortMapper extends Mapper&lt;LongWritable, Text, FlowBean, Text&gt;&#123;</div><div class="line">	FlowBean bean = new FlowBean();</div><div class="line">	Text v = new Text();</div><div class="line"></div><div class="line">	@Override</div><div class="line">	protected void map(LongWritable key, Text value, Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line"></div><div class="line">		// 1 获取一行</div><div class="line">		String line = value.toString();</div><div class="line">		</div><div class="line">		// 2 截取</div><div class="line">		String[] fields = line.split(&quot;\t&quot;);</div><div class="line">		</div><div class="line">		// 3 封装对象</div><div class="line">		String phoneNbr = fields[0];</div><div class="line">		long upFlow = Long.parseLong(fields[1]);</div><div class="line">		long downFlow = Long.parseLong(fields[2]);</div><div class="line">		</div><div class="line">		bean.set(upFlow, downFlow);</div><div class="line">		v.set(phoneNbr);</div><div class="line">		</div><div class="line">		// 4 输出</div><div class="line">		context.write(bean, v);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（3）编写reducer</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.sort;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line">public class FlowCountSortReducer extends Reducer&lt;FlowBean, Text, Text, FlowBean&gt;&#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	protected void reduce(FlowBean key, Iterable&lt;Text&gt; values, Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		// 循环输出，避免总流量相同情况</div><div class="line">		for (Text text : values) &#123;</div><div class="line">			context.write(text, key);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（4）编写driver</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.sort;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line">public class FlowCountSortDriver &#123;</div><div class="line"></div><div class="line">	public static void main(String[] args) throws ClassNotFoundException, IOException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		// 1 获取配置信息，或者job对象实例</div><div class="line">		Configuration configuration = new Configuration();</div><div class="line">		Job job = Job.getInstance(configuration);</div><div class="line"></div><div class="line">		// 6 指定本程序的jar包所在的本地路径</div><div class="line">		job.setJarByClass(FlowCountSortDriver.class);</div><div class="line"></div><div class="line">		// 2 指定本业务job要使用的mapper/Reducer业务类</div><div class="line">		job.setMapperClass(FlowCountSortMapper.class);</div><div class="line">		job.setReducerClass(FlowCountSortReducer.class);</div><div class="line"></div><div class="line">		// 3 指定mapper输出数据的kv类型</div><div class="line">		job.setMapOutputKeyClass(FlowBean.class);</div><div class="line">		job.setMapOutputValueClass(Text.class);</div><div class="line"></div><div class="line">		// 4 指定最终输出的数据的kv类型</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(FlowBean.class);</div><div class="line"></div><div class="line">		// 5 指定job的输入原始文件所在目录</div><div class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</div><div class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</div><div class="line">		</div><div class="line">		// 7 将job中配置的相关参数，以及job所用的java类所在的jar包， 提交给yarn去运行</div><div class="line">		boolean result = job.waitForCompletion(true);</div><div class="line">		System.exit(result ? 0 : 1);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h5 id="3-2-案例2"><a href="#3-2-案例2" class="headerlink" title="3.2 案例2"></a>3.2 案例2</h5><p>改造案例1的需求</p>
<p>​      <strong>要求每个省份手机号输出的文件中按照总流量内部排序。</strong>（部分排序）</p>
<p>2）做法</p>
<p>在案例1的基础上增加自定义分区类即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.sort;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Partitioner;</div><div class="line"></div><div class="line">public class ProvincePartitioner extends Partitioner&lt;FlowBean, Text&gt; &#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public int getPartition(FlowBean key, Text value, int numPartitions) &#123;</div><div class="line">		</div><div class="line">		// 1 获取手机号码前三位</div><div class="line">		String preNum = value.toString().substring(0, 3);</div><div class="line">		</div><div class="line">		int partition = 4;</div><div class="line">		</div><div class="line">		// 2 根据手机号归属地设置分区</div><div class="line">		if (&quot;136&quot;.equals(preNum)) &#123;</div><div class="line">			partition = 0;</div><div class="line">		&#125;else if (&quot;137&quot;.equals(preNum)) &#123;</div><div class="line">			partition = 1;</div><div class="line">		&#125;else if (&quot;138&quot;.equals(preNum)) &#123;</div><div class="line">			partition = 2;</div><div class="line">		&#125;else if (&quot;139&quot;.equals(preNum)) &#123;</div><div class="line">			partition = 3;</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		return partition;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（2）在驱动类中添加分区类</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">	// 加载自定义分区类</div><div class="line">job.setPartitionerClass(FlowSortPartitioner.class);</div><div class="line">// 设置Reducetask个数</div><div class="line">	job.setNumReduceTasks(5);</div></pre></td></tr></table></figure>
<h3 id="3-4-4-GroupingComparator分组（辅助排序）"><a href="#3-4-4-GroupingComparator分组（辅助排序）" class="headerlink" title="3.4.4 GroupingComparator分组（辅助排序）"></a>3.4.4 GroupingComparator分组（辅助排序）</h3><p>1）对reduce阶段的数据根据某一个或几个字段进行分组。</p>
<p>2）案例</p>
<p>​    求出每一个订单中最贵的商品（GroupingComparator）</p>
<p>1）需求</p>
<p>有如下订单数据</p>
<table>
<thead>
<tr>
<th>订单id</th>
<th>商品id</th>
<th>成交金额</th>
</tr>
</thead>
<tbody>
<tr>
<td>0000001</td>
<td>Pdt_01</td>
<td>222.8</td>
</tr>
<tr>
<td>0000001</td>
<td>Pdt_06</td>
<td>25.8</td>
</tr>
<tr>
<td>0000002</td>
<td>Pdt_03</td>
<td>522.8</td>
</tr>
<tr>
<td>0000002</td>
<td>Pdt_04</td>
<td>122.4</td>
</tr>
<tr>
<td>0000002</td>
<td>Pdt_05</td>
<td>722.4</td>
</tr>
<tr>
<td>0000003</td>
<td>Pdt_01</td>
<td>222.8</td>
</tr>
<tr>
<td>0000003</td>
<td>Pdt_02</td>
<td>33.8</td>
</tr>
</tbody>
</table>
<p>现在需要求出每一个订单中最贵的商品。</p>
<p>2）输入数据</p>
<p>goods.txt</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">0000001	Pdt_01	222.8</div><div class="line">0000002	Pdt_06	722.4</div><div class="line">0000001	Pdt_05	25.8</div><div class="line">0000003	Pdt_01	222.8</div><div class="line">0000003	Pdt_01	33.8</div><div class="line">0000002	Pdt_03	522.8</div><div class="line">0000002	Pdt_04	122.4</div></pre></td></tr></table></figure>
<p>输出数据预期：</p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/clip_image004.png" alt="img">  <img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/clip_image006.png" alt="img">  <img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/clip_image008.png" alt="img"></p>
<p>​      3        222.8                2    722.4                 1        222.8</p>
<p>3）分析</p>
<p>（1）利用“订单id和成交金额”作为key，可以将map阶段读取到的所有订单数据按照id分区，按照金额排序，发送到reduce。</p>
<p>（2）在reduce端利用groupingcomparator将订单id相同的kv聚合成组，然后取第一个即是最大值。</p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/15.png" alt="1560776918628"></p>
<p>4）代码实现</p>
<p>（1）定义订单信息OrderBean</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.order;</div><div class="line">import java.io.DataInput;</div><div class="line">import java.io.DataOutput;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.WritableComparable;</div><div class="line"></div><div class="line">public class OrderBean implements WritableComparable&lt;OrderBean&gt; &#123;</div><div class="line"></div><div class="line">	private int order_id; // 订单id号</div><div class="line">	private double price; // 价格</div><div class="line"></div><div class="line">	public OrderBean() &#123;</div><div class="line">		super();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public OrderBean(int order_id, double price) &#123;</div><div class="line">		super();</div><div class="line">		this.order_id = order_id;</div><div class="line">		this.price = price;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public void write(DataOutput out) throws IOException &#123;</div><div class="line">		out.writeInt(order_id);</div><div class="line">		out.writeDouble(price);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public void readFields(DataInput in) throws IOException &#123;</div><div class="line">		order_id = in.readInt();</div><div class="line">		price = in.readDouble();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public String toString() &#123;</div><div class="line">		return order_id + &quot;\t&quot; + price;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public int getOrder_id() &#123;</div><div class="line">		return order_id;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setOrder_id(int order_id) &#123;</div><div class="line">		this.order_id = order_id;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public double getPrice() &#123;</div><div class="line">		return price;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setPrice(double price) &#123;</div><div class="line">		this.price = price;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	// 二次排序</div><div class="line">	@Override</div><div class="line">	public int compareTo(OrderBean o) &#123;</div><div class="line"></div><div class="line">		int result;</div><div class="line"></div><div class="line">		if (order_id &gt; o.getOrder_id()) &#123;</div><div class="line">			result = 1;</div><div class="line">		&#125; else if (order_id &lt; o.getOrder_id()) &#123;</div><div class="line">			result = -1;</div><div class="line">		&#125; else &#123;</div><div class="line">			// 价格倒序排序</div><div class="line">			result = price &gt; o.getPrice() ? -1 : 1;</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		return result;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（2）编写OrderSortMapper</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.order;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.LongWritable;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line">public class OrderMapper extends Mapper&lt;LongWritable, Text, OrderBean, NullWritable&gt; &#123;</div><div class="line">	OrderBean k = new OrderBean();</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		// 1 获取一行</div><div class="line">		String line = value.toString();</div><div class="line">		</div><div class="line">		// 2 截取</div><div class="line">		String[] fields = line.split(&quot;\t&quot;);</div><div class="line">		</div><div class="line">		// 3 封装对象</div><div class="line">		k.setOrder_id(Integer.parseInt(fields[0]));</div><div class="line">		k.setPrice(Double.parseDouble(fields[2]));</div><div class="line">		</div><div class="line">		// 4 写出</div><div class="line">		context.write(k, NullWritable.get());</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（3）编写OrderSortPartitioner</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.order;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.mapreduce.Partitioner;</div><div class="line"></div><div class="line">public class OrderPartitioner extends Partitioner&lt;OrderBean, NullWritable&gt; &#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public int getPartition(OrderBean key, NullWritable value, int numReduceTasks) &#123;</div><div class="line">		</div><div class="line">		return (key.getOrder_id() &amp; Integer.MAX_VALUE) % numReduceTasks;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（4）编写OrderSortGroupingComparator</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.order;</div><div class="line">import org.apache.hadoop.io.WritableComparable;</div><div class="line">import org.apache.hadoop.io.WritableComparator;</div><div class="line"></div><div class="line">public class OrderGroupingComparator extends WritableComparator &#123;</div><div class="line"></div><div class="line">	protected OrderGroupingComparator() &#123; //可以查看super的源代码，true是必须要传的，否则汇报空指针，因为我们在下面的compare方法中使用了强转的操作，那么如果不注明比较的bean的类型，那么就会有问题。</div><div class="line">		super(OrderBean.class, true);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@SuppressWarnings(&quot;rawtypes&quot;)</div><div class="line">	@Override</div><div class="line">	public int compare(WritableComparable a, WritableComparable b) &#123;</div><div class="line"></div><div class="line">		OrderBean aBean = (OrderBean) a;</div><div class="line">		OrderBean bBean = (OrderBean) b;</div><div class="line"></div><div class="line">		int result;</div><div class="line">		if (aBean.getOrder_id() &gt; bBean.getOrder_id()) &#123;</div><div class="line">			result = 1;</div><div class="line">		&#125; else if (aBean.getOrder_id() &lt; bBean.getOrder_id()) &#123;</div><div class="line">			result = -1;</div><div class="line">		&#125; else &#123;</div><div class="line">			result = 0;</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		return result;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（5）编写OrderSortReducer</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.order;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line">public class OrderReducer extends Reducer&lt;OrderBean, NullWritable, OrderBean, NullWritable&gt; &#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	protected void reduce(OrderBean key, Iterable&lt;NullWritable&gt; values, Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		context.write(key, NullWritable.get());</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（6）编写OrderSortDriver</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.order;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line">public class OrderDriver &#123;</div><div class="line"></div><div class="line">	public static void main(String[] args) throws Exception, IOException &#123;</div><div class="line"></div><div class="line">		// 1 获取配置信息</div><div class="line">		Configuration conf = new Configuration();</div><div class="line">		Job job = Job.getInstance(conf);</div><div class="line"></div><div class="line">		// 2 设置jar包加载路径</div><div class="line">		job.setJarByClass(OrderDriver.class);</div><div class="line"></div><div class="line">		// 3 加载map/reduce类</div><div class="line">		job.setMapperClass(OrderMapper.class);</div><div class="line">		job.setReducerClass(OrderReducer.class);</div><div class="line"></div><div class="line">		// 4 设置map输出数据key和value类型</div><div class="line">		job.setMapOutputKeyClass(OrderBean.class);</div><div class="line">		job.setMapOutputValueClass(NullWritable.class);</div><div class="line"></div><div class="line">		// 5 设置最终输出数据的key和value类型</div><div class="line">		job.setOutputKeyClass(OrderBean.class);</div><div class="line">		job.setOutputValueClass(NullWritable.class);</div><div class="line"></div><div class="line">		// 6 设置输入数据和输出数据路径</div><div class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</div><div class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</div><div class="line"></div><div class="line">		// 10 设置reduce端的分组</div><div class="line">		job.setGroupingComparatorClass(OrderGroupingComparator.class);</div><div class="line"></div><div class="line">		// 7 设置分区</div><div class="line">		job.setPartitionerClass(OrderPartitioner.class);</div><div class="line"></div><div class="line">		// 8 设置reduce个数</div><div class="line">		job.setNumReduceTasks(3);</div><div class="line"></div><div class="line">		// 9 提交</div><div class="line">		boolean result = job.waitForCompletion(true);</div><div class="line">		System.exit(result ? 0 : 1);</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">//如果不使用GroupingComparator方法，那么就无法实现功能，因为我们知道进入reduce的数据，他们key一定是一样的。那么上面的OrderBean作为key很明显是不一样的，就算order_id相同，但是他们的price不相同。那么GroupingComparator就可以帮我们做到，假设某个值是相同的，那么他就认为整个key是相同的。那么OrderBean作为key就可以分组处理</div><div class="line"></div><div class="line">也就是说，我们通过在GroupingComparator方法中指明了，相同key的规则，那么就可以实现进入reduce的数据的分组情况</div><div class="line"></div><div class="line">尖叫提示：</div><div class="line">   Map阶段结束后，马上进入GroupingComparator方法，进行判断key的逻辑。每判断一次完后，就调用reduce一次。循环此操作直到数据统计结束。</div><div class="line">   在进入GroupingComparator之前，map阶段输出的数据，已经按照订单分区，分区内的价格也已经按照大到小排序。</div></pre></td></tr></table></figure>
<h3 id="3-4-5-Combiner合并"><a href="#3-4-5-Combiner合并" class="headerlink" title="3.4.5 Combiner合并"></a>3.4.5 Combiner合并</h3><p>1）combiner是MR程序中Mapper和Reducer之外的一种组件。</p>
<p>2）combiner组件的父类就是Reducer。</p>
<p>3）combiner和reducer的区别在于运行的位置：</p>
<p>Combiner是在每一个maptask所在的节点运行;</p>
<p>Reducer是接收全局所有Mapper的输出结果；</p>
<p>4）combiner的意义就是对每一个maptask的输出进行局部汇总，以减小网络传输量。</p>
<p>5）<strong>combiner能够应用的前提是不能影响最终的业务逻辑</strong>，而且，combiner的输出kv应该跟reducer的输入kv类型要对应起来。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">Mapper</div><div class="line">3 5 7 -&gt;(3+5+7)/3=5 </div><div class="line">2 6 -&gt;(2+6)/2=4</div><div class="line">Reducer</div><div class="line">(3+5+7+2+6)/5=23/5    不等于    (5+4)/2=9/2</div></pre></td></tr></table></figure>
<p>很明显，combiner不适合做求平均值这样的操作。他适合做汇总这样的业务场景。</p>
<p>6）自定义Combiner实现步骤：</p>
<p>（1）自定义一个combiner继承Reducer，重写reduce方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">public class WordcountCombiner extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt;&#123;</div><div class="line">	@Override</div><div class="line">	protected void reduce(Text key, Iterable&lt;IntWritable&gt; values,</div><div class="line">			Context context) throws IOException, InterruptedException &#123;</div><div class="line">        // 1 汇总操作</div><div class="line">		int count = 0;</div><div class="line">		for(IntWritable v :values)&#123;</div><div class="line">			count = v.get();</div><div class="line">		&#125;</div><div class="line">        // 2 写出</div><div class="line">		context.write(key, new IntWritable(count));</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（2）在job驱动类中设置：  </p>
<p>   job.setCombinerClass(WordcountCombiner.class);   </p>
<p>7）案例</p>
<p>​       前提：结合&lt;<strong>hadoop大数据(十)-Mapreduce基础 的 1.5 4） 章节–统计一堆文件中单词出现的个数</strong>&gt; 代码</p>
<p>数据输入也是同上</p>
<p>​       需求：统计过程中对每一个maptask的输出进行局部汇总，以减小网络传输量即采用Combiner功能。</p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/560777243680.png" alt="1560777243680"></p>
<p><strong>方案一</strong></p>
<p>1）增加一个WordcountCombiner类继承Reducer</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mr.combiner;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.IntWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line">public class WordcountCombiner extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt;&#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	protected void reduce(Text key, Iterable&lt;IntWritable&gt; values,</div><div class="line">			Context context) throws IOException, InterruptedException &#123;</div><div class="line">        // 1 汇总</div><div class="line">		int count = 0;</div><div class="line">		for(IntWritable v :values)&#123;</div><div class="line">			count += v.get();</div><div class="line">		&#125;</div><div class="line">		// 2 写出</div><div class="line">		context.write(key, new IntWritable(count));</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>   // 9 指定需要使用combiner，以及用哪个类作为combiner的逻辑   job.setCombinerClass(WordcountCombiner.class);   </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">// 9 指定需要使用combiner，以及用哪个类作为combiner的逻辑</div><div class="line">job.setCombinerClass(WordcountCombiner.class);</div></pre></td></tr></table></figure>
<p><strong>方案二</strong></p>
<p>1）将WordcountReducer作为combiner在WordcountDriver驱动类中指定</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">// 指定需要使用combiner，以及用哪个类作为combiner的逻辑</div><div class="line">job.setCombinerClass(WordcountReducer.class);</div></pre></td></tr></table></figure>
<p>运行程序</p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/8787878.png" alt="1560777579011"></p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/777616071.png" alt="1560777616071"></p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>自定义Combiner的调用时机：是在MapTask阶段的split溢写阶段，需要写入到磁盘的之前进行。<strong>将有相同</strong> <strong>key</strong> <strong>的</strong> <strong>key/value</strong> <strong>对的</strong> <strong>value</strong> <strong>加起来，减少溢写到磁盘的数据量。调用完后进入**</strong>reduce<strong>**方法</strong></p>
<p>​     </p>
<h2 id="3-5-ReduceTask工作机制"><a href="#3-5-ReduceTask工作机制" class="headerlink" title="3.5 ReduceTask工作机制"></a>3.5 ReduceTask工作机制</h2><p>1）设置ReduceTask并行度（个数）</p>
<p>reducetask的并行度同样影响整个job的执行并发度和执行效率，<strong>但与maptask的并发数由切片数决定不同</strong>，Reducetask数量的决定是可以直接手动设置：</p>
<p>   //默认值是1，手动设置为4   job.setNumReduceTasks(4);   </p>
<p>2）注意</p>
<p>（1）reducetask=0 ，表示没有reduce阶段，输出文件个数和map个数一致。</p>
<p>​     例子7.1.1    job.setNumReduceTasks(0); 输出</p>
<p>  <img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/10.png" alt=""></p>
<p>​      生成一个分区，但是分区内的单词没有汇总</p>
<p>​         （2）reducetask默认值就是1，所以输出文件个数为一个。</p>
<p>（3）如果数据分布不均匀，就有可能在reduce阶段产生数据倾斜（<strong>也就是说，相同key被partition分配到一个分区里,造成了’一个人累死,其他人闲死’的情况</strong>）</p>
<p>（4）reducetask数量并不是任意设置，还要考虑业务逻辑需求，有些情况下，需要计算全局汇总结果，就只能有1个reducetask。</p>
<p>（5）具体多少个reducetask，需要根据集群性能而定。</p>
<p>（6）如果分区数不是1，但是reducetask为1，是否执行分区过程。答案是：不执行分区过程。因为在maptask的源码中，执行分区的前提是先判断reduceNum个数是否大于1。不大于1肯定不执行。</p>
<p>3）实验：测试reducetask多少合适。</p>
<p>（1）实验环境：1个master节点，16个slave节点：CPU:8GHZ，内存: 2G</p>
<p>（2）实验结论：</p>
<p>​                            表1 改变reduce task （数据量为1GB）</p>
<table>
<thead>
<tr>
<th>Map task =16</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Reduce task</td>
<td>1</td>
<td>5</td>
<td>10</td>
<td>15</td>
<td>16</td>
<td>20</td>
<td>25</td>
<td>30</td>
<td>45</td>
<td>60</td>
</tr>
<tr>
<td>总时间</td>
<td>892</td>
<td>146</td>
<td>110</td>
<td>92</td>
<td>88</td>
<td>100</td>
<td>128</td>
<td>101</td>
<td>145</td>
<td>104</td>
</tr>
</tbody>
</table>
<p>4）ReduceTask工作机制</p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/12.png" alt="1560702180711"></p>
<p>​         （1）Copy阶段：ReduceTask从各个MapTask上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</p>
<p>​         （2）Merge阶段：在远程拷贝数据的同时，ReduceTask启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。</p>
<p>​         （3）Sort阶段：按照MapReduce语义，用户编写reduce()函数输入数据是按key进行聚集的一组数据。为了将key相同的数据聚在一起，Hadoop采用了基于排序的策略。由于各个MapTask已经实现对自己的处理结果进行了局部排序，因此，ReduceTask只需对所有数据进行一次归并排序即可。</p>
<p>​         （4）Reduce阶段：reduce()函数将计算结果写到HDFS上。</p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/13.png" alt=""></p>
<h2 id="3-6-OutputFormat数据输出"><a href="#3-6-OutputFormat数据输出" class="headerlink" title="3.6 OutputFormat数据输出"></a>3.6 OutputFormat数据输出</h2><h3 id="3-6-1-OutputFormat接口实现类"><a href="#3-6-1-OutputFormat接口实现类" class="headerlink" title="3.6.1 OutputFormat接口实现类"></a>3.6.1 OutputFormat接口实现类</h3><p> OutputFormat是MapReduce输出的基类，所有实现MapReduce输出都实现了 OutputFormat接口。下面我们介绍几种常见的OutputFormat实现类。</p>
<p>1）文本输出TextOutputFormat</p>
<p>​        默认的输出格式是TextOutputFormat，它把每条记录写为文本行。它的键和值可以是任意类型，因为TextOutputFormat调用toString()方法把它们转换为字符串。</p>
<p>2）SequenceFileOutputFormat</p>
<p> SequenceFileOutputFormat将它的输出写为一个顺序文件。如果输出需要作为后续 MapReduce任务的输入，这便是一种好的输出格式，因为它的格式紧凑，很容易被压缩。</p>
<p>3）自定义OutputFormat</p>
<p>​         根据用户需求，自定义实现输出。</p>
<h3 id="3-6-2-自定义OutputFormat"><a href="#3-6-2-自定义OutputFormat" class="headerlink" title="3.6.2 自定义OutputFormat"></a>3.6.2 自定义OutputFormat</h3><p>为了实现控制最终文件的输出路径，可以自定义OutputFormat。</p>
<p>要在一个mapreduce程序中根据数据的不同输出两类结果到不同目录，这类灵活的输出需求可以通过自定义outputformat来实现。</p>
<h4 id="1）自定义OutputFormat步骤"><a href="#1）自定义OutputFormat步骤" class="headerlink" title="1）自定义OutputFormat步骤"></a>1）自定义OutputFormat步骤</h4><p>（1）自定义一个类继承FileOutputFormat。</p>
<p>（2）改写recordwriter，具体改写输出数据的方法write()。</p>
<h4 id="2）案例-1"><a href="#2）案例-1" class="headerlink" title="2）案例"></a>2）案例</h4><p>​       修改日志内容及自定义日志输出路径（自定义OutputFormat）。</p>
<p>1）需求</p>
<p>​         过滤输入的log日志中是否包含kingge</p>
<p>​         （1）包含kingge的网站输出到e:/kingge.log</p>
<p>​         （2）不包含kingge的网站输出到e:/other.log</p>
<p>2）输入数据（pp.txt）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">http://www.baidu.com</div><div class="line">http://www.google.com</div><div class="line">http://cn.bing.com</div><div class="line">http://www.kingge.com</div><div class="line">http://www.sohu.com</div><div class="line">http://www.sina.com</div><div class="line">http://www.sin2a.com</div><div class="line">http://www.sin2desa.com</div><div class="line">http://www.sindsafa.com</div></pre></td></tr></table></figure>
<p>输出预期：</p>
<blockquote>
<p>kingge.log文件包含： <strong><a href="http://www.kingge.com" target="_blank" rel="external">http://www.kingge.com</a></strong> </p>
<p>other.log文件包含：</p>
<p><a href="http://cn.bing.com" target="_blank" rel="external">http://cn.bing.com</a><br><a href="http://www.baidu.com" target="_blank" rel="external">http://www.baidu.com</a><br><a href="http://www.google.com" target="_blank" rel="external">http://www.google.com</a><br><a href="http://www.sin2a.com" target="_blank" rel="external">http://www.sin2a.com</a><br><a href="http://www.sin2desa.com" target="_blank" rel="external">http://www.sin2desa.com</a><br><a href="http://www.sina.com" target="_blank" rel="external">http://www.sina.com</a><br><a href="http://www.sindsafa.com" target="_blank" rel="external">http://www.sindsafa.com</a><br><a href="http://www.sohu.com" target="_blank" rel="external">http://www.sohu.com</a></p>
</blockquote>
<p>3）代码实现：</p>
<p>（1）自定义一个outputformat</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.outputformat;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.RecordWriter;</div><div class="line">import org.apache.hadoop.mapreduce.TaskAttemptContext;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line">public class FilterOutputFormat extends FileOutputFormat&lt;Text, NullWritable&gt;&#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public RecordWriter&lt;Text, NullWritable&gt; getRecordWriter(TaskAttemptContext job)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line"></div><div class="line">		// 创建一个RecordWriter</div><div class="line">		return new FilterRecordWriter(job);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（2）具体的写数据RecordWriter</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.outputformat;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.fs.FSDataOutputStream;</div><div class="line">import org.apache.hadoop.fs.FileSystem;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.RecordWriter;</div><div class="line">import org.apache.hadoop.mapreduce.TaskAttemptContext;</div><div class="line"></div><div class="line">public class FilterRecordWriter extends RecordWriter&lt;Text, NullWritable&gt; &#123;</div><div class="line">	FSDataOutputStream kinggeOut = null;</div><div class="line">	FSDataOutputStream otherOut = null;</div><div class="line"></div><div class="line">	public FilterRecordWriter(TaskAttemptContext job) &#123;</div><div class="line">		// 1 获取文件系统</div><div class="line">		FileSystem fs;</div><div class="line"></div><div class="line">		try &#123;</div><div class="line">			fs = FileSystem.get(job.getConfiguration());</div><div class="line"></div><div class="line">			// 2 创建输出文件路径</div><div class="line">			Path kinggePath = new Path(&quot;e:/kingge.log&quot;);</div><div class="line">			Path otherPath = new Path(&quot;e:/other.log&quot;);</div><div class="line"></div><div class="line">			// 3 创建输出流</div><div class="line">			kinggeOut = fs.create(kinggePath);</div><div class="line">			otherOut = fs.create(otherPath);</div><div class="line">		&#125; catch (IOException e) &#123;</div><div class="line">			e.printStackTrace();</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public void write(Text key, NullWritable value) throws IOException, InterruptedException &#123;</div><div class="line"></div><div class="line">		// 判断是否包含“kingge”输出到不同文件</div><div class="line">		if (key.toString().contains(&quot;kingge&quot;)) &#123;</div><div class="line">			kinggeOut.write(key.toString().getBytes());</div><div class="line">		&#125; else &#123;</div><div class="line">			otherOut.write(key.toString().getBytes());</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public void close(TaskAttemptContext context) throws IOException, InterruptedException &#123;</div><div class="line">		// 关闭资源</div><div class="line">		if (kinggeOut != null) &#123;</div><div class="line">			kinggeOut.close();</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		if (otherOut != null) &#123;</div><div class="line">			otherOut.close();</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（3）编写FilterMapper</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.outputformat;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.LongWritable;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line">public class FilterMapper extends Mapper&lt;LongWritable, Text, Text, NullWritable&gt;&#123;</div><div class="line">	</div><div class="line">	Text k = new Text();</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	protected void map(LongWritable key, Text value, Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		// 1 获取一行</div><div class="line">		String line = value.toString();</div><div class="line">		</div><div class="line">		k.set(line);</div><div class="line">		</div><div class="line">		// 3 写出</div><div class="line">		context.write(k, NullWritable.get());</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（4）编写FilterReducer</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.outputformat;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line">public class FilterReducer extends Reducer&lt;Text, NullWritable, Text, NullWritable&gt; &#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	protected void reduce(Text key, Iterable&lt;NullWritable&gt; values, Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line"></div><div class="line">		String k = key.toString();</div><div class="line">		k = k + &quot;\r\n&quot;;</div><div class="line"></div><div class="line">		context.write(new Text(k), NullWritable.get());</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（5）编写FilterDriver</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.outputformat;</div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line">public class FilterDriver &#123;</div><div class="line">	public static void main(String[] args) throws Exception &#123;</div><div class="line"></div><div class="line">args = new String[] &#123; &quot;e:/input/inputoutputformat&quot;, &quot;e:/output2&quot; &#125;;</div><div class="line"></div><div class="line">		Configuration conf = new Configuration();</div><div class="line"></div><div class="line">		Job job = Job.getInstance(conf);</div><div class="line"></div><div class="line">		job.setJarByClass(FilterDriver.class);</div><div class="line">		job.setMapperClass(FilterMapper.class);</div><div class="line">		job.setReducerClass(FilterReducer.class);</div><div class="line"></div><div class="line">		job.setMapOutputKeyClass(Text.class);</div><div class="line">		job.setMapOutputValueClass(NullWritable.class);</div><div class="line">		</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(NullWritable.class);</div><div class="line"></div><div class="line">		// 要将自定义的输出格式组件设置到job中</div><div class="line">		job.setOutputFormatClass(FilterOutputFormat.class);</div><div class="line"></div><div class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</div><div class="line"></div><div class="line">		// 虽然我们自定义了outputformat，但是因为我们的outputformat继承自fileoutputformat</div><div class="line">		// 而fileoutputformat要输出一个_SUCCESS文件，所以，在这还得指定一个输出目录</div><div class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</div><div class="line"></div><div class="line">		boolean result = job.waitForCompletion(true);</div><div class="line">		System.exit(result ? 0 : 1);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="3-7-Join多种应用"><a href="#3-7-Join多种应用" class="headerlink" title="3.7 Join多种应用"></a>3.7 Join多种应用</h2><h3 id="3-7-1-Reduce-join"><a href="#3-7-1-Reduce-join" class="headerlink" title="3.7.1 Reduce join"></a>3.7.1 Reduce join</h3><p><strong>1）原理：</strong></p>
<p>Map端的主要工作：为来自不同表(文件)的key/value对打标签以区别不同来源的记录。然后用连接字段作为key，其余部分和新加的标志作为value，最后进行输出。</p>
<p>Reduce端的主要工作：在reduce端以连接字段作为key的分组已经完成，我们只需要在每一个分组当中将那些来源于不同文件的记录(在map阶段已经打标志)分开，最后进行合并就ok了。</p>
<p><strong>2）该方法的缺点</strong></p>
<p><strong>这种方式的缺点很明显就是会造成map和reduce端也就是shuffle阶段出现大量的数据传输，效率很低。</strong></p>
<h4 id="3）案例-1"><a href="#3）案例-1" class="headerlink" title="3）案例"></a><strong>3）案例</strong></h4><p>​      reduce端表合并（数据倾斜）</p>
<p>通过将关联条件作为map输出的key，将两表满足join条件的数据并携带数据所来源的文件信息，发往同一个reduce<br>task，在reduce中进行数据的串联。</p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/16.png" alt="1560778194940"></p>
<p>1）代码实现</p>
<p>​    1.1 创建商品和订合并后的bean类</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.table;</div><div class="line">import java.io.DataInput;</div><div class="line">import java.io.DataOutput;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.Writable;</div><div class="line"></div><div class="line">public class TableBean implements Writable &#123;</div><div class="line">	private String order_id; // 订单id</div><div class="line">	private String p_id; // 产品id</div><div class="line">	private int amount; // 产品数量</div><div class="line">	private String pname; // 产品名称</div><div class="line">	private String flag;// 表的标记</div><div class="line"></div><div class="line">	public TableBean() &#123;</div><div class="line">		super();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public TableBean(String order_id, String p_id, int amount, String pname, String flag) &#123;</div><div class="line">		super();</div><div class="line">		this.order_id = order_id;</div><div class="line">		this.p_id = p_id;</div><div class="line">		this.amount = amount;</div><div class="line">		this.pname = pname;</div><div class="line">		this.flag = flag;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public String getFlag() &#123;</div><div class="line">		return flag;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setFlag(String flag) &#123;</div><div class="line">		this.flag = flag;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public String getOrder_id() &#123;</div><div class="line">		return order_id;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setOrder_id(String order_id) &#123;</div><div class="line">		this.order_id = order_id;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public String getP_id() &#123;</div><div class="line">		return p_id;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setP_id(String p_id) &#123;</div><div class="line">		this.p_id = p_id;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public int getAmount() &#123;</div><div class="line">		return amount;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setAmount(int amount) &#123;</div><div class="line">		this.amount = amount;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public String getPname() &#123;</div><div class="line">		return pname;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setPname(String pname) &#123;</div><div class="line">		this.pname = pname;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public void write(DataOutput out) throws IOException &#123;</div><div class="line">		out.writeUTF(order_id);</div><div class="line">		out.writeUTF(p_id);</div><div class="line">		out.writeInt(amount);</div><div class="line">		out.writeUTF(pname);</div><div class="line">		out.writeUTF(flag);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public void readFields(DataInput in) throws IOException &#123;</div><div class="line">		this.order_id = in.readUTF();</div><div class="line">		this.p_id = in.readUTF();</div><div class="line">		this.amount = in.readInt();</div><div class="line">		this.pname = in.readUTF();</div><div class="line">		this.flag = in.readUTF();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public String toString() &#123;</div><div class="line">		return order_id + &quot;\t&quot; + pname + &quot;\t&quot; + amount + &quot;\t&quot; ;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>2）编写TableMapper程序</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.table;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.LongWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileSplit;</div><div class="line"></div><div class="line">public class TableMapper extends Mapper&lt;LongWritable, Text, Text, TableBean&gt;&#123;</div><div class="line">	TableBean bean = new TableBean();</div><div class="line">	Text k = new Text();</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	protected void map(LongWritable key, Text value, Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		// 1 获取输入文件类型</div><div class="line">		FileSplit split = (FileSplit) context.getInputSplit();</div><div class="line">		String name = split.getPath().getName();</div><div class="line">		</div><div class="line">		// 2 获取输入数据</div><div class="line">		String line = value.toString();</div><div class="line">		</div><div class="line">		// 3 不同文件分别处理</div><div class="line">		if (name.startsWith(&quot;order&quot;)) &#123;// 订单表处理</div><div class="line">			// 3.1 切割</div><div class="line">			String[] fields = line.split(&quot;\t&quot;);</div><div class="line">			</div><div class="line">			// 3.2 封装bean对象</div><div class="line">			bean.setOrder_id(fields[0]);</div><div class="line">			bean.setP_id(fields[1]);</div><div class="line">			bean.setAmount(Integer.parseInt(fields[2]));</div><div class="line">			bean.setPname(&quot;&quot;);</div><div class="line">			bean.setFlag(&quot;0&quot;);</div><div class="line">			</div><div class="line">			k.set(fields[1]);</div><div class="line">		&#125;else &#123;// 产品表处理</div><div class="line">			// 3.3 切割</div><div class="line">			String[] fields = line.split(&quot;\t&quot;);</div><div class="line">			</div><div class="line">			// 3.4 封装bean对象</div><div class="line">			bean.setP_id(fields[0]);</div><div class="line">			bean.setPname(fields[1]);</div><div class="line">			bean.setFlag(&quot;1&quot;);</div><div class="line">			bean.setAmount(0);</div><div class="line">			bean.setOrder_id(&quot;&quot;);</div><div class="line">			</div><div class="line">			k.set(fields[0]);</div><div class="line">		&#125;</div><div class="line">		// 4 写出</div><div class="line">		context.write(k, bean);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>3）编写TableReducer程序</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.table;</div><div class="line">import java.io.IOException;</div><div class="line">import java.util.ArrayList;</div><div class="line">import org.apache.commons.beanutils.BeanUtils;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line">public class TableReducer extends Reducer&lt;Text, TableBean, TableBean, NullWritable&gt; &#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	protected void reduce(Text key, Iterable&lt;TableBean&gt; values, Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line"></div><div class="line">		// 1准备存储订单的集合</div><div class="line">		ArrayList&lt;TableBean&gt; orderBeans = new ArrayList&lt;&gt;();</div><div class="line">		// 2 准备bean对象</div><div class="line">		TableBean pdBean = new TableBean();</div><div class="line"></div><div class="line">		for (TableBean bean : values) &#123;</div><div class="line"></div><div class="line">			if (&quot;0&quot;.equals(bean.getFlag())) &#123;// 订单表</div><div class="line">				// 拷贝传递过来的每条订单数据到集合中</div><div class="line">				TableBean orderBean = new TableBean();</div><div class="line">				try &#123;</div><div class="line">					BeanUtils.copyProperties(orderBean, bean);</div><div class="line">				&#125; catch (Exception e) &#123;</div><div class="line">					e.printStackTrace();</div><div class="line">				&#125;</div><div class="line"></div><div class="line">				orderBeans.add(orderBean);</div><div class="line">			&#125; else &#123;// 产品表</div><div class="line">				try &#123;</div><div class="line">					// 拷贝传递过来的产品表到内存中</div><div class="line">					BeanUtils.copyProperties(pdBean, bean);</div><div class="line">				&#125; catch (Exception e) &#123;</div><div class="line">					e.printStackTrace();</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		// 3 表的拼接</div><div class="line">		for(TableBean bean:orderBeans)&#123;</div><div class="line">			bean.setPname (pdBean.getPname());</div><div class="line">			</div><div class="line">			// 4 数据写出去</div><div class="line">			context.write(bean, NullWritable.get());</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>4）编写TableDriver程序</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.table;</div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line">public class TableDriver &#123;</div><div class="line"></div><div class="line">	public static void main(String[] args) throws Exception &#123;</div><div class="line">		// 1 获取配置信息，或者job对象实例</div><div class="line">		Configuration configuration = new Configuration();</div><div class="line">		Job job = Job.getInstance(configuration);</div><div class="line"></div><div class="line">		// 2 指定本程序的jar包所在的本地路径</div><div class="line">		job.setJarByClass(TableDriver.class);</div><div class="line"></div><div class="line">		// 3 指定本业务job要使用的mapper/Reducer业务类</div><div class="line">		job.setMapperClass(TableMapper.class);</div><div class="line">		job.setReducerClass(TableReducer.class);</div><div class="line"></div><div class="line">		// 4 指定mapper输出数据的kv类型</div><div class="line">		job.setMapOutputKeyClass(Text.class);</div><div class="line">		job.setMapOutputValueClass(TableBean.class);</div><div class="line"></div><div class="line">		// 5 指定最终输出的数据的kv类型</div><div class="line">		job.setOutputKeyClass(TableBean.class);</div><div class="line">		job.setOutputValueClass(NullWritable.class);</div><div class="line"></div><div class="line">		// 6 指定job的输入原始文件所在目录</div><div class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</div><div class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</div><div class="line"></div><div class="line">		// 7 将job中配置的相关参数，以及job所用的java类所在的jar包， 提交给yarn去运行</div><div class="line">		boolean result = job.waitForCompletion(true);</div><div class="line">		System.exit(result ? 0 : 1);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>3）运行程序查看结果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">1001	小米	1	</div><div class="line">1001	小米	1	</div><div class="line">1002	华为	2	</div><div class="line">1002	华为	2	</div><div class="line">1003	格力	3	</div><div class="line">1003	格力	3</div></pre></td></tr></table></figure>
<p><strong>缺点：这种方式中，合并的操作是在reduce阶段完成，reduce端的处理压力太大，map节点的运算负载则很低，资源利用率不高，且在reduce阶段极易产生数据倾斜</strong></p>
<p><strong>解决方案： map端实现数据合并</strong></p>
<h3 id="3-7-2-Map-join（Distributedcache分布式缓存）"><a href="#3-7-2-Map-join（Distributedcache分布式缓存）" class="headerlink" title="3.7.2 Map join（Distributedcache分布式缓存）"></a>3.7.2 Map join（Distributedcache分布式缓存）</h3><p>1）使用场景：一张表十分小、一张表很大。</p>
<p>2）解决方案</p>
<p>在map端缓存多张表，提前处理业务逻辑，这样增加map端业务，减少reduce端数据的压力，尽可能的减少数据倾斜。</p>
<p>3）具体办法：采用distributedcache</p>
<p>​         （1）在mapper的setup阶段，将文件读取到缓存集合中。</p>
<p>​         （2）在驱动函数中加载缓存。</p>
<p>job.addCacheFile(new URI(“file:/e:/mapjoincache/pd.txt”));// 缓存普通文件到task运行节点</p>
<h4 id="4）案例："><a href="#4）案例：" class="headerlink" title="4）案例："></a>4）案例：</h4><p>​            map端表合并（Distributedcache）  - 结合上个案例代码（3.7.1 3 案例）</p>
<p>1）分析</p>
<p>适用于关联表中有小表的情形；</p>
<p>可以将小表分发到所有的map节点，这样，map节点就可以在本地对自己所读到的大表数据进行合并并输出最终结果，可以大大提高合并操作的并发度，加快处理速度。</p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/17.png" alt="1560778526618"></p>
<p>2）实操案例</p>
<p>（1）先在驱动模块中添加缓存文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package test;</div><div class="line">import java.net.URI;</div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line">public class DistributedCacheDriver &#123;</div><div class="line"></div><div class="line">	public static void main(String[] args) throws Exception &#123;</div><div class="line">		// 1 获取job信息</div><div class="line">		Configuration configuration = new Configuration();</div><div class="line">		Job job = Job.getInstance(configuration);</div><div class="line"></div><div class="line">		// 2 设置加载jar包路径</div><div class="line">		job.setJarByClass(DistributedCacheDriver.class);</div><div class="line"></div><div class="line">		// 3 关联map</div><div class="line">		job.setMapperClass(DistributedCacheMapper.class);</div><div class="line">		</div><div class="line">		// 4 设置最终输出数据类型</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(NullWritable.class);</div><div class="line"></div><div class="line">		// 5 设置输入输出路径</div><div class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</div><div class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</div><div class="line"></div><div class="line">		// 6 加载缓存数据</div><div class="line">		job.addCacheFile(new URI(&quot;file:///e:/inputcache/pd.txt&quot;));</div><div class="line">		</div><div class="line">		// 7 map端join的逻辑不需要reduce阶段，设置reducetask数量为0</div><div class="line">		job.setNumReduceTasks(0);</div><div class="line"></div><div class="line">		// 8 提交</div><div class="line">		boolean result = job.waitForCompletion(true);</div><div class="line">		System.exit(result ? 0 : 1);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（2）读取缓存的文件数据</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package test;</div><div class="line">import java.io.BufferedReader;</div><div class="line">import java.io.FileInputStream;</div><div class="line">import java.io.IOException;</div><div class="line">import java.io.InputStreamReader;</div><div class="line">import java.util.HashMap;</div><div class="line">import java.util.Map;</div><div class="line">import org.apache.commons.lang.StringUtils;</div><div class="line">import org.apache.hadoop.io.LongWritable;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line">public class DistributedCacheMapper extends Mapper&lt;LongWritable, Text, Text, NullWritable&gt;&#123;</div><div class="line"></div><div class="line">	Map&lt;String, String&gt; pdMap = new HashMap&lt;&gt;();</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	protected void setup(Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line"></div><div class="line">		// 1 获取缓存的文件</div><div class="line">		BufferedReader reader = new BufferedReader(new InputStreamReader(new FileInputStream(&quot;pd.txt&quot;),&quot;UTF-8&quot;));</div><div class="line">		</div><div class="line">		String line;</div><div class="line">		while(StringUtils.isNotEmpty(line = reader.readLine()))&#123;</div><div class="line">			// 2 切割</div><div class="line">			String[] fields = line.split(&quot;\t&quot;);</div><div class="line">			</div><div class="line">			// 3 缓存数据到集合</div><div class="line">			pdMap.put(fields[0], fields[1]);</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		// 4 关流</div><div class="line">		reader.close();</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	Text k = new Text();</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	protected void map(LongWritable key, Text value, Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		// 1 获取一行</div><div class="line">		String line = value.toString();</div><div class="line">		</div><div class="line">		// 2 截取</div><div class="line">		String[] fields = line.split(&quot;\t&quot;);</div><div class="line">		</div><div class="line">		// 3 获取产品id</div><div class="line">		String pId = fields[1];</div><div class="line">		</div><div class="line">		// 4 获取商品名称</div><div class="line">		String pdName = pdMap.get(pId);</div><div class="line">		</div><div class="line">		// 5 拼接</div><div class="line">		k.set(line + &quot;\t&quot;+ pdName);</div><div class="line">		</div><div class="line">		// 6 写出</div><div class="line">		context.write(k, NullWritable.get());</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="3-8-数据清洗（ETL）"><a href="#3-8-数据清洗（ETL）" class="headerlink" title="3.8 数据清洗（ETL）"></a>3.8 数据清洗（ETL）</h2><p>1）概述</p>
<p>在运行核心业务Mapreduce程序之前，往往要先对数据进行清洗，清理掉不符合用户要求的数据。清理的过程往往只需要运行mapper程序，不需要运行reduce程序。</p>
<h4 id="2）案例-2"><a href="#2）案例-2" class="headerlink" title="2）案例"></a>2）案例</h4><p>日志清洗（数据清洗）。</p>
<h5 id="简单解析版"><a href="#简单解析版" class="headerlink" title="简单解析版"></a>简单解析版</h5><p>1）需求：</p>
<p>去除日志中字段长度小于等于11的日志。</p>
<p>2）输入数据</p>
<p><img src="/2018/03/18/hadoop大数据-十一-Mapreduce框架原理/clip_image00772.png" alt="img"></p>
<p>里面的内容就是我们平时网站输出的日志。例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">194.237.142.21 - - [18/Sep/2013:06:49:18 +0000] &quot;GET /wp-content/uploads/2013/07/rstudio-git3.png HTTP/1.1&quot; 304 0 &quot;-&quot; &quot;Mozilla/4.0 (compatible;)&quot;</div><div class="line">183.49.46.228 - - [18/Sep/2013:06:49:23 +0000] &quot;-&quot; 400 0 &quot;-&quot; &quot;-&quot;</div><div class="line">163.177.71.12 - - [18/Sep/2013:06:49:33 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</div><div class="line">163.177.71.12 - - [18/Sep/2013:06:49:36 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</div><div class="line">101.226.68.137 - - [18/Sep/2013:06:49:42 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</div><div class="line">101.226.68.137 - - [18/Sep/2013:06:49:45 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</div><div class="line">60.208.6.156 - - [18/Sep/2013:06:49:48 +0000] &quot;GET /wp-content/uploads/2013/07/rcassandra.png HTTP/1.0&quot; 200 185524 &quot;http://cos.name/category/software/packages/&quot; &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36&quot;</div><div class="line">222.68.172.190 - - [18/Sep/2013:06:49:57 +0000] &quot;GET /images/my.jpg HTTP/1.1&quot; 200 19939 &quot;http://www.angularjs.cn/A00n&quot; &quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.66 Safari/537.36&quot;</div><div class="line">222.68.172.190 - - [18/Sep/2013:06:50:08 +0000] &quot;-&quot; 400 0 &quot;-&quot; &quot;-&quot;</div><div class="line">183.195.232.138 - - [18/Sep/2013:06:50:16 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</div><div class="line">183.195.232.138 - - [18/Sep/2013:06:50:16 +0000] &quot;HEAD / HTTP/1.1&quot; 200 20 &quot;-&quot; &quot;DNSPod-Monitor/1.0&quot;</div></pre></td></tr></table></figure>
<p>3）实现代码：</p>
<p>（1）编写LogMapper </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.weblog;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.LongWritable;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line">public class LogMapper extends Mapper&lt;LongWritable, Text, Text, NullWritable&gt;&#123;</div><div class="line">	</div><div class="line">	Text k = new Text();</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	protected void map(LongWritable key, Text value, Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		// 1 获取1行数据</div><div class="line">		String line = value.toString();</div><div class="line">		</div><div class="line">		// 2 解析日志</div><div class="line">		boolean result = parseLog(line,context);</div><div class="line">		</div><div class="line">		// 3 日志不合法退出</div><div class="line">		if (!result) &#123;</div><div class="line">			return;</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		// 4 设置key</div><div class="line">		k.set(line);</div><div class="line">		</div><div class="line">		// 5 写出数据</div><div class="line">		context.write(k, NullWritable.get());</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	// 2 解析日志</div><div class="line">	private boolean parseLog(String line, Context context) &#123;</div><div class="line">		// 1 截取</div><div class="line">		String[] fields = line.split(&quot; &quot;);</div><div class="line">		</div><div class="line">		// 2 日志长度大于11的为合法</div><div class="line">		if (fields.length &gt; 11) &#123;</div><div class="line">			// 系统计数器</div><div class="line">			context.getCounter(&quot;map&quot;, &quot;true&quot;).increment(1);</div><div class="line">			return true;</div><div class="line">		&#125;else &#123;</div><div class="line">			context.getCounter(&quot;map&quot;, &quot;false&quot;).increment(1);</div><div class="line">			return false;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（2）编写LogDriver</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.weblog;</div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line">public class LogDriver &#123;</div><div class="line"></div><div class="line">	public static void main(String[] args) throws Exception &#123;</div><div class="line"></div><div class="line">        args = new String[] &#123; &quot;e:/input/inputlog&quot;, &quot;e:/output1&quot; &#125;;</div><div class="line"></div><div class="line">		// 1 获取job信息</div><div class="line">		Configuration conf = new Configuration();</div><div class="line">		Job job = Job.getInstance(conf);</div><div class="line"></div><div class="line">		// 2 加载jar包</div><div class="line">		job.setJarByClass(LogDriver.class);</div><div class="line"></div><div class="line">		// 3 关联map</div><div class="line">		job.setMapperClass(LogMapper.class);</div><div class="line"></div><div class="line">		// 4 设置最终输出类型</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(NullWritable.class);</div><div class="line"></div><div class="line">		// 设置reducetask个数为0</div><div class="line">		job.setNumReduceTasks(0);</div><div class="line"></div><div class="line">		// 5 设置输入和输出路径</div><div class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</div><div class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</div><div class="line"></div><div class="line">		// 6 提交</div><div class="line">		job.waitForCompletion(true);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h5 id="复杂解析版"><a href="#复杂解析版" class="headerlink" title="复杂解析版"></a>复杂解析版</h5><p>1）需求：</p>
<p>对web访问日志中的各字段识别切分</p>
<p>去除日志中不合法的记录</p>
<p>根据统计需求，生成各类访问请求过滤数据</p>
<p>2）输入数据</p>
<p>   输入同上一个案例</p>
<p>3）实现代码：</p>
<p>（1）定义一个bean，用来记录日志数据中的各数据字段</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.log;</div><div class="line"></div><div class="line">public class LogBean &#123;</div><div class="line">	private String remote_addr;// 记录客户端的ip地址</div><div class="line">	private String remote_user;// 记录客户端用户名称,忽略属性&quot;-&quot;</div><div class="line">	private String time_local;// 记录访问时间与时区</div><div class="line">	private String request;// 记录请求的url与http协议</div><div class="line">	private String status;// 记录请求状态；成功是200</div><div class="line">	private String body_bytes_sent;// 记录发送给客户端文件主体内容大小</div><div class="line">	private String http_referer;// 用来记录从那个页面链接访问过来的</div><div class="line">	private String http_user_agent;// 记录客户浏览器的相关信息</div><div class="line"></div><div class="line">	private boolean valid = true;// 判断数据是否合法</div><div class="line"></div><div class="line">	public String getRemote_addr() &#123;</div><div class="line">		return remote_addr;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setRemote_addr(String remote_addr) &#123;</div><div class="line">		this.remote_addr = remote_addr;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public String getRemote_user() &#123;</div><div class="line">		return remote_user;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setRemote_user(String remote_user) &#123;</div><div class="line">		this.remote_user = remote_user;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public String getTime_local() &#123;</div><div class="line">		return time_local;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setTime_local(String time_local) &#123;</div><div class="line">		this.time_local = time_local;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public String getRequest() &#123;</div><div class="line">		return request;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setRequest(String request) &#123;</div><div class="line">		this.request = request;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public String getStatus() &#123;</div><div class="line">		return status;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setStatus(String status) &#123;</div><div class="line">		this.status = status;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public String getBody_bytes_sent() &#123;</div><div class="line">		return body_bytes_sent;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setBody_bytes_sent(String body_bytes_sent) &#123;</div><div class="line">		this.body_bytes_sent = body_bytes_sent;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public String getHttp_referer() &#123;</div><div class="line">		return http_referer;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setHttp_referer(String http_referer) &#123;</div><div class="line">		this.http_referer = http_referer;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public String getHttp_user_agent() &#123;</div><div class="line">		return http_user_agent;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setHttp_user_agent(String http_user_agent) &#123;</div><div class="line">		this.http_user_agent = http_user_agent;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public boolean isValid() &#123;</div><div class="line">		return valid;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setValid(boolean valid) &#123;</div><div class="line">		this.valid = valid;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	public String toString() &#123;</div><div class="line">		StringBuilder sb = new StringBuilder();</div><div class="line">		sb.append(this.valid);</div><div class="line">		sb.append(&quot;\001&quot;).append(this.remote_addr);</div><div class="line">		sb.append(&quot;\001&quot;).append(this.remote_user);</div><div class="line">		sb.append(&quot;\001&quot;).append(this.time_local);</div><div class="line">		sb.append(&quot;\001&quot;).append(this.request);</div><div class="line">		sb.append(&quot;\001&quot;).append(this.status);</div><div class="line">		sb.append(&quot;\001&quot;).append(this.body_bytes_sent);</div><div class="line">		sb.append(&quot;\001&quot;).append(this.http_referer);</div><div class="line">		sb.append(&quot;\001&quot;).append(this.http_user_agent);</div><div class="line">		</div><div class="line">		return sb.toString();</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（2）编写LogMapper程序</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.log;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.LongWritable;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line">public class LogMapper extends Mapper&lt;LongWritable, Text, Text, NullWritable&gt;&#123;</div><div class="line">	Text k = new Text();</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	protected void map(LongWritable key, Text value, Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		// 1 获取1行</div><div class="line">		String line = value.toString();</div><div class="line">		</div><div class="line">		// 2 解析日志是否合法</div><div class="line">		LogBean bean = pressLog(line);</div><div class="line">		</div><div class="line">		if (!bean.isValid()) &#123;</div><div class="line">			return;</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		k.set(bean.toString());</div><div class="line">		</div><div class="line">		// 3 输出</div><div class="line">		context.write(k, NullWritable.get());</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	// 解析日志</div><div class="line">	private LogBean pressLog(String line) &#123;</div><div class="line">		LogBean logBean = new LogBean();</div><div class="line">		</div><div class="line">		// 1 截取</div><div class="line">		String[] fields = line.split(&quot; &quot;);</div><div class="line">		</div><div class="line">		if (fields.length &gt; 11) &#123;</div><div class="line">			// 2封装数据</div><div class="line">			logBean.setRemote_addr(fields[0]);</div><div class="line">			logBean.setRemote_user(fields[1]);</div><div class="line">			logBean.setTime_local(fields[3].substring(1));</div><div class="line">			logBean.setRequest(fields[6]);</div><div class="line">			logBean.setStatus(fields[8]);</div><div class="line">			logBean.setBody_bytes_sent(fields[9]);</div><div class="line">			logBean.setHttp_referer(fields[10]);</div><div class="line">			</div><div class="line">			if (fields.length &gt; 12) &#123;</div><div class="line">				logBean.setHttp_user_agent(fields[11] + &quot; &quot;+ fields[12]);</div><div class="line">			&#125;else &#123;</div><div class="line">				logBean.setHttp_user_agent(fields[11]);</div><div class="line">			&#125;</div><div class="line">			</div><div class="line">			// 大于400，HTTP错误</div><div class="line">			if (Integer.parseInt(logBean.getStatus()) &gt;= 400) &#123;</div><div class="line">				logBean.setValid(false);</div><div class="line">			&#125;</div><div class="line">		&#125;else &#123;</div><div class="line">			logBean.setValid(false);</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		return logBean;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（3）编写LogDriver程序</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.log;</div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.NullWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line">public class LogDriver &#123;</div><div class="line">	public static void main(String[] args) throws Exception &#123;</div><div class="line">		// 1 获取job信息</div><div class="line">		Configuration conf = new Configuration();</div><div class="line">		Job job = Job.getInstance(conf);</div><div class="line"></div><div class="line">		// 2 加载jar包</div><div class="line">		job.setJarByClass(LogDriver.class);</div><div class="line"></div><div class="line">		// 3 关联map</div><div class="line">		job.setMapperClass(LogMapper.class);</div><div class="line"></div><div class="line">		// 4 设置最终输出类型</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(NullWritable.class);</div><div class="line"></div><div class="line">		// 5 设置输入和输出路径</div><div class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</div><div class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</div><div class="line"></div><div class="line">		// 6 提交</div><div class="line">		job.waitForCompletion(true);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="3-9-计数器应用"><a href="#3-9-计数器应用" class="headerlink" title="3.9 计数器应用"></a>3.9 计数器应用</h2><p>​         Hadoop为每个作业维护若干内置计数器，以描述多项指标。例如，某些计数器记录已处理的字节数和记录数，使用户可监控已处理的输入数据量和已产生的输出数据量。</p>
<p>1）API</p>
<p>​         （1）采用枚举的方式统计计数</p>
<p>enum MyCounter{MALFORORMED,NORMAL}</p>
<p>//对枚举定义的自定义计数器加1</p>
<p>context.getCounter(MyCounter.MALFORORMED).increment(1);</p>
<p>（2）采用计数器组、计数器名称的方式统计</p>
<p>context.getCounter(“counterGroup”, “countera”).increment(1);</p>
<p>​                 组名和计数器名称随便起，但最好有意义。</p>
<p>​         （3）计数结果在程序运行后的控制台上查看。</p>
<p>2）案例</p>
<p>​      数据清洗的两个案例</p>
<h2 id="3-10-MapReduce开发总结"><a href="#3-10-MapReduce开发总结" class="headerlink" title="3.10 MapReduce开发总结"></a>3.10 MapReduce开发总结</h2><p>在编写mapreduce程序时，需要考虑的几个方面：</p>
<p>1）输入数据接口：InputFormat </p>
<p>   默认使用的实现类是：TextInputFormat </p>
<p>   TextInputFormat的功能逻辑是：一次读一行文本，然后将该行的起始偏移量作为key，行内容作为value返回。</p>
<p>KeyValueTextInputFormat每一行均为一条记录，被分隔符分割为key，value。默认分隔符是tab（\t）。</p>
<p>NlineInputFormat按照指定的行数N来划分切片。</p>
<p>CombineTextInputFormat可以把多个小文件合并成一个切片处理，提高处理效率。</p>
<p>用户还可以自定义InputFormat。</p>
<p>2）逻辑处理接口：Mapper  </p>
<p>   用户根据业务需求实现其中三个方法：map()   setup()   cleanup () </p>
<p>3）Partitioner分区</p>
<p>​         有默认实现 HashPartitioner，逻辑是根据key的哈希值和numReduces来返回一个分区号；key.hashCode()&amp;Integer.MAXVALUE % numReduces</p>
<p>​         如果业务上有特别的需求，可以自定义分区。</p>
<p>4）Comparable排序</p>
<p>​         当我们用自定义的对象作为key来输出时，就必须要实现WritableComparable接口，重写其中的compareTo()方法。</p>
<p>​         部分排序：对最终输出的每一个文件进行内部排序。</p>
<p>​         全排序：对所有数据进行排序，通常只有一个Reduce。</p>
<p>​         二次排序：排序的条件有两个。</p>
<p>5）Combiner合并</p>
<p>Combiner合并可以提高程序执行效率，减少io传输。但是使用时必须不能影响原有的业务处理结果。</p>
<p>6）reduce端分组：Groupingcomparator</p>
<p>​         reduceTask拿到输入数据（一个partition的所有数据）后，首先需要对数据进行分组，其分组的默认原则是key相同，然后对每一组kv数据调用一次reduce()方法，并且将这一组kv中的第一个kv的key作为参数传给reduce的key，将这一组数据的value的迭代器传给reduce()的values参数。</p>
<p>​         利用上述这个机制，我们可以实现一个高效的分组取最大值的逻辑。</p>
<p>​         自定义一个bean对象用来封装我们的数据，然后改写其compareTo方法产生倒序排序的效果。然后自定义一个Groupingcomparator，将bean对象的分组逻辑改成按照我们的业务分组id来分组（比如订单号）。这样，我们要取的最大值就是reduce()方法中传进来key。</p>
<p>7）逻辑处理接口：Reducer</p>
<p>​         用户根据业务需求实现其中三个方法：reduce()   setup()   cleanup () </p>
<p>8）输出数据接口：OutputFormat</p>
<p>​         默认实现类是TextOutputFormat，功能逻辑是：将每一个KV对向目标文本文件中输出为一行。</p>
<p> SequenceFileOutputFormat将它的输出写为一个顺序文件。如果输出需要作为后续 MapReduce任务的输入，这便是一种好的输出格式，因为它的格式紧凑，很容易被压缩。</p>
<p>用户还可以自定义OutputFormat。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;三-MapReduce框架原理&quot;&gt;&lt;a href=&quot;#三-MapReduce框架原理&quot; class=&quot;headerlink&quot; title=&quot;三 MapReduce框架原理&quot;&gt;&lt;/a&gt;三 MapReduce框架原理&lt;/h1&gt;&lt;h2 id=&quot;3-1-MapReduce
    
    </summary>
    
      <category term="hadoop" scheme="http://kingge.top/categories/hadoop/"/>
    
    
      <category term="hadoop" scheme="http://kingge.top/tags/hadoop/"/>
    
      <category term="大数据" scheme="http://kingge.top/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="MapReduce" scheme="http://kingge.top/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>hadoop大数据(十)-Mapreduce基础</title>
    <link href="http://kingge.top/2018/03/16/hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE-%E5%8D%81-Mapreduce%E5%9F%BA%E7%A1%80/"/>
    <id>http://kingge.top/2018/03/16/hadoop大数据-十-Mapreduce基础/</id>
    <published>2018-03-16T11:59:59.000Z</published>
    <updated>2019-06-17T12:46:35.921Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一-MapReduce入门"><a href="#一-MapReduce入门" class="headerlink" title="一 MapReduce入门"></a>一 MapReduce入门</h1><h2 id="1-1-MapReduce定义"><a href="#1-1-MapReduce定义" class="headerlink" title="1.1 MapReduce定义"></a>1.1 MapReduce定义</h2><p>Mapreduce是一个分布式运算程序的编程框架，是用户开发“基于hadoop的数据分析应用”的核心框架。</p>
<p>Mapreduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个hadoop集群上。</p>
<h2 id="1-2-MapReduce优缺点"><a href="#1-2-MapReduce优缺点" class="headerlink" title="1.2 MapReduce优缺点"></a>1.2 MapReduce优缺点</h2><h3 id="1-2-1-优点"><a href="#1-2-1-优点" class="headerlink" title="1.2.1 优点"></a>1.2.1 优点</h3><p><strong>1**</strong>）MapReduce<strong> </strong>易于编程。**它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量廉价的PC机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得MapReduce编程变得非常流行。</p>
<p><strong>2**</strong>）良好的扩展性。**当你的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。</p>
<p><strong>3**</strong>）高容错性。**MapReduce设计的初衷就是使程序能够部署在廉价的PC机器上，这就要求它具有很高的容错性。比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由 Hadoop内部完成的。</p>
<p><strong>4**</strong>）适合PB<strong>**级以上海量数据的</strong>离线处理<strong>（他跟其他的分布式运行框架不同，例如spark等等）。</strong>这里加红字体离线处理，说明它适合离线处理而不适合在线处理。比如像毫秒级别的返回一个结果，MapReduce很难做到。</p>
<h3 id="1-2-2-缺点"><a href="#1-2-2-缺点" class="headerlink" title="1.2.2 缺点"></a>1.2.2 缺点</h3><p><strong>MapReduce不擅长做实时计算、流式计算、DAG（有向图）计算。</strong></p>
<p><strong>1）实时计算。</strong>MapReduce无法像Mysql一样，在毫秒或者秒级内返回结果。</p>
<p><strong>2）流式计算。</strong>流式计算的输入数据是动态的，而MapReduce的输入数据集是静态的，不能动态变化。这是因为MapReduce自身的设计特点决定了<strong>数据源必须是静态的</strong>。</p>
<p><strong>3）DAG</strong>（有向图）计算。多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce并不是不能做，而是使用后，每个MapReduce作业的输出结果都会写入到磁盘，会造成大量的磁盘IO，导致性能非常的低下。</p>
<h2 id="1-3-MapReduce核心思想"><a href="#1-3-MapReduce核心思想" class="headerlink" title="1.3 MapReduce核心思想"></a>1.3 MapReduce核心思想</h2><p>  下面根据一个小小的案例来体现 mapreduce的运转流程。</p>
<p><img src="/2018/03/16/hadoop大数据-十-Mapreduce基础/5C1560695415804.png" alt=""></p>
<p>根据块大小（128M）进行分片运算，每个maptask负责处理自己所属的块数据，把每个单词出现个数计算统计然后放到hashmap（实际上是放到磁盘上）中，key是单词，value是单词出现次数。</p>
<p>1）分布式的运算程序往往需要分成至少2个阶段。（<strong>map阶段和reduce阶段</strong>）</p>
<p>2）第一个阶段的maptask并发实例，完全并行运行，互不相干。</p>
<p>3）第二个阶段的reduce task并发实例互不相干，但是他们的数据依赖于上一个阶段的所有maptask并发实例的输出。</p>
<p>4）MapReduce编程模型只能包含一个map阶段和一个reduce阶段，<strong>如果用户的业务逻辑非常复杂，那就只能多个mapreduce程序，串行运行</strong>。</p>
<h2 id="1-4-MapReduce进程"><a href="#1-4-MapReduce进程" class="headerlink" title="1.4 MapReduce进程"></a>1.4 <em>MapReduce进程</em></h2><p>一个完整的mapreduce程序在分布式运行时有三类实例进程：</p>
<p>1）MrAppMaster：负责整个程序的过程调度及状态协调。</p>
<p>2）MapTask：负责map阶段的整个数据处理流程。</p>
<p>3）ReduceTask：负责reduce阶段的整个数据处理流程。</p>
<h2 id="1-5-MapReduce编程规范"><a href="#1-5-MapReduce编程规范" class="headerlink" title="1.5 MapReduce编程规范"></a>1.5 MapReduce编程规范</h2><p>用户编写的程序分成三个部分：Mapper，Reducer，Driver(提交运行mr程序的客户端)</p>
<h3 id="1）Mapper阶段"><a href="#1）Mapper阶段" class="headerlink" title="1）Mapper阶段"></a>1）Mapper阶段</h3><p>​         （1）用户自定义的Mapper要继承自己的父类</p>
<p>​         （2）Mapper的输入数据是KV对的形式（KV的类型可自定义）</p>
<p>​         （3）Mapper中的业务逻辑写在map()方法中</p>
<p>​         （4）Mapper的输出数据是KV对的形式（KV的类型可自定义）</p>
<p>​         （5）map()方法（maptask进程）对每一个<k,v>调用一次</k,v></p>
<h3 id="2）Reducer阶段"><a href="#2）Reducer阶段" class="headerlink" title="2）Reducer阶段"></a>2）Reducer阶段</h3><p>​         （1）用户自定义的Reducer要继承自己的父类</p>
<p>​         （2）Reducer的输入数据类型对应Mapper的输出数据类型，也是KV</p>
<p>​         （3）Reducer的业务逻辑写在reduce()方法中</p>
<p>​         （4）Reducetask进程对每一组相同k的<k,v>组调用一次reduce()方法</k,v></p>
<h3 id="3）Driver阶段"><a href="#3）Driver阶段" class="headerlink" title="3）Driver阶段"></a>3）Driver阶段</h3><p>整个程序需要一个Drvier来进行提交，提交的是一个描述了各种必要信息的job对象</p>
<h3 id="4）案例"><a href="#4）案例" class="headerlink" title="4）案例"></a>4）案例</h3><p>​         统计一堆文件中单词出现的个数（WordCount案例）。</p>
<p>在一堆给定的文本文件中统计输出每一个单词出现的总次数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">1.数据准备 anly.text 包涵一下数据。</div><div class="line"></div><div class="line">hello world</div><div class="line">kingge kingge</div><div class="line">hadoop </div><div class="line">spark</div><div class="line">hello world</div><div class="line">kingge	kingge</div><div class="line">hadoop </div><div class="line">spark</div><div class="line">hello world</div><div class="line">hadoop </div><div class="line">spark</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">2.按照mapreduce编程规范，分别编写Mapper，Reducer，Driver。</div></pre></td></tr></table></figure>
<p><img src="/2018/03/16/hadoop大数据-十-Mapreduce基础/1560696740319.png" alt=""></p>
<p>简单案例分析</p>
<p><img src="/2018/03/16/hadoop大数据-十-Mapreduce基础/1560696778909.png" alt=""></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">3.书写java代码</div><div class="line">（1）编写mapper类</div><div class="line"></div><div class="line">package com.kingge.mapreduce;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.IntWritable;</div><div class="line">import org.apache.hadoop.io.LongWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line">//四个参数：前两个是map的输入参数类型，后两个数输出参数类型</div><div class="line">//很明显，执行一个map，数据的key值是long类型代表着数据所属的行号，那么value值就是string类型，对应Hadoop的序列化类型是text.</div><div class="line">//输出的结果是，每个单词对应的个数。那么输出的key应该是Text,代表单词,value应该是Int类型，代表这个单词的个数</div><div class="line">public class WordcountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt;&#123;</div><div class="line">	</div><div class="line">	Text k = new Text();</div><div class="line">	IntWritable v = new IntWritable(1);</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	protected void map(LongWritable key, Text value, Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		// 1 获取一行-因为map是一行一行进行处理的</div><div class="line">		String line = value.toString();</div><div class="line">		</div><div class="line">		// 2 切割</div><div class="line">		String[] words = line.split(&quot; &quot;);</div><div class="line">		</div><div class="line">		// 3 输出</div><div class="line">		for (String word : words) &#123;</div><div class="line">			</div><div class="line">			k.set(word);</div><div class="line">			context.write(k, v);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">（2）编写reducer类</div><div class="line"></div><div class="line">package com.kingge.mapreduce.wordcount;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.IntWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line">public class WordcountReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt;&#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	protected void reduce(Text key, Iterable&lt;IntWritable&gt; value,</div><div class="line">			Context context) throws IOException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		// 1 累加求和</div><div class="line">		int sum = 0;</div><div class="line">		for (IntWritable count : value) &#123;</div><div class="line">			sum += count.get();</div><div class="line">		&#125;</div><div class="line">		</div><div class="line">		// 2 输出</div><div class="line">		context.write(key, new IntWritable(sum));</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">执行到reduce阶段，那么经过map的计算和排序，最终会形成了一组一组的相同key的KV键值对（key group）。然后相同组的会进行reduce统计。一组接着一组进行计算。并不是所有组都通过reduce。</div><div class="line">//例如假设最终返回的KV值是：</div><div class="line">//hello 1</div><div class="line">//hello 1</div><div class="line">//word 1</div><div class="line">//word 1</div><div class="line">   那么 前两个hello为一组，经过reduce运算，然后返回，同时word为一组也经过统计返回。这两组并不会都由同一个reduce处理</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">（3）编写驱动类</div><div class="line">package com.kingge.mapreduce.wordcount;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.IntWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line">public class WordcountDriver &#123;</div><div class="line"></div><div class="line">	public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123;</div><div class="line"></div><div class="line">		// 1 获取配置信息</div><div class="line">		Configuration configuration = new Configuration();</div><div class="line">		Job job = Job.getInstance(configuration);</div><div class="line"></div><div class="line">		// 2 设置jar加载路径</div><div class="line">		job.setJarByClass(WordcountDriver.class);</div><div class="line"></div><div class="line">		// 3 设置map和Reduce类</div><div class="line">		job.setMapperClass(WordcountMapper.class);</div><div class="line">		job.setReducerClass(WordcountReducer.class);</div><div class="line"></div><div class="line">		// 4 设置map输出</div><div class="line">		job.setMapOutputKeyClass(Text.class);</div><div class="line">		job.setMapOutputValueClass(IntWritable.class);</div><div class="line"></div><div class="line">		// 5 设置Reduce输出</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(IntWritable.class);</div><div class="line">		</div><div class="line">		// 6 设置输入和输出路径</div><div class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</div><div class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</div><div class="line"></div><div class="line">		// 7 提交</div><div class="line">		boolean result = job.waitForCompletion(true);</div><div class="line"></div><div class="line">		System.exit(result ? 0 : 1);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>4）集群上测试</p>
<p>（1）将程序打成jar包，然后拷贝到hadoop集群中。</p>
<p>（2）启动hadoop集群</p>
<p>（3）执行wordcount程序</p>
<p>[kingge@hadoop102 software]$ hadoop jar  wc.jar com.kingge.wordcount.WordcountDriver /user/kingge/input /user/kingge/output1</p>
<p>5）本地测试</p>
<p>（1）在windows环境上配置HADOOP_HOME环境变量。</p>
<p>（2）在eclipse上运行程序</p>
<p><strong>（3）注意：如果eclipse打印不出日志，在控制台上只显示</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">1.log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).  </div><div class="line">2.log4j:WARN Please initialize the log4j system properly.  </div><div class="line">3.log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.</div></pre></td></tr></table></figure>
<p>需要在项目的src目录下，新建一个文件，命名为“log4j.properties”，在文件中填入</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">log4j.rootLogger=INFO, stdout  </div><div class="line">log4j.appender.stdout=org.apache.log4j.ConsoleAppender  </div><div class="line">log4j.appender.stdout.layout=org.apache.log4j.PatternLayout  </div><div class="line">log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n  </div><div class="line">log4j.appender.logfile=org.apache.log4j.FileAppender  </div><div class="line">log4j.appender.logfile.File=target/spring.log  </div><div class="line">log4j.appender.logfile.layout=org.apache.log4j.PatternLayout  </div><div class="line">log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n  </div><div class="line"></div><div class="line">经过debug发现，只有当map处理完所有数据，才会进入reduce，map处理数据是一行一行进行处理的，每一行数据的处理都会经过一次map方法，直到所有数据处理完毕。Map处理完所有数据后，会排序所有的key，进行分组。然后一组一组的经过reduce，进行统计操作。直到所有组统计完毕，然后输出数据。</div></pre></td></tr></table></figure>
<h1 id="二-Hadoop序列化"><a href="#二-Hadoop序列化" class="headerlink" title="二 Hadoop序列化"></a>二 Hadoop序列化</h1><h2 id="2-1-为什么要序列化？"><a href="#2-1-为什么要序列化？" class="headerlink" title="2.1 为什么要序列化？"></a>2.1 为什么要序列化？</h2><p>​        一般来说，“活的”对象只生存在内存里，关机断电就没有了。而且“活的”对象只能由本地的进程使用，不能被发送到网络上的另外一台计算机。 然而序列化可以存储“活的”对象，可以将“活的”对象发送到远程计算机。</p>
<h2 id="2-2-什么是序列化？"><a href="#2-2-什么是序列化？" class="headerlink" title="2.2 什么是序列化？"></a>2.2 什么是序列化？</h2><p>序列化就是把内存中的对象，转换成字节序列（或其他数据传输协议）以便于存储（持久化）和网络传输。 </p>
<p>反序列化就是将收到字节序列（或其他数据传输协议）或者是硬盘的持久化数据，转换成内存中的对象。</p>
<h2 id="2-3-为什么不用Java的序列化？"><a href="#2-3-为什么不用Java的序列化？" class="headerlink" title="2.3 为什么不用Java的序列化？"></a>2.3 为什么不用Java的序列化？</h2><p>​        Java的序列化是一个重量级序列化框架（Serializable），一个对象被序列化后，会附带很多额外的信息（各种校验信息，header，继承体系等），不便于在网络中高效传输。所以，hadoop自己开发了一套序列化机制（Writable），精简、高效。</p>
<h2 id="2-4-为什么序列化对Hadoop很重要？"><a href="#2-4-为什么序列化对Hadoop很重要？" class="headerlink" title="2.4 为什么序列化对Hadoop很重要？"></a>2.4 为什么序列化对Hadoop很重要？</h2><p>​         <strong>因为Hadoop在集群之间进行通讯或者RPC调用的时候</strong>，需要序列化，而且要求序列化要快，且体积要小，占用带宽要小。所以必须理解Hadoop的序列化机制。</p>
<p>​        序列化和反序列化在分布式数据处理领域经常出现：进程通信和永久存储。然而Hadoop中各个节点的通信是通过远程调用（RPC）实现的，那么RPC序列化要求具有以下特点：</p>
<p>1）紧凑：紧凑的格式能让我们充分利用网络带宽，而带宽是数据中心最稀缺的资源</p>
<p>2）快速：进程通信形成了分布式系统的骨架，所以需要尽量减少序列化和反序列化的性能开销，这是基本的；</p>
<p>3）可扩展：协议为了满足新的需求变化，所以控制客户端和服务器过程中，需要直接引进相应的协议，这些是新协议，原序列化方式能支持新的协议报文；</p>
<p>4）互操作：能支持不同语言写的客户端和服务端进行交互； </p>
<h2 id="2-5-常用数据序列化类型"><a href="#2-5-常用数据序列化类型" class="headerlink" title="2.5 常用数据序列化类型"></a>2.5 常用数据序列化类型</h2><p>常用的数据类型对应的hadoop数据序列化类型</p>
<table>
<thead>
<tr>
<th><strong>Java**</strong>类型**</th>
<th><strong>Hadoop Writable**</strong>类型**</th>
</tr>
</thead>
<tbody>
<tr>
<td>boolean</td>
<td>BooleanWritable</td>
</tr>
<tr>
<td>byte</td>
<td>ByteWritable</td>
</tr>
<tr>
<td>int</td>
<td>IntWritable</td>
</tr>
<tr>
<td>float</td>
<td>FloatWritable</td>
</tr>
<tr>
<td>long</td>
<td>LongWritable</td>
</tr>
<tr>
<td>double</td>
<td>DoubleWritable</td>
</tr>
<tr>
<td>string</td>
<td>Text</td>
</tr>
<tr>
<td>map</td>
<td>MapWritable</td>
</tr>
<tr>
<td>array</td>
<td>ArrayWritable</td>
</tr>
</tbody>
</table>
<h2 id="2-6-自定义bean对象实现序列化接口（Writable）"><a href="#2-6-自定义bean对象实现序列化接口（Writable）" class="headerlink" title="2.6 自定义bean对象实现序列化接口（Writable）"></a>2.6 自定义bean对象实现序列化接口（Writable）</h2><p>1）自定义bean对象要想序列化传输，必须实现序列化接口，需要注意以下7项。</p>
<p>（1）必须实现Writable接口</p>
<p> <img src="/2018/03/16/hadoop大数据-十-Mapreduce基础/clip_image001.png" alt=""></p>
<p>（2）反序列化时，需要反射调用空参构造函数，所以必须有空参构造</p>
<p>​            <strong>public</strong>   FlowBean() {                    <strong>super</strong>();            }   </p>
<p>（3）重写序列化方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Override</div><div class="line">	public void write(DataOutput out) throws IOException &#123;</div><div class="line">		out.writeLong(upFlow);</div><div class="line">		out.writeLong(downFlow);</div><div class="line">		out.writeLong(sumFlow);</div><div class="line">	&#125;</div></pre></td></tr></table></figure>
<p>（4）重写反序列化方法</p>
<p>​            </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Override</div><div class="line">public void readFields(DataInput in) throws IOException &#123;</div><div class="line">	upFlow = in.readLong();</div><div class="line">	downFlow = in.readLong();</div><div class="line">	sumFlow = in.readLong();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（5）<strong>注意反序列化的顺序和序列化的顺序完全一致</strong></p>
<p>（6）要想把结果显示在文件中，需要重写toString()，可用”\t”分开，方便后续用。</p>
<p>（7）如果需要将<strong>自定义的bean放在key中传输</strong>，则还需要实现WritableComparable接口，因为mapreduce框中的shuffle过程一定会对key进行排序。</p>
<p>​     <strong>《自定义的bean放在key中传输》是什么意思呢？因为我们知道map操作中输入数据的存储结构是-key-value的形式.</strong>上面的例子中统计文本单词数，那么文本文件中每一行的文本的序号就是key（0,1,2,3）每一行的文本，就是value<strong><strong>的值。Map</strong></strong>操作完后输出的数据结构也是key-value<strong><strong>的形式。</strong></strong>而且输出的数据会根据key<strong><strong>排序</strong></strong>，以便reduce<strong><strong>处理。那么怎么排序在hadoop</strong></strong>中有一个默认规则（如果key<strong><strong>是2.5</strong></strong>中的常用数据类型），如果使我们自定义的序列化数据类型作为key<strong><strong>。那么默认排序规则就会失效，那么就需要我们制定一个排序规则就需要覆盖compareTo</strong></strong>方法。**</p>
<p>​           </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Override</div><div class="line">public int compareTo(FlowBean o) &#123;</div><div class="line">	// 倒序排列，从大到小</div><div class="line">	return this.sumFlow &gt; o.getSumFlow() ? -1 : 1;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="2）案例"><a href="#2）案例" class="headerlink" title="2）案例"></a>2）案例</h3><p>​         每一个手机号耗费的总上行流量、下行流量、总流量（序列化）。</p>
<h4 id="2-1-数据准备"><a href="#2-1-数据准备" class="headerlink" title="2.1 数据准备"></a>2.1 数据准备</h4><p>pd.txt</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">1363157985066 	13726230503	00-FD-07-A4-72-B8:CMCC	120.196.100.82	i02.c.aliimg.com		24	27	2481	24681	200</div><div class="line">1363157995052 	13826544101	5C-0E-8B-C7-F1-E0:CMCC	120.197.40.4			4	0	264	0	200</div><div class="line">1363157991076 	13926435656	20-10-7A-28-CC-0A:CMCC	120.196.100.99			2	4	132	1512	200</div><div class="line">1363154400022 	13926251106	5C-0E-8B-8B-B1-50:CMCC	120.197.40.4			4	0	240	0	200</div><div class="line">1363157993044 	18211575961	94-71-AC-CD-E6-18:CMCC-EASY	120.196.100.99	iface.qiyi.com	视频网站	15	12	1527	2106	200</div><div class="line">1363157995074 	84138413	5C-0E-8B-8C-E8-20:7DaysInn	120.197.40.4	122.72.52.12		20	16	4116	1432	200</div><div class="line">1363157993055 	13560439658	C4-17-FE-BA-DE-D9:CMCC	120.196.100.99			18	15	1116	954	200</div><div class="line">1363157995033 	15920133257	5C-0E-8B-C7-BA-20:CMCC	120.197.40.4	sug.so.360.cn	信息安全	20	20	3156	2936	200</div><div class="line">1363157983019 	13719199419	68-A1-B7-03-07-B1:CMCC-EASY	120.196.100.82			4	0	240	0	200</div><div class="line">1363157984041 	13660577991	5C-0E-8B-92-5C-20:CMCC-EASY	120.197.40.4	s19.cnzz.com	站点统计	24	9	6960	690	200</div><div class="line">1363157973098 	15013685858	5C-0E-8B-C7-F7-90:CMCC	120.197.40.4	rank.ie.sogou.com	搜索引擎	28	27	3659	3538	200</div><div class="line">1363157986029 	15989002119	E8-99-C4-4E-93-E0:CMCC-EASY	120.196.100.99	www.umeng.com	站点统计	3	3	1938	180	200</div><div class="line">1363157992093 	13560439658	C4-17-FE-BA-DE-D9:CMCC	120.196.100.99			15	9	918	4938	200</div><div class="line">1363157986041 	13480253104	5C-0E-8B-C7-FC-80:CMCC-EASY	120.197.40.4			3	3	180	180	200</div><div class="line">1363157984040 	13602846565	5C-0E-8B-8B-B6-00:CMCC	120.197.40.4	2052.flash2-http.qq.com	综合门户	15	12	1938	2910	200</div><div class="line">1363157995093 	13922314466	00-FD-07-A2-EC-BA:CMCC	120.196.100.82	img.qfc.cn		12	12	3008	3720	200</div><div class="line">1363157982040 	13502468823	5C-0A-5B-6A-0B-D4:CMCC-EASY	120.196.100.99	y0.ifengimg.com	综合门户	57	102	7335	110349	200</div><div class="line">1363157986072 	18320173382	84-25-DB-4F-10-1A:CMCC-EASY	120.196.100.99	input.shouji.sogou.com	搜索引擎	21	18	9531	2412	200</div><div class="line">1363157990043 	13925057413	00-1F-64-E1-E6-9A:CMCC	120.196.100.55	t3.baidu.com	搜索引擎	69	63	11058	48243	200</div><div class="line">1363157988072 	13760778710	00-FD-07-A4-7B-08:CMCC	120.196.100.82			2	2	120	120	200</div><div class="line">1363157985066 	13560436666	00-FD-07-A4-72-B8:CMCC	120.196.100.82	i02.c.aliimg.com		24	27	2481	24681	200</div><div class="line">1363157993055 	13560436666	C4-17-FE-BA-DE-D9:CMCC	120.196.100.99			18	15	1116	954	200</div></pre></td></tr></table></figure>
<p>输入数据格式： </p>
<p><img src="/2018/03/16/hadoop大数据-十-Mapreduce基础/1560697913154.png" alt=""></p>
<p>输出数据格式</p>
<p><img src="/2018/03/16/hadoop大数据-十-Mapreduce基础/0697933916.png" alt=""></p>
<h4 id="2-2-分析"><a href="#2-2-分析" class="headerlink" title="2.2 分析"></a>2.2 分析</h4><p>基本思路：</p>
<p>Map阶段：</p>
<p>（1）读取一行数据，切分字段</p>
<p>（2）抽取手机号、上行流量、下行流量</p>
<p>（3）以手机号为key，bean对象为value输出，即context.write(手机号,bean);</p>
<p>Reduce阶段：</p>
<p>（1）累加上行流量和下行流量得到总流量。</p>
<p>（2）实现自定义的bean来封装流量信息，并将bean作为map输出的key来传输</p>
<p>（3）MR程序在处理数据的过程中会对数据排序(map输出的kv对传输到reduce之前，会排序)，排序的依据是map输出的key</p>
<p><strong>所以，我们如果要实现自己需要的排序规则，则可以考虑将排序因素放到key中，让key实现接口：WritableComparable。然后重写key的compareTo方法。</strong></p>
<h4 id="2-3-编写mapreduce程序"><a href="#2-3-编写mapreduce程序" class="headerlink" title="2.3 编写mapreduce程序"></a>2.3 编写mapreduce程序</h4><p>（1）编写流量统计的bean对象</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.flowsum;</div><div class="line">import java.io.DataInput;</div><div class="line">import java.io.DataOutput;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.Writable;</div><div class="line"></div><div class="line">// 1 实现writable接口</div><div class="line">public class FlowBean implements Writable&#123;</div><div class="line"></div><div class="line">	private long upFlow ;</div><div class="line">	private long downFlow;</div><div class="line">	private long sumFlow;</div><div class="line">	</div><div class="line">	//2  反序列化时，需要反射调用空参构造函数，所以必须有</div><div class="line">	public FlowBean() &#123;</div><div class="line">		super();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public FlowBean(long upFlow, long downFlow) &#123;</div><div class="line">		super();</div><div class="line">		this.upFlow = upFlow;</div><div class="line">		this.downFlow = downFlow;</div><div class="line">		this.sumFlow = upFlow + downFlow;</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	//3  写序列化方法</div><div class="line">	@Override</div><div class="line">	public void write(DataOutput out) throws IOException &#123;</div><div class="line">		out.writeLong(upFlow);</div><div class="line">		out.writeLong(downFlow);</div><div class="line">		out.writeLong(sumFlow);</div><div class="line">	&#125;</div><div class="line">	</div><div class="line">	//4 反序列化方法</div><div class="line">	//5 反序列化方法读顺序必须和写序列化方法的写顺序必须一致</div><div class="line">	@Override</div><div class="line">	public void readFields(DataInput in) throws IOException &#123;</div><div class="line">		this.upFlow  = in.readLong();</div><div class="line">		this.downFlow = in.readLong();</div><div class="line">		this.sumFlow = in.readLong();</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	// 6 编写toString方法，方便后续打印到文本</div><div class="line">	@Override</div><div class="line">	public String toString() &#123;</div><div class="line">		return upFlow + &quot;\t&quot; + downFlow + &quot;\t&quot; + sumFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public long getUpFlow() &#123;</div><div class="line">		return upFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setUpFlow(long upFlow) &#123;</div><div class="line">		this.upFlow = upFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public long getDownFlow() &#123;</div><div class="line">		return downFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setDownFlow(long downFlow) &#123;</div><div class="line">		this.downFlow = downFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public long getSumFlow() &#123;</div><div class="line">		return sumFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	public void setSumFlow(long sumFlow) &#123;</div><div class="line">		this.sumFlow = sumFlow;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（2）编写mapper</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.flowsum;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.LongWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line"></div><div class="line">public class FlowCountMapper extends Mapper&lt;LongWritable, Text, Text, FlowBean&gt;&#123;</div><div class="line">	</div><div class="line">	FlowBean v = new FlowBean();</div><div class="line">	Text k = new Text();</div><div class="line">	</div><div class="line">	@Override</div><div class="line">	protected void map(LongWritable key, Text value, Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		// 1 获取一行</div><div class="line">		String line = value.toString();</div><div class="line">		</div><div class="line">		// 2 切割字段</div><div class="line">		String[] fields = line.split(&quot;\t&quot;);</div><div class="line">		</div><div class="line">		// 3 封装对象</div><div class="line">		// 取出手机号码</div><div class="line">		String phoneNum = fields[1];</div><div class="line">		// 取出上行流量和下行流量</div><div class="line">		long upFlow = Long.parseLong(fields[fields.length - 3]);</div><div class="line">		long downFlow = Long.parseLong(fields[fields.length - 2]);</div><div class="line">		</div><div class="line">		v.set(downFlow, upFlow);</div><div class="line">		</div><div class="line">		// 4 写出</div><div class="line">		context.write(new Text(phoneNum), new FlowBean(upFlow, downFlow));</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（3）编写reducer</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.flowsum;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Reducer;</div><div class="line"></div><div class="line">public class FlowCountReducer extends Reducer&lt;Text, FlowBean, Text, FlowBean&gt; &#123;</div><div class="line"></div><div class="line">	@Override</div><div class="line">	protected void reduce(Text key, Iterable&lt;FlowBean&gt; values, Context context)</div><div class="line">			throws IOException, InterruptedException &#123;</div><div class="line"></div><div class="line">		long sum_upFlow = 0;</div><div class="line">		long sum_downFlow = 0;</div><div class="line"></div><div class="line">		// 1 遍历所用bean，将其中的上行流量，下行流量分别累加</div><div class="line">		for (FlowBean flowBean : values) &#123;</div><div class="line">			sum_upFlow += flowBean.getSumFlow();</div><div class="line">			sum_downFlow += flowBean.getDownFlow();</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		// 2 封装对象</div><div class="line">		FlowBean resultBean = new FlowBean(sum_upFlow, sum_downFlow);</div><div class="line">		</div><div class="line">		// 3 写出</div><div class="line">		context.write(key, resultBean);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>（4）编写驱动</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">package com.kingge.mapreduce.flowsum;</div><div class="line">import java.io.IOException;</div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line">public class FlowsumDriver &#123;</div><div class="line"></div><div class="line">	public static void main(String[] args) throws IllegalArgumentException, IOException, ClassNotFoundException, InterruptedException &#123;</div><div class="line">		</div><div class="line">		// 1 获取配置信息，或者job对象实例</div><div class="line">		Configuration configuration = new Configuration();</div><div class="line">		Job job = Job.getInstance(configuration);</div><div class="line"></div><div class="line">		// 6 指定本程序的jar包所在的本地路径</div><div class="line">		job.setJarByClass(FlowsumDriver.class);</div><div class="line"></div><div class="line">		// 2 指定本业务job要使用的mapper/Reducer业务类</div><div class="line">		job.setMapperClass(FlowCountMapper.class);</div><div class="line">		job.setReducerClass(FlowCountReducer.class);</div><div class="line"></div><div class="line">		// 3 指定mapper输出数据的kv类型</div><div class="line">		job.setMapOutputKeyClass(Text.class);</div><div class="line">		job.setMapOutputValueClass(FlowBean.class);</div><div class="line"></div><div class="line">		// 4 指定最终输出的数据的kv类型</div><div class="line">		job.setOutputKeyClass(Text.class);</div><div class="line">		job.setOutputValueClass(FlowBean.class);</div><div class="line">		</div><div class="line">		// 5 指定job的输入原始文件所在目录</div><div class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</div><div class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</div><div class="line"></div><div class="line">		// 7 将job中配置的相关参数，以及job所用的java类所在的jar包， 提交给yarn去运行</div><div class="line">		boolean result = job.waitForCompletion(true);</div><div class="line">		System.exit(result ? 0 : 1);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一-MapReduce入门&quot;&gt;&lt;a href=&quot;#一-MapReduce入门&quot; class=&quot;headerlink&quot; title=&quot;一 MapReduce入门&quot;&gt;&lt;/a&gt;一 MapReduce入门&lt;/h1&gt;&lt;h2 id=&quot;1-1-MapReduce定义&quot;&gt;&lt;a h
    
    </summary>
    
      <category term="hadoop" scheme="http://kingge.top/categories/hadoop/"/>
    
    
      <category term="hadoop" scheme="http://kingge.top/tags/hadoop/"/>
    
      <category term="大数据" scheme="http://kingge.top/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="MapReduce" scheme="http://kingge.top/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>hadoop大数据(九)-yarn</title>
    <link href="http://kingge.top/2018/03/14/hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE-%E4%B9%9D-yarn/"/>
    <id>http://kingge.top/2018/03/14/hadoop大数据-九-yarn/</id>
    <published>2018-03-14T14:59:59.000Z</published>
    <updated>2019-08-01T13:33:46.678Z</updated>
    
    <content type="html"><![CDATA[<h2 id="5-1-Hadoop1-x和Hadoop2-x架构区别"><a href="#5-1-Hadoop1-x和Hadoop2-x架构区别" class="headerlink" title="5.1 Hadoop1.x和Hadoop2.x架构区别"></a>5.1 Hadoop1.x和Hadoop2.x架构区别</h2><p>在Hadoop1.x时代，Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度，耦合性较大。</p>
<blockquote>
<ol>
<li>ResourceManagement 资源管理</li>
<li>JobScheduling/JobMonitoring 任务调度监控</li>
</ol>
</blockquote>
<p>在Hadoop2.x时代，增加了Yarn。Yarn只负责资源的调度，MapReduce只负责运算。这样就能够各司其职</p>
<blockquote>
<ol>
<li>ResourceManger</li>
<li>ApplicationMaster</li>
</ol>
</blockquote>
<p>​    需要注意的是，在Yarn中我们把job的概念换成了<code>application</code>，因为在新的Hadoop2.x中，运行的应用不只是MapReduce了，还有可能是其它应用如一个DAG（有向无环图Directed Acyclic Graph，例如storm应用）。Yarn的另一个目标就是拓展Hadoop，使得它不仅仅可以支持MapReduce计算，还能很方便的管理诸如Hive、Hbase、Pig、Spark/Shark等应用。这种新的架构设计能够使得各种类型的应用运行在Hadoop上面，并通过Yarn从系统层面进行统一的管理，也就是说，有了Yarn，各种应用就可以互不干扰的运行在同一个Hadoop系统中，共享整个集群资源。</p>
<h2 id="5-2-Yarn概述"><a href="#5-2-Yarn概述" class="headerlink" title="5.2 Yarn概述"></a>5.2 Yarn概述</h2><p><strong>Yarn是一个资源调度平台，负责为运算程序提供服务器运算资源</strong>，相当于一个分布式的操作系统平台，而<strong>MapReduce等运算程序则相当于运行于操作系统之上的应用程序</strong>。</p>
<p><img src="/2018/03/14/hadoop大数据-九-yarn/5399709.png" alt="1564665399709"></p>
<h2 id="5-3-Yarn基本架构"><a href="#5-3-Yarn基本架构" class="headerlink" title="5.3 Yarn基本架构"></a>5.3 Yarn基本架构</h2><p>​         YARN主要由ResourceManager、NodeManager、ApplicationMaster和Container等组件构成。</p>
<p><img src="/2018/03/14/hadoop大数据-九-yarn/4665463356.png" alt="1564665463356"></p>
<h2 id="5-4-Yarn工作机制"><a href="#5-4-Yarn工作机制" class="headerlink" title="5.4 Yarn工作机制"></a>5.4 Yarn工作机制</h2><p>1）Yarn运行机制</p>
<p><img src="/2018/03/14/hadoop大数据-九-yarn/665729629.png" alt="1564665729629"></p>
<p>2）工作机制详解</p>
<blockquote>
<p>​         （0）Mr程序提交到客户端所在的节点。</p>
<p>​         （1）Yarnrunner向Resourcemanager申请一个Application。</p>
<p>​         （2）rm将该应用程序的资源路径返回给yarnrunner。</p>
<p>​         （3）该程序将运行所需资源提交到HDFS上。</p>
<p>​         （4）程序资源提交完毕后，申请运行mrAppMaster。</p>
<p>​         （5）RM将用户的请求初始化成一个task。</p>
<p>​         （6）其中一个NodeManager领取到task任务。</p>
<p>​         （7）该NodeManager创建容器Container，并产生MRAppmaster。</p>
<p>​         （8）Container从HDFS上拷贝资源到本地。</p>
<p>​         （9）MRAppmaster向RM 申请运行maptask资源。</p>
<p>​         （10）RM将运行maptask任务分配给另外两个NodeManager，另两个NodeManager分别领取任务并创建容器。</p>
<p>​         （11）MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动maptask，maptask对数据分区排序。</p>
<p>（12）MrAppMaster等待所有maptask运行完毕后，向RM申请容器，运行reduce task。</p>
<p>​         （13）reduce task向maptask获取相应分区的数据。</p>
<p>​         （14）程序运行完毕后，MR会向RM申请注销自己。</p>
</blockquote>
<h2 id="5-5-作业提交全过程"><a href="#5-5-作业提交全过程" class="headerlink" title="5.5 作业提交全过程"></a>5.5 作业提交全过程</h2><p>1）作业提交过程之YARN</p>
<p><img src="/2018/03/14/hadoop大数据-九-yarn/665811570.png" alt="1564665811570"></p>
<p>作业提交全过程详解</p>
<h3 id="（1）作业提交"><a href="#（1）作业提交" class="headerlink" title="（1）作业提交"></a>（1）作业提交</h3><p>第0步：client调用job.waitForCompletion方法，向整个集群提交MapReduce作业。</p>
<p>第1步：client向RM申请一个作业id。</p>
<p>第2步：RM给client返回该job资源的提交路径和作业id。</p>
<p>第3步：client提交jar包、切片信息和配置文件到指定的资源提交路径。</p>
<p>第4步：client提交完资源后，向RM申请运行MrAppMaster。</p>
<h3 id="（2）作业初始化"><a href="#（2）作业初始化" class="headerlink" title="（2）作业初始化"></a>（2）作业初始化</h3><p>第5步：当RM收到client的请求后，将该job添加到容量调度器中。</p>
<p>第6步：某一个空闲的NM领取到该job。</p>
<p>第7步：该NM创建Container，并产生MRAppmaster。</p>
<p>第8步：下载client提交的资源到本地。</p>
<h3 id="（3）任务分配"><a href="#（3）任务分配" class="headerlink" title="（3）任务分配"></a>（3）任务分配</h3><p>第9步：MrAppMaster向RM申请运行多个maptask任务资源。</p>
<p>第10步：RM将运行maptask任务分配给另外两个NodeManager，另两个NodeManager分别领取任务并创建容器。</p>
<h3 id="（4）任务运行"><a href="#（4）任务运行" class="headerlink" title="（4）任务运行"></a>（4）任务运行</h3><p>第11步：MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动maptask，maptask对数据分区排序。</p>
<p>第12步：MrAppMaster等待所有maptask运行完毕后，向RM申请容器，运行reduce task。</p>
<p>第13步：reduce task向maptask获取相应分区的数据。</p>
<p>第14步：程序运行完毕后，MR会向RM申请注销自己。</p>
<h3 id="（5）进度和状态更新"><a href="#（5）进度和状态更新" class="headerlink" title="（5）进度和状态更新"></a>（5）进度和状态更新</h3><p>YARN中的任务将其进度和状态(包括counter)返回给应用管理器, 客户端每秒(通过mapreduce.client.progressmonitor.pollinterval设置)向应用管理器请求进度更新, 展示给用户。</p>
<h3 id="（6）作业完成"><a href="#（6）作业完成" class="headerlink" title="（6）作业完成"></a>（6）作业完成</h3><p>除了向应用管理器请求作业进度外, 客户端每5分钟都会通过调用waitForCompletion()来检查作业是否完成。时间间隔可以通过mapreduce.client.completion.pollinterval来设置。作业完成之后, 应用管理器和container会清理工作状态。作业的信息会被作业历史服务器存储以备之后用户核查。</p>
<p>2）作业提交过程之MapReduce</p>
<p><img src="/2018/03/14/hadoop大数据-九-yarn/65974601.png" alt="1564665974601"></p>
<p>3）作业提交过程之读数据</p>
<p><img src="/2018/03/14/hadoop大数据-九-yarn/4666063752.png" alt="1564666063752"></p>
<p>4）作业提交过程之写数据</p>
<p><img src="/2018/03/14/hadoop大数据-九-yarn/64666122043.png" alt="1564666122043"></p>
<h2 id="5-6-资源调度器"><a href="#5-6-资源调度器" class="headerlink" title="5.6 资源调度器"></a>5.6 资源调度器</h2><p>目前，Hadoop作业调度器主要有三种：FIFO、Capacity Scheduler和Fair Scheduler。Hadoop2.7.2默认的资源调度器是Capacity Scheduler。</p>
<p>具体设置详见：yarn-default.xml文件</p>
   <property>       <description>The class to use as   the resource scheduler.</description>         <name>yarn.resourcemanager.scheduler.class</name>   <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</value>   </property>   

<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">    &lt;description&gt;The class to use as the resource scheduler.&lt;/description&gt;</div><div class="line">    &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt;</div><div class="line">&lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
<p>　　1）先进先出调度器（FIFO）</p>
<p><img src="/2018/03/14/hadoop大数据-九-yarn/66221031.png" alt="1564666221031">      </p>
<p>   2）容量调度器（Capacity Scheduler）</p>
<p><img src="/2018/03/14/hadoop大数据-九-yarn/4666258448.png" alt="1564666258448">        </p>
<p> 3）公平调度器（Fair Scheduler）</p>
<p><img src="/2018/03/14/hadoop大数据-九-yarn/564666314115.png" alt="1564666314115"></p>
<h2 id="5-7-任务的推测执行"><a href="#5-7-任务的推测执行" class="headerlink" title="5.7 任务的推测执行"></a>5.7 任务的推测执行</h2><p>1）作业完成时间取决于最慢的任务完成时间</p>
<p>一个作业由若干个Map任务和Reduce任务构成。因硬件老化、软件Bug等，某些任务可能运行非常慢。</p>
<p>典型案例：系统中有99%的Map任务都完成了，只有少数几个Map老是进度很慢，完不成，怎么办？</p>
<p>2）推测执行机制：</p>
<p>发现拖后腿的任务，比如某个任务运行速度远慢于任务平均速度。为拖后腿任务启动一个备份任务，同时运行。谁先运行完，则采用谁的结果。</p>
<p>3）执行推测任务的前提条件</p>
<p>（1）每个task只能有一个备份任务；</p>
<p>（2）当前job已完成的task必须不小于0.05（5%）</p>
<p>（3）开启推测执行参数设置。Hadoop2.7.2 mapred-site.xml文件中默认是打开的。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;mapreduce.map.speculative&lt;/name&gt;</div><div class="line">  &lt;value&gt;true&lt;/value&gt;</div><div class="line">  &lt;description&gt;If true, then multiple instances of some map tasks                may be executed in parallel.&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line"></div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;mapreduce.reduce.speculative&lt;/name&gt;</div><div class="line">  &lt;value&gt;true&lt;/value&gt;</div><div class="line">  &lt;description&gt;If true, then multiple instances of some reduce tasks </div><div class="line">               may be executed in parallel.&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
   <property>       <name>mapreduce.map.speculative</name>       <value>true</value>     <description>If   true, then multiple instances of some map tasks                may be executed in   parallel.</description>   </property>       <property>       <name>mapreduce.reduce.speculative</name>       <value>true</value>       <description>If true, then multiple instances of some reduce   tasks                   may be executed in   parallel.</description>   </property>   

<p>4）不能启用推测执行机制情况</p>
<p>   （1）任务间存在严重的负载倾斜；</p>
<p>   （2）特殊任务，比如任务向数据库中写数据。</p>
<p>5）算法原理：</p>
<p><img src="/2018/03/14/hadoop大数据-九-yarn/64666366883.png" alt="1564666366883"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;5-1-Hadoop1-x和Hadoop2-x架构区别&quot;&gt;&lt;a href=&quot;#5-1-Hadoop1-x和Hadoop2-x架构区别&quot; class=&quot;headerlink&quot; title=&quot;5.1 Hadoop1.x和Hadoop2.x架构区别&quot;&gt;&lt;/a&gt;5.1 H
    
    </summary>
    
      <category term="hadoop" scheme="http://kingge.top/categories/hadoop/"/>
    
    
      <category term="hadoop" scheme="http://kingge.top/tags/hadoop/"/>
    
      <category term="大数据" scheme="http://kingge.top/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="yarn" scheme="http://kingge.top/tags/yarn/"/>
    
  </entry>
  
  <entry>
    <title>hadoop大数据(八)-namenode和resourcemanager高可用</title>
    <link href="http://kingge.top/2018/03/12/hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE-%E5%85%AB-namenode%E5%92%8Cresourcemanager%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    <id>http://kingge.top/2018/03/12/hadoop大数据-八-namenode和resourcemanager高可用/</id>
    <published>2018-03-12T12:59:59.000Z</published>
    <updated>2019-06-10T13:20:52.956Z</updated>
    
    <content type="html"><![CDATA[<h1 id="HDFS-高可用"><a href="#HDFS-高可用" class="headerlink" title="HDFS 高可用"></a>HDFS 高可用</h1><h2 id="高可用概述"><a href="#高可用概述" class="headerlink" title="高可用概述"></a>高可用概述</h2><p>1）所谓HA（high available），即高可用（7*24小时不中断服务）。</p>
<p>2）实现高可用最关键的策略是消除单点故障。HA严格来说应该分成各个组件的HA机制：HDFS的HA和YARN的HA。</p>
<p>3）Hadoop2.0之前，在HDFS集群中NameNode存在单点故障（SPOF）。</p>
<p>4）NameNode主要在以下两个方面影响HDFS集群</p>
<p>​         NameNode机器发生意外，如宕机，集群将无法使用，直到管理员重启</p>
<p>​         NameNode机器需要升级，包括软件、硬件升级，此时集群也将无法使用</p>
<p>HDFS HA功能通过配置Active/Standby两个nameNodes实现在集群中对NameNode的热备来解决上述问题。如果出现故障，如机器崩溃或机器需要升级维护，这时可通过此种方式将NameNode很快的切换到另外一台机器。</p>
<h2 id="HDFS-HA工作机制"><a href="#HDFS-HA工作机制" class="headerlink" title="HDFS-HA工作机制"></a>HDFS-HA工作机制</h2><p>1）通过双namenode消除单点故障</p>
<h3 id="HDFS-HA工作要点"><a href="#HDFS-HA工作要点" class="headerlink" title="HDFS-HA工作要点"></a>HDFS-HA工作要点</h3><p>1）元数据管理方式需要改变：</p>
<p>内存中各自保存一份元数据；</p>
<p>Edits日志只有Active状态的namenode节点可以做写操作；</p>
<p>两个namenode都可以读取edits；</p>
<p>共享的edits放在一个共享存储中管理（qjournal和NFS两个主流实现）；</p>
<p>2）需要一个状态管理功能模块</p>
<p>实现了一个zkfailover，常驻在每一个namenode所在的节点，每一个zkfailover负责监控自己所在namenode节点，利用zk进行状态标识，当需要进行状态切换时，由zkfailover来负责切换，切换时需要防止<strong>brain split（脑裂）</strong>现象的发生。</p>
<p>脑裂：集群中存在两台active状态的namenode。</p>
<p>3）必须保证两个NameNode之间能够ssh无密码登录。</p>
<p>4）隔离（Fence），即同一时刻仅仅有一个NameNode对外提供服务</p>
<p>怎么能够保证两台namenode，有一台是active另一台是standby，而不出现脑裂现象呢？</p>
<p>  假想一：两台namenode进行通信，周期请求对面，告知自己状态。在一定的条件下可以实现高可用，但是存在如下问题：1.两台namenode直接通信，如果namenode1（active）处理client请求时，没空响应namenode2那么nn2等待了一段时间，就认为nn1已经碟机，那么nn2启动（切换为active）。这个时候集群出现脑裂现象。2.nn1和nn2 因为网络问题，可能存在一定的延迟，无法实时的切换（nn1碟机，切换到nn2的时候，可能会等待一两分钟）。</p>
<p>  假想二：使用zookeeper记录namenode 的状态。也会出现上面的问题。如果网络出现问题，nn1（active）无法正确汇报自己的状态到zookeeper，那么nn2启动，也会出现脑裂问题。</p>
<p>   假想三：zkfailover，一个namenode的内部进程（解决网络交互问题）</p>
<h3 id="HDFS-HA自动故障转移工作机制"><a href="#HDFS-HA自动故障转移工作机制" class="headerlink" title="HDFS-HA自动故障转移工作机制"></a>HDFS-HA自动故障转移工作机制</h3><p>前面学习了使用命令hdfs haadmin -failover手动进行故障转移，在该模式下，即使现役NameNode已经失效，系统也不会自动从现役NameNode转移到待机NameNode，下面学习如何配置部署HA自动进行故障转移。自动故障转移为HDFS部署增加了两个新组件：ZooKeeper和ZKFailoverController（ZKFC）进程。ZooKeeper是维护少量协调数据，通知客户端这些数据的改变和监视客户端故障的高可用服务。HA的自动故障转移依赖于ZooKeeper的以下功能：</p>
<p><strong>1）故障检测：</strong>集群中的每个NameNode在ZooKeeper中维护了一个持久会话，如果机器崩溃，ZooKeeper中的会话将终止，ZooKeeper通知另一个NameNode需要触发故障转移。</p>
<p><strong>2）现役NameNode选择：</strong>ZooKeeper提供了一个简单的机制用于唯一的选择一个节点为active状态。如果目前现役NameNode崩溃，另一个节点可能从ZooKeeper获得特殊的排外锁以表明它应该成为现役NameNode。</p>
<p>ZKFC是自动故障转移中的另一个新组件，是ZooKeeper的客户端，也监视和管理NameNode的状态。每个运行NameNode的主机也运行了一个ZKFC进程，ZKFC负责：</p>
<p><strong>1）健康监测：</strong>ZKFC使用一个健康检查命令定期地ping与之在相同主机的NameNode，只要该NameNode及时地回复健康状态，ZKFC认为该节点是健康的。如果该节点崩溃，冻结或进入不健康状态，健康监测器标识该节点为非健康的。</p>
<p><strong>2）ZooKeeper会话管理：</strong>当本地NameNode是健康的，ZKFC保持一个在ZooKeeper中打开的会话。如果本地NameNode处于active状态，ZKFC也保持一个特殊的znode锁，该锁使用了ZooKeeper对短暂节点的支持，如果会话终止，锁节点将自动删除。</p>
<p><strong>3）基于ZooKeeper的选择：</strong>如果本地NameNode是健康的，且ZKFC发现没有其它的节点当前持有znode锁，它将为自己获取该锁。如果成功，则它已经赢得了选择，并负责运行故障转移进程以使它的本地NameNode为active。故障转移进程与前面描述的手动故障转移相似，首先如果必要保护之前的现役NameNode，然后本地NameNode转换为active状态。</p>
<p>​                                                                 zookeeper服务端</p>
<p><img src="/2018/03/12/hadoop大数据-八-namenode和resourcemanager高可用/560172363333.png" alt="1560172363333"></p>
<h2 id="HDFS-HA集群配置"><a href="#HDFS-HA集群配置" class="headerlink" title="HDFS-HA集群配置"></a>HDFS-HA集群配置</h2><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><p>1）修改IP</p>
<p>2）修改主机名及主机名和IP地址的映射</p>
<p>3）关闭防火墙</p>
<p>4）ssh免密登录</p>
<p>5）安装JDK，配置环境变量等</p>
<h3 id="规划集群"><a href="#规划集群" class="headerlink" title="规划集群"></a>规划集群</h3><p>hadoop102                               hadoop103                              hadoop104               </p>
<p>NameNode                                 NameNode</p>
<p>JournalNode                              JournalNode                             JournalNode            </p>
<p>DataNode                                   DataNode                                  DataNode                 </p>
<p>ZK                                              ZK                                              ZK</p>
<p>ResourceManager</p>
<p>NodeManager                           NodeManager                           NodeManager         </p>
<h3 id="配置Zookeeper集群"><a href="#配置Zookeeper集群" class="headerlink" title="配置Zookeeper集群"></a>配置Zookeeper集群</h3><p>0）集群规划</p>
<p>在hadoop102、hadoop103和hadoop104三个节点上部署Zookeeper。</p>
<p>1）解压安装</p>
<p>（1）解压zookeeper安装包到/opt/module/目录下</p>
<p> [kingge@hadoop102 software]$ tar -zxvf zookeeper-3.4.10.tar.gz -C /opt/module/</p>
<p>（2）在/opt/module/zookeeper-3.4.10/这个目录下创建zkData</p>
<p>​         mkdir -p zkData</p>
<p>（3）重命名/opt/module/zookeeper-3.4.10/conf这个目录下的zoo_sample.cfg为zoo.cfg</p>
<p>​         mv zoo_sample.cfg zoo.cfg</p>
<p>2）配置zoo.cfg文件</p>
<p>​         （1）具体配置</p>
<p>​         dataDir=/opt/module/zookeeper-3.4.10/zkData</p>
<p>​         增加如下配置</p>
<p>​         #######################cluster##########################</p>
<p>server.2=hadoop102:2888:3888</p>
<p>server.3=hadoop103:2888:3888</p>
<p>server.4=hadoop104:2888:3888</p>
<p>（2）配置参数解读</p>
<p>Server.A=B:C:D。</p>
<p>A是一个数字，表示这个是第几号服务器；</p>
<p>B是这个服务器的ip地址；</p>
<p>C是这个服务器与集群中的Leader服务器交换信息的端口；</p>
<p>D是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。</p>
<p>集群模式下配置一个文件myid，这个文件在dataDir目录下，这个文件里面有一个数据就是A的值，Zookeeper启动时读取此文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。</p>
<p>3）集群操作</p>
<p>（1）在/opt/module/zookeeper-3.4.10/zkData目录下创建一个myid的文件</p>
<p>​         touch myid</p>
<p><strong>添加myid文件，注意一定要在linux里面创建，在notepad++里面很可能乱码</strong></p>
<p>（2）编辑myid文件</p>
<p>​         vi myid</p>
<p>​         在文件中添加与server对应的编号：如2</p>
<p>（3）拷贝配置好的zookeeper到其他机器上</p>
<p>​         scp -r zookeeper-3.4.10/ <a href="mailto:root@hadoop103.kingge.com:/opt/app/" target="_blank" rel="external">root@hadoop103.kingge.com:/opt/app/</a></p>
<p>​         scp -r zookeeper-3.4.10/ <a href="mailto:root@hadoop104.kingge.com:/opt/app/" target="_blank" rel="external">root@hadoop104.kingge.com:/opt/app/</a></p>
<p>​         并分别修改myid文件中内容为3、4</p>
<p>（4）分别启动zookeeper</p>
<p>​         [root@hadoop102 zookeeper-3.4.10]# bin/zkServer.sh start</p>
<p>[root@hadoop103 zookeeper-3.4.10]# bin/zkServer.sh start</p>
<p>[root@hadoop104 zookeeper-3.4.10]# bin/zkServer.sh start</p>
<p>（5）查看状态</p>
<p>[root@hadoop102 zookeeper-3.4.10]# bin/zkServer.sh status</p>
<p>JMX enabled by default</p>
<p>Using config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfg</p>
<p>Mode: follower</p>
<p>[root@hadoop103 zookeeper-3.4.10]# bin/zkServer.sh status</p>
<p>JMX enabled by default</p>
<p>Using config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfg</p>
<p>Mode: leader</p>
<p>[root@hadoop104 zookeeper-3.4.5]# bin/zkServer.sh status</p>
<p>JMX enabled by default</p>
<p>Using config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfg</p>
<p>Mode: follower</p>
<h3 id="配置HDFS-HA集群（手动故障转移配置）"><a href="#配置HDFS-HA集群（手动故障转移配置）" class="headerlink" title="配置HDFS-HA集群（手动故障转移配置）"></a>配置HDFS-HA集群（手动故障转移配置）</h3><p>  <strong>为什么说是手动，因为假设某一台namenode</strong> <strong>出现了问题，并不会自动的切换另一台namenode为active状态，需要我们手动切换</strong></p>
<p>1）官方地址：<a href="http://hadoop.apache.org/" target="_blank" rel="external">http://hadoop.apache.org/</a></p>
<p>2）在opt目录下创建一个ha文件夹</p>
<p>mkdir ha</p>
<p>3）将/opt/app/下的 hadoop-2.7.2拷贝到/opt/ha目录下</p>
<p>cp -r hadoop-2.7.2/ /opt/ha/</p>
<p>4）配置hadoop-env.sh</p>
<p>   export JAVA_HOME=/opt/module/jdk1.8.0_144   </p>
<p>5）配置core-site.xml</p>
   <configuration>   <!-- 把两个NameNode）的地址组装成一个集群mycluster -->                    <property>                             <name>fs.defaultFS</name>                    <value>hdfs://mycluster</value> //任意名字，代表着整个namenode集群，至于调用那个namenode，他会自己分配                    </property>                        <!-- 指定hadoop运行时产生文件的存储目录 -->                    <property>                             <name>hadoop.tmp.dir</name>                             <value>/opt/ha/hadoop-2.7.2/data/tmp</value>                    </property>   </configuration>   

<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">&lt;!-- 把两个NameNode）的地址组装成一个集群mycluster --&gt;</div><div class="line">		&lt;property&gt;</div><div class="line">			&lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">        	&lt;value&gt;hdfs://mycluster&lt;/value&gt; //任意名字，代表着整个namenode集群，至于调用那个namenode，他会自己分配</div><div class="line">		&lt;/property&gt;</div><div class="line"></div><div class="line">		&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;</div><div class="line">		&lt;property&gt;</div><div class="line">			&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</div><div class="line">			&lt;value&gt;/opt/ha/hadoop-2.7.2/data/tmp&lt;/value&gt;</div><div class="line">		&lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<p>6）配置hdfs-site.xml（<strong>因为有了热备namenode，那么就可以把secondary-namenode关闭，功能重复</strong>）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;!—可以配置文件块备份数--&gt;</div><div class="line">	&lt;!-- 完全分布式集群名称 --&gt;</div><div class="line">	&lt;property&gt;</div><div class="line">		&lt;name&gt;dfs.nameservices&lt;/name&gt;</div><div class="line">		&lt;value&gt;mycluster&lt;/value&gt; //这个名字必须与上面的mycluster一致</div><div class="line">	&lt;/property&gt;</div><div class="line"></div><div class="line">	&lt;!-- 集群中NameNode节点都有哪些 --&gt;</div><div class="line">	&lt;property&gt;</div><div class="line">		&lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt;</div><div class="line">		&lt;value&gt;nn1,nn2&lt;/value&gt;</div><div class="line">	&lt;/property&gt;</div><div class="line"></div><div class="line">	&lt;!-- nn1的RPC通信地址 --&gt;</div><div class="line">	&lt;property&gt;</div><div class="line">		&lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt;</div><div class="line">		&lt;value&gt;hadoop102:9000&lt;/value&gt;</div><div class="line">	&lt;/property&gt;</div><div class="line"></div><div class="line">	&lt;!-- nn2的RPC通信地址 --&gt;</div><div class="line">	&lt;property&gt;</div><div class="line">		&lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt;</div><div class="line">		&lt;value&gt;hadoop103:9000&lt;/value&gt;</div><div class="line">	&lt;/property&gt;</div><div class="line"></div><div class="line">	&lt;!-- nn1的http通信地址 --&gt;</div><div class="line">	&lt;property&gt;</div><div class="line">		&lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt;</div><div class="line">		&lt;value&gt;hadoop102:50070&lt;/value&gt;</div><div class="line">	&lt;/property&gt;</div><div class="line"></div><div class="line">	&lt;!-- nn2的http通信地址 --&gt;</div><div class="line">	&lt;property&gt;</div><div class="line">		&lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt;</div><div class="line">		&lt;value&gt;hadoop103:50070&lt;/value&gt;</div><div class="line">	&lt;/property&gt;</div><div class="line"></div><div class="line">	&lt;!-- 指定NameNode元数据（edit.log）在JournalNode上的存放位置 --&gt;</div><div class="line">	&lt;property&gt;</div><div class="line">		&lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;</div><div class="line">	&lt;value&gt;qjournal://hadoop102:8485;hadoop103:8485;hadoop104:8485/mycluster&lt;/value&gt;</div><div class="line">	&lt;/property&gt;</div><div class="line"></div><div class="line">	&lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 防止脑裂--&gt;</div><div class="line">	&lt;property&gt;</div><div class="line">		&lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;</div><div class="line">		&lt;value&gt;sshfence&lt;/value&gt;</div><div class="line">	&lt;/property&gt;</div><div class="line"></div><div class="line">	&lt;!-- 使用隔离机制时需要ssh无秘钥登录--&gt;</div><div class="line">	&lt;property&gt;</div><div class="line">		&lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;</div><div class="line">		&lt;value&gt;/home/kingge/.ssh/id_rsa&lt;/value&gt;</div><div class="line">	&lt;/property&gt;</div><div class="line"></div><div class="line">	&lt;!-- 声明journalnode服务器存储目录--&gt;</div><div class="line">	&lt;property&gt;</div><div class="line">		&lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;</div><div class="line">		&lt;value&gt;/opt/ha/hadoop-2.7.2/data/jn&lt;/value&gt;</div><div class="line">	&lt;/property&gt;</div><div class="line"></div><div class="line">	&lt;!-- 关闭权限检查--&gt;</div><div class="line">	&lt;property&gt;</div><div class="line">		&lt;name&gt;dfs.permissions.enable&lt;/name&gt;</div><div class="line">		&lt;value&gt;false&lt;/value&gt;</div><div class="line">	&lt;/property&gt;</div><div class="line"></div><div class="line">	&lt;!-- 访问代理类：client，mycluster，active配置失败自动切换实现方式--&gt;</div><div class="line">	&lt;property&gt;</div><div class="line">  		&lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt;</div><div class="line">	&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;</div><div class="line">	&lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
   <configuration>       &lt;!—可以配置文件块备份数–&gt;            <!-- 完全分布式集群名称 -->            <property>                    <name>dfs.nameservices</name>                    <value>mycluster</value>   //这个名字必须与上面的mycluster一致            </property>                <!-- 集群中NameNode节点都有哪些   -->            <property>                    <name>dfs.ha.namenodes.mycluster</name>                    <value>nn1,nn2</value>            </property>                <!-- nn1的RPC通信地址 -->            <property>                    <name>dfs.namenode.rpc-address.mycluster.nn1</name>                    <value>hadoop102:9000</value>            </property>                <!-- nn2的RPC通信地址 -->            <property>                    <name>dfs.namenode.rpc-address.mycluster.nn2</name>                    <value>hadoop103:9000</value>            </property>                <!-- nn1的http通信地址 -->            <property>                    <name>dfs.namenode.http-address.mycluster.nn1</name>                    <value>hadoop102:50070</value>            </property>                <!-- nn2的http通信地址 -->            <property>                    <name>dfs.namenode.http-address.mycluster.nn2</name>                    <value>hadoop103:50070</value>            </property>                <!-- 指定NameNode元数据（edit.log）在JournalNode上的存放位置   -->            <property>                    <name>dfs.namenode.shared.edits.dir</name>            <value>qjournal://hadoop102:8485;hadoop103:8485;hadoop104:8485/mycluster</value>            </property>                <!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 **防止脑裂**-->            <property>                    <name>dfs.ha.fencing.methods</name>                    <value>sshfence</value>            </property>                <!-- 使用隔离机制时需要ssh无秘钥登录-->            <property>                    <name>dfs.ha.fencing.ssh.private-key-files</name>                    <value>/home/atguigu/.ssh/id_rsa</value>            </property>                <!-- 声明journalnode服务器存储目录-->            <property>                    <name>dfs.journalnode.edits.dir</name>                    <value>/opt/ha/hadoop-2.7.2/data/jn</value>            </property>                <!-- 关闭权限检查-->            <property>                    <name>dfs.permissions.enable</name>                    <value>false</value>            </property>                <!-- 访问代理类：client，mycluster，active配置失败自动切换实现方式-->            <property>                  <name>dfs.client.failover.proxy.provider.mycluster</name>            <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>            </property>   </configuration>   

<p>7）可以关闭secondary namenode和关闭原先的namenode 的http访问模式</p>
<p><img src="/2018/03/12/hadoop大数据-八-namenode和resourcemanager高可用/560172564080.png" alt="1560172564080"></p>
<p>8）拷贝配置好的hadoop环境到其他节点</p>
<h3 id="启动HDFS-HA集群"><a href="#启动HDFS-HA集群" class="headerlink" title="启动HDFS-HA集群"></a>启动HDFS-HA集群</h3><p>1）在各个JournalNode节点上，输入以下命令启动journalnode服务：（在这里是hadoop102、hadoop103.、hadoop104 三台服务器都需要执行下面命令）</p>
<p>​         sbin/hadoop-daemon.sh start journalnode</p>
<p>2）在[nn1]上，对其进行格式化，并启动：</p>
<p>​         bin/hdfs namenode –format  // </p>
<p>​         sbin/hadoop-daemon.sh start namenode //开启active namenode</p>
<p>3）在[nn2]上，同步nn1的元数据信息：</p>
<p>​         bin/hdfs namenode -bootstrapStandby</p>
<p>4）启动[nn2]：启动备用namenode</p>
<p>​         sbin/hadoop-daemon.sh start namenode</p>
<p>5）查看web页面显示</p>
<p><img src="/2018/03/12/hadoop大数据-八-namenode和resourcemanager高可用/5C1560172587527.png" alt="1560172587527"></p>
<p>6）在[nn1]上，启动所有datanode</p>
<p>​         sbin/hadoop-daemons.sh start datanode</p>
<p>7）将[nn1]切换为Active</p>
<p>​         bin/hdfs haadmin -transitionToActive nn1</p>
<p>8）查看是否Active</p>
<p>​         bin/hdfs haadmin -getServiceState nn1</p>
<p>9）尝试kill 掉nn1的namenode</p>
<p>  Kill 7575</p>
<p>查看nn1和nn2的namenode 状态， 你会发现nn1挂掉后，nn2不还是standby状态，没有自动切换为active，需要手动切换为Active</p>
<h3 id="配置HDFS-HA自动故障转移（上面的是手动故障转移，就是需要手动启动某个namenode为active）"><a href="#配置HDFS-HA自动故障转移（上面的是手动故障转移，就是需要手动启动某个namenode为active）" class="headerlink" title="配置HDFS-HA自动故障转移（上面的是手动故障转移，就是需要手动启动某个namenode为active）"></a>配置HDFS-HA自动故障转移（上面的是手动故障转移，就是需要手动启动某个namenode为active）</h3><p>1）具体配置</p>
<p>​         （1）在hdfs-site.xml中增加</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">	&lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;</div><div class="line">	&lt;value&gt;true&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
   <property>            <name>dfs.ha.automatic-failover.enabled</name>            <value>true</value>   </property>   

<p>​         （2）在core-site.xml文件中增加</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">	&lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;</div><div class="line">	&lt;value&gt;hadoop102:2181,hadoop103:2181,hadoop104:2181&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
   <property>            <name>ha.zookeeper.quorum</name>            <value>hadoop102:2181,hadoop103:2181,hadoop104:2181</value>   </property>   

<p>2）启动</p>
<p>​         （1）关闭所有HDFS服务：</p>
<p>​                 sbin/stop-dfs.sh</p>
<p>​         （2）启动Zookeeper集群：</p>
<p>​                 bin/zkServer.sh start</p>
<p>​         （3）初始化HA在Zookeeper中状态：</p>
<p>​                 bin/hdfs zkfc -formatZK</p>
<p>​         （4）启动HDFS服务：</p>
<p>​                 sbin/start-dfs.sh</p>
<p>​         （5）在各个NameNode节点上启动DFSZK Failover Controller，先在哪台机器启动，哪个机器的NameNode就是Active NameNode</p>
<p>​                 sbin/hadoop-daemin.sh start zkfc</p>
<p>3）验证</p>
<p>​         （1）将Active NameNode进程kill</p>
<p>​                 kill -9 namenode的进程id</p>
<p>​         （2）将Active NameNode机器断开网络</p>
<p>​                 service network stop</p>
<h2 id="YARN-高可用配置"><a href="#YARN-高可用配置" class="headerlink" title="YARN-高可用配置"></a>YARN-高可用配置</h2><h3 id="YARN-HA工作机制"><a href="#YARN-HA工作机制" class="headerlink" title="YARN-HA工作机制"></a>YARN-HA工作机制</h3><p>1）官方文档：</p>
<p><a href="http://hadoop.apache.org/docs/r2.7.2/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html" target="_blank" rel="external">http://hadoop.apache.org/docs/r2.7.2/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html</a></p>
<p>2）YARN-HA工作机制</p>
<p><img src="/2018/03/12/hadoop大数据-八-namenode和resourcemanager高可用/C1560172645503.png" alt="1560172645503"></p>
<h3 id="配置YARN-HA集群（也就是开两台resourcemanager）"><a href="#配置YARN-HA集群（也就是开两台resourcemanager）" class="headerlink" title="配置YARN-HA集群（也就是开两台resourcemanager）"></a>配置YARN-HA集群（也就是开两台resourcemanager）</h3><p>0）环境准备</p>
<p>（1）修改IP</p>
<p>（2）修改主机名及主机名和IP地址的映射</p>
<p>（3）关闭防火墙</p>
<p>（4）ssh免密登录</p>
<p>（5）安装JDK，配置环境变量等</p>
<p>​         （6）配置Zookeeper集群</p>
<p>1）规划集群</p>
<p>hadoop102                              hadoop103                             hadoop104               </p>
<p>NameNode                                NameNode</p>
<p>JournalNode                             JournalNode                             JournalNode            </p>
<p>DataNode                                  DataNode                                  DataNode                 </p>
<p>ZK                                              ZK                                              ZK</p>
<p>ResourceManager                    ResourceManager</p>
<p>NodeManager                           NodeManager                          NodeManager         </p>
<p>2）具体配置</p>
<p>（1）yarn-site.xml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line"></div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</div><div class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;!--启用resourcemanager ha--&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;</div><div class="line">        &lt;value&gt;true&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"> </div><div class="line">    &lt;!--声明两台resourcemanager的地址--&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;</div><div class="line">        &lt;value&gt;cluster-yarn1&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;</div><div class="line">        &lt;value&gt;rm1,rm2&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;</div><div class="line">        &lt;value&gt;hadoop102&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;</div><div class="line">        &lt;value&gt;hadoop103&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"> </div><div class="line">    &lt;!--指定zookeeper集群的地址--&gt; </div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;</div><div class="line">        &lt;value&gt;hadoop102:2181,hadoop103:2181,hadoop104:2181&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;!--启用自动恢复 – 当resourcemanager碟机后自动重启--&gt; </div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt;</div><div class="line">        &lt;value&gt;true&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"> </div><div class="line">    &lt;!--指定resourcemanager的状态信息存储在zookeeper集群--&gt; </div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt;     &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line"></div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
   <configuration>           <property>             <name>yarn.nodemanager.aux-services</name>           <value>mapreduce_shuffle</value>       </property>           <!--启用resourcemanager   ha-->       <property>             <name>yarn.resourcemanager.ha.enabled</name>           <value>true</value>       </property>           <!--声明两台resourcemanager的地址-->       <property>           <name>yarn.resourcemanager.cluster-id</name>             <value>cluster-yarn1</value>       </property>           <property>             <name>yarn.resourcemanager.ha.rm-ids</name>           <value>rm1,rm2</value>       </property>           <property>           <name>yarn.resourcemanager.hostname.rm1</name>           <value>hadoop102</value>       </property>           <property>             <name>yarn.resourcemanager.hostname.rm2</name>           <value>hadoop103</value>       </property>           <!--指定zookeeper集群的地址-->        <property>           <name>yarn.resourcemanager.zk-address</name>             <value>hadoop102:2181,hadoop103:2181,hadoop104:2181</value>       </property>           <!--启用自动恢复 – 当resourcemanager碟机后自动重启-->        <property>             <name>yarn.resourcemanager.recovery.enabled</name>           <value>true</value>       </property>           <!--指定resourcemanager的状态信息存储在zookeeper集群-->        <property>             <name>yarn.resourcemanager.store.class</name>       <value>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore</value>   </property>       </configuration>   

<p>​         （2）同步更新其他节点的配置信息</p>
<p>3）启动hdfs </p>
<p>（1）在各个JournalNode节点上，输入以下命令启动journalnode服务：</p>
<p>​         sbin/hadoop-daemon.sh start journalnode</p>
<p>（2）在[nn1]上，对其进行格式化，并启动：</p>
<p>​         bin/hdfs namenode -format</p>
<p>​         sbin/hadoop-daemon.sh start namenode</p>
<p>（3）在[nn2]上，同步nn1的元数据信息：</p>
<p>​         bin/hdfs namenode -bootstrapStandby</p>
<p>（4）启动[nn2]：</p>
<p>​         sbin/hadoop-daemon.sh start namenode</p>
<p>（5）启动所有datanode</p>
<p>​         sbin/hadoop-daemons.sh start datanode</p>
<p>（6）将[nn1]切换为Active</p>
<p>​         bin/hdfs haadmin -transitionToActive nn1</p>
<p>4）启动yarn </p>
<p>（1）在hadoop102中执行：</p>
<p>sbin/start-yarn.sh</p>
<p>（2）在hadoop103中执行：</p>
<p>sbin/yarn-daemon.sh start resourcemanager</p>
<p>（3）查看服务状态</p>
<p>bin/yarn rmadmin -getServiceState rm1</p>
<p><img src="/2018/03/12/hadoop大数据-八-namenode和resourcemanager高可用/5C1560172700630.png" alt="1560172700630"></p>
<h2 id="HDFS-Federation架构设计"><a href="#HDFS-Federation架构设计" class="headerlink" title="HDFS Federation架构设计"></a>HDFS Federation架构设计</h2><p>1）  NameNode架构的局限性</p>
<p>（1）Namespace（命名空间）的限制</p>
<p>由于NameNode在内存中存储所有的元数据（metadata），因此单个namenode所能存储的对象（文件+块）数目受到namenode所在JVM的heap size的限制。50G的heap能够存储20亿（200million）个对象，这20亿个对象支持4000个datanode，12PB的存储（假设文件平均大小为40MB）。随着数据的飞速增长，存储的需求也随之增长。单个datanode从4T增长到36T，集群的尺寸增长到8000个datanode。存储的需求从12PB增长到大于100PB。</p>
<p>（2）隔离问题</p>
<p>由于HDFS仅有一个namenode，无法隔离各个程序，因此HDFS上的一个实验程序就很有可能影响整个HDFS上运行的程序。</p>
<p>​         （3）性能的瓶颈</p>
<p>​         由于是单个namenode的HDFS架构，因此整个HDFS文件系统的吞吐量受限于单个namenode的吞吐量。</p>
<p>2）HDFS Federation架构设计</p>
<p>能不能有多个NameNode</p>
<p>NameNode                                         NameNode                                         NameNode</p>
<p>元数据                                                元数据                                                元数据</p>
<p>Log                                                     machine                                             电商数据/话单数据</p>
<p><img src="/2018/03/12/hadoop大数据-八-namenode和resourcemanager高可用/5C1560172721474.png" alt="1560172721474"></p>
<p>3）HDFS Federation应用思考</p>
<p>不同应用可以使用不同NameNode进行数据管理</p>
<p>​          图片业务、爬虫业务、日志审计业务</p>
<p>Hadoop生态系统中，不同的框架使用不同的namenode进行管理namespace。（隔离性）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;HDFS-高可用&quot;&gt;&lt;a href=&quot;#HDFS-高可用&quot; class=&quot;headerlink&quot; title=&quot;HDFS 高可用&quot;&gt;&lt;/a&gt;HDFS 高可用&lt;/h1&gt;&lt;h2 id=&quot;高可用概述&quot;&gt;&lt;a href=&quot;#高可用概述&quot; class=&quot;headerlink
    
    </summary>
    
      <category term="hadoop" scheme="http://kingge.top/categories/hadoop/"/>
    
    
      <category term="hadoop" scheme="http://kingge.top/tags/hadoop/"/>
    
      <category term="大数据" scheme="http://kingge.top/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="HDFS" scheme="http://kingge.top/tags/HDFS/"/>
    
      <category term="hadoop高可用" scheme="http://kingge.top/tags/hadoop%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    
  </entry>
  
  <entry>
    <title>hadoop大数据(七)-HDFS的Namenode和Datanode</title>
    <link href="http://kingge.top/2018/03/10/hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE-%E4%B8%83-HDFS%E7%9A%84Namenode%E5%92%8CDatanode/"/>
    <id>http://kingge.top/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/</id>
    <published>2018-03-10T07:38:59.000Z</published>
    <updated>2019-06-10T12:56:33.609Z</updated>
    
    <content type="html"><![CDATA[<h1 id="五-NameNode工作机制"><a href="#五-NameNode工作机制" class="headerlink" title="五 NameNode工作机制"></a>五 NameNode工作机制</h1><h2 id="5-1-NameNode-amp-Secondary-NameNode工作机制"><a href="#5-1-NameNode-amp-Secondary-NameNode工作机制" class="headerlink" title="5.1 NameNode&amp;Secondary NameNode工作机制"></a>5.1 NameNode&amp;Secondary NameNode工作机制</h2><p><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/clip_image002.png" alt="img"></p>
<h3 id="1）第一阶段：namenode启动"><a href="#1）第一阶段：namenode启动" class="headerlink" title="1）第一阶段：namenode启动"></a>1）第一阶段：namenode启动</h3><p>（1）第一次启动namenode格式化后，创建fsimage和edits文件<strong>。如果不是第一次启动，直接加载编辑日志和镜像文件到内存</strong>（初始化系统为上一次退出时的最新状态）。</p>
<p>（2）客户端对元数据进行增删改的请求</p>
<p>（3）namenode记录操作日志，更新滚动日志。</p>
<p>（4）namenode在内存中对数据进行增删改查</p>
<p><strong><em>对于namenode而言最新的操作日志是 edits.in.progress(正在执行的日志)</em></strong></p>
<h3 id="2）第二阶段：Secondary-NameNode工作"><a href="#2）第二阶段：Secondary-NameNode工作" class="headerlink" title="2）第二阶段：Secondary NameNode工作"></a><strong>2）第二阶段：Secondary NameNode工作</strong></h3><blockquote>
<p>   <strong>核心工作：检查是否需要合并namenode的编辑日志和镜像文件（checkpoint）</strong></p>
</blockquote>
<p>​         （1）Secondary NameNode询问namenode是否需要checkpoint。直接带回namenode是否检查结果。<strong>定时时间默认1小时，edits默认一百万次</strong></p>
<p>​         （2）Secondary NameNode请求执行checkpoint。（是否需要合并两个文件）</p>
<p>​         （3）namenode滚动正在写的edits日志（<strong>edits.in.progress</strong>）</p>
<p>​         （4）将<strong>滚动前的编辑日志和镜像文件拷贝</strong>到Secondary NameNode</p>
<p>​         （5）Secondary NameNode加载编辑日志和镜像文件到内存，并合并。</p>
<p>​         （6）生成新的镜像文件fsimage.chkpoint</p>
<p>​         （7）拷贝fsimage.chkpoint到namenode</p>
<p>​         （8）namenode将fsimage.chkpoint重新命名成fsimage</p>
<blockquote>
<p><strong>也就是说，secondarynamenode的主要作用是帮助namenode分担他的压力，主要是帮助namenode合并镜像和操作日志，合并后，推给namenode。</strong></p>
</blockquote>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">正如上面所分析的，Hadoop文件系统会出现编辑日志（edits）不断增长的情况，尽管在NameNode运行期间不会对文件系统造成影响，但是如果NameNode重新启动，它将会花费大量的时间运行编辑日志中的每个操作，在此期间也就是我们前面所说的安全模式下，文件系统是不可用的。</div><div class="line"></div><div class="line">为了解决上述问题，Hadoop会运行一个Secondary NameNode进程，它的任务就是为原NameNode内存中的文件系统元数据产生检查点。其实说白了，就是辅助NameNode来处理fsimage文件与edits文件的一个进程。它从NameNode中复制fsimage与edits到临时目录并定期合并成一个新的fsimage并且删除原来的编辑日志edits。具体 步骤如下：</div><div class="line"></div><div class="line">（1）Secondary NameNode首先请求原NameNode进行edits的滚动，这样会产生一个新的编辑日志文件edits来保存对文件系统的操作（例如：上传新文件，删除文件，修改文件）。</div><div class="line"></div><div class="line">（2）Secondary NameNode通过Http方式读取原NameNode中的fsimage及edits。</div><div class="line"></div><div class="line">（3）Secondary NameNode将fsimage及edits进行合并产生新的fsimage</div><div class="line"></div><div class="line">（4）Secondary NameNode通过Http方式将新生成的fsimage发送到原来的NameNode中</div><div class="line"></div><div class="line">（5）原NameNode用新生成的fsimage替换掉旧的fsimage文件，新生成的edits文件也就是（1）生成的滚动编辑日志文件替换掉之前的edits文件</div></pre></td></tr></table></figure>
<h3 id="3）web端访问SecondaryNameNode"><a href="#3）web端访问SecondaryNameNode" class="headerlink" title="3）web端访问SecondaryNameNode"></a><strong>3）web端访问SecondaryNameNode</strong></h3><p>​         （1）启动集群</p>
<p>​         （2）浏览器中输入：<a href="http://hadoop102:50090/status.html" target="_blank" rel="external">http://hadoop102:50090/status.html</a></p>
<p>​         （3）查看SecondaryNameNode信息</p>
<p><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/clip_image0024.jpg" alt="img"></p>
<h3 id="4）chkpoint检查时间参数设置"><a href="#4）chkpoint检查时间参数设置" class="headerlink" title="4）chkpoint检查时间参数设置"></a><strong>4）chkpoint检查时间参数设置</strong></h3><p>（1）通常情况下，SecondaryNameNode每隔一小时执行一次。</p>
<p>​         [hdfs-default.xml]</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;dfs.namenode.checkpoint.period&lt;/name&gt;</div><div class="line">  &lt;value&gt;3600&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
<p>（2）一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode执行一次。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;dfs.namenode.checkpoint.txns&lt;/name&gt;</div><div class="line">  &lt;value&gt;1000000&lt;/value&gt;</div><div class="line">&lt;description&gt;操作动作次数&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line"></div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;dfs.namenode.checkpoint.check.period&lt;/name&gt;</div><div class="line">  &lt;value&gt;60&lt;/value&gt;</div><div class="line">&lt;description&gt; 1分钟检查一次操作次数&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
<h2 id="5-2-镜像文件和编辑日志文件"><a href="#5-2-镜像文件和编辑日志文件" class="headerlink" title="5.2 镜像文件和编辑日志文件"></a>5.2 镜像文件和编辑日志文件</h2><h3 id="1）概念"><a href="#1）概念" class="headerlink" title="1）概念"></a>1）概念</h3><p>​         namenode被格式化之后，将在/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current目录中产生如下文件</p>
<p>   edits_0000000000000000000   fsimage_0000000000000000000.md5   seen_txid   VERSION   </p>
<p>（1）Fsimage文件：HDFS文件系统元数据的一个永久性的检查点，其中包含HDFS文件系统的所有目录和文件idnode的序列化信息。 </p>
<p>（2）Edits文件：存放HDFS文件系统的所有更新操作的路径，文件系统客户端执行的所有写操作首先会被记录到edits文件中。 </p>
<p>（3）seen<em>txid文件保存的是一个数字，就是最后一个edits</em>的数字（最后一次操作的序号）</p>
<p>（4）每次Namenode启动的时候都会将fsimage文件读入内存，并从00001开始到seen_txid中记录的数字依次执行每个edits里面的更新操作，保证内存中的元数据信息是最新的、同步的，<strong>可以看成Namenode启动的时候就将fsimage和edits文件进行了合并。</strong></p>
<h3 id="2）oiv查看fsimage文件"><a href="#2）oiv查看fsimage文件" class="headerlink" title="2）oiv查看fsimage文件"></a>2）oiv查看fsimage文件</h3><p>（1）查看oiv和oev命令</p>
<p>[kingge@hadoop102 current]$ hdfs</p>
<p>oiv                  apply the offline fsimage viewer to an fsimage</p>
<p>oev                  apply the offline edits viewer to an edits file</p>
<p>（2）基本语法</p>
<p>hdfs oiv -p 文件类型 -i镜像文件 -o 转换后文件输出路径</p>
<p>（3）案例实操</p>
<p>[kingge@hadoop102 current]$ pwd</p>
<p>/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current</p>
<p>[kingge@hadoop102 current]$ hdfs oiv -p XML -i fsimage_0000000000000000025 -o /opt/module/hadoop-2.7.2/fsimage.xml</p>
<p>[kingge@hadoop102 current]$ cat /opt/module/hadoop-2.7.2/fsimage.xml</p>
<p>将显示的xml文件内容拷贝到eclipse中创建的xml文件中，并格式化。</p>
<p><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/clip_imag4e002.jpg" alt="img"></p>
<p>​        <strong>总结</strong></p>
<p>查看XML你会发现，里面存储了HDFS中文件或者文件夹的创建日期，权限，名称等等元数据信息。<strong>但是并没有存储文件保存的位置，也就是：并没有发现文件存储的DataNode节点信息</strong>信息那么当客户端请求读数据的时候，namenode是怎么返回数据所在块信息呢？<strong>原来他会一直跟datanode进行交互，获取数据所在块信息。</strong></p>
<h3 id="3）oev查看edits文件"><a href="#3）oev查看edits文件" class="headerlink" title="3）oev查看edits文件"></a>3）oev查看edits文件</h3><p>edits包括两类，edits_XXX,edits_inprogress_XXX</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">edits_XXX：保存文件系统的操作，查看方式见下面语法</div><div class="line"></div><div class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</div><div class="line">-&lt;EDITS&gt;</div><div class="line">&lt;EDITS_VERSION&gt;-63&lt;/EDITS_VERSION&gt;</div><div class="line">-&lt;RECORD&gt;</div><div class="line">&lt;OPCODE&gt;OP_START_LOG_SEGMENT&lt;/OPCODE&gt;</div><div class="line">-&lt;DATA&gt;</div><div class="line">&lt;TXID&gt;7170&lt;/TXID&gt;</div><div class="line">&lt;/DATA&gt;</div><div class="line">&lt;/RECORD&gt;</div><div class="line">-&lt;RECORD&gt;</div><div class="line">&lt;OPCODE&gt;OP_ADD&lt;/OPCODE&gt;</div><div class="line">-&lt;DATA&gt;</div><div class="line">&lt;TXID&gt;7171&lt;/TXID&gt;</div><div class="line">&lt;LENGTH&gt;0&lt;/LENGTH&gt;</div><div class="line">&lt;INODEID&gt;17787&lt;/INODEID&gt;</div><div class="line">&lt;PATH&gt;/user/zpx/a.txt&lt;/PATH&gt;</div><div class="line">&lt;REPLICATION&gt;3&lt;/REPLICATION&gt;</div><div class="line">&lt;MTIME&gt;1489118864779&lt;/MTIME&gt;</div><div class="line">&lt;ATIME&gt;1489118864779&lt;/ATIME&gt;</div><div class="line">&lt;BLOCKSIZE&gt;数据的大小&lt;/BLOCKSIZE&gt;</div><div class="line">&lt;CLIENT_NAME&gt;DFSClient_NONMAPREDUCE_1295720148_1&lt;/CLIENT_NAME&gt;</div><div class="line">&lt;CLIENT_MACHINE&gt;192.168.231.1&lt;/CLIENT_MACHINE&gt;</div><div class="line">&lt;OVERWRITE&gt;true&lt;/OVERWRITE&gt;</div><div class="line">-&lt;PERMISSION_STATUS&gt;</div><div class="line">&lt;USERNAME&gt;Administrator&lt;/USERNAME&gt;</div><div class="line">&lt;GROUPNAME&gt;supergroup&lt;/GROUPNAME&gt;</div><div class="line">&lt;MODE&gt;420&lt;/MODE&gt;</div><div class="line">&lt;/PERMISSION_STATUS&gt;</div><div class="line">&lt;RPC_CLIENTID&gt;0c9a5af9-26a8-45d9-8754-cd0e7e47f65b&lt;/RPC_CLIENTID&gt;</div><div class="line">&lt;RPC_CALLID&gt;0&lt;/RPC_CALLID&gt;</div><div class="line">&lt;/DATA&gt;</div><div class="line">&lt;/RECORD&gt;</div><div class="line">&lt;/EDITS&gt;</div><div class="line"></div><div class="line">对Hdfs文件系统的每一个操作都保存在了edits文件中，每一个操作都是事务，有事务id——&lt;TXID&gt;7171&lt;/TXID&gt;，还有当前操作做了什么&lt;OPCODE&gt;OP_ADD&lt;/OPCODE&gt;，副本数，以及大小</div><div class="line"></div><div class="line">edits_inprogress_XXX：正在使用的过程，当前正在向前滚动。查看方式见下面语法</div></pre></td></tr></table></figure>
<p>（1）基本语法</p>
<p>hdfs oev -p 文件类型 -i编辑日志 -o 转换后文件输出路径</p>
<p>（2）案例实操</p>
<p>[kingge@hadoop102 current]$ hdfs oev -p XML -i edits_0000000000000000012-0000000000000000013 -o /opt/module/hadoop-2.7.2/edits.xml</p>
<p>[kingge@hadoop102 current]$ cat /opt/module/hadoop-2.7.2/edits.xml</p>
<p>将显示的xml文件内容拷贝到eclipse中创建的xml文件中，并格式化。</p>
<p>总结</p>
<p><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/clip_imag9e002.jpg" alt="img"></p>
<p>你会发现，edits_inprogress，记录的是当前客户端请求执行的操作（增量记录当前操作）</p>
<h2 id="5-3-滚动编辑日志"><a href="#5-3-滚动编辑日志" class="headerlink" title="5.3 滚动编辑日志"></a>5.3 滚动编辑日志</h2><p>正常情况HDFS文件系统有更新操作时，就会滚动编辑日志。也可以用命令强制滚动编辑日志。</p>
<p>1）滚动编辑日志（前提必须启动集群）</p>
<p>[kingge@hadoop102 current]$ hdfs dfsadmin -rollEdits</p>
<p>2）镜像文件什么时候产生</p>
<p>Namenode启动时加载镜像文件和编辑日志</p>
<p><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/169952390.png" alt="1560169952390"></p>
<h2 id="5-4-Namenode版本号"><a href="#5-4-Namenode版本号" class="headerlink" title="5.4 Namenode版本号"></a>5.4 Namenode版本号</h2><p>1）查看namenode版本号</p>
<p>在/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current这个目录下查看VERSION</p>
<p>namespaceID=1933630176</p>
<p>clusterID=CID-1f2bf8d1-5ad2-4202-af1c-6713ab381175</p>
<p>cTime=0</p>
<p>storageType=NAME_NODE</p>
<p>blockpoolID=BP-97847618-192.168.10.102-1493726072779</p>
<p>layoutVersion=-63</p>
<p>2）namenode版本号具体解释</p>
<p>（1） namespaceID在HDFS上，会有多个Namenode，所以不同Namenode的namespaceID是不同的，分别管理一组blockpoolID。</p>
<p>（2）clusterID集群id，全局唯一</p>
<p>（3）cTime属性标记了namenode存储系统的创建时间，对于刚刚格式化的存储系统，这个属性为0；但是在文件系统升级之后，该值会更新到新的时间戳。</p>
<p>（4）storageType属性说明该存储目录包含的是namenode的数据结构。</p>
<p>（5）blockpoolID：一个block pool id标识一个block pool，并且是跨集群的全局唯一。当一个新的Namespace被创建的时候(format过程的一部分)会创建并持久化一个唯一ID。在创建过程构建全局唯一的BlockPoolID比人为的配置更可靠一些。NN将BlockPoolID持久化到磁盘中，在后续的启动过程中，会再次load并使用。</p>
<p>（6）layoutVersion是一个负整数。通常只有HDFS增加新特性时才会更新这个版本号。</p>
<h2 id="5-5-SecondaryNameNode目录结构"><a href="#5-5-SecondaryNameNode目录结构" class="headerlink" title="5.5 SecondaryNameNode目录结构"></a>5.5 SecondaryNameNode目录结构</h2><p>Secondary NameNode用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</p>
<p><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/0170177897.png" alt="1560170177897"></p>
<blockquote>
<p><strong>也即是说存在两种情况secondarynamenode会向namenode请求合并镜像文件和日志文件。（1）当上次请求时间已经间隔了一个小时后，会去请求（2）当操作数（edits，操作日志数）到达一百万次时，会去请求</strong><br><strong>那么他怎么知道操作次数到达一百万次呢？答案是，一分钟请求namenode一次，查询操作次数是否到达一百万次。注意，这个检查操作数的时间设置最好不要跟</strong><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/clip_image001.png" alt="img"></p>
</blockquote>
<p>一致，不然他会默认执行第一种场景（间隔一个小时）</p>
<p><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/70270685.png" alt="1560170270685"></p>
<p>在/opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary/current这个目录中查看SecondaryNameNode目录结构。</p>
<p>   edits_0000000000000000001-0000000000000000002   fsimage_0000000000000000002   fsimage_0000000000000000002.md5   VERSION   </p>
<p>SecondaryNameNode的namesecondary/current目录和主namenode的current目录的布局相同。</p>
<p><strong>好处：在主namenode**</strong>发生故障时（假设没有及时备份数据），可以从SecondaryNameNode<strong>**恢复数据。</strong></p>
<h3 id="根据secondarynamenode恢复namenode"><a href="#根据secondarynamenode恢复namenode" class="headerlink" title="根据secondarynamenode恢复namenode"></a>根据secondarynamenode恢复namenode</h3><p>方法一：将SecondaryNameNode中数据拷贝到namenode存储数据的目录；</p>
<p>方法二：使用-importCheckpoint选项启动namenode守护进程，从而将SecondaryNameNode中数据拷贝到namenode目录中。</p>
<p>1）案例实操（一）：</p>
<p>模拟namenode故障，并采用方法一，恢复namenode数据</p>
<p>（1）kill -9 namenode进程</p>
<p>（2）删除namenode存储的数据（/opt/module/hadoop-2.7.2/data/tmp/dfs/name）</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ rm -rf /opt/module/hadoop-2.7.2/data/tmp/dfs/name/*</p>
<p>（3）拷贝SecondaryNameNode中数据到原namenode存储数据目录</p>
<p>​           [kingge@hadoop102 hadoop-2.7.2]$ scp -R /opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary/* /opt/module/hadoop-2.7.2/data/tmp/dfs/name/</p>
<p>（4）重新启动namenode</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode</p>
<p>2）案例实操（二）：</p>
<p>模拟namenode故障，并采用方法二，恢复namenode数据</p>
<p>（0）修改hdfs-site.xml中的</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;dfs.namenode.checkpoint.period&lt;/name&gt;</div><div class="line">  &lt;value&gt;120&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">#  120秒checkpoint一次</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</div><div class="line">  &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp/dfs/name&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line"># namenode镜像文件和操作日志存放目录</div></pre></td></tr></table></figure>
<p>（1）kill -9 namenode进程</p>
<p>（2）删除namenode存储的数据（/opt/module/hadoop-2.7.2/data/tmp/dfs/name）</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ rm -rf /opt/module/hadoop-2.7.2/data/tmp/dfs/name/*</p>
<p>（3）如果SecondaryNameNode不和Namenode在一个主机节点上，需要将SecondaryNameNode存储数据的目录拷贝到Namenode存储数据的平级目录。Scp命令拷贝过来</p>
<p><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/70458431.png" alt="1560170458431"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">  </div><div class="line">[kingge@hadoop102 dfs]$ pwd</div><div class="line">/opt/module/hadoop-2.7.2/data/tmp/dfs</div><div class="line">[kingge@hadoop102 dfs]$ ls</div><div class="line">data  name  namesecondary</div></pre></td></tr></table></figure>
<p>（4）导入检查点数据（等待一会ctrl+c结束掉）</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ bin/hdfs namenode -importCheckpoint</p>
<p>（5）启动namenode</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode</p>
<p>（6）如果提示文件锁了，可以删除in_use.lock </p>
<p>​                 [kingge@hadoop102 hadoop-2.7.2]$ rm -rf /opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary/in_use.lock</p>
<h2 id="5-5-5-设置checkpoint检查时间"><a href="#5-5-5-设置checkpoint检查时间" class="headerlink" title="5.5.5 设置checkpoint检查时间"></a>5.5.5 设置checkpoint检查时间</h2><p>默认的checkpoint period是1个小时。可以去hdfs-site.xml中修改</p>
<p><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/0170515392.png" alt="1560170515392"></p>
<h2 id="5-6-集群安全模式操作"><a href="#5-6-集群安全模式操作" class="headerlink" title="5.6 集群安全模式操作"></a>5.6 集群安全模式操作</h2><p>1）概述</p>
<p>Namenode启动时，首先将映像文件（fsimage）载入内存，并执行编辑日志（edits）中的各项操作。一旦在内存中成功建立文件系统元数据的映像，则创建一个新的fsimage文件和一个空的编辑日志。此时，namenode开始监听datanode请求。但是此刻，namenode运行在安全模式，即namenode的文件系统对于客户端来说是只读的。（<strong>可以解释为什么在namenode启动的时候，我们put数据到hdfs会提示，安全模式错误</strong>）因为这个时候namenode和datanode还没有联通对方，需要等待连通后，安全模式自动关闭，然后就可以上传文件了</p>
<p>系统中的数据块的位置并不是由namenode维护的，而是以块列表的形式存储在datanode中。在系统的正常操作期间，namenode会在内存中保留所有块位置的映射信息。在安全模式下，各个datanode会向namenode发送最新的块列表信息，namenode了解到足够多的块位置信息之后，即可高效运行文件系统。</p>
<p>如果满足“最小副本条件”，namenode会在30秒钟之后就退出安全模式。所谓的最小副本条件指的是在整个文件系统中99.9%的块满足最小副本级别（默认值：dfs.replication.min=1）。在启动一个刚刚格式化的HDFS集群时，因为系统中还没有任何块，所以namenode不会进入安全模式。</p>
<p>2）基本语法</p>
<p>集群处于安全模式，不能执行重要操作（写操作）。集群启动完成后，自动退出安全模式。</p>
<p>（1）bin/hdfs dfsadmin -safemode get          （功能描述：查看安全模式状态）</p>
<p>（2）bin/hdfs dfsadmin -safemode enter     （功能描述：进入安全模式状态）</p>
<p>（3）bin/hdfs dfsadmin -safemode leave      （功能描述：离开安全模式状态）</p>
<p>（4）bin/hdfs dfsadmin -safemode wait        （功能描述：等待安全模式状态）</p>
<p>3）案例</p>
<p>​         模拟等待安全模式</p>
<p>​         1）先进入安全模式</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ bin/hdfs dfsadmin -safemode enter</p>
<p>​         2）执行下面的脚本</p>
<p>编辑一个脚本</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">#!/bin/bash</div><div class="line">bin/hdfs dfsadmin -safemode wait</div><div class="line">bin/hdfs dfs -put ~/hello.txt /root/hello.txt</div></pre></td></tr></table></figure>
<p>​         3）再打开一个窗口，执行</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ bin/hdfs dfsadmin -safemode leave</p>
<h2 id="5-7-Namenode多目录配置"><a href="#5-7-Namenode多目录配置" class="headerlink" title="5.7 Namenode多目录配置"></a>5.7 Namenode多目录配置</h2><p>1）namenode的本地目录可以配置成多个，<strong>且每个目录存放内容相同</strong>，增加了可靠性。</p>
<p>2）具体配置如下：</p>
<p>​         hdfs-site.xml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</div><div class="line">&lt;value&gt;file:///$&#123;hadoop.tmp.dir&#125;/dfs/name1,file:///$&#123;hadoop.tmp.dir&#125;/dfs/name2&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line"></div><div class="line"></div><div class="line"> 2.停止集群，删除数据文件 --  rm -rf data/logs (集群里有多少台服务器就删除多少台)</div><div class="line"></div><div class="line">3.格式化namenode</div><div class="line"></div><div class="line">4.调用xsync 分发脚本到各个集群 </div><div class="line"></div><div class="line">5.启动集群</div><div class="line"></div><div class="line">6.查看设置的本地目录name1、name2 你会发现里面的数据一模一样</div></pre></td></tr></table></figure>
<h2 id="测试NameNode"><a href="#测试NameNode" class="headerlink" title="测试NameNode"></a>测试NameNode</h2><p>场景：关闭namenode（stop-dfs.sh），关闭yarn（stop-yarn.sh），删除hadoop目录下的data目录和log目录。</p>
<p>1.格式化namenode  – bin/hdfs namenode -format</p>
<p>2.启动hdfs和yarn</p>
<h1 id="六-DataNode工作机制"><a href="#六-DataNode工作机制" class="headerlink" title="六 DataNode工作机制"></a>六 DataNode工作机制</h1><h2 id="6-1-DataNode工作机制"><a href="#6-1-DataNode工作机制" class="headerlink" title="6.1 DataNode工作机制"></a>6.1 DataNode工作机制</h2><p><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/170744123.png" alt="1560170744123"></p>
<p>1）一个数据块在datanode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。</p>
<p>2）DataNode启动后向namenode注册，通过后，周期性（1小时）的向namenode上报所有的块信息。</p>
<p>3）心跳是每3秒一次，心跳返回结果带有namenode给该datanode的命令如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个datanode的心跳，则认为该节点不可用。</p>
<p>4）<strong>集群运行中可以安全加入和退出一些机器</strong>（在不关闭集群的情况下服役和退役服务器）</p>
<h2 id="6-2-数据完整性"><a href="#6-2-数据完整性" class="headerlink" title="6.2 数据完整性"></a>6.2 数据完整性</h2><p>1）当DataNode读取block的时候，它会计算checksum</p>
<p>2）如果计算后的checksum，与block创建时值不一样，说明block已经损坏。</p>
<p>3）client读取其他DataNode上的block。</p>
<p>4）datanode在其文件创建后周期验证checksum</p>
<p><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/0170775293.png" alt="1560170775293"></p>
<h2 id="6-3-掉线时限参数设置"><a href="#6-3-掉线时限参数设置" class="headerlink" title="6.3 掉线时限参数设置"></a>6.3 掉线时限参数设置</h2><p>datanode进程死亡或者网络故障造成datanode无法与namenode通信，namenode不会立即把该节点判定为死亡，要经过一段时间，这段时间暂称作超时时长。HDFS默认的超时时长为10分钟+30秒。如果定义超时时间为timeout，则超时时长的计算公式为：</p>
<p>​         timeout  = 2 <em> dfs.namenode.heartbeat.recheck-interval + 10 </em> dfs.heartbeat.interval。</p>
<p>​         而默认的dfs.namenode.heartbeat.recheck-interval 大小为5分钟，dfs.heartbeat.interval默认为3秒。</p>
<p>​         需要注意的是hdfs-site.xml 配置文件中的heartbeat.recheck.interval的单位为毫秒，dfs.heartbeat.interval的单位为秒。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.namenode.heartbeat.recheck-interval&lt;/name&gt;</div><div class="line">    &lt;value&gt;300000&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt; dfs.heartbeat.interval &lt;/name&gt;</div><div class="line">    &lt;value&gt;3&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
<h2 id="6-4-DataNode的目录结构"><a href="#6-4-DataNode的目录结构" class="headerlink" title="6.4 DataNode的目录结构"></a>6.4 DataNode的目录结构</h2><p>和namenode不同的是，datanode的存储目录是初始阶段自动创建的，不需要额外格式化。</p>
<p>1）在/opt/module/hadoop-2.7.2/data/tmp/dfs/data/current这个目录下查看版本号</p>
<p>[kingge@hadoop102 current]$ cat VERSION </p>
<p>storageID=DS-1b998a1d-71a3-43d5-82dc-c0ff3294921b</p>
<p>clusterID=CID-1f2bf8d1-5ad2-4202-af1c-6713ab381175</p>
<p>cTime=0</p>
<p>datanodeUuid=970b2daf-63b8-4e17-a514-d81741392165</p>
<p>storageType=DATA_NODE</p>
<p>layoutVersion=-56</p>
<p>2）具体解释</p>
<p>​         （1）storageID：存储id号</p>
<p>​         （2）clusterID集群id，全局唯一</p>
<p>​         （3）cTime属性标记了datanode存储系统的创建时间，对于刚刚格式化的存储系统，这个属性为0；但是在文件系统升级之后，该值会更新到新的时间戳。</p>
<p>​         （4）datanodeUuid：datanode的唯一识别码</p>
<p>​         （5）storageType：存储类型</p>
<p>​         （6）layoutVersion是一个负整数。通常只有HDFS增加新特性时才会更新这个版本号。</p>
<p>3）在/opt/module/hadoop-2.7.2/data/tmp/dfs/data/current/BP-97847618-192.168.10.102-1493726072779/current这个目录下查看该数据块的版本号</p>
<p>[kingge@hadoop102 current]$ cat VERSION </p>
<p>#Mon May 08 16:30:19 CST 2017</p>
<p>namespaceID=1933630176</p>
<p>cTime=0</p>
<p>blockpoolID=BP-97847618-192.168.10.102-1493726072779</p>
<p>layoutVersion=-56</p>
<p>4）具体解释</p>
<p>（1）namespaceID：是datanode首次访问namenode的时候从namenode处获取的storageID对每个datanode来说是唯一的（但对于单个datanode中所有存储目录来说则是相同的），namenode可用这个属性来区分不同datanode。</p>
<p>（2）cTime属性标记了datanode存储系统的创建时间，对于刚刚格式化的存储系统，这个属性为0；但是在文件系统升级之后，该值会更新到新的时间戳。</p>
<p>（3）blockpoolID：一个block pool id标识一个block pool，并且是跨集群的全局唯一。当一个新的Namespace被创建的时候(format过程的一部分)会创建并持久化一个唯一ID。在创建过程构建全局唯一的BlockPoolID比人为的配置更可靠一些。NN将BlockPoolID持久化到磁盘中，在后续的启动过程中，会再次load并使用。</p>
<p>（4）layoutVersion是一个负整数。通常只有HDFS增加新特性时才会更新这个版本号。</p>
<h2 id="6-5-服役新数据节点"><a href="#6-5-服役新数据节点" class="headerlink" title="6.5 服役新数据节点"></a>6.5 服役新数据节点</h2><p>0）需求：</p>
<p>随着公司业务的增长，数据量越来越大，原有的数据节点的容量已经不能满足存储数据的需求，需要在原有集群基础上动态添加新的数据节点。</p>
<p>1）环境准备</p>
<p>​         （1）克隆一台虚拟机</p>
<p>​         （2）修改ip地址和主机名称</p>
<p>​         （3）修改xcall和xsync文件，增加新`增节点的同步ssh</p>
<p>​         （4）删除原来HDFS文件系统留存的文件</p>
<p>​                 /opt/module/hadoop-2.7.2/data 和 /opt/module/hadoop-2.7.2/log目录</p>
<p>2）服役新节点具体步骤（<strong>下面的操作建议在namenode所在节点进行操作</strong>）</p>
<p>​         （1）在<strong>namenode</strong>的/opt/module/hadoop-2.7.2/etc/hadoop目录下创建dfs.hosts文件</p>
<p>[kingge@hadoop105 hadoop]$ pwd</p>
<p>/opt/module/hadoop-2.7.2/etc/hadoop</p>
<p>[kingge@hadoop105 hadoop]$ touch dfs.hosts （<strong>名字任意</strong>）</p>
<p>[kingge@hadoop105 hadoop]$ vi dfs.hosts</p>
<p>添加如下主机名称（包含新服役的节点）</p>
<p>hadoop102</p>
<p>hadoop103</p>
<p>hadoop104</p>
<p>hadoop105</p>
<p>​         （2）在namenode的hdfs-site.xml配置文件中增加dfs.hosts属性</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">&lt;name&gt;dfs.hosts&lt;/name&gt;</div><div class="line">      &lt;value&gt;/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
<p>​         （3）刷新namenode </p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -refreshNodes</p>
<p>Refresh nodes successful</p>
<p>​         （4）更新resourcemanager节点</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ yarn rmadmin -refreshNodes</p>
<p>17/06/24 14:17:11 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.1.103:8033</p>
<p><strong>操作完后，打开**</strong>hdfs<strong><strong>文件系统，发现已经服役了一个新的</strong></strong>data<strong>**节点</strong></p>
<p><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/560171043334.png" alt="1560171043334"></p>
<p>​         （5）在namenode的slaves文件中增加新主机名称</p>
<p>​                 增加105  不需要分发</p>
<p>hadoop102</p>
<p>hadoop103</p>
<p>hadoop104</p>
<p>hadoop105</p>
<p>​         （6）单独命令启动新的数据节点和节点管理器</p>
<p>[kingge@hadoop105 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start datanode</p>
<p>starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-kingge-datanode-hadoop105.out</p>
<p>[kingge@hadoop105 hadoop-2.7.2]$ sbin/yarn-daemon.sh start nodemanager</p>
<p>starting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-kingge-nodemanager-hadoop105.out</p>
<p>​         （7）在web浏览器上检查是否ok</p>
<p>3）如果数据不均衡，可以用命令实现集群的再平衡</p>
<p>​         [kingge@hadoop102 sbin]$ ./start-balancer.sh</p>
<p>starting balancer, logging to /opt/module/hadoop-2.7.2/logs/hadoop-kingge-balancer-hadoop102.out</p>
<p>Time Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved</p>
<h2 id="6-6-退役旧数据节点"><a href="#6-6-退役旧数据节点" class="headerlink" title="6.6 退役旧数据节点"></a>6.6 退役旧数据节点</h2><p>1）在namenode的/opt/module/hadoop-2.7.2/etc/hadoop目录下创建dfs.hosts.exclude文件</p>
<p>​         [kingge@hadoop102 hadoop]$ pwd</p>
<p>/opt/module/hadoop-2.7.2/etc/hadoop</p>
<p>[kingge@hadoop102 hadoop]$ touch dfs.hosts.exclude</p>
<p>[kingge@hadoop102 hadoop]$ vi dfs.hosts.exclude</p>
<p>添加如下主机名称（要退役的节点）</p>
<p>hadoop105</p>
<p>2）在namenode的hdfs-site.xml配置文件中增加dfs.hosts.exclude属性</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">&lt;name&gt;dfs.hosts.exclude&lt;/name&gt;</div><div class="line">      &lt;value&gt;/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts.exclude&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
<p>3）刷新namenode、刷新resourcemanager</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -refreshNodes</p>
<p>Refresh nodes successful</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ yarn rmadmin -refreshNodes</p>
<p>17/06/24 14:55:56 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.1.103:8033</p>
<p>4）检查web浏览器，退役节点的状态为decommission in progress（退役中），说明数据节点正在复制块到其他节点。</p>
<p><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/1560171084624.png" alt="1560171084624"></p>
<p>5）等待退役节点状态为decommissioned（所有块已经复制完成），停止该节点及节点资源管理器。注意：如果副本数是3，服役的节点小于等于3，是不能退役成功的，需要修改副本数后才能退役。·</p>
<p><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/560171100904.png" alt="1560171100904"></p>
<p>[kingge@hadoop105 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop datanode</p>
<p>stopping datanode</p>
<p>[kingge@hadoop105 hadoop-2.7.2]$ sbin/yarn-daemon.sh stop nodemanager</p>
<p>stopping nodemanager</p>
<p>6）从include文件中删除退役节点，再运行刷新节点的命令</p>
<p>​         （1）从namenode的dfs.hosts文件中删除退役节点hadoop105</p>
<p>hadoop102</p>
<p>hadoop103</p>
<p>hadoop104</p>
<p>​         （2）刷新namenode，刷新resourcemanager</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -refreshNodes</p>
<p>Refresh nodes successful</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ yarn rmadmin -refreshNodes</p>
<p>17/06/24 14:55:56 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.1.103:8033</p>
<p>7）从namenode的slave文件中删除退役节点hadoop105</p>
<p>hadoop102</p>
<p>hadoop103</p>
<p>hadoop104</p>
<p>8）如果数据不均衡，可以用命令实现集群的再平衡</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ sbin/start-balancer.sh </p>
<p>starting balancer, logging to /opt/module/hadoop-2.7.2/logs/hadoop-kingge-balancer-hadoop102.out</p>
<p>Time Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved</p>
<h2 id="6-7-Datanode多目录配置"><a href="#6-7-Datanode多目录配置" class="headerlink" title="6.7 Datanode多目录配置"></a>6.7 Datanode多目录配置</h2><p>1）datanode也可以配置成多个目录，<strong>每个目录存储的数据不一样，即是上传一个文本，那么文本存储在data，但是data2什么都没有（跟namenode多目录区别）</strong>。即：数据不是副本。</p>
<p>2）具体配置如下：</p>
<p>​         hdfs-site.xml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</div><div class="line">        &lt;value&gt;file:///$&#123;hadoop.tmp.dir&#125;/dfs/data1,file:///$&#123;hadoop.tmp.dir&#125;/dfs/data2&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
<h1 id="七-HDFS其他功能"><a href="#七-HDFS其他功能" class="headerlink" title="七 HDFS其他功能"></a>七 HDFS其他功能</h1><h2 id="7-1-集群间数据拷贝"><a href="#7-1-集群间数据拷贝" class="headerlink" title="7.1 集群间数据拷贝"></a>7.1 集群间数据拷贝</h2><p>1）scp实现两个远程主机之间的文件复制</p>
<p>​         scp -r hello.txt <a href="mailto:root@hadoop103:/user/kingge/hello.txt" target="_blank" rel="external">root@hadoop103:/user/kingge/hello.txt</a>                 // 推 push</p>
<p>​         scp -r <a href="mailto:root@hadoop103:/user/kingge/hello.txt%20%20hello.txt" target="_blank" rel="external">root@hadoop103:/user/kingge/hello.txt  hello.txt</a>             // 拉 pull</p>
<p>​         scp -r <a href="mailto:root@hadoop103:/user/kingge/hello.txt" target="_blank" rel="external">root@hadoop103:/user/kingge/hello.txt</a> root@hadoop104:/user/kingge   //是通过本地主机中转实现两个远程主机的文件复制；如果在两个远程主机之间ssh没有配置的情况下可以使用该方式。</p>
<p>2）采用discp命令实现两个hadoop集群之间的递归数据复制</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$  bin/hadoop distcp hdfs://haoop102:9000/user/kingge/hello.txt hdfs://hadoop103:9000/user/kingge/hello.txt</p>
<h2 id="7-2-Hadoop存档"><a href="#7-2-Hadoop存档" class="headerlink" title="7.2 Hadoop存档"></a>7.2 Hadoop存档</h2><p>1）理论概述</p>
<p>每个文件均按块存储，每个块的元数据存储在namenode的内存中，因此hadoop存储小文件会非常低效。因为大量的小文件会耗尽namenode中的大部分内存。但注意，存储小文件所需要的磁盘容量和存储这些文件原始内容所需要的磁盘空间相比也不会增多。例如，一个1MB的文件以大小为128MB的块存储，使用的是1MB的磁盘空间，而不是128MB。</p>
<p>Hadoop存档文件或HAR文件，是一个更高效的文件存档工具，它将文件存入HDFS块，在减少namenode内存使用的同时，允许对文件进行透明的访问。具体说来，Hadoop存档文件可以用作MapReduce的输入。</p>
<p>2）案例实操</p>
<p>（1）需要启动yarn进程</p>
<p>​         [kingge@hadoop102 hadoop-2.7.2]$ start-yarn.sh</p>
<p>（2）归档文件</p>
<p>​         归档成一个叫做xxx.har的文件夹，该文件夹下有相应的数据文件。Xx.har目录是一个整体，该目录看成是一个归档文件即可。</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ bin/hadoop archive -archiveName myhar.har -p /user/kingge   /user/my</p>
<p>（3）查看归档</p>
<p>​         [kingge@hadoop102 hadoop-2.7.2]$ hadoop fs -lsr /user/my/myhar.har</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hadoop fs -lsr har:///myhar.har</p>
<p>（4）解归档文件</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hadoop fs -cp har:/// user/my/myhar.har /* /user/kingge</p>
<h2 id="7-3-快照管理"><a href="#7-3-快照管理" class="headerlink" title="7.3 快照管理"></a>7.3 快照管理</h2><p>快照相当于对目录做一个备份。并不会立即复制所有文件，而是指向同一个文件。当写入发生时，才会产生新文件。</p>
<p>1）基本语法</p>
<p>​         （1）hdfs dfsadmin -allowSnapshot 路径   （功能描述：开启指定目录的快照功能）</p>
<p>​         （2）hdfs dfsadmin -disallowSnapshot 路径 （功能描述：禁用指定目录的快照功能，默认是禁用）</p>
<p>​         （3）hdfs dfs -createSnapshot 路径        （功能描述：对目录创建快照）</p>
<p>​         （4）hdfs dfs -createSnapshot 路径 名称   （功能描述：指定名称创建快照）</p>
<p>​         （5）hdfs dfs -renameSnapshot 路径 旧名称 新名称 （功能描述：重命名快照）</p>
<p>​         （6）hdfs lsSnapshottableDir         （功能描述：列出当前用户所有可快照目录）</p>
<p>​         （7）hdfs snapshotDiff 路径1 路径2 （功能描述：比较两个快照目录的不同之处）</p>
<p>​         （8）hdfs dfs -deleteSnapshot <path></path> <snapshotname>  （功能描述：删除快照）</snapshotname></p>
<p>2）案例实操</p>
<p>​         （1）开启/禁用指定目录的快照功能</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -allowSnapshot /user/kingge/data</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -disallowSnapshot /user/kingge/data</p>
<p>​         （2）对目录创建快照</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hdfs dfs -createSnapshot /user/kingge/data      </p>
<p>通过web访问hdfs://hadoop102:9000/user/kingge/data/.snapshot/s…..// 快照和源文件使用相同数据块</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hdfs dfs -lsr /user/kingge/data/.snapshot/</p>
<p>​         （3）指定名称创建快照</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hdfs dfs -createSnapshot /user/kingge/data miao170508</p>
<p>​         （4）重命名快照</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hdfs dfs -renameSnapshot /user/kingge/data/ miao170508 kingge170508</p>
<p>​         （5）列出当前用户所有可快照目录</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hdfs lsSnapshottableDir</p>
<p>​         （6）比较两个快照目录的不同之处</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hdfs snapshotDiff /user/kingge/data/  .  .snapshot/kingge170508 </p>
<p>​         （7）恢复快照</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hdfs dfs -cp /user/kingge/input/.snapshot/s20170708-134303.027 /user</p>
<h2 id="7-4-回收站"><a href="#7-4-回收站" class="headerlink" title="7.4 回收站"></a>7.4 回收站</h2><p>1）默认回收站</p>
<p>默认值fs.trash.interval=0，0表示禁用回收站，可以设置删除文件的存活时间。</p>
<p>默认值fs.trash.checkpoint.interval=0，检查回收站的间隔时间。</p>
<p>要求fs.trash.checkpoint.interval&lt;=fs.trash.interval。</p>
<p><img src="/2018/03/10/hadoop大数据-七-HDFS的Namenode和Datanode/60171183235.png" alt="1560171183235"></p>
<p>2）启用回收站</p>
<p>修改core-site.xml，配置垃圾回收时间为1分钟。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;fs.trash.interval&lt;/name&gt;</div><div class="line">    &lt;value&gt;1&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
<p>3）查看回收站</p>
<p>回收站在集群中的；路径：/user/kingge/.Trash/….</p>
<p>4）修改访问垃圾回收站用户名称(<strong>如果不修改为想要查看该回收站的用户的名称，那么该用户试图进入回收站时会提示权限问题</strong>)</p>
<p>​         进入垃圾回收站用户名称，默认是dr.who，修改为kingge用户</p>
<p>​         [core-site.xml]</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;</div><div class="line">  &lt;value&gt;kingge&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
<p>5）通过程序删除的文件不会经过回收站，需要调用moveToTrash()才进入回收站</p>
<p>Trash trash = New Trash(conf);</p>
<p>trash.moveToTrash(path);</p>
<p>6）恢复回收站数据</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hadoop fs -mv /user/kingge/.Trash/Current/user/kingge/input    /user/kingge/input</p>
<p>7）清空回收站（<strong>他并不是真正删除文件，而是生成一个当前时间戳的文件夹然后把回收站里面的文件都放到这个文件夹里面</strong>）</p>
<p>[kingge@hadoop102 hadoop-2.7.2]$ hdfs dfs -expunge</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;五-NameNode工作机制&quot;&gt;&lt;a href=&quot;#五-NameNode工作机制&quot; class=&quot;headerlink&quot; title=&quot;五 NameNode工作机制&quot;&gt;&lt;/a&gt;五 NameNode工作机制&lt;/h1&gt;&lt;h2 id=&quot;5-1-NameNode-amp-
    
    </summary>
    
      <category term="hadoop" scheme="http://kingge.top/categories/hadoop/"/>
    
    
      <category term="hadoop" scheme="http://kingge.top/tags/hadoop/"/>
    
      <category term="大数据" scheme="http://kingge.top/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="HDFS" scheme="http://kingge.top/tags/HDFS/"/>
    
  </entry>
  
</feed>
